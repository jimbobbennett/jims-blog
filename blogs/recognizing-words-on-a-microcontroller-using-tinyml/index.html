<!doctype html><html><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><link rel=icon href=/fav.png type=image/png><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Alata&family=Lora&family=Muli:ital,wght@0,400;0,500;0,600;0,700;1,400;1,500;1,600;1,700&family=Roboto&family=Muli:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Alata&family=Lora&family=Muli:ital,wght@0,400;0,500;0,600;0,700;1,400;1,500;1,600;1,700&family=Roboto&family=Muli:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" media=print onload='this.media="all"'><noscript><link href="https://fonts.googleapis.com/css2?family=Alata&family=Lora&family=Muli:ital,wght@0,400;0,500;0,600;0,700;1,400;1,500;1,600;1,700&family=Roboto&family=Muli:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" rel=stylesheet></noscript><link rel=stylesheet href=/css/font.css media=all><meta property="og:title" content="Recognizing words on a microcontroller using TinyML"><meta property="og:description" content="Learn how to train a TinyML word recognizer to run on a microcontroller using Azure ML Studio and the Adafruit EdgeBadge."><meta property="og:type" content="article"><meta property="og:url" content="https://jimbobbennett.dev/blogs/recognizing-words-on-a-microcontroller-using-tinyml/"><meta property="og:image" content="https://jimbobbennett.dev/blogs/recognizing-words-on-a-microcontroller-using-tinyml/banner.png"><meta property="article:section" content="blogs"><meta property="article:published_time" content="2020-04-21T18:00:00+00:00"><meta property="article:modified_time" content="2020-04-21T18:00:00+00:00"><meta property="og:site_name" content="JimBobBennett"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://jimbobbennett.dev/blogs/recognizing-words-on-a-microcontroller-using-tinyml/banner.png"><meta name=twitter:title content="Recognizing words on a microcontroller using TinyML"><meta name=twitter:description content="Learn how to train a TinyML word recognizer to run on a microcontroller using Azure ML Studio and the Adafruit EdgeBadge."><meta name=twitter:site content="@jimbobbennett"><meta name=twitter:creator content="@jimbobbennett"><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css integrity=sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3 crossorigin=anonymous><link rel=stylesheet href=/css/header.css media=all><link rel=stylesheet href=/css/footer.css media=all><link rel=stylesheet href=/css/theme.css media=all><link rel="shortcut icon" type=image/png href=/fav.png><link rel="shortcut icon" sizes=192x192 href=/fav.png><link rel=apple-touch-icon href=/fav.png><link rel=alternate type=application/rss+xml href=https://jimbobbennett.dev/index.xml title=JimBobBennett><script type=text/javascript>(function(e,t,n,s,o,i,a){e[n]=e[n]||function(){(e[n].q=e[n].q||[]).push(arguments)},i=t.createElement(s),i.async=1,i.src="https://www.clarity.ms/tag/"+o,a=t.getElementsByTagName(s)[0],a.parentNode.insertBefore(i,a)})(window,document,"clarity","script","dctc2ydykv")</script><script data-goatcounter=https://jimbobbennett.goatcounter.com/count async src=//gc.zgo.at/count.js></script><style>:root{--text-color:#343a40;--text-secondary-color:#6c757d;--background-color:#000;--secondary-background-color:#64ffda1a;--primary-color:#007bff;--secondary-color:#f8f9fa;--text-color-dark:#e4e6eb;--text-secondary-color-dark:#b0b3b8;--background-color-dark:#000000;--secondary-background-color-dark:#212529;--primary-color-dark:#ffffff;--secondary-color-dark:#212529}body{background-color:#000;font-size:1rem;font-weight:400;line-height:1.5;text-align:left}</style><meta name=description content><link rel=stylesheet href=/css/index.css><link rel=stylesheet href=/css/single.css><link rel=stylesheet href=/css/projects.css media=all><script defer src=/fontawesome-5/all-5.15.4.js></script><title>Recognizing words on a microcontroller using TinyML | JimBobBennett</title></head><body class=light onload=loading()><header><nav class="pt-3 navbar navbar-expand-lg"><div class="container-fluid mx-xs-2 mx-sm-5 mx-md-5 mx-lg-5"><a class="navbar-brand primary-font text-wrap" href=/><img src=/fav.png width=30 height=30 class="d-inline-block align-top">
JimBobBennett
</a><button class=navbar-toggler type=button data-bs-toggle=collapse data-bs-target=#navbarContent aria-controls=navbarContent aria-expanded=false aria-label="Toggle navigation"><svg aria-hidden="true" height="24" viewBox="0 0 16 16" width="24" data-view-component="true"><path fill-rule="evenodd" d="M1 2.75A.75.75.0 011.75 2h12.5a.75.75.0 110 1.5H1.75A.75.75.0 011 2.75zm0 5A.75.75.0 011.75 7h12.5a.75.75.0 110 1.5H1.75A.75.75.0 011 7.75zM1.75 12a.75.75.0 100 1.5h12.5a.75.75.0 100-1.5H1.75z"/></svg></button><div class="collapse navbar-collapse text-wrap primary-font" id=navbarContent><ul class="navbar-nav ms-auto text-center"><li class="nav-item navbar-text"><a class=nav-link href=/ aria-label=home>Home</a></li><li class="nav-item navbar-text"><a class=nav-link href=/#about aria-label=about>About</a></li><li class="nav-item navbar-text"><a class=nav-link href=/#projects aria-label=projects>Recent Highlights</a></li><li class="nav-item navbar-text"><a class=nav-link href=/blogs title="Blog posts">Blog</a></li><li class="nav-item navbar-text"><a class=nav-link href=/videos title=Videos>Videos</a></li><li class="nav-item navbar-text"><a class=nav-link href=/livestreams title=Livestreams>Livestreams</a></li><li class="nav-item navbar-text"><a class=nav-link href=/conferences title=Conferences>Conferences</a></li><li class="nav-item navbar-text"><a class=nav-link href=/resume title=Resume>Resume</a></li></ul></div></div></nav></header><div id=content><section id=projects><div class="container pt-5" id=list-page><div class="row justify-content-center px-3 px-md-5"><h1 class="text-left pb-2 content">Recognizing words on a microcontroller using TinyML</h1><div class="text-left content"><a href=https://linkedin.com/in/jimbobbennett>Jim Bennett
</a><small>|</small>
Apr 21, 2020</div></div></div></section><section id=single><div class=container><div class="row justify-content-center"><div class="col-sm-12 col-md-12 col-lg-9"><div class=pr-lg-4><article class="page-content p-2"><p>AI has traditionally been the realm of expensive computers, with models trained and run on GPUs and other expensive hardware. More recently this has started to change with a move towards TinyML - small machine learning models that are trained on the expensive hardware, but run on smaller, cheaper devices including the low power micro-controllers that run IoT and maker devices.</p><p>Adafruit have recently released a device to run TinyML models on called the <a href=https://www.adafruit.com/product/4400>EdgeBadge</a>.</p><p><img src=https://cdn-shop.adafruit.com/970x728/4400-15.jpg alt="The Adafruit Edgebadge"></p><p>This device is based off their PyBadge device - a board with a screen, game style controllers, NeoPixel LEDs and connectors so you can wear it on a lanyard. The difference with the EdgeBadge is it has a built in microphone so you can use it for audio recognition. The product page has links to a demo you can run that recognizes two words, yes or no, and displays an image on screen when the words are detected.</p><p>You can find the demo on <a href=https://learn.adafruit.com/tensorflow-lite-for-edgebadge-kit-quickstart>Adafruit Learn</a>.</p><p>I thought it would be fun to repurpose this example and learn how to retrain the board to recognize &lsquo;Stop&rsquo; and &lsquo;Go&rsquo; instead of yes and no.</p><h2 id=train-the-model>Train the model</h2><p>The yes/no detection model is a TensorFlow model, created using an example from the TensorFlow GitHub repository. The model is trained using a huge file of recordings of people saying a number of different words. Once the model has been trained, it is then shrunk down to run on tiny devices such as micro-controllers, and weighs in at only a few kilobytes.</p><p>You can find the original TensorFlow example in the <a href=https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/audio_recognition.md>TensorFlow GitHub repo</a>.</p><p>I trained my new model using the <a href="https://azure.microsoft.com/services/machine-learning/#product-overview/?WT.mc_id=aiapril-blog-jabenn">Azure Machine Learning Studio</a>, a service that allows you to build and train models using cloud compute, then either host them in the cloud or download them for use offline.</p><h3 id=create-an-azure-account>Create an Azure account</h3><p>To use Azure services you will need an Azure subscription. If you don&rsquo;t have a subscription you can sign up for free.</p><ul><li><p>If you are a student aged 18 and up and have an email address from an academic institution, you can sign up for the free Azure for Students offer at <a href="https://azure.microsoft.com/free/students/?WT.mc_id=aiapril-blog-jabenn">azure.microsoft.com/free/students</a> without a credit card. At the time of writing this gives you $100 of credit to use over 12 months, as well as free tiers of a number of services for that 2 months. At the end of the 12 months, if you are still a student you can renew and get another $100 in credit and 12 months of free services.</p></li><li><p>If you are not a student, you can sign up at <a href="https://azure.microsoft.com/free/?WT.mc_id=aiapril-blog-jabenn">azure.microsoft.com/free</a>. You will need a credit card for verification purposes only, you will not be billed unless you decide to upgrade your account to a paid offering. At the time of writing the free account will give you US$200 of free credit to spend on what you like in the first 30 days, 12 months of free services, plus a load of services that have tiers that are always free.</p></li></ul><h3 id=create-a-machine-learning-resource>Create a Machine Learning resource</h3><p>Before you can use the Azure Machine Learning (ML) Studio, you need to spin up a Machine Learning resource. This is created in your Azure subscription but then can be shared with other developers so that you can all share the same ML Studio workspace.</p><ol><li><p>Open the <a href="https://portal.azure.com/?WT.mc_id=aiapril-blog-jabenn">Azure portal</a></p></li><li><p>Select <strong>Create a resource</strong> then search for <code>Machine Learning</code>. Select <strong>Machine Learning</strong> then select <strong>Create</strong>.</p><p><img src=https://raw.githubusercontent.com/jimbobbennett/EdgeBadge-WordRecogniser/master/images/CreateMLResource.png alt="The Machine Learning resource"></p></li><li><p>Give the workspace a name and select your Azure subscription.</p></li><li><p>Create a new resource group for this service.</p><blockquote><p>Resource groups are logic groupings of services, so it is good practice to put all the resources for one project in a single resource group so that you can manage them together. When you create a Machine Learning resource it will create a few different services, so having them in the same resource group means you can delete them all together by deleting the resource group.</p></blockquote></li><li><p>Select the location nearest to you. For the workspace edition, select <strong>Basic</strong>. This price tier of the core service is free to use, you only pay for the compute used to train or run models.</p></li><li><p>Select <strong>Review + Create</strong>, then select <strong>Create</strong></p></li></ol><p>The resource will be created.</p><h3 id=set-up-ml-studio>Set up ML Studio</h3><p>Now that the Machine Learning resource has been created, you can use it from ML Studio.</p><ol><li><p>Open ML Studio at <a href="https://ml.azure.com/?WT.mc_id=aiapril-blog-jabenn">ml.azure.com</a></p></li><li><p>Log in with your Azure account, then select your directory, subscription and the workspace you just created</p></li><li><p>Select <strong>Get started</strong></p></li></ol><p>ML Studio will log in to your workspace. From here you can run Machine Learning workloads using Jupyter notebooks, AutoML to create models for you based off data sets, or a drag and drop designer.</p><h3 id=set-up-compute>Set up compute</h3><p>The TensorFlow example uses a Jupyter notebook to train the model. For this, I used a slightly tweaked version of the notebook, tweaked to fix some versioning issues and use the power of ML Studio.</p><p>To run a notebook, you need compute - a machine allocated to run the training. This compute is paid for based on the time it&rsquo;s running and the power of the machine, the more powerful, the more you pay per minute.</p><blockquote><p>You can see the pricing per hour on the <a href="https://azure.microsoft.com/pricing/details/machine-learning/?WT.mc_id=aiapril-blog-jabenn">Machine Learning pricing page</a></p></blockquote><ol><li><p>Select <strong>Compute</strong> from the left-hand menu</p></li><li><p>Select <strong>+ New</strong></p></li><li><p>Give the compute a name</p></li><li><p>Drop down the <em>Virtual Machine Size</em> box, and select <strong>GPU</strong> to list the GPU-based compute options. Select the <strong>Standard_NC12</strong> machine - this has 2 GPUs and is enough to train this model in an hour and a half or so. At the time of writing the cost is US$1.80 per hour when running in the US.</p></li><li><p>Select <strong>Create</strong></p></li></ol><p>The compute will be created a spun up.</p><h3 id=upload-the-notebook>Upload the notebook</h3><p>You can find the notebook in the Releases in this GitHub repository. Use this link to download the notebook:</p><p><a href=https://github.com/jimbobbennett/EdgeBadge-WordRecogniser/releases/download/v1.0/word-recognizer-training.ipynb>word-recognizer-training.ipynb</a>.</p><p>Once you&rsquo;ve downloaded the notebook, you need to upload it to ML Studio.</p><ol><li><p>Select <strong>Notebooks</strong> from the left-hand menu</p></li><li><p>Select <strong>Upload files</strong></p></li><li><p>Find the notebook you&rsquo;ve just downloaded, and select it</p></li></ol><p>The notebook will be uploaded and available to run. You will see it in a file tree on the left hand side of the <strong>Notebooks</strong> blade.</p><ol><li><p>Select the notebook and it will open up in read only mode</p></li><li><p>Select the compute you created in the menu at the top</p></li><li><p>Select <strong>Edit -> Edit in Jupyter</strong> top open the notebook in Jupyter notebooks. You will need to sign in to your Azure account again.</p></li></ol><p>The notebook has a number of sections, each documented so read the notebook to see what each section does. A basic overview is:</p><ol><li><p>Create some environment variables to define the words to train for and the number of training iterations.</p></li><li><p>Install a specific version of TensorFlow GPU to ensure the training uses the GPU, and uses a version that the example training script was written for</p><blockquote><p>The training script will only work against TensorFlow 1.5.x, don&rsquo;t update the notebook to a later version otherwise the training will fail</p></blockquote></li><li><p>Clone the TensorFlow repository to get access to the training script</p></li><li><p>Run the training, then freeze the created TensorFlow graph to save down the weights</p></li><li><p>Convert the model to TensorFlow light to make it smaller, then save it out as binary data in a C code file so that it can be used from code.</p></li></ol><p>From the Jupyter notebooks:</p><ol><li><p>The first cell defines the words the model should be trained for.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># A comma-delimited list of the words you want to train for.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># All other words will be used to train an &#34;unknown&#34; category.</span>
</span></span><span style=display:flex><span>os<span style=color:#f92672>.</span>environ[<span style=color:#e6db74>&#34;WANTED_WORDS&#34;</span>] <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;stop,go&#34;</span>
</span></span></code></pre></div><p>The data set supports the following words:</p><table><thead><tr><th></th><th></th><th></th><th></th></tr></thead><tbody><tr><td>Yes</td><td>No</td><td>Up</td><td>Down</td></tr><tr><td>Left</td><td>Right</td><td>On</td><td>Off</td></tr><tr><td>Stop</td><td>Go</td><td>Zero</td><td>One</td></tr><tr><td>Two</td><td>Three</td><td>Four</td><td>Five</td></tr><tr><td>Six</td><td>Seven</td><td>Eight</td><td>Nine</td></tr></tbody></table><p>The notebook is set to train for &lsquo;Stop&rsquo; and &lsquo;Go&rsquo;, but if you want to change the words it is trained for, change the array.</p></li><li><p>Select <strong>Run</strong> from the top menu for each cell to run them one at a time, or select <strong>Cell -> Run All</strong> to run all the cells. The training step will take 1.5-2 hours to run.</p></li><li><p>Once the steps have all finished, head back to ML Studio, select <strong>Compute</strong> from the left-hand menu, check the box next to your compute and select <strong>Stop</strong> to stop the compute.</p></li><li><p>Select <strong>Notebooks</strong> from the left-hand menu. Expand the <em>Content</em> node above the notebook in the file explorer, and select the <code>tiny_conv.cc</code> file. This is the C code for the resulting model.</p></li></ol><blockquote><p>Don&rsquo;t forget to stop the compute once the model is trained! You pay for the time that the compute is running, not the time that the notebooks are running, so to avoid unnecessary costs, remember to stop the compute as soon as you are finished, then restart it if you want to train the model again.</p></blockquote><h2 id=compile-the-code-for-the-edgebadge>Compile the code for the EdgeBadge</h2><p>Now that the model is created, it can be compiled into the sample app for the EdgeBadge.</p><h3 id=set-up-the-development-environment>Set up the development environment</h3><p>It takes a bit of setup to be able to program Adafruit devices using C++. The Arduino IDE is the main tool for programming them, but I personally like to use Visual Studio Code as an IDE, and the Arduino extension to allow Visual Studio Code to control Arduino to program the boards.</p><h4 id=install-the-tools>Install the tools</h4><ol><li><p>Install <a href="https://code.visualstudio.com/Download/?WT.mc_id=aiapril-blog-jabenn">Visual Studio Code</a></p></li><li><p>Install the <a href=https://www.arduino.cc/en/Main/Software>Arduino IDE</a> - <strong>NOTE</strong> On Windows DO NOT install using the Windows store, instead use the <em>Windows Installer, for Windows XP and up</em>.</p></li><li><p>Inside Visual Studio Code, select the <strong>Extensions</strong> tab from the left hand side, and search for an install the <em>Arduino</em> extension. Make sure to install the one from Microsoft as there is more than one extension called <em>Arduino</em>.</p></li></ol><h4 id=configure-the-arduino-ide-and-visual-studio-code-for-adafruit-development>Configure the Arduino IDE and Visual Studio Code for Adafruit development</h4><p>To talk to Adafruit boards, the Arduino IDE needs to be configured to know how to send the compiled code.</p><ol><li><p>Follow the instructions on the Adafruit site to configure the Arduino IDE for Adafruit boards: <a href=https://learn.adafruit.com/adafruit-pybadge/using-with-arduino-ide>learn.adafruit.com/adafruit-pybadge/using-with-arduino-ide</a></p></li><li><p>From Visual Studio Code launch the command palette, then select <em>Arduino: Library manager</em>. From here you can install some additional libraries that are needed to compile the code.</p></li><li><p>Search for and install the following libraries:</p><ol><li>Adafruit EPD</li><li>Adafruit TinyUSB Library</li><li>Adafruit WavePlayer Library</li><li>Adafruit SPIFlash</li><li>Adafruit ImageReader Library</li><li>Adafruit ST7735_and_ST7789 Library</li><li>Adafruit Unified_Sensor</li><li>Adafruit LIS3DH</li><li>Adafruit TouchScreen</li><li>Adafruit NeoPixel</li><li>Adafruit GFX Library</li><li>Adafruit Arcada Library</li><li>Adafruit Zero_PDM Library</li><li>Adafruit ZeroTimer Library</li><li>Adafruit TensorFlow Lite</li><li>Arduino TensorFlowLite</li><li>SdFat - Adafruit Fork (make sure to install the Adafruit fork, not the original SdFat)</li></ol></li></ol><h4 id=configure-the-board>Configure the board</h4><ol><li><p>Connect your EdgeBadge to your computer via USB and make sure the device is switched on</p></li><li><p>From the command palette, select <em>Arduino: Board Configuration</em></p></li><li><p>Select the following settings:</p><table><thead><tr><th>Setting</th><th>Value</th></tr></thead><tbody><tr><td>Selected board</td><td>Adafruit pyBadge M4 Express (SAMD51)</td></tr><tr><td>Cache</td><td>Enabled</td></tr><tr><td>CPU Speed</td><td>180 MHz (overclock)</td></tr><tr><td>Optimize</td><td>Fastest (-Ofast)</td></tr><tr><td>Max QSPI</td><td>50 MHz (standard)</td></tr><tr><td>USB Stack</td><td>TinyUSB</td></tr><tr><td>Debug</td><td>Off</td></tr></tbody></table></li><li><p>From the command palette, select <em>Arduino: Select serial port</em> and select the port the EdgeBadge is plugged into. On macOS it will be named something like <code>/dev/cu.usbmodem&lt;xxx></code> where <code>&lt;xxx></code> is a number. On Windows it will be called <code>COM&lt;x></code> where <code>&lt;x></code> is a number.</p></li></ol><h3 id=compile-the-code>Compile the code</h3><p>The code for the edge badge is in the <code>word_recognizer</code> folder in <a href=https://github.com/jimbobbennett/EdgeBadge-WordRecogniser>this GitHub repo</a>. Clone the repo and open the <code>word_recognizer</code> folder in Visual Studio Code.</p><p>The code contains images and a model that can recognize two words, &lsquo;Stop&rsquo; and &lsquo;Go&rsquo;.</p><ol><li><p>Double tap the <strong>Reset</strong> button on the back of the EdgeBadge to put it into the boot loader ready to program</p><p><img src=https://raw.githubusercontent.com/jimbobbennett/EdgeBadge-WordRecogniser/master/images/BootLoader.png alt="EdgeBadge in bootloader mode"></p></li><li><p>From the command palette, select <em>Arduino: Upload</em>. The code will be compiled and uploaded to the board.</p></li><li><p>Once the device reboots, say the words &lsquo;Stop&rsquo; and &lsquo;Go&rsquo;, and the board will show an image for the word you have said.</p></li></ol><p>Select the image below to see a video of this in action.</p><p><a href="https://www.youtube.com/watch?v=Z0XiTjXCOdk"><img src=https://img.youtube.com/vi/Z0XiTjXCOdk/0.jpg alt="The badge responding to stop"></a></p><h3 id=use-your-own-model>Use your own model</h3><p>If you want to use your own model trained using Azure ML Studio, you will need to update the code to use this model, and provide image files.</p><h4 id=upload-image-files>Upload image files</h4><ol><li><p>Create bitmaps for each word that you are detecting, named in the format <code>&lt;word>.bmp</code>. For example, if you trained the model for &lsquo;Yes&rsquo; and &lsquo;No&rsquo; you will need <code>Yes.bmp</code> and <code>No.bmp</code>. These files must be 24-bit bitmaps at a size of 160x128. The best tools to use to create these is good old-fashioned MS Paint on Windows or ImageMagik on macOS.</p></li><li><p>Reset the EdgeBadge. It will mount on your computer with a disk called <strong>CIRCUITPY</strong></p></li><li><p>Copy the bitmaps into this drive</p></li></ol><h4 id=update-the-code>Update the code</h4><ol><li><p>Open <code>micro_features_micro_model_settings.cpp</code></p></li><li><p>Update <code>kCategoryLabels</code> to include the words the model was trained on. Keep <code>"silence"</code> and <code>"unknown"</code> at the start of the array, and put the words after in the order they were specified in the notebook. Ensure the casing of the words matches the names of the bitmaps created earlier.</p><blockquote><p>The words <strong>HAVE</strong> to be in the same order as the notebook or the wrong word will be detected</p></blockquote></li><li><p>Open `micro_features_micro_model_settings.h</p></li><li><p>Update <code>kCategoryCount</code> to be 2 higher than the number of words you trained the model for, so that it is the same as the size of the <code>kCategoryLabels</code> array. For example if you trained it for &lsquo;Yes&rsquo; and &lsquo;No&rsquo;, set <code>kCategoryCount</code> to <code>4</code>.</p></li><li><p>Open <code>micro_features_tiny_conv_micro_features_model_data.cpp</code></p></li><li><p>Replace the contents of the <code>g_tiny_conv_micro_features_model_data</code> array with the values from <code>__content_tiny_conv_tflite</code> in the <code>tiny_conv.cc</code> file downloaded from the Azure ML Studio notebook</p></li><li><p>Replace the value of <code>g_tiny_conv_micro_features_model_data_len</code> with the value of <code>__content_tiny_conv_tflite_len</code> from the <code>tiny_conv.cc</code> file downloaded from the Azure ML Studio notebook</p></li><li><p>Use the steps above to compile and deploy this new code to the device, then test it out.</p></li></ol></article></div></div><div class="col-sm-12 col-md-12 col-lg-3"><div class=sticky-sidebar><aside class=toc><h5>Table Of Contents</h5><div class=toc-content><nav id=TableOfContents><ul><li><a href=#train-the-model>Train the model</a><ul><li><a href=#create-an-azure-account>Create an Azure account</a></li><li><a href=#create-a-machine-learning-resource>Create a Machine Learning resource</a></li><li><a href=#set-up-ml-studio>Set up ML Studio</a></li><li><a href=#set-up-compute>Set up compute</a></li><li><a href=#upload-the-notebook>Upload the notebook</a></li></ul></li><li><a href=#compile-the-code-for-the-edgebadge>Compile the code for the EdgeBadge</a><ul><li><a href=#set-up-the-development-environment>Set up the development environment</a></li><li><a href=#compile-the-code>Compile the code</a></li><li><a href=#use-your-own-model>Use your own model</a></li></ul></li></ul></nav></div></aside><aside class=tags><h5>Tags</h5><ul class="tags-ul list-unstyled list-inline"><li class=list-inline-item><a href=https://jimbobbennett.dev/tags/technology target=_blank>technology</a></li><li class=list-inline-item><a href=https://jimbobbennett.dev/tags/ai target=_blank>AI</a></li><li class=list-inline-item><a href=https://jimbobbennett.dev/tags/iot target=_blank>IoT</a></li><li class=list-inline-item><a href=https://jimbobbennett.dev/tags/adafruit target=_blank>adafruit</a></li><li class=list-inline-item><a href=https://jimbobbennett.dev/tags/tinyml target=_blank>tinyml</a></li><li class=list-inline-item><a href=https://jimbobbennett.dev/tags/edge target=_blank>edge</a></li></ul></aside></div></div></div><div class=row><div class="col-sm-12 col-md-12 col-lg-9 p-4"><div id=disqus_thread></div><script>var disqus_config=function(){this.page.url="https://jimbobbennett.dev/blogs/recognizing-words-on-a-microcontroller-using-tinyml/",this.page.identifier="4c87e0f27c8a7cc17f7c9e6edd507fa0"};(function(){if(window.location.hostname=="localhost")return;var e=document,t=e.createElement("script");t.src="https://jimbobbennett.disqus.com/embed.js",t.setAttribute("data-timestamp",+new Date),(e.head||e.body).appendChild(t)})()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript></div></div></div><button class="p-2 px-3" onclick=topFunction() id=topScroll>
<i class="fas fa-angle-up"></i></button></section><script>var topScroll=document.getElementById("topScroll");window.onscroll=function(){scrollFunction()};function scrollFunction(){document.body.scrollTop>20||document.documentElement.scrollTop>20?topScroll.style.display="block":topScroll.style.display="none"}function topFunction(){document.body.scrollTop=0,document.documentElement.scrollTop=0}</script></div><footer><div class="container py-4"><div class="row justify-content-center"><div class="col-md-4 text-center">&copy; 2024 All Rights Reserved</div></div></div></div></footer><script src=https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.min.js integrity=sha384-QJHtvGhmr9XOIpI6YVutG+2QOK9T+ZnN4kzFN1RtK3zEFEIsxhlmWl5/YESvpZ13 crossorigin=anonymous></script><script>document.body.className.includes("light")&&(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))</script><script>let loadingIcons;function loading(){myVar=setTimeout(showPage,100)}function showPage(){try{document.getElementById("loading-icons").style.display="block"}catch{}}</script><script>function createCopyButton(e,t){const n=document.createElement("button");n.className="copy-code-button",n.type="button",n.innerText="Copy",n.addEventListener("click",()=>copyCodeToClipboard(n,e,t)),addCopyButtonToDom(n,e)}async function copyCodeToClipboard(e,t,n){const s=t.querySelector("pre > code").innerText;try{n.writeText(s)}finally{codeWasCopied(e)}}function codeWasCopied(e){e.blur(),e.innerText="Copied!",setTimeout(function(){e.innerText="Copy"},2e3)}function addCopyButtonToDom(e,t){t.insertBefore(e,t.firstChild);const n=document.createElement("div");n.className="highlight-wrapper",t.parentNode.insertBefore(n,t),n.appendChild(t)}if(navigator&&navigator.clipboard)document.querySelectorAll(".highlight").forEach(e=>createCopyButton(e,navigator.clipboard));else{var script=document.createElement("script");script.src="https://cdnjs.cloudflare.com/ajax/libs/clipboard-polyfill/2.7.0/clipboard-polyfill.promise.js",script.integrity="sha256-waClS2re9NUbXRsryKoof+F9qc1gjjIhc2eT7ZbIv94=",script.crossOrigin="anonymous",script.onload=function(){addCopyButtons(clipboard)},document.querySelectorAll(".highlight").forEach(e=>createCopyButton(e,script)),document.body.appendChild(script)}</script></body></html>