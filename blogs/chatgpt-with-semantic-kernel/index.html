<!doctype html><html><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><link rel=icon href=/fav.png type=image/png><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Alata&family=Lora&family=Muli:ital,wght@0,400;0,500;0,600;0,700;1,400;1,500;1,600;1,700&family=Roboto&family=Muli:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Alata&family=Lora&family=Muli:ital,wght@0,400;0,500;0,600;0,700;1,400;1,500;1,600;1,700&family=Roboto&family=Muli:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" media=print onload='this.media="all"'><noscript><link href="https://fonts.googleapis.com/css2?family=Alata&family=Lora&family=Muli:ital,wght@0,400;0,500;0,600;0,700;1,400;1,500;1,600;1,700&family=Roboto&family=Muli:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" rel=stylesheet></noscript><link rel=stylesheet href=/css/font.css media=all><meta property="og:title" content="Build a ChatGPT clone in .NET using OpenAI and Semantic Kernel"><meta property="og:description" content="Build a ChatGPT clone in .NET using OpenAI and Semantic Kernel"><meta property="og:type" content="article"><meta property="og:url" content="https://jimbobbennett.dev/blogs/chatgpt-with-semantic-kernel/"><meta property="og:image" content="https://jimbobbennett.dev/blogs/chatgpt-with-semantic-kernel/banner.png"><meta property="article:section" content="blogs"><meta property="article:published_time" content="2023-04-11T00:00:00+00:00"><meta property="article:modified_time" content="2023-04-11T00:00:00+00:00"><meta property="og:site_name" content="JimBobBennett"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://jimbobbennett.dev/blogs/chatgpt-with-semantic-kernel/banner.png"><meta name=twitter:title content="Build a ChatGPT clone in .NET using OpenAI and Semantic Kernel"><meta name=twitter:description content="Build a ChatGPT clone in .NET using OpenAI and Semantic Kernel"><meta name=twitter:site content="@jimbobbennett"><meta name=twitter:creator content="@jimbobbennett"><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css integrity=sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3 crossorigin=anonymous><link rel=stylesheet href=/css/header.css media=all><link rel=stylesheet href=/css/footer.css media=all><link rel=stylesheet href=/css/theme.css media=all><link rel="shortcut icon" type=image/png href=/fav.png><link rel="shortcut icon" sizes=192x192 href=/fav.png><link rel=apple-touch-icon href=/fav.png><link rel=alternate type=application/rss+xml href=https://jimbobbennett.dev//index.xml title=JimBobBennett><script type=text/javascript>(function(e,t,n,s,o,i,a){e[n]=e[n]||function(){(e[n].q=e[n].q||[]).push(arguments)},i=t.createElement(s),i.async=1,i.src="https://www.clarity.ms/tag/"+o,a=t.getElementsByTagName(s)[0],a.parentNode.insertBefore(i,a)})(window,document,"clarity","script","dctc2ydykv")</script><script data-goatcounter=https://jimbobbennett.goatcounter.com/count async src=//gc.zgo.at/count.js></script><style>:root{--text-color:#343a40;--text-secondary-color:#6c757d;--background-color:#000;--secondary-background-color:#64ffda1a;--primary-color:#007bff;--secondary-color:#f8f9fa;--text-color-dark:#e4e6eb;--text-secondary-color-dark:#b0b3b8;--background-color-dark:#000000;--secondary-background-color-dark:#212529;--primary-color-dark:#ffffff;--secondary-color-dark:#212529}body{background-color:#000;font-size:1rem;font-weight:400;line-height:1.5;text-align:left}</style><meta name=description content="Build a ChatGPT clone in .NET using OpenAI and Semantic Kernel"><link rel=stylesheet href=/css/index.css><link rel=stylesheet href=/css/single.css><link rel=stylesheet href=/css/projects.css media=all><script defer src=/fontawesome-5/all-5.15.4.js></script><title>Build a ChatGPT clone in .NET using OpenAI and Semantic Kernel | JimBobBennett</title></head><body class=light onload=loading()><header><nav class="pt-3 navbar navbar-expand-lg"><div class="container-fluid mx-xs-2 mx-sm-5 mx-md-5 mx-lg-5"><a class="navbar-brand primary-font text-wrap" href=/><img src=/fav.png width=30 height=30 class="d-inline-block align-top">
JimBobBennett
</a><button class=navbar-toggler type=button data-bs-toggle=collapse data-bs-target=#navbarContent aria-controls=navbarContent aria-expanded=false aria-label="Toggle navigation"><svg aria-hidden="true" height="24" viewBox="0 0 16 16" width="24" data-view-component="true"><path fill-rule="evenodd" d="M1 2.75A.75.75.0 011.75 2h12.5a.75.75.0 110 1.5H1.75A.75.75.0 011 2.75zm0 5A.75.75.0 011.75 7h12.5a.75.75.0 110 1.5H1.75A.75.75.0 011 7.75zM1.75 12a.75.75.0 100 1.5h12.5a.75.75.0 100-1.5H1.75z"/></svg></button><div class="collapse navbar-collapse text-wrap primary-font" id=navbarContent><ul class="navbar-nav ms-auto text-center"><li class="nav-item navbar-text"><a class=nav-link href=/ aria-label=home>Home</a></li><li class="nav-item navbar-text"><a class=nav-link href=/#about aria-label=about>About</a></li><li class="nav-item navbar-text"><a class=nav-link href=/#projects aria-label=projects>Recent Highlights</a></li><li class="nav-item navbar-text"><a class=nav-link href=/blogs title="Blog posts">Blog</a></li><li class="nav-item navbar-text"><a class=nav-link href=/videos title=Videos>Videos</a></li><li class="nav-item navbar-text"><a class=nav-link href=/podcasts title=Podcasts>Podcasts</a></li><li class="nav-item navbar-text"><a class=nav-link href=/livestreams title=Livestreams>Livestreams</a></li><li class="nav-item navbar-text"><a class=nav-link href=/conferences title=Conferences>Conferences</a></li><li class="nav-item navbar-text"><a class=nav-link href=/resume title=Resume>Resume</a></li></ul></div></div></nav></header><div id=content><section id=projects><div class="container pt-5" id=list-page><div class="row justify-content-center px-3 px-md-5"><h1 class="text-left pb-2 content">Build a ChatGPT clone in .NET using OpenAI and Semantic Kernel</h1><div class="text-left content"><a href=https://linkedin.com/in/jimbobbennett>Jim Bennett
</a><small>|</small>
Apr 11, 2023</div></div></div></section><section id=single><div class=container><div class="row justify-content-center"><div class="col-sm-12 col-md-12 col-lg-9"><div class=pr-lg-4><div class=featured-image><img class=img-fluid src=banner.png alt="Build a ChatGPT clone in .NET using OpenAI and Semantic Kernel"></div><article class="page-content p-2"><p>ChatGPT is the latest big thing, reaching over 100 million users in just 2 months. It&rsquo;s being used by millions of people for all manner of tasks, and it feels like every day there are 10 new startups leveraging either ChatGPT or the large language models (LLMs) that power it.</p><p><img src=chat-gpt-hot.png alt="Mugatu meme of Chat GPT, so hot right now"></p><p>So what if you want to build your own version of ChatGPT, or another app that leverages an LLM? Out of the box, LLMs just provide an API to send a prompt and get a response, so what tools are there to help?</p><p>One tool is Semantic Kernel, an open source .NET library from Microsoft that is designed to do a lot of the heavy lifting when it comes to interacting with LLMs.</p><p><img src=skpatternlarge.png alt="THe sematic kernel pattern of pink circles with different shades for each quadrant"></p><p><strong>If you prefer video, here&rsquo;s a 10 minute video version of this blog post</strong></p><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden><iframe src=https://www.youtube.com/embed/Pg-9W0a1OXw style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 allowfullscreen title="YouTube Video"></iframe></div><h2 id=how-does-chatgpt-work-with-an-llm>How does ChatGPT work with an LLM?</h2><p>ChatGPT allows you to have a conversation with a large language model, with ChatGPT being able to base the response to one question on the results of previous questions.</p><p>For example, if you ask it:</p><blockquote><p>What is the most recent star wars movie?</p></blockquote><p>It will respond something like:</p><blockquote><p>The most recent Star Wars movie is &ldquo;Star Wars: The Rise of Skywalker,&rdquo; which was released in December 2019. It is the ninth and final installment in the Skywalker saga.</p></blockquote><p>If you then ask a follow up question such as:</p><blockquote><p>Who is the main character?</p></blockquote><p>The response will &lsquo;know&rsquo; that the question refers to the movie the Rise of Skywalker:</p><blockquote><p>The main character in &ldquo;Star Wars: The Rise of Skywalker&rdquo; is Rey, played by Daisy Ridley. She is a powerful Jedi who is trying to find her place in the galaxy and confronts the evil First Order, led by Kylo Ren, played by Adam Driver. The movie also features other beloved characters from the Star Wars franchise, such as Finn, Poe Dameron, Chewbacca, and C-3PO.</p></blockquote><p>LLMs, the core technology behind ChatGPT, don’t chat – they take a prompt and return a response, that’s all. To chat, they need to be guided by having access to the previous questions and responses.</p><p>ChatGPT works by doing the following:</p><ul><li>The user enters a question, referred to as a prompt</li><li>This prompt is enriched by a system prompt that helps guide the LLM, such as &lsquo;you are a helpful chatbot&rsquo;</li><li>The prompt is sent to the LLM and the response is returned to the user</li><li>The user enters a second question</li><li>This time the prompt is enriched by the system prompt as well as the previous question and response</li><li>The prompt is sent to the LLM and the response is returned to the user</li></ul><p>For example, when the second question is sent, the full prompt might be:</p><blockquote><p>You are a helpful chatbot. You were asked &lsquo;What is the most recent star wars movie?&rsquo; and you answered &lsquo;The most recent Star Wars movie is &ldquo;Star Wars: The Rise of Skywalker,&rdquo; which was released in December 2019. It is the ninth and final installment in the Skywalker saga&rsquo;. Who is the main character?</p></blockquote><p>To implement your own ChatGPT you need to implement code to get the prompt from the user, enrich it with a system prompt, send it to the LLM, get the response, then enrich further questions with the previous questions and responses.</p><h2 id=how-can-semantic-kernel-help>How can semantic kernel help?</h2><p>Semantic Kernel provides a load of features to help you implement this:</p><ul><li>Services to interact with LLMs from OpenAI either directly or via the Azure OpenAI service</li><li>System prompts to pre-configure the conversation</li><li>Chat history, or &lsquo;memory&rsquo;</li><li>Semantic functions that can be defined in code such as getting user input and returning the response, or defined as prompts that can be sent to the LLM</li><li>Function pipelines to chain semantic functions</li><li>Core skills such as interacting with HTTP APIs or files.</li></ul><h3 id=semantic-functions-and-pipelines>Semantic functions and pipelines</h3><p>The core of semantic kernel is a pipeline that runs a series of functions. These functions either take text, return text, or both. Large language models work with text, so text is the main way to interact. The idea of the pipeline is text is passed through from function to function.</p><p>For example, for a ChatGPT clone, you could have a pipeline that gets input from the user, sends it to the LLM with the previous questions and responses, then send the response back to the user.</p><p>For a sample project, check out <a href=https://github.com/jimbobbennett/console-gpt>github.com/jimbobbennett/console-gpt</a>.</p><p>In this code, there is a <code>ConsoleGPTService</code> that has a pipeline:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-csharp data-lang=csharp><span style=display:flex><span>ISKFunction[] pipeline = {_speechSkill[<span style=color:#e6db74>&#34;Listen&#34;</span>], _chatSkill[<span style=color:#e6db74>&#34;Prompt&#34;</span>], _speechSkill[<span style=color:#e6db74>&#34;Respond&#34;</span>]};
</span></span><span style=display:flex><span><span style=color:#66d9ef>await</span> _semanticKernel.RunAsync(pipeline);
</span></span></code></pre></div><p>This pipeline runs 3 semantic functions, routing the output of one into the input of the other. Semantic functions are C# functions that are marked with an attribute and loaded into the pipeline.</p><p>The <code>Listen</code> function in this code is defined in the <code>ConsoleSkill</code> and gets data from the console:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-csharp data-lang=csharp><span style=display:flex><span><span style=color:#a6e22e>[SKFunction(&#34;Get console input.&#34;)]</span>
</span></span><span style=display:flex><span><span style=color:#a6e22e>[SKFunctionName(&#34;Listen&#34;)]</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>public</span> Task&lt;<span style=color:#66d9ef>string</span>&gt; Listen(SKContext context)
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> Task.Run(() =&gt; Console.ReadLine());
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>This returns what the used inputs, and this is passed to the <code>Prompt</code> semantic function in the <code>ChatSkill</code>:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-csharp data-lang=csharp><span style=display:flex><span><span style=color:#a6e22e>[SKFunction(&#34;Send a prompt to the LLM.&#34;)]</span>
</span></span><span style=display:flex><span><span style=color:#a6e22e>[SKFunctionName(&#34;Prompt&#34;)]</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>public</span> <span style=color:#66d9ef>async</span> Task&lt;<span style=color:#66d9ef>string</span>&gt; Prompt(<span style=color:#66d9ef>string</span> prompt)
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>    _chatHistory.AddUserMessage(prompt);
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>var</span> reply = <span style=color:#66d9ef>await</span> _chatCompletion.GenerateMessageAsync(_chatHistory, _chatRequestSettings);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>// Add the interaction to the chat history.</span>
</span></span><span style=display:flex><span>    _chatHistory.AddAssistantMessage(reply);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> reply;
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>This uses the <code>AddOpenAIChatCompletionService</code>, a service provided by the semantic kernel to interact with OpenAI. This service is a chat service, so manages history - when you call it you pass the complete chat history including a system prompt that sets up the conversation, and all the prompts and responses.</p><p>The output of this is then passed to a <code>Respond</code> semantic function to write it to the console:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-csharp data-lang=csharp><span style=display:flex><span><span style=color:#a6e22e>[SKFunction(&#34;Write a response to the console.&#34;)]</span>
</span></span><span style=display:flex><span><span style=color:#a6e22e>[SKFunctionName(&#34;Respond&#34;)]</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>public</span> Task&lt;<span style=color:#66d9ef>string</span>&gt; Respond(<span style=color:#66d9ef>string</span> message, SKContext context)
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> Task.Run(() =&gt; Console.WriteLine(message));
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>By using semantic functions you can quickly swap out functions by implementing the same signature in multiple places and bringing the one you want into the semantic kernel. You can also construct pipelines on the fly, adding sections if you need.</p><p>Semantic functions can also be created using prompts rather than code. For example:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-csharp data-lang=csharp><span style=display:flex><span><span style=color:#66d9ef>var</span> poemPrompt = <span style=color:#e6db74>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74></span>  Take <span style=color:#66d9ef>this</span> <span style=color:#e6db74>&#34;{{$INPUT}}&#34;</span> and convert it to a poem <span style=color:#66d9ef>in</span> iambic pentameter.
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;&#34;&#34;;
</span></span></span><span style=display:flex><span><span style=color:#e6db74></span>
</span></span><span style=display:flex><span>_poemFunction = _semanticKernel.CreateSemanticFunction(poemPrompt);
</span></span></code></pre></div><p>You can then add this to the pipeline, and the output from the previous function in the pipeline is passed to the <code>{{$INPUT}}</code> variable in the prompt. In this case using the LLM to convert to a poem.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-csharp data-lang=csharp><span style=display:flex><span>ISKFunction[] pipeline = {_speechSkill[<span style=color:#e6db74>&#34;Listen&#34;</span>], _chatSkill[<span style=color:#e6db74>&#34;Prompt&#34;</span>], _poemFunction, _speechSkill[<span style=color:#e6db74>&#34;Respond&#34;</span>]};
</span></span><span style=display:flex><span><span style=color:#66d9ef>await</span> _semanticKernel.RunAsync(pipeline);
</span></span></code></pre></div><p>This means for the prompt:</p><blockquote><p>What is the most recent star wars movie?</p></blockquote><p>You might get this poem:</p><blockquote><p>The Force of Fate has brought us here,</p><p>To see the Rise of Skywalker near,</p><p>The ninth and final part of this tale,</p><p>Released in December, &rsquo;twas no fail.</p><p>Star Wars, the movie, we all know,</p><p>The saga of the Skywalkers show,</p><p>The Force will live on, we can see,</p><p>In this movie, &rsquo;tis our destiny.</p></blockquote><h2 id=get-the-code>Get the code</h2><p>You can get the code on my <a href=https://github.com/jimbobbennett/console-gpt>console-gpt repo on GitHub</a>.</p><div class=github-card data-github=jimbobbennett/console-gpt data-width=400 data-height data-theme=default></div><script src=//cdn.jsdelivr.net/github-cards/latest/widget.js></script><h2 id=learn-more>Learn more</h2><p>Here are some more resources for Semantic Kernel</p><ul><li><a href=https://learn.microsoft.com/semantic-kernel>The Semantic Kernel documentation on Microsoft Learn</a></li><li><a href=https://github.com/microsoft/semantic-kernel>The Semantic Kernel repo on GitHub</a></li><li><a href=https://aka.ms/sk/discord>The Semantic Kernel Discord</a></li><li><a href=https://devblogs.microsoft.com/semantic-kernel/>The Semantic Kernel blog</a></li></ul></article></div></div><div class="col-sm-12 col-md-12 col-lg-3"><div class=sticky-sidebar><aside class=toc><h5>Table Of Contents</h5><div class=toc-content><nav id=TableOfContents><ul><li><a href=#how-does-chatgpt-work-with-an-llm>How does ChatGPT work with an LLM?</a></li><li><a href=#how-can-semantic-kernel-help>How can semantic kernel help?</a><ul><li><a href=#semantic-functions-and-pipelines>Semantic functions and pipelines</a></li></ul></li><li><a href=#get-the-code>Get the code</a></li><li><a href=#learn-more>Learn more</a></li></ul></nav></div></aside><aside class=tags><h5>Tags</h5><ul class="tags-ul list-unstyled list-inline"><li class=list-inline-item><a href=https://jimbobbennett.dev/tags/openai target=_blank>openai</a></li><li class=list-inline-item><a href=https://jimbobbennett.dev/tags/chatgpt target=_blank>chatgpt</a></li><li class=list-inline-item><a href=https://jimbobbennett.dev/tags/llm target=_blank>llm</a></li><li class=list-inline-item><a href=https://jimbobbennett.dev/tags/largelanguagemodel target=_blank>largelanguagemodel</a></li><li class=list-inline-item><a href=https://jimbobbennett.dev/tags/c target=_blank>c#</a></li><li class=list-inline-item><a href=https://jimbobbennett.dev/tags/dotnet target=_blank>dotnet</a></li><li class=list-inline-item><a href=https://jimbobbennett.dev/tags/semantickernel target=_blank>semantickernel</a></li></ul></aside></div></div></div><div class=row><div class="col-sm-12 col-md-12 col-lg-9 p-4"><div id=disqus_thread></div><script>var disqus_config=function(){this.page.url="https://jimbobbennett.dev/blogs/chatgpt-with-semantic-kernel/",this.page.identifier="02d05f1add860a4818ae60f62298ee57"};(function(){if(window.location.hostname=="localhost")return;var e=document,t=e.createElement("script");t.src="https://jimbobbennett.disqus.com/embed.js",t.setAttribute("data-timestamp",+new Date),(e.head||e.body).appendChild(t)})()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript></div></div></div><button class="p-2 px-3" onclick=topFunction() id=topScroll>
<i class="fas fa-angle-up"></i></button></section><script>var topScroll=document.getElementById("topScroll");window.onscroll=function(){scrollFunction()};function scrollFunction(){document.body.scrollTop>20||document.documentElement.scrollTop>20?topScroll.style.display="block":topScroll.style.display="none"}function topFunction(){document.body.scrollTop=0,document.documentElement.scrollTop=0}</script></div><footer><div class="container py-4"><div class="row justify-content-center"><div class="col-md-4 text-center">&copy; 2025 All Rights Reserved</div></div></div></div></footer><script src=https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.min.js integrity=sha384-QJHtvGhmr9XOIpI6YVutG+2QOK9T+ZnN4kzFN1RtK3zEFEIsxhlmWl5/YESvpZ13 crossorigin=anonymous></script><script>document.body.className.includes("light")&&(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))</script><script>let loadingIcons;function loading(){myVar=setTimeout(showPage,100)}function showPage(){try{document.getElementById("loading-icons").style.display="block"}catch{}}</script><script>function createCopyButton(e,t){const n=document.createElement("button");n.className="copy-code-button",n.type="button",n.innerText="Copy",n.addEventListener("click",()=>copyCodeToClipboard(n,e,t)),addCopyButtonToDom(n,e)}async function copyCodeToClipboard(e,t,n){const s=t.querySelector("pre > code").innerText;try{n.writeText(s)}finally{codeWasCopied(e)}}function codeWasCopied(e){e.blur(),e.innerText="Copied!",setTimeout(function(){e.innerText="Copy"},2e3)}function addCopyButtonToDom(e,t){t.insertBefore(e,t.firstChild);const n=document.createElement("div");n.className="highlight-wrapper",t.parentNode.insertBefore(n,t),n.appendChild(t)}if(navigator&&navigator.clipboard)document.querySelectorAll(".highlight").forEach(e=>createCopyButton(e,navigator.clipboard));else{var script=document.createElement("script");script.src="https://cdnjs.cloudflare.com/ajax/libs/clipboard-polyfill/2.7.0/clipboard-polyfill.promise.js",script.integrity="sha256-waClS2re9NUbXRsryKoof+F9qc1gjjIhc2eT7ZbIv94=",script.crossOrigin="anonymous",script.onload=function(){addCopyButtons(clipboard)},document.querySelectorAll(".highlight").forEach(e=>createCopyButton(e,script)),document.body.appendChild(script)}</script></body></html>