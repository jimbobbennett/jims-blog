<!doctype html><html><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><link rel=icon href=/fav.png type=image/png><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Alata&family=Lora&family=Muli:ital,wght@0,400;0,500;0,600;0,700;1,400;1,500;1,600;1,700&family=Roboto&family=Muli:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Alata&family=Lora&family=Muli:ital,wght@0,400;0,500;0,600;0,700;1,400;1,500;1,600;1,700&family=Roboto&family=Muli:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" media=print onload='this.media="all"'><noscript><link href="https://fonts.googleapis.com/css2?family=Alata&family=Lora&family=Muli:ital,wght@0,400;0,500;0,600;0,700;1,400;1,500;1,600;1,700&family=Roboto&family=Muli:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" rel=stylesheet></noscript><link rel=stylesheet href=/css/font.css media=all><meta property="og:title" content="Identifying my daughters toys using AI - Part 5, Plugin for on-device models"><meta property="og:description" content="In the first part of this series I used the Azure Custom Vision service to create an image classifier to allow me to easily identify my daughters cuddly toys. Once created I tested it by uploading an image and seeing what tags the classifier found for the image.
In the second part I accessed this model from a Xamarin app, so that I could use the camera to take a photo to run through the classifier using a NuGet package that talks to the Custom Vision service."><meta property="og:type" content="article"><meta property="og:url" content="https://jimbobbennett.dev/blogs/identifying-my-daughters-toys-using-ai-part-5-plugin-for-on-device-models/"><meta property="og:image" content="https://jimbobbennett.dev/blogs/identifying-my-daughters-toys-using-ai-part-5-plugin-for-on-device-models/banner.png"><meta property="article:section" content="blogs"><meta property="article:published_time" content="2018-02-26T15:22:18+00:00"><meta property="article:modified_time" content="2018-02-26T15:22:18+00:00"><meta property="og:site_name" content="JimBobBennett"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://jimbobbennett.dev/blogs/identifying-my-daughters-toys-using-ai-part-5-plugin-for-on-device-models/banner.png"><meta name=twitter:title content="Identifying my daughters toys using AI - Part 5, Plugin for on-device models"><meta name=twitter:description content="In the first part of this series I used the Azure Custom Vision service to create an image classifier to allow me to easily identify my daughters cuddly toys. Once created I tested it by uploading an image and seeing what tags the classifier found for the image.
In the second part I accessed this model from a Xamarin app, so that I could use the camera to take a photo to run through the classifier using a NuGet package that talks to the Custom Vision service."><meta name=twitter:site content="@jimbobbennett"><meta name=twitter:creator content="@jimbobbennett"><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css integrity=sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3 crossorigin=anonymous><link rel=stylesheet href=/css/header.css media=all><link rel=stylesheet href=/css/footer.css media=all><link rel=stylesheet href=/css/theme.css media=all><link rel="shortcut icon" type=image/png href=/fav.png><link rel="shortcut icon" sizes=192x192 href=/fav.png><link rel=apple-touch-icon href=/fav.png><link rel=alternate type=application/rss+xml href=https://jimbobbennett.dev/index.xml title=JimBobBennett><script type=text/javascript>(function(e,t,n,s,o,i,a){e[n]=e[n]||function(){(e[n].q=e[n].q||[]).push(arguments)},i=t.createElement(s),i.async=1,i.src="https://www.clarity.ms/tag/"+o,a=t.getElementsByTagName(s)[0],a.parentNode.insertBefore(i,a)})(window,document,"clarity","script","dctc2ydykv")</script><script data-goatcounter=https://jimbobbennett.goatcounter.com/count async src=//gc.zgo.at/count.js></script><style>:root{--text-color:#343a40;--text-secondary-color:#6c757d;--background-color:#000;--secondary-background-color:#64ffda1a;--primary-color:#007bff;--secondary-color:#f8f9fa;--text-color-dark:#e4e6eb;--text-secondary-color-dark:#b0b3b8;--background-color-dark:#000000;--secondary-background-color-dark:#212529;--primary-color-dark:#ffffff;--secondary-color-dark:#212529}body{background-color:#000;font-size:1rem;font-weight:400;line-height:1.5;text-align:left}</style><meta name=description content><link rel=stylesheet href=/css/index.css><link rel=stylesheet href=/css/single.css><link rel=stylesheet href=/css/projects.css media=all><script defer src=/fontawesome-5/all-5.15.4.js></script><title>Identifying my daughters toys using AI - Part 5, Plugin for on-device models | JimBobBennett</title></head><body class=light onload=loading()><header><nav class="pt-3 navbar navbar-expand-lg"><div class="container-fluid mx-xs-2 mx-sm-5 mx-md-5 mx-lg-5"><a class="navbar-brand primary-font text-wrap" href=/><img src=/fav.png width=30 height=30 class="d-inline-block align-top">
JimBobBennett
</a><button class=navbar-toggler type=button data-bs-toggle=collapse data-bs-target=#navbarContent aria-controls=navbarContent aria-expanded=false aria-label="Toggle navigation"><svg aria-hidden="true" height="24" viewBox="0 0 16 16" width="24" data-view-component="true"><path fill-rule="evenodd" d="M1 2.75A.75.75.0 011.75 2h12.5a.75.75.0 110 1.5H1.75A.75.75.0 011 2.75zm0 5A.75.75.0 011.75 7h12.5a.75.75.0 110 1.5H1.75A.75.75.0 011 7.75zM1.75 12a.75.75.0 100 1.5h12.5a.75.75.0 100-1.5H1.75z"/></svg></button><div class="collapse navbar-collapse text-wrap primary-font" id=navbarContent><ul class="navbar-nav ms-auto text-center"><li class="nav-item navbar-text"><a class=nav-link href=/ aria-label=home>Home</a></li><li class="nav-item navbar-text"><a class=nav-link href=/#about aria-label=about>About</a></li><li class="nav-item navbar-text"><a class=nav-link href=/#projects aria-label=projects>Recent Highlights</a></li><li class="nav-item navbar-text"><a class=nav-link href=/blogs title="Blog posts">Blog</a></li><li class="nav-item navbar-text"><a class=nav-link href=/videos title=Videos>Videos</a></li><li class="nav-item navbar-text"><a class=nav-link href=/livestreams title=Livestreams>Livestreams</a></li><li class="nav-item navbar-text"><a class=nav-link href=/conferences title=Conferences>Conferences</a></li><li class="nav-item navbar-text"><a class=nav-link href=/resume title=Resume>Resume</a></li></ul></div></div></nav></header><div id=content><section id=projects><div class="container pt-5" id=list-page><div class="row justify-content-center px-3 px-md-5"><h1 class="text-left pb-2 content">Identifying my daughters toys using AI - Part 5, Plugin for on-device models</h1><div class="text-left content"><a href=https://linkedin.com/in/jimbobbennett>Jim Bennett
</a><small>|</small>
Feb 26, 2018</div></div></div></section><section id=single><div class=container><div class="row justify-content-center"><div class="col-sm-12 col-md-12 col-lg-9"><div class=pr-lg-4><article class="page-content p-2"><p>In the <a href=/blogs/identifying-my-daughters-toys-using-ai/>first part of this series</a> I used the <a href="http://customvision.ai/?wt.mc_id=toyidentifier-blog-jabenn">Azure Custom Vision service</a> to create an image classifier to allow me to easily identify my daughters cuddly toys. Once created I tested it by uploading an image and seeing what tags the classifier found for the image.</p><p>In the <a href=/blogs/identifying-my-daughters-toys-using-ai-part-2-using-the-model/>second part</a> I accessed this model from a Xamarin app, so that I could use the camera to take a photo to run through the classifier using a NuGet package that talks to the Custom Vision service.</p><p>In the <a href=/blogs/identifying-my-daughters-toys-using-ai-part-3-offline-ios/>third part</a> I showed how to download this model for iOS and run it locally, on device, using CoreML.</p><p>In the <a href=/blogs/https://www.jimbobbennett.io/identifying-my-daughters-toys-using-ai-part-4-offline-android/>fourth part</a> I showed how to download this model for Android and run it locally, on device, using Tensorflow.</p><p>To run these models locally is a lot of boilerplate code, so I decided to make it easier and create a NuGet package containing a Xamarin plugin that can be used from iOS, Android and Xamarin.Forms apps.</p><p>This plugin makes it easy to download and use these models offline from inside your mobile app, using CoreML on iOS or Tensorflow on Android. These models can then be called from a .NET standard library, using something like Xam.Plugins.Media to take photos for classification.</p><h4 id=setup>Setup</h4><ul><li>Available on NuGet: <a href=https://www.nuget.org/packages/Xam.Plugins.OnDeviceCustomVision/>https://www.nuget.org/packages/Xam.Plugins.OnDeviceCustomVision/</a> <a href=https://www.nuget.org/packages/Xam.Plugins.OnDeviceCustomVision/><img src="https://img.shields.io/nuget/v/Xam.Plugins.OnDeviceCustomVision.svg?label=NuGet" alt=NuGet></a></li><li>Install into your .NET Standard project and iOS and Android client projects.</li></ul><h4 id=platform-support>Platform Support</h4><p>This requires iOS 11 and up to use models from CoreML. For Android with Tensorflow the minimum supported SDK version is 21.</p><h4 id=usage>Usage</h4><p>Before you can use this API, you need to initialise it with the model file downloaded from CustomVision. Trying to classify an image without calling <code>Init</code> will result in a <code>ImageClassifierException</code> being thrown.</p><h5 id=ios>iOS</h5><p>Download the Core ML model from Custom Vision.</p><h6 id=pre-compiled-models>Pre-compiled models</h6><p>Models can be compiled before beiong used, or compiled on the device. To use a pre-compiled model, compile the downloaded model using:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>xcrun coremlcompiler compile &lt;model_file_name&gt;.mlmodel &lt;model_name&gt;.mlmodelc
</span></span></code></pre></div><p>This will spit out a folder called <code>&lt;model_name>.mlmodelc</code> containing a number of files. Add this entire folder to the <code>Resources</code> folder in your iOS app. Once this has been added, add a call to <code>Init</code> to your app delegate, passing in the name of your compiled model without the extension (i.e. the name of the model folder <strong>without</strong> <code>mlmodelc</code>) and the type of model downloaded from the custom vision service:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cs data-lang=cs><span style=display:flex><span><span style=color:#66d9ef>public</span> <span style=color:#66d9ef>override</span> <span style=color:#66d9ef>bool</span> FinishedLaunching(UIApplication uiApplication, NSDictionary launchOptions)
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>   ...
</span></span><span style=display:flex><span>   CrossImageClassifier.Current.Init(<span style=color:#e6db74>&#34;&lt;model_name&gt;&#34;</span>, ModelType.General);
</span></span><span style=display:flex><span>   <span style=color:#66d9ef>return</span> <span style=color:#66d9ef>base</span>.FinishedLaunching(uiApplication, launchOptions);
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><h6 id=uncompiled-models>Uncompiled models</h6><p>Add the downloaded model, called <code>&lt;model_name>.mlmodel</code>, to the <code>Resources</code> folder in your iOS app.Once this has been added, add a call to <code>Init</code> to your app delegate, passing in the name of your model without the extension (i.e. the name of the model folder <strong>without</strong> <code>mlmodel</code>) and the type of model downloaded from the custom vision service:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cs data-lang=cs><span style=display:flex><span><span style=color:#66d9ef>public</span> <span style=color:#66d9ef>override</span> <span style=color:#66d9ef>bool</span> FinishedLaunching(UIApplication uiApplication, NSDictionary launchOptions)
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>   ...
</span></span><span style=display:flex><span>   CrossImageClassifier.Current.Init(<span style=color:#e6db74>&#34;&lt;model_name&gt;&#34;</span>, ModelType.General);
</span></span><span style=display:flex><span>   <span style=color:#66d9ef>return</span> <span style=color:#66d9ef>base</span>.FinishedLaunching(uiApplication, launchOptions);
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>The call to <code>Init</code> will attempt to compile the model, throwning a <code>ImageClassifierException</code> if the compile fails.</p><h5 id=android>Android</h5><p>Download the tensorflow model from Custom Vision. This will be a folder containing two files.</p><ul><li><code>labels.txt</code></li><li><code>model.pb</code></li></ul><p>Add both these files to the <code>Assets</code> folder in your Android app. Once these are added, add a call to <code>Init</code> to your main activity passing in the name of the model file and the type of model downloaded from the custom vision service:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cs data-lang=cs><span style=display:flex><span><span style=color:#66d9ef>protected</span> <span style=color:#66d9ef>override</span> <span style=color:#66d9ef>void</span> OnCreate(Bundle savedInstanceState)
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>   ...
</span></span><span style=display:flex><span>   CrossImageClassifier.Current.Init(<span style=color:#e6db74>&#34;model.pb&#34;</span>, ModelType.General);
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Note - the labels file must be present and called <code>labels.txt</code>.</p><h5 id=calling-this-from-your-net-standard-library>Calling this from your .NET Standard library</h5><p>To classify an image, call:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cs data-lang=cs><span style=display:flex><span><span style=color:#66d9ef>var</span> tags = <span style=color:#66d9ef>await</span> CrossImageClassifier.Current.ClassifyImage(stream);
</span></span></code></pre></div><p>Passing in an image as a stream. You can use a library like <a href=https://github.com/jamesmontemagno/MediaPlugin>Xam.Plugins.Media</a> to get an image as a stream from the camera or image library.</p><p>This will return a list of <code>ImageClassification</code> instances, one per tag in the model with the probabilty that the image matches that tag. Probabilities are doubles in the range of 0 - 1, with 1 being 100% probability that the image matches the tag. To find the most likely classification use:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cs data-lang=cs><span style=display:flex><span>tags.OrderByDescending(t =&gt; t.Probability)
</span></span><span style=display:flex><span>    .First().Tag;
</span></span></code></pre></div><h5 id=using-with-an-ioc-container>Using with an IoC container</h5><p><code>CrossImageClassifier.Current</code> returns an instance of the <code>IImageClassifier</code> interface, and this can be stored inside your IoC container and injected where required.</p><h4 id=getting-the-code>Getting the code</h4><p>If you want to see the code for this, head to <a href=https://github.com/jimbobbennett/Xam.Plugins.OnDeviceCustomVision>https://github.com/jimbobbennett/Xam.Plugins.OnDeviceCustomVision</a>.</p></article></div></div><div class="col-sm-12 col-md-12 col-lg-3"><div class=sticky-sidebar><aside class=toc><h5>Table Of Contents</h5><div class=toc-content><nav id=TableOfContents><ul><li><ul><li></li></ul></li></ul></nav></div></aside><aside class=tags><h5>Tags</h5><ul class="tags-ul list-unstyled list-inline"><li class=list-inline-item><a href=https://jimbobbennett.dev/tags/xamarin target=_blank>xamarin</a></li><li class=list-inline-item><a href=https://jimbobbennett.dev/tags/xamarin.ios target=_blank>xamarin.ios</a></li><li class=list-inline-item><a href=https://jimbobbennett.dev/tags/xamarin.android target=_blank>xamarin.android</a></li><li class=list-inline-item><a href=https://jimbobbennett.dev/tags/xamarin.forms target=_blank>xamarin.forms</a></li><li class=list-inline-item><a href=https://jimbobbennett.dev/tags/tensorflow target=_blank>Tensorflow</a></li><li class=list-inline-item><a href=https://jimbobbennett.dev/tags/ai target=_blank>AI</a></li><li class=list-inline-item><a href=https://jimbobbennett.dev/tags/coreml target=_blank>CoreML</a></li><li class=list-inline-item><a href=https://jimbobbennett.dev/tags/nuget target=_blank>nuget</a></li><li class=list-inline-item><a href=https://jimbobbennett.dev/tags/custom-vision target=_blank>custom vision</a></li><li class=list-inline-item><a href=https://jimbobbennett.dev/tags/cognitive-services target=_blank>cognitive services</a></li><li class=list-inline-item><a href=https://jimbobbennett.dev/tags/azure target=_blank>azure</a></li><li class=list-inline-item><a href=https://jimbobbennett.dev/tags/technology target=_blank>technology</a></li></ul></aside></div></div></div><div class=row><div class="col-sm-12 col-md-12 col-lg-9 p-4"><div id=disqus_thread></div><script>var disqus_config=function(){this.page.url="https://jimbobbennett.dev/blogs/identifying-my-daughters-toys-using-ai-part-5-plugin-for-on-device-models/",this.page.identifier="0970b0dd3ff60e0a9a34c416fcde0d88"};(function(){if(window.location.hostname=="localhost")return;var e=document,t=e.createElement("script");t.src="https://jimbobbennett.disqus.com/embed.js",t.setAttribute("data-timestamp",+new Date),(e.head||e.body).appendChild(t)})()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript></div></div></div><button class="p-2 px-3" onclick=topFunction() id=topScroll>
<i class="fas fa-angle-up"></i></button></section><script>var topScroll=document.getElementById("topScroll");window.onscroll=function(){scrollFunction()};function scrollFunction(){document.body.scrollTop>20||document.documentElement.scrollTop>20?topScroll.style.display="block":topScroll.style.display="none"}function topFunction(){document.body.scrollTop=0,document.documentElement.scrollTop=0}</script></div><footer><div class="container py-4"><div class="row justify-content-center"><div class="col-md-4 text-center">&copy; 2023 All Rights Reserved</div></div></div></div></footer><script src=https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.min.js integrity=sha384-QJHtvGhmr9XOIpI6YVutG+2QOK9T+ZnN4kzFN1RtK3zEFEIsxhlmWl5/YESvpZ13 crossorigin=anonymous></script><script>document.body.className.includes("light")&&(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))</script><script>let loadingIcons;function loading(){myVar=setTimeout(showPage,100)}function showPage(){try{document.getElementById("loading-icons").style.display="block"}catch{}}</script><script>function createCopyButton(e,t){const n=document.createElement("button");n.className="copy-code-button",n.type="button",n.innerText="Copy",n.addEventListener("click",()=>copyCodeToClipboard(n,e,t)),addCopyButtonToDom(n,e)}async function copyCodeToClipboard(e,t,n){const s=t.querySelector("pre > code").innerText;try{n.writeText(s)}finally{codeWasCopied(e)}}function codeWasCopied(e){e.blur(),e.innerText="Copied!",setTimeout(function(){e.innerText="Copy"},2e3)}function addCopyButtonToDom(e,t){t.insertBefore(e,t.firstChild);const n=document.createElement("div");n.className="highlight-wrapper",t.parentNode.insertBefore(n,t),n.appendChild(t)}if(navigator&&navigator.clipboard)document.querySelectorAll(".highlight").forEach(e=>createCopyButton(e,navigator.clipboard));else{var script=document.createElement("script");script.src="https://cdnjs.cloudflare.com/ajax/libs/clipboard-polyfill/2.7.0/clipboard-polyfill.promise.js",script.integrity="sha256-waClS2re9NUbXRsryKoof+F9qc1gjjIhc2eT7ZbIv94=",script.crossOrigin="anonymous",script.onload=function(){addCopyButtons(clipboard)},document.querySelectorAll(".highlight").forEach(e=>createCopyButton(e,script)),document.body.appendChild(script)}</script></body></html>