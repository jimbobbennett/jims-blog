<!doctype html><html><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><link rel=icon href=/fav.png type=image/png><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Alata&family=Lora&family=Muli:ital,wght@0,400;0,500;0,600;0,700;1,400;1,500;1,600;1,700&family=Roboto&family=Muli:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Alata&family=Lora&family=Muli:ital,wght@0,400;0,500;0,600;0,700;1,400;1,500;1,600;1,700&family=Roboto&family=Muli:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" media=print onload='this.media="all"'><noscript><link href="https://fonts.googleapis.com/css2?family=Alata&family=Lora&family=Muli:ital,wght@0,400;0,500;0,600;0,700;1,400;1,500;1,600;1,700&family=Roboto&family=Muli:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" rel=stylesheet></noscript><link rel=stylesheet href=/css/font.css media=all><meta property="og:title" content="Running AI models on iOS, Android and Windows using Xamarin"><meta property="og:description" content="I created a NuGet package a while ago to allow you to run models exported from the Azure Custom Vision service on iOS and Android in Xamarin apps from your cross-platform code. You can read about this here.
Since then, the Custom Vision service has added ONNX export, meaning you can now run these models on-device on Windows as well. This meant it was time to update my plugin to support Windows."><meta property="og:type" content="article"><meta property="og:url" content="https://jimbobbennett.dev/blogs/running-ai-models-on-ios-android-and-windows-using-xamarin/"><meta property="og:image" content="https://jimbobbennett.dev/blogs/running-ai-models-on-ios-android-and-windows-using-xamarin/banner.png"><meta property="article:section" content="blogs"><meta property="article:published_time" content="2018-07-20T16:59:01+00:00"><meta property="article:modified_time" content="2018-07-20T16:59:01+00:00"><meta property="og:site_name" content="JimBobBennett"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://jimbobbennett.dev/blogs/running-ai-models-on-ios-android-and-windows-using-xamarin/banner.png"><meta name=twitter:title content="Running AI models on iOS, Android and Windows using Xamarin"><meta name=twitter:description content="I created a NuGet package a while ago to allow you to run models exported from the Azure Custom Vision service on iOS and Android in Xamarin apps from your cross-platform code. You can read about this here.
Since then, the Custom Vision service has added ONNX export, meaning you can now run these models on-device on Windows as well. This meant it was time to update my plugin to support Windows."><meta name=twitter:site content="@jimbobbennett"><meta name=twitter:creator content="@jimbobbennett"><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css integrity=sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3 crossorigin=anonymous><link rel=stylesheet href=/css/header.css media=all><link rel=stylesheet href=/css/footer.css media=all><link rel=stylesheet href=/css/theme.css media=all><link rel="shortcut icon" type=image/png href=/fav.png><link rel="shortcut icon" sizes=192x192 href=/fav.png><link rel=apple-touch-icon href=/fav.png><link rel=alternate type=application/rss+xml href=https://jimbobbennett.dev//index.xml title=JimBobBennett><script type=text/javascript>(function(e,t,n,s,o,i,a){e[n]=e[n]||function(){(e[n].q=e[n].q||[]).push(arguments)},i=t.createElement(s),i.async=1,i.src="https://www.clarity.ms/tag/"+o,a=t.getElementsByTagName(s)[0],a.parentNode.insertBefore(i,a)})(window,document,"clarity","script","dctc2ydykv")</script><script data-goatcounter=https://jimbobbennett.goatcounter.com/count async src=//gc.zgo.at/count.js></script><style>:root{--text-color:#343a40;--text-secondary-color:#6c757d;--background-color:#000;--secondary-background-color:#64ffda1a;--primary-color:#007bff;--secondary-color:#f8f9fa;--text-color-dark:#e4e6eb;--text-secondary-color-dark:#b0b3b8;--background-color-dark:#000000;--secondary-background-color-dark:#212529;--primary-color-dark:#ffffff;--secondary-color-dark:#212529}body{background-color:#000;font-size:1rem;font-weight:400;line-height:1.5;text-align:left}</style><meta name=description content><link rel=stylesheet href=/css/index.css><link rel=stylesheet href=/css/single.css><link rel=stylesheet href=/css/projects.css media=all><script defer src=/fontawesome-5/all-5.15.4.js></script><title>Running AI models on iOS, Android and Windows using Xamarin | JimBobBennett</title></head><body class=light onload=loading()><header><nav class="pt-3 navbar navbar-expand-lg"><div class="container-fluid mx-xs-2 mx-sm-5 mx-md-5 mx-lg-5"><a class="navbar-brand primary-font text-wrap" href=/><img src=/fav.png width=30 height=30 class="d-inline-block align-top">
JimBobBennett
</a><button class=navbar-toggler type=button data-bs-toggle=collapse data-bs-target=#navbarContent aria-controls=navbarContent aria-expanded=false aria-label="Toggle navigation"><svg aria-hidden="true" height="24" viewBox="0 0 16 16" width="24" data-view-component="true"><path fill-rule="evenodd" d="M1 2.75A.75.75.0 011.75 2h12.5a.75.75.0 110 1.5H1.75A.75.75.0 011 2.75zm0 5A.75.75.0 011.75 7h12.5a.75.75.0 110 1.5H1.75A.75.75.0 011 7.75zM1.75 12a.75.75.0 100 1.5h12.5a.75.75.0 100-1.5H1.75z"/></svg></button><div class="collapse navbar-collapse text-wrap primary-font" id=navbarContent><ul class="navbar-nav ms-auto text-center"><li class="nav-item navbar-text"><a class=nav-link href=/ aria-label=home>Home</a></li><li class="nav-item navbar-text"><a class=nav-link href=/#about aria-label=about>About</a></li><li class="nav-item navbar-text"><a class=nav-link href=/#projects aria-label=projects>Recent Highlights</a></li><li class="nav-item navbar-text"><a class=nav-link href=/blogs title="Blog posts">Blog</a></li><li class="nav-item navbar-text"><a class=nav-link href=/videos title=Videos>Videos</a></li><li class="nav-item navbar-text"><a class=nav-link href=/podcasts title=Podcasts>Podcasts</a></li><li class="nav-item navbar-text"><a class=nav-link href=/livestreams title=Livestreams>Livestreams</a></li><li class="nav-item navbar-text"><a class=nav-link href=/conferences title=Conferences>Conferences</a></li><li class="nav-item navbar-text"><a class=nav-link href=/resume title=Resume>Resume</a></li></ul></div></div></nav></header><div id=content><section id=projects><div class="container pt-5" id=list-page><div class="row justify-content-center px-3 px-md-5"><h1 class="text-left pb-2 content">Running AI models on iOS, Android and Windows using Xamarin</h1><div class="text-left content"><a href=https://linkedin.com/in/jimbobbennett>Jim Bennett
</a><small>|</small>
Jul 20, 2018</div></div></div></section><section id=single><div class=container><div class="row justify-content-center"><div class="col-sm-12 col-md-12 col-lg-9"><div class=pr-lg-4><article class="page-content p-2"><p>I created a <a href=https://www.nuget.org/packages/Xam.Plugins.OnDeviceCustomVision/>NuGet package</a> a while ago to allow you to run models exported from the <a href=https://customvision.ai>Azure Custom Vision</a> service on iOS and Android in Xamarin apps from your cross-platform code. You can read about this <a href=/blogs/identifying-my-daughters-toys-using-ai-part-5-plugin-for-on-device-models/>here</a>.</p><p>Since then, the Custom Vision service has added <a href=/blogs/running-custom-vision-models-on-a-windows-device/>ONNX export</a>, meaning you can now run these models on-device on Windows as well. This meant it was time to update my plugin to support Windows.</p><p>This was released in v2.0 of the plugin - I thought I&rsquo;d be a good developer and bump the major version number as I&rsquo;ve broken the API.</p><h4 id=api-changes>API changes</h4><p>The main change is that the <code>IImageClassifier.Init</code> method has now gone. When I wrote this it was a bit of a fudge - it took a single model name and a model type. The model type was only needed on Android as some image adjustments needed to be made based on the model type used. It also meant that there was no way to use a different TensorFlow labels file, it had to be called <code>labels.txt</code>. With Windows, the <code>Init</code> call would need a list of labels, so it made sense to strip it down and have platform-specific calls to allow each platform to be passes just what is needed.</p><h5 id=initialization-on-ios>Initialization on iOS</h5><p>Models can be compiled before being used, or compiled on the device. To use a pre-compiled model, compile the downloaded model using:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>xcrun coremlcompiler compile &lt;model_file_name&gt;.mlmodel &lt;model_name&gt;.mlmodelc
</span></span></code></pre></div><p>Add the model (compiled or uncompiled) to the <code>Resources</code> folder in your iOS app. Then initialize the plugin using:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cs data-lang=cs><span style=display:flex><span>iOSImageClassifier.Init(<span style=color:#e6db74>&#34;&lt;model_name&gt;&#34;</span>);
</span></span></code></pre></div><p>Passing in the name of the model without the <code>mlmodel</code> or <code>mlmodelc</code> extension. If the model is uncompiled, it will be compiled before use.</p><h5 id=initialization-on-android>Initialization on Android</h5><p>Add the <code>model.pb</code> and <code>labels.txt</code> files to the <code>Assets</code> folder of your Android app. Then initalize the plugin using:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cs data-lang=cs><span style=display:flex><span>AndroidImageClassifier.Current.Init(<span style=color:#e6db74>&#34;model.pb&#34;</span>, <span style=color:#e6db74>&#34;labels.txt&#34;</span>, ModelType.General);
</span></span></code></pre></div><p>These values are actually defaults, so you can leave these off and just use <code>AndroidImageClassifier.Current.Init()</code> if you want.</p><blockquote><p>A note about model types. You needed the model type because the original TensorFlow export created models that needed image adjustments for some model types to work correctly. Since 7th May 2018 then models have a layer that adjusts for this automatically. The plugin will detect this and only make image adjustments if needed, so the model type is only relevant for models created before this date. It is ignored for models created after.</p></blockquote><h5 id=initialization-on-windows>Initialization on Windows</h5><p>Add the <code>&lt;model>.onnx</code> file to the <code>Assets</code> folder of your Windows app. A <code>&lt;model>.cs</code> file will be created to process the model in the root of your UWP app. The wrapper will have a class called <code>&lt;model>ModelOutput</code> and in the constructor for this class will be some code to create a dictionary called loss:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cs data-lang=cs><span style=display:flex><span><span style=color:#66d9ef>this</span>.loss = <span style=color:#66d9ef>new</span> Dictionary&lt;<span style=color:#66d9ef>string</span>, <span style=color:#66d9ef>float</span>&gt;()
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>    { <span style=color:#e6db74>&#34;&lt;label 1&gt;&#34;</span>, <span style=color:#66d9ef>float</span>.NaN },
</span></span><span style=display:flex><span>    { <span style=color:#e6db74>&#34;&lt;label 2&gt;&#34;</span>, <span style=color:#66d9ef>float</span>.NaN },
</span></span><span style=display:flex><span>    ...
</span></span><span style=display:flex><span>};
</span></span></code></pre></div><p>This defines the labels in the correct order for the model. These labels will need to be passed to the <code>Init</code> method in the correct order.</p><p>The <code>Init</code> method on Windows is also an async method, so will need to be called from another async method, such as by overriding <code>OnNavigatedTo</code> on a page and marking it as <code>async</code>. Await the init method passing the model name and labels like this:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cs data-lang=cs><span style=display:flex><span><span style=color:#66d9ef>await</span> WindowsImageClassifier.Init(<span style=color:#e6db74>&#34;Currency&#34;</span>, <span style=color:#66d9ef>new</span>[] { <span style=color:#e6db74>&#34;&lt;label 1&gt;&#34;</span>, <span style=color:#e6db74>&#34;&lt;label 2&gt;&#34;</span>, ... });
</span></span></code></pre></div><hr><p>I&rsquo;m sure this can be improved, including adding code to detect the labels from the ONNX model, so feel free to raise a PR with any improvements. All the code is on <a href=https://github.com/jimbobbennett/Xam.Plugins.OnDeviceCustomVision>GitHub here</a>.</p></article></div></div><div class="col-sm-12 col-md-12 col-lg-3"><div class=sticky-sidebar><aside class=toc><h5>Table Of Contents</h5><div class=toc-content><nav id=TableOfContents><ul><li><ul><li></li></ul></li></ul></nav></div></aside><aside class=tags><h5>Tags</h5><ul class="tags-ul list-unstyled list-inline"><li class=list-inline-item><a href=https://jimbobbennett.dev/tags/xamarin.forms target=_blank>xamarin.forms</a></li><li class=list-inline-item><a href=https://jimbobbennett.dev/tags/ai target=_blank>AI</a></li><li class=list-inline-item><a href=https://jimbobbennett.dev/tags/windows target=_blank>windows</a></li><li class=list-inline-item><a href=https://jimbobbennett.dev/tags/ios target=_blank>iOS</a></li><li class=list-inline-item><a href=https://jimbobbennett.dev/tags/android target=_blank>Android</a></li><li class=list-inline-item><a href=https://jimbobbennett.dev/tags/onnx target=_blank>onnx</a></li><li class=list-inline-item><a href=https://jimbobbennett.dev/tags/nuget target=_blank>nuget</a></li><li class=list-inline-item><a href=https://jimbobbennett.dev/tags/technology target=_blank>technology</a></li><li class=list-inline-item><a href=https://jimbobbennett.dev/tags/xamarin target=_blank>xamarin</a></li></ul></aside></div></div></div><div class=row><div class="col-sm-12 col-md-12 col-lg-9 p-4"><div id=disqus_thread></div><script>var disqus_config=function(){this.page.url="https://jimbobbennett.dev/blogs/running-ai-models-on-ios-android-and-windows-using-xamarin/",this.page.identifier="f31549999922d638eb10ceaa8f4e9a91"};(function(){if(window.location.hostname=="localhost")return;var e=document,t=e.createElement("script");t.src="https://jimbobbennett.disqus.com/embed.js",t.setAttribute("data-timestamp",+new Date),(e.head||e.body).appendChild(t)})()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript></div></div></div><button class="p-2 px-3" onclick=topFunction() id=topScroll>
<i class="fas fa-angle-up"></i></button></section><script>var topScroll=document.getElementById("topScroll");window.onscroll=function(){scrollFunction()};function scrollFunction(){document.body.scrollTop>20||document.documentElement.scrollTop>20?topScroll.style.display="block":topScroll.style.display="none"}function topFunction(){document.body.scrollTop=0,document.documentElement.scrollTop=0}</script></div><footer><div class="container py-4"><div class="row justify-content-center"><div class="col-md-4 text-center">&copy; 2025 All Rights Reserved</div></div></div></div></footer><script src=https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.min.js integrity=sha384-QJHtvGhmr9XOIpI6YVutG+2QOK9T+ZnN4kzFN1RtK3zEFEIsxhlmWl5/YESvpZ13 crossorigin=anonymous></script><script>document.body.className.includes("light")&&(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))</script><script>let loadingIcons;function loading(){myVar=setTimeout(showPage,100)}function showPage(){try{document.getElementById("loading-icons").style.display="block"}catch{}}</script><script>function createCopyButton(e,t){const n=document.createElement("button");n.className="copy-code-button",n.type="button",n.innerText="Copy",n.addEventListener("click",()=>copyCodeToClipboard(n,e,t)),addCopyButtonToDom(n,e)}async function copyCodeToClipboard(e,t,n){const s=t.querySelector("pre > code").innerText;try{n.writeText(s)}finally{codeWasCopied(e)}}function codeWasCopied(e){e.blur(),e.innerText="Copied!",setTimeout(function(){e.innerText="Copy"},2e3)}function addCopyButtonToDom(e,t){t.insertBefore(e,t.firstChild);const n=document.createElement("div");n.className="highlight-wrapper",t.parentNode.insertBefore(n,t),n.appendChild(t)}if(navigator&&navigator.clipboard)document.querySelectorAll(".highlight").forEach(e=>createCopyButton(e,navigator.clipboard));else{var script=document.createElement("script");script.src="https://cdnjs.cloudflare.com/ajax/libs/clipboard-polyfill/2.7.0/clipboard-polyfill.promise.js",script.integrity="sha256-waClS2re9NUbXRsryKoof+F9qc1gjjIhc2eT7ZbIv94=",script.crossOrigin="anonymous",script.onload=function(){addCopyButtons(clipboard)},document.querySelectorAll(".highlight").forEach(e=>createCopyButton(e,script)),document.body.appendChild(script)}</script></body></html>