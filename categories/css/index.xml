<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Css on JimBobBennett</title><link>https://jimbobbennett.dev/</link><description>Recent content in Css on JimBobBennett</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><managingEditor>jim@jimbobbennett.io (Jim Bennett)</managingEditor><webMaster>jim@jimbobbennett.io (Jim Bennett)</webMaster><lastBuildDate>Sat, 13 Sep 2014 10:52:26 +0000</lastBuildDate><atom:link href="https://jimbobbennett.dev/categories/css/index.xml" rel="self" type="application/rss+xml"/><item><title>Can AI help with user personas</title><link>https://jimbobbennett.dev/blogs/can-ai-help-with-user-personas/</link><pubDate>Tue, 04 Mar 2025 00:00:00 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/can-ai-help-with-user-personas/</guid><description>&lt;p>I recently recorded an episode of the &lt;a href="https://youtube.com/playlist?list=PL3ufX1Aqkp14nCfVUrDjLD3_GTFN0bo95&amp;amp;si=I721SMH3kncXMe2c">Pieces AI productivity podcast&lt;/a> with &lt;a href="https://www.linkedin.com/in/jasonarbon/">Jason Arbon&lt;/a>, the CEO of &lt;a href="https://testers.ai/">Testers.ai&lt;/a> and &lt;a href="https://www.checkie.ai/">Checkie.ai&lt;/a>.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/jCB_Xp-MdDs" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;p>During this podcast we were discussing how well AI can do at replicating hte actions of humans, and I made the claim that AI will never be as good as humans as it lacks basic empathy. When we consider designing and testing a product, my position was that an AI will never be able to provide those human-level decisions that consider the needs of the individual users.&lt;/p>
&lt;h2 id="example---a-mobile-app-for-truck-drivers">Example - a mobile app for truck drivers&lt;/h2>
&lt;p>I gave an example of a mobile app I built at a company many years ago designed for truck drivers to inspect vehicles. The first ideas for the app failed to take into consideration the UX requirements of the audience. Truck drivers in New Zealand and the US (our audience) are typically:&lt;/p>
&lt;ul>
&lt;li>Older as this is not a career young people want to get into&lt;/li>
&lt;li>Larger than average due to a sedentary job with poor food choices available at truck stops&lt;/li>
&lt;li>Less tech savvy&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>This is the typical user, and doesn&amp;rsquo;t represent the entire user base, but we should always design for the least able users&lt;/p>
&lt;/blockquote>
&lt;p>The initial design for our app was sleek and modern, with small UI controls and an experience that used up to date mobile UI experiences. Which was great for the young, healthy, designers and developers, but would fall down when it hit our users.&lt;/p>
&lt;p>We got to these considerations by discussing the app with some of the more customer focused members of the company, folks who were former truck drivers themselves, or folks who meet and work with drivers every day. These are the best people to work with - the ones who have access to the lived experience of the customer. This took days to get the data, with many meetings and discussions to drill down to a set of statements that we could verify the UI designs against.&lt;/p>
&lt;p>&lt;strong>Our users are typically older&lt;/strong> - which means more potential for poor eyesight. Small controls and text are hard to read.&lt;/p>
&lt;p>&lt;strong>Our users are typically larger than average&lt;/strong> - which means larger fingers. A tight UI makes it hard to select the right buttons.&lt;/p>
&lt;p>&lt;strong>Our users are typically less tech savvy&lt;/strong> - which means they are not as used to mobile patterns as the young, tech friendly development team. The experience needs to be intuitive and guide them through the actions they need to do.&lt;/p>
&lt;p>So it was back to the drawing board with these thoughts in mind, designing a UI that had larger controls, larger, shorter text, and a simpler flow guiding uses through it step by step.&lt;/p>
&lt;h2 id="can-an-ai-empathize-like-this">Can an AI empathize like this?&lt;/h2>
&lt;p>Now in my discussion with Jason, I argued that an AI would not make these design choices. It would not have enough empathy about the user to be able to consider aspects like larger fingers, or poorer eyesight. Jason on te other had disagreed - his experience shows that AI is surprisingly good at building user personas. It has access to such a huge corpus of information around many different characteristics of humans, that it is able to reason across these details and come up with recommendations that are accurate and detailed. AI also has the advantage that it can do this at scale, so when you are considering systems that might have multiple types of users, it can create multiple user personas much faster than a human would. You can then feed these personas into AI testing tools to quickly validate the UX of apps for these different users.&lt;/p>
&lt;h2 id="what-considerations-are-there-for-creating-user-personas">What considerations are there for creating user personas?&lt;/h2>
&lt;p>When you use an AI to create a user persona, the key point that Jason made was it is better to be vague rather than explicit. The more you guide the AI, the more bias you put into the system. You want an unbiased view, allowing the AI to consider areas you didn&amp;rsquo;t.&lt;/p>
&lt;p>For example, if you prompt an AI with:&lt;/p>
&lt;p>&amp;ldquo;I need to build a UI for an app for truck drivers. What design considerations should I have for the user experience based off truck drivers typically having poor eyesight and large fingers?&amp;rdquo;&lt;/p>
&lt;p>You are going to get a response that focuses on poor eyesight and large fingers. Which is great, as you need to know what UX considerations there are for these situations, but misses out on any other situations you might consider.&lt;/p>
&lt;p>Instead it is better to do some prompt chaining. Start by asking what design considerations I should have for the user interface first. Then when you have the list prompt again to get more information on each consideration. This way the AI is not biased by your thoughts in what is important, and it can add its own ideas.&lt;/p>
&lt;h2 id="lets-put-it-to-the-test">Let&amp;rsquo;s put it to the test&lt;/h2>
&lt;p>So based on Jason&amp;rsquo;s theory, I decided to put this to the test. Let&amp;rsquo;s see if an AI can help with user personas.&lt;/p>
&lt;h3 id="prompt-1---get-the-ux-considerations">Prompt 1 - get the UX considerations&lt;/h3>
&lt;p>Prompt 1: &amp;ldquo;I need to build a UI for an app for truck drivers. What design considerations should I have for an optimal user experience?&amp;rdquo;&lt;/p>
&lt;p>This is a very generic statement. Let&amp;rsquo;s see how GPT-4o Mini handles this.&lt;/p>
&lt;blockquote>
&lt;p>When designing a UI for an app aimed at truck drivers, there are several key considerations to ensure an optimal user experience. Here are some important design considerations:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>Simplicity and Clarity&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Use a clean and straightforward layout. Avoid clutter and ensure that the most important features are easily accessible.&lt;/li>
&lt;li>Use clear and concise language. Truck drivers may be on the road and need to quickly understand what to do.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Large Touch Targets&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Ensure buttons and interactive elements are large enough to be easily tapped while driving. This reduces the risk of accidental touches and improves usability.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Voice Commands&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Incorporate voice command functionality to allow drivers to interact with the app without taking their hands off the wheel or eyes off the road.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Offline Functionality&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Truck drivers may travel through areas with poor connectivity. Ensure that critical features of the app can function offline and sync data when a connection is available.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Navigation and Mapping&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Integrate reliable navigation features that provide real-time traffic updates, route optimization, and truck-specific routing (considering height, weight, and restrictions).&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Notifications and Alerts&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Use non-intrusive notifications to alert drivers about important updates (e.g., delivery reminders, route changes) without being distracting.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Customization&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Allow users to customize their dashboard or main screen to prioritize the features they use most often.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Accessibility&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Ensure the app is accessible to all users, including those with disabilities. Consider color contrast, text size, and screen reader compatibility.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Safety Features&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Include features that promote safety, such as a &amp;ldquo;Do Not Disturb&amp;rdquo; mode while driving, which can limit notifications and interactions.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>User Feedback&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Provide a way for users to give feedback easily. This can help you improve the app based on real-world usage and needs.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Consistent Design Language&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Maintain a consistent design language throughout the app to help users navigate intuitively. Use familiar icons and terminology.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Testing in Real-World Scenarios&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Conduct usability testing with actual truck drivers to gather insights on how they interact with the app in real-world conditions.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;p>By focusing on these design considerations, you can create a user-friendly app that meets the needs of truck drivers while ensuring their safety and efficiency on the road.&lt;/p>
&lt;/blockquote>
&lt;p>So far this is pretty good. The focus is more around considerations when driving - so large touch targets because the user may be driving so can&amp;rsquo;t devote attention to looking at the app. It also highlighted connectivity - &amp;ldquo;Truck drivers may travel through areas with poor connectivity. Ensure that critical features of the app can function offline and sync data when a connection is available&amp;rdquo;. This is something that wasn&amp;rsquo;t considered initially, so bonus points to the AI.&lt;/p>
&lt;p>So we have some good things here, and some we didn&amp;rsquo;t think off. But we can now take this and dig in further with more prompts.&lt;/p>
&lt;h3 id="prompt-2---get-accessibility-considerations">Prompt 2 - get accessibility considerations&lt;/h3>
&lt;p>The first response focused on driving, so let&amp;rsquo;s try a prompt that focuses more on accessibility.&lt;/p>
&lt;p>&amp;ldquo;For this app, what accessibility considerations are there? What are the typical physical characteristics of a truck driver that may impact the design of the app.&amp;rdquo;&lt;/p>
&lt;blockquote>
&lt;p>When designing an app for truck drivers, it&amp;rsquo;s essential to consider accessibility to ensure that all users, including those with disabilities, can effectively use the app. Here are some key accessibility considerations:&lt;/p>
&lt;h3 id="accessibility-considerations">Accessibility Considerations:&lt;/h3>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>Color Contrast&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Ensure sufficient contrast between text and background colors to aid users with visual impairments. Use tools to check color contrast ratios.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Text Size and Scalability&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Allow users to adjust text size for better readability. Use scalable fonts that maintain clarity when resized.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Screen Reader Compatibility&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Ensure that all elements of the app are compatible with screen readers. Use semantic HTML and ARIA (Accessible Rich Internet Applications) roles to provide context.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Alternative Text for Images&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Provide descriptive alt text for images and icons to assist users who rely on screen readers.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Keyboard Navigation&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Ensure that all interactive elements can be accessed and operated using a keyboard. This is crucial for users with mobility impairments.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Voice Control&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Incorporate voice control features to allow users to navigate the app without needing to use touch controls.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Clear and Simple Language&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Use plain language and avoid jargon to make the app more understandable for users with cognitive disabilities.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Feedback Mechanisms&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Provide clear feedback for user actions (e.g., button presses, form submissions) to help users understand the results of their interactions.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Customizable UI&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Allow users to customize the interface to suit their needs, such as changing color schemes or layouts.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;h3 id="typical-physical-characteristics-of-truck-drivers">Typical Physical Characteristics of Truck Drivers:&lt;/h3>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>Age Range&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Truck drivers can vary widely in age, which may affect their comfort with technology. Older drivers may prefer larger text and simpler interfaces.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Physical Stamina&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Truck drivers often spend long hours on the road, which can lead to fatigue. The app should minimize cognitive load and provide quick access to essential features.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Hand Dexterity&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Some drivers may have reduced dexterity due to age or physical conditions. Ensure that touch targets are large enough and spaced adequately to prevent accidental touches.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Visual Impairments&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Some drivers may experience vision issues, such as reduced acuity or color blindness. The app should accommodate these conditions through adjustable settings.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Hearing Impairments&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Consider drivers who may have hearing impairments by providing visual alerts and notifications in addition to audio cues.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Cognitive Load&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Truck drivers need to manage multiple tasks while driving. The app should be designed to minimize distractions and present information clearly and concisely.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;p>By addressing these accessibility considerations and understanding the physical characteristics of truck drivers, you can create an app that is inclusive and user-friendly for a diverse audience.&lt;/p>
&lt;/blockquote>
&lt;p>Now we have more good stuff here. The AI has considered age and dexterity, focusing on large text, simpler interfaces, large targets, and adjustable text. The small worry is the AI is recommending thoughts for folks who use screen readers - unlikely to be the typical truck driver, if your eyesight is bad enough to use a screen reader it is unlikely you would be driving.&lt;/p>
&lt;p>It also had recommendations around cognitive load - reducing the impact on drivers who are focusing on the road. Distractions are a major cause of accidents, so anything the app can do to reduce these is a benefit.&lt;/p>
&lt;h2 id="who-wins-ai-or-humans">Who wins, AI or humans?&lt;/h2>
&lt;p>So who is the better at empathizing about the human? Are humans better, or as the AI the winner.&lt;/p>
&lt;p>As much as it pains me to say it, I think in this case the AI wins. We humans put together a small set of considerations in a matter of days with many back and forth discussions between teams. The AI however was able to replicate what we decided and more in only 2 prompts. About 1 minutes work.&lt;/p>
&lt;p>Does this mean we should discount the human and go all in on AI? Absolutely not. AI makes mistakes. In this example the mistakes are few, just references to users who&amp;rsquo;s visual impairments need accommodations such as screen readers, far outside what is needed legally to drive.&lt;/p>
&lt;p>Is this a great contribution? Very much so. To me if I was doing a similar exercise again I would run multiple prompts through the AI, gather data, then work through these with humans to build a final set of design considerations in a very short space of time, saving days.&lt;/p>
&lt;p>Please let me know your thoughts? Have you used AI to design a product? Did it have the right design considerations for your user personas? Let me know in the comments.&lt;/p></description></item><item><title>Build GitHub Actions faster with act</title><link>https://jimbobbennett.dev/blogs/build-github-actions-faster-with-act/</link><pubDate>Mon, 23 Sep 2024 00:00:00 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/build-github-actions-faster-with-act/</guid><description>&lt;p>If I said to you that I made 34 commits to a repo, each one with small changes to a single file, with commit messages like &amp;ldquo;Hoping this works&amp;rdquo;, &amp;ldquo;Please work&amp;rdquo;, and &amp;ldquo;For f*cks sake, work this time&amp;rdquo;, you would know exactly why - I&amp;rsquo;m setting up a &lt;strong>CI/CD pipeline&lt;/strong>!&lt;/p>
&lt;p>We&amp;rsquo;ve all been through this - having to commit our changes to GitHub to test them out as there is no way to do it locally, and ending up with way too many commits because our only feedback loop is to run and check the logs. Compound this with repo permissions where every commit needs to be a PR that is reviewed and approved, and you have way too much work and time spent working on what should be a simple task. If only there was a better way&amp;hellip;&lt;/p>
&lt;p>There is! This post is all about &lt;a href="https://nektosact.com/introduction.html">&lt;strong>act&lt;/strong>&lt;/a>, a tool for running &lt;strong>GitHub Actions&lt;/strong> locally, so you can debug and fix them before committing to your repo. It shows act off using the real world example of the GitHub Action I created for the &lt;a href="https://github.com/pieces-app/pieces-os-client-sdk-for-csharp">Pieces for Developers C# SDK&lt;/a>.&lt;/p>
&lt;h2 id="what-is-act">What is act&lt;/h2>
&lt;blockquote>
&lt;p>&amp;ldquo;Think globally, &lt;code>act&lt;/code> locally&amp;rdquo;&lt;/p>
&lt;/blockquote>
&lt;p>The goal of &lt;a href="https://nektosact.com/introduction.html">&lt;strong>act&lt;/strong>&lt;/a> is to provide a way to spin up a GitHub Action locally, running them in a container as if they were running in GitHub. It can handle environment variables, secrets, using external actions and more, with a file system setup that mimics what GitHub has. And best of all, this is a free, open source project!&lt;/p>
&lt;h3 id="install-act">Install act&lt;/h3>
&lt;p>Installation of act is pretty simple. It uses &lt;a href="https://www.docker.com">Docker&lt;/a>, so you need that installed (or a compatible container engine), then after that you can install from your package manager of choice. All the options are listed in &lt;a href="https://nektosact.com/installation/index.html">the act installation guide&lt;/a>. I&amp;rsquo;m a mac user, so used &lt;a href="https://formulae.brew.sh/formula/act#default">homebrew&lt;/a>:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>brew install act
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="run-act">Run act&lt;/h3>
&lt;p>You can run act from the command line. When run, it will run all the jobs in your &lt;code>.github/workflows&lt;/code> folder.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>act
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The first time you run act, it will give you a choice of what type of container you want to run everything in - from huge with everything, to tiny with minimal support for external actions. I chose the middle ground, with a 500MB download (which conveniently enough I was able to do on airplane WiFi).&lt;/p>
&lt;p>You can configure which jobs are run by passing &lt;a href="https://nektosact.com/usage/index.html#events">events&lt;/a> to the command line. This allows you to simulate a pull request, or a push to a branch. For example, to only run actions triggered by a push, run:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>act push
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="use-act-to-build-an-action">Use act to build an action&lt;/h2>
&lt;p>I recently used act to help me build out a GitHub Action to build and publish the &lt;a href="https://github.com/pieces-app/pieces-os-client-sdk-for-csharp">Pieces for Developers C# SDK&lt;/a> to nuget. This action needs to do the following:&lt;/p>
&lt;ol>
&lt;li>Be triggered from a new tag&lt;/li>
&lt;li>Install .NET 8 (the current LTS version)&lt;/li>
&lt;li>Compile the SDK with a release build, passing the version from the tag to the build command&lt;/li>
&lt;li>Sign the created nuget package (this is created on build) using a cert and password from the secrets&lt;/li>
&lt;li>Push the package to nuget, using an API key that is a secret&lt;/li>
&lt;/ol>
&lt;h3 id="use-external-actions-with-act">Use external actions with act&lt;/h3>
&lt;p>Act has full support for external actions made available with a &lt;code>uses&lt;/code> statement. It will clone the action locally, then run it with docker so that it runs as if it was in a GitHub Action. In my case, this means I can check out my code, and install .NET using the default GitHub &lt;code>actions/setup-dotnet&lt;/code> action.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">Release&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">on&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">push&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">tags&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#e6db74">&amp;#39;*&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">jobs&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">publish-to-nuget&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">runs-on&lt;/span>: &lt;span style="color:#ae81ff">ubuntu-latest&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">steps&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">uses&lt;/span>: &lt;span style="color:#ae81ff">actions/checkout@v4&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">Setup .NET&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">uses&lt;/span>: &lt;span style="color:#ae81ff">actions/setup-dotnet@v4&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">with&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">dotnet-version&lt;/span>: &lt;span style="color:#ae81ff">8.0&lt;/span>&lt;span style="color:#ae81ff">.*&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;blockquote>
&lt;p>Top tip - running an action that installs a large tool like .NET on airplane WiFi is not recommended! Ask me how I know&amp;hellip;&lt;/p>
&lt;/blockquote>
&lt;h3 id="use-a-tag-with-act">Use a tag with act&lt;/h3>
&lt;p>The next step is to build the nuget package. As part of this, I want to set the version from the tag.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>- &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">Build&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">working-directory&lt;/span>: &lt;span style="color:#ae81ff">./src/Client&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">run&lt;/span>: &lt;span style="color:#ae81ff">dotnet build -c Release -p:Version=${GITHUB_REF#refs/tags/v}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>GitHub automatically passes this tag through to the action as a &lt;a href="https://docs.github.com/actions/writing-workflows/choosing-what-your-workflow-does/store-information-in-variables#default-environment-variables">default environment variable&lt;/a> when run inside GitHub Actions. With act, I can also set environment variables either by passing them into the command line, or adding them to a .env file:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-ini" data-lang="ini">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">GITHUB_REF&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">refs/tags/v0.0.7-beta&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This allows me to set the tag used for each run, in this example to &lt;code>refs/tags/v0.0.7-beta&lt;/code>. The syntax of my build command, &lt;code>${GITHUB_REF#refs/tags/v}&lt;/code> strips the &lt;code>refs/tags/v&lt;/code> section, so my build sets the version to &lt;code>0.0.7-beta&lt;/code>.&lt;/p>
&lt;h3 id="use-secrets-with-act">Use secrets with act&lt;/h3>
&lt;p>GitHub Actions supports &lt;a href="https://docs.github.com/actions/security-for-github-actions/security-guides/using-secrets-in-github-actions">secrets&lt;/a> - special values you can configure as the owner of the repo that are surfaced to your actions, but not visible to anyone looking at the repo. These are great for things like API keys or passwords. In my case I need 3 secrets - a certificate to sign my nuget package, a password for the certificate, and an API key for nuget to show it&amp;rsquo;s me uploading the package.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>- &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">Get the nuget signing certificate&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">id&lt;/span>: &lt;span style="color:#ae81ff">cert_file&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">uses&lt;/span>: &lt;span style="color:#ae81ff">timheuer/base64-to-file@v1.2&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">with&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">fileName&lt;/span>: &lt;span style="color:#e6db74">&amp;#39;certfile.pfx&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">encodedString&lt;/span>: &lt;span style="color:#ae81ff">${{ secrets.NUGET_CERTIFICATE }}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>- &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">Sign the nuget package&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">working-directory&lt;/span>: &lt;span style="color:#ae81ff">./src/Client&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">run&lt;/span>: |&lt;span style="color:#e6db74">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> dotnet nuget sign ./bin/Release/Pieces.OS.Client.${GITHUB_REF#refs/tags/v}.nupkg
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> --certificate-path /tmp/certfile.pfx
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> --certificate-password ${{ secrets.NUGET_CERTIFICATE_PASSWORD }}
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> --timestamper http://timestamp.digicert.com&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>- &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">Push to NuGet&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">working-directory&lt;/span>: &lt;span style="color:#ae81ff">./src/Client&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">run&lt;/span>: |&lt;span style="color:#e6db74">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> dotnet nuget push ./bin/Release/*.nupkg -k ${{ secrets.NUGET_API_KEY }}
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> -s https://nuget.org&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>With act, you can &lt;a href="https://nektosact.com/usage/index.html#secrets">pass secrets using a &lt;code>.secrets&lt;/code> file&lt;/a>. This is similar to the &lt;code>.env&lt;/code> file, just with your secrets in it. I created a local &lt;code>.secrets&lt;/code> file with the secrets I needed.&lt;/p>
&lt;p>For the signing certificate, I need a &lt;code>.pfx&lt;/code> file, so my way to do this is to encode the contents of the file in base64, upload that as a secret, then use the &lt;code>timheuer/base64-to-file@v1.2&lt;/code> action to convert that secret to a file on the local file system. More details in &lt;a href="https://www.timheuer.com/blog/use-nuget-with-github-actions-github-packages/">this blog post from Tim&lt;/a>.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-ini" data-lang="ini">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">NUGET_API_KEY&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;lt;key&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">NUGET_CERTIFICATE_PASSWORD&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;lt;password&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">NUGET_CERTIFICATE&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;lt;base64 encoded cert&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;blockquote>
&lt;p>Always add the &lt;code>.secrets&lt;/code> to your &lt;code>.gitignore&lt;/code> to avoid accidentally exposing them by adding this file to your repo!&lt;/p>
&lt;/blockquote>
&lt;h2 id="test-it-out">Test it out&lt;/h2>
&lt;p>With my environment variables and secrets all set up, I was able to test out my action. As always, things failed with each run, but I was able to iterate locally without needing to push my action, raise a PR, get it reviewed and approved, merge it, then tag each time.&lt;/p>
&lt;p>The kind of errors I hit were:&lt;/p>
&lt;ul>
&lt;li>Not setting the working directory&lt;/li>
&lt;li>Setting the version of the build wrong&lt;/li>
&lt;li>Getting the path of the certificate file wrong&lt;/li>
&lt;li>Inconsistent case of &lt;code>release&lt;/code> and &lt;code>Release&lt;/code> for the output folder&lt;/li>
&lt;/ul>
&lt;p>All these are easy mistakes to make when you can&amp;rsquo;t run locally, and would normally take multiple fixes. All fixed locally before I committed my code.&lt;/p>
&lt;p>The action ran as if I was inside a GitHub Action - not only did it actually check out my code and build it, it also signed the nuget package and pushed it to the nuget repo. I could see the result with the new package visible inside nuget. This gave me the confidence to raise my PR.&lt;/p>
&lt;h2 id="conclusion">Conclusion&lt;/h2>
&lt;p>If you are using GitHub Actions, act is an invaluable tool to help you develop your actions and test them locally. Check it out at &lt;a href="https://github.com/nektos/act">github.com/nektos/act&lt;/a>.&lt;/p></description></item><item><title>Circles of DevRel part 1 - grow your circle of influence through collaboration</title><link>https://jimbobbennett.dev/blogs/circles-of-influence-1/</link><pubDate>Sat, 20 Jul 2024 00:00:00 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/circles-of-influence-1/</guid><description>&lt;blockquote>
&lt;p>This is the first part of a multipart blog post focusing on looking at DevRel through the idea of circles of influence.&lt;/p>
&lt;/blockquote>
&lt;p>As &lt;a href="https://jimbobbennett.dev/blogs/so-what-is-devrel/">dev rel people&lt;/a>, part of our job is to drive awareness of our product. If you think in terms of sales/marketing, this is feeding the top of the funnel. If you think in terms of the &lt;a href="https://www.devrel.agency/developerjourney">developer journey&lt;/a>, this is the discover phase.&lt;/p>
&lt;p>&lt;img src="sales-funnel.webp" alt="A sales funnel - awareness, interest, decision, action">&lt;/p>
&lt;p>&lt;img src="developer-journey.webp" alt="The developer journey - discover, evaluate, learn, build, scale">&lt;/p>
&lt;p>However you look at it, it is about helping developers to discover your product, inspiring them to evaluate it, learn more, and ultimately use it in their day to day.&lt;/p>
&lt;p>This post focuses on being better at driving awareness by considering circles of influence, and looking at how you can collaborate with others to drive more awareness.&lt;/p>
&lt;h2 id="successfully-driving-awareness">Successfully driving awareness&lt;/h2>
&lt;p>What does success look like when driving awareness? I’m sure there are many opinions on this, but mine is simple:&lt;/p>
&lt;blockquote>
&lt;p>How can I make a &lt;strong>new&lt;/strong> audience aware of product/feature/thing?&lt;/p>
&lt;/blockquote>
&lt;p>Emphasis on the &lt;strong>new&lt;/strong> part. To be successful we need to focus on that new. This can be completely new people who are not aware of your product, or existing customers who are not aware of feature X, or new product Y.&lt;/p>
&lt;h2 id="dev-rel-circle-of-influence">Dev Rel circle of influence&lt;/h2>
&lt;p>As dev rel people, we all have what I think of as a &lt;em>circle of influence&lt;/em>, either personally or on our company properties. This might be our social followers, the subscribers to our newsletter, readers of our employers blog, or folks who follow us in other ways. Although we want to grow this circle, in general this stays reasonably static with steady growth as we do more activities.&lt;/p>
&lt;p>Each of these content and social locations has a circle of influence, and they all wrap up to your one overarching circle of influence, encompassing personal and company circles.&lt;/p>
&lt;p>&lt;img src="circle-of-influence.webp" alt="One large circle of influence made of multiple smaller circles based on different audiences">&lt;/p>
&lt;p>If we just use these same circles to promote our thing, then we are at risk of preaching to the converted. It’s hard to get net new signups by tweeting to the same circle of people, once we reach saturation there is no more potential customers to reach.&lt;/p>
&lt;p>Although it can be good to reach the same circle, for example to keep customers updated on new features, or support community heroes, we risk the echo chamber. The same people attend your livestream and you are spending hours with no quantifiable return on your time as you are not driving awareness. The same people attend your Twitter space, or watch your talk, or read your blog.&lt;/p>
&lt;p>To drive more awareness, you need to grow that audience.&lt;/p>
&lt;h2 id="grow-your-audience">Grow your audience&lt;/h2>
&lt;p>To get more return on your efforts and grow that new audience, you need to do one of 2 things:&lt;/p>
&lt;ul>
&lt;li>Grow your circle of influence&lt;/li>
&lt;li>Overlap with someone else’s circle of influence.&lt;/li>
&lt;/ul>
&lt;p>The first part is outside the scope of this post, the rest of this post focuses on the second.&lt;/p>
&lt;h2 id="overlap-with-another-circle-of-influence">Overlap with another circle of influence&lt;/h2>
&lt;p>The easiest way to two your circle of influence is to leverage the connections you already have to create collaborative content. By that I mean build new content with someone else who has a circle of influence, that way your content reaches their circle as well as yours.&lt;/p>
&lt;p>&lt;img src="2-circles-of-influence.webp" alt="Content reaching 2 circles of influence">&lt;/p>
&lt;h3 id="collaboration-on-content">Collaboration on content&lt;/h3>
&lt;p>As dev rel people, we create content. Some of this content is directly about our product, but very few products are used completely in isolation. Instead we integrate with others. Sometimes directly - using a web framework on a site deployed to a hosting provider, sometimes indirectly - using AI dev tool to write code to talk to a service.&lt;/p>
&lt;p>It’s very normal for us to create this kind of content, so the obvious thing to do is to do this in collaboration with a dev rel for that integration. This is a win-win situation. You both have content that is relevant to your product, it’s been easier to create as 2 of you are working on it, and most importantly this overlaps your circles of influence.&lt;/p>
&lt;p>For example, at Pieces we have an AI tool that leverages a range of context such as code snippets. If I wanted to write code using a specific cloud service, chances are I have a range of code snippets saved, such as the code to save an object into storage, or post a message to a queue.&lt;/p>
&lt;p>If I write a blog post about ‘using Pieces to manage code snippets to interact with cloud service’, not only does it show a real world use case for Pieces, but it also shows a way to interact with the cloud service easier. This is great content for me and can reach my circle of influence when published to my audience. if however, I collaborate on this with a dev rel from the cloud service, the content will then reach their circle of influence as well.&lt;/p>
&lt;p>&lt;img src="overlap-circles-of-influence.webp" alt="2 overlapping circles of influence">&lt;/p>
&lt;p>Suddenly they reach my circle of influence, and I reach theirs. This increases the reach of the content, and drives that awareness we want towards new developers. And importantly this is a mutually beneficial relationship. I’m not taking advantage of someone else’s influence, we are sharing our reach.&lt;/p>
&lt;h3 id="the-venn-diagram-of-circles-of-influence">The Venn diagram of circles of influence&lt;/h3>
&lt;p>When we think of collaboration, we need to consider 2 things:&lt;/p>
&lt;ul>
&lt;li>Is there a logical content overlap that tells a good story?&lt;/li>
&lt;li>Do we have a sufficiently unique circle of influence?&lt;/li>
&lt;/ul>
&lt;p>The first point refers to the content. Is it worth us collaborating? If there is no logical story, then no. A blog post on using a flutter UI component with a k8s management pipeline makes no sense. This content won’t resonate with our audience. Instead we want to collaborate with people who are likely to have an interest in using both products. Using Pieces with a popular cloud tool for example, lots of Pieces users want to use various cloud tools, and cloud tool users may want to manage code snippets and can benefit from Pieces. For collaborative content to work there needs to be overlap in the needs, desires, or tech stacks of the audience.&lt;/p>
&lt;p>On the other hand, we don’t want our circles of influence to overlap too much. If the Venn diagram of my circle of influence and my collaborators is a circle, then we fail in our goal of reaching new developers.&lt;/p>
&lt;p>&lt;img src="large-overlap.webp" alt="A Venn diagram that’s actually a circle">&lt;/p>
&lt;p>How do you ensure this? I don’t have a magic formula, it’s all gut feel, but sometimes just looking at the number of mutuals on social can be enough. Harder with things like corporate blog reach, so a lot is finger in the air guess work. The best way is to try it, track metrics, and see if there is net new growth. If you collaborate with multiple people you should be able to measure from new sign ups what topics work well and double down on those.&lt;/p>
&lt;h2 id="fairness-of-contributions">Fairness of contributions&lt;/h2>
&lt;p>Now this benefit is not always equal - sometimes the collaborator has a much bigger reach, or a much smaller reach. Personally I believe in sharing the love, so the way you ‘pay back’ working with someone with a much larger audience is by working with someone else with a smaller audience. We are a community of dev rel people, so we help the community without transactionality. If you work for a very small, new, growing company then you don’t have much reach to bring to a FAANG dev rel for example, but pay it back later. Collaborate now, then as you grow, support the next generation of dev rels with small circles of influence.&lt;/p>
&lt;h2 id="conclusion">Conclusion&lt;/h2>
&lt;p>We all have a circle of influence. To avoid constantly speaking to the same people, consider how collaborations can increase the circle of influence of both you and your collaborators.&lt;/p></description></item><item><title>So what exactly is Dev Rel?</title><link>https://jimbobbennett.dev/blogs/so-what-is-devrel/</link><pubDate>Thu, 25 Apr 2024 00:00:00 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/so-what-is-devrel/</guid><description>&lt;p>I work in developer relations - usually abbreviated to dev rel. Despite this being a popular field, with a lot of companies hiring dev rel folks such as developer advocates, there is still a lot of confusion around what developer relations actually is. In this post, I want to give my opinion on what it is, how it can contribute to your companies success, and also a little bit of what it isn&amp;rsquo;t.&lt;/p>
&lt;p>Before we dive in, I do want to note that dev rel can be many, many things. Although there are similarities in what dev rel folks do, I think &lt;a href="https://twitter.com/kelseyhightower">Kelsey Hightower&lt;/a> sums it up best:&lt;/p>
&lt;p>Developer relations is about building relations with developers, and covers a multitude of roles. I&amp;rsquo;ve written this post more from the perspective of developer advocacy, but I do give a call out to the rest of the folks who help build relationships with developers later in this post.&lt;/p>
&lt;p>So let&amp;rsquo;s dig in to this fun topic! This is a long post and a bit of a brain dump, so please share feedback! Oh, and I won&amp;rsquo;t be covering metrics, that is a &lt;a href="https://www.amazon.com/Business-Value-Developer-Relations-Communities/dp/1484237471/ref=sr_1_1">book in itself&lt;/a>&amp;hellip;&lt;/p>
&lt;h2 id="how-do-i-describe-my-job">How do I describe my job&lt;/h2>
&lt;p>One lesson I&amp;rsquo;ve learned from famed tech storyteller &lt;a href="https://twitter.com/docjamesw">James Whittaker&lt;/a> is to have a story that describes what you do. This is currently mine:&lt;/p>
&lt;blockquote>
&lt;p>I help developers be successful with liblab&lt;/p>
&lt;/blockquote>
&lt;p>Prior to my current role, I was at Microsoft, where it was &amp;lsquo;I help developers be successful with microsoft technologies&amp;rsquo;&lt;/p>
&lt;p>This is a very simple statement but a lot to unpack, and I feel it sums up developer relations in very broad strokes.&lt;/p>
&lt;blockquote>
&lt;p>I &lt;strong>help developers&lt;/strong> be &lt;strong>successful&lt;/strong> with &lt;strong>liblab&lt;/strong>&lt;/p>
&lt;/blockquote>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>I help developers&lt;/strong> - The core of developer relations is helping. I used to work for &lt;a href="https://twitter.com/chadfowler">Chad Fowler&lt;/a> at Microsoft, and he gave a guiding principle for the team that I still follow today. &amp;ldquo;Help first, sell last&amp;rdquo;. Dev rel focuses on &lt;strong>helping&lt;/strong> developers. By &lt;strong>helping&lt;/strong> we can have an authentic relationship as we are here to help, not to convince you to buy anything. By &lt;strong>helping&lt;/strong> we can solve your problems and make you more productive, or help you ship what you need. Sell last, not because sales are not important - they are, I like getting paid as Lego is expensive, but sales will happen because the product you are advocating for solves their needs and they or their company decide to buy or expand their usage. I&amp;rsquo;ll come back to sales later.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>be successful&lt;/strong> - Developers often don&amp;rsquo;t often care about your product or company. Some do (and these are your source of community heros), but most want to build the thing and go home. Anything you can do to help this happen is a good thing. Sometimes this is awareness of your product and how it can help their particular case, other times it&amp;rsquo;s content to show them how to do the thing, be it docs, videos, tutorials or other types of content. Sometimes it&amp;rsquo;s hand-holding where you work one-on-one with the developer. As a dev rel, your content helps them be successful so they can finish their work and go home.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>with liblab&lt;/strong> - Insert your company or product here. At the end of the day you work for someone, they are paying the bills, and you need developers to use their technology so you can get paid. If they are successful with your technology, your company gets paid and you get paid. Sometimes the &lt;strong>successful with&lt;/strong> part is just using your technology, but most of the time it is integrating your technology with another technology. For example, liblab is an SDK generation tool, but is most powerful integrated into a CI/CD pipeline so developers can update their API spec, have their SDKs generated automatically, and, yes, go home.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="what-does-be-successful-look-like">What does &amp;lsquo;be successful&amp;rsquo; look like?&lt;/h2>
&lt;p>As I mentioned earlier - developers want to do their job and go home, so being successful is about empowering developers to do just that by using your tool or product. To achieve this success, they need to take a number of steps:&lt;/p>
&lt;ol>
&lt;li>Discover&lt;/li>
&lt;li>Evaluate&lt;/li>
&lt;li>Learn&lt;/li>
&lt;li>Build&lt;/li>
&lt;li>Scale&lt;/li>
&lt;/ol>
&lt;p>This list is taken from &lt;a href="https://www.devrel.agency/developerjourney">the Developer Journey&lt;/a> from &lt;a href="https://www.devrel.agency/">DevRel.Agency&lt;/a> which is an excellent resource for planning your dev rel strategy. I like to split this list into 2 sections - outbound and inbound. Advocating to, and advocating for. Discover and to some degree Evaluate are about outbound advocacy, you enable these by advocating to the developer. For sales and marketing folks, this is the top of the funnel. Evaluate, Learn, Build and Scale are more focused on inbound advocacy, or advocating for the developer. This is the middle to the bottom of the funnel.&lt;/p>
&lt;ul>
&lt;li>Outbound advocacy/Advocating to - providing a mix of first and third party content to drive awareness. This is how you help your company be successful.&lt;/li>
&lt;li>Inbound advocacy/Advocating for - providing first party content to help the developer learn, and providing product feedback to help the product be successful. This is how you help your users be successful.&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>In a perfect world you go where developers are (Discover), and bring them back to you (Evaluate, Learn, Build, Scale).&lt;/p>
&lt;/blockquote>
&lt;p>At every step you will lose developers, just like a typical sales funnel. Your goal as dev rel is to ensure that as much is in place as possible to avoid developers falling out of the funnel.&lt;/p>
&lt;h3 id="discover">Discover&lt;/h3>
&lt;p>To be successful with your product, developers need to be aware of it! Put simply if they don&amp;rsquo;t know about your product, they will never use it. This is your job as dev rel to raise awareness. You do this by going where developers are, and raising awareness of your product.&lt;/p>
&lt;p>Now who are these &amp;lsquo;developers&amp;rsquo;? A lot of that depends on your product. Ideally you should define one or more &amp;lsquo;ideal customer profiles&amp;rsquo; or ICPs that provide a rough summary of who your users might be. You can then target content to these.&lt;/p>
&lt;p>For smaller companies, this awareness is around both product and company. For larger companies, this awareness is usually around product. For example, with liblab I have to raise awareness of the company and the product. At Microsoft I was raising awareness of individual products or product areas - after all, most developers have heard of Microsoft.&lt;/p>
&lt;p>&lt;strong>Going where developers are, and raising awareness of your product&lt;/strong> - again, a &amp;lsquo;simple` sentence that has a lot of meaning.&lt;/p>
&lt;h4 id="go-where-developers-are">Go where developers are&lt;/h4>
&lt;p>Developers will not come to your docs, blog, LinkedIn page or Discord server if they don&amp;rsquo;t know about you. You need to share your message in places where those developers are. There are a lot of places, some where developers are seeking answers, some where discovery is more organic. The main thing here though is to be authentic! Help first, sell last.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Conferences - Developers come to these to learn, often with specific problems in mind from their job. The reach is small, but you can have deeper conversations, learn what their problems or use cases are, and show how your product can help. Conferences are &lt;em>very&lt;/em> expensive when you count travel, time and sponsorship, but can lead to some big deals if, and only if, you meet the right people there. The return on investment (ROI) can vary dramatically. It&amp;rsquo;s also hard to measure the ROI as someone who you didn&amp;rsquo;t track as a lead may be responsible for a huge sale!&lt;/p>
&lt;p>Conferences can also help with other parts of your job, such as validating your customer base for product market fit, and testing out product messaging&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Workshops - Workshops are an interesting way to reach developers. Often these take up a large amount of a developers time, or even cost money. If a developer is wiling to make that kind of commitment, then they are interested in solving a problem that your product might help with. Small turn out, but very engaged.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Meetups and smaller community events - These are events usually with a technology focus. If your product fits into that technology (such as talking about Python SDK generation at a Python meetup), they can be a relatively cheap and low lift way to put your message to the audience. In person meetups might come with travel cost and maybe pizza and drinks, remote ones can be done from home. The audiences are typically small, and the ROI can vary. Meetup organizers are always looking for speakers - they are the commodity in the shortest supply, so it is relatively easy to get a speaking slot.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Podcasts and live streams - There is a wealth of podcasts and livestreams out there, some focusing on specific technologies, some very general. The hosts of these shows are always on the lookout for new guests and in return let you promote your product.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Blog posts - Although your first party blog might be ok for organic search, third party blogs are a great place to put content. They likely have a large readership, and allow you to put your message across to their audience. I can cross post to a popular tech blog from the liblab blog and get 100x or even 1000x views in a few days!&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Tech communities - If you are a large company, you may already have a first party tech community that you can promote your product to. For smaller companies there are third party communities you can reach out to. Get involved, show how your product can help, and that can drive awareness.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Organic search - There are a huge number of &lt;a href="https://www.hanselman.com/blog/dark-matter-developers-the-unseen-99">dark matter developers&lt;/a> who will not see your product at conferences or communities, instead they will search for a solution to their problem. This is where good web properties with good SEO can help.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h4 id="raise-awareness">Raise awareness&lt;/h4>
&lt;p>To raise awareness of your product you have to help first, sell last. What I mean by this is when you go where developers are, they have problems to solve so they can go home. You have to ensure the message you have is about how your product can solve their problem. This is the focus of your content, and where storytelling is important. Tell the stories of how your product can solve similar problems and you will hook the developer in.&lt;/p>
&lt;ul>
&lt;li>Bring an authentic message - Your product is the hero in a story starring the developer who is trying to defeat the monster that is a problem. The developer wants to fight the ogre in the swamp that is manually creating and maintaining SDKs, and on their journey to the ogre&amp;rsquo;s lair discovers liblab which gives them the magic to do this. OK - not a talk you would give, but linking it back to the classic storytelling - a protagonist, an antagonist, a journey, a &lt;a href="https://en.wikipedia.org/wiki/MacGuffin">MacGuffin&lt;/a>, and a happy ending. Your product is the MacGuffin, your content is the guide on the journey.&lt;/li>
&lt;li>Know your audience - The most important thing about content creation is knowing your audience. If you are reaching out to a Python community, then don&amp;rsquo;t show off your TypeScript SDK. Talking about API governance at a conference focusing on UI design is a waste of time. Pick the places where developers are who your product can help.&lt;/li>
&lt;li>Reuse content - Content creation is hard and time consuming. Always think about how you can re-use content to get more mileage. You have a tutorial on using yor product with AI? Can you make a workshop, video or conference talk out of this? You are going to a conference to give a talk? Are there any meetups local to the conference where you can give the same talk at?&lt;/li>
&lt;/ul>
&lt;h3 id="evaluate">Evaluate&lt;/h3>
&lt;p>Once developers are aware of your product, they want to evaluate it. This will be where you can start to bring them back to your first party content.&lt;/p>
&lt;p>To evaluate your product, a developer may do one or more of the following:&lt;/p>
&lt;ul>
&lt;li>Consume more content to see if your product matches their use case&lt;/li>
&lt;li>Sign up for/install your product&lt;/li>
&lt;li>Work through a &amp;lsquo;hello world&amp;rsquo;, a tutorial, quickstart or other getting started guide&lt;/li>
&lt;li>Join your community, such as your Discord server&lt;/li>
&lt;/ul>
&lt;p>Most of this is content. If you are a developer advocate, you might be responsible for creating this content, or you may have a technical writing team to do it for you.&lt;/p>
&lt;p>The goal here is to get the developer quickly to a point where they feel your product can solve their problem. You need to provide a mixture of content so that the developer can see something that is close to their use case so they can do a relevant evaluation. Obviously this is hard as there are infinite use cases, but you should be able to pick a few broad topics that cover most, especially if you have defined a number of ICPs.&lt;/p>
&lt;p>To evaluate, you need as few gates as possible. Yeah, an email address to sign up is normal, but if a developer has to talk to a person to get a trial then it won&amp;rsquo;t happen. Your product needs to be self service, with a free tier that is enough to fully evaluate. As a dev rel, you are responsible for product feedback, and that includes feedback on the size of this trial. As an engineer yourself, can you evaluate with the available trial? If not, it needs to be changed.&lt;/p>
&lt;h3 id="learn">Learn&lt;/h3>
&lt;p>Once the developer has evaluated your product an decided it is for them, they need to learn more. This is where good documentation is vital. If the developer cannot find out how to solve their problems, then they will go elsewhere. As a dev rel you may be responsible for the docs, or you may have a team to do this. At the very least, you are responsible for product feedback, and that includes feedback on documentation. Yes - documentation &lt;strong>is&lt;/strong> a product and anyone who says different is very, very wrong.&lt;/p>
&lt;blockquote>
&lt;p>If it&amp;rsquo;s not documented it doesn&amp;rsquo;t exist.&lt;/p>
&lt;/blockquote>
&lt;p>In dev rel, you should always be reading and using your docs. Any thing missing or wrong - you should work to get it fixed, whether that is writing those docs yourself, or working with the documentation team to get them fixed.&lt;/p>
&lt;p>Your documentation needs to help the developer learn all they need. This means you need a mixture of docs - reference documentation, tutorials, concepts, all packaged up in a way that quickly allows the developer to get their answers.&lt;/p>
&lt;h3 id="build">Build&lt;/h3>
&lt;p>After learning what they need, the developer will start building with your product. Learn and Build usually go hand in hand - reading docs whilst building out with your product. Building is the phase where they are in proof-of-concept (PoC), or even production mode. By now they may have paid you a little, or have approval to pay you once their trial runs out. For your company to get the bigger payout, they need to be successful.&lt;/p>
&lt;p>This is where support, community and documentation are important. You don&amp;rsquo;t want the developer to get stuck on the build out, not complete, and not convert from a free trial. You may have a support team to help, but dev rel folks should be monitoring the popular support requests and use that as feedback on what content to create. How you do this depends on your support team - maybe a meeting once a month to get the most popular issues, then you write docs for these.&lt;/p>
&lt;p>Developers like communities - they want to ask questions on stack overflow or a Discord server. Again, in dev rel part of this sits on your shoulders. Even if you have a support team to do this, you need to be aware of the trends to build content. If you don&amp;rsquo;t have a support team then set aside some time each day or week to scan stack overflow and your community tools to provide help, and encourage engineers to do this to!&lt;/p>
&lt;p>If you see developers being active with your product then dropping off, don&amp;rsquo;t be afraid to reach out to them. Help first and all that. &amp;lsquo;Hey, I saw you were using our tool then stopped at this point, are you stuck on something that I can help with?&amp;rsquo; type messages can achieve a lot. Often providing a simple answer or guidance can unblock them and get them back building. And of course, update this into your documentation!&lt;/p>
&lt;h3 id="scale">Scale&lt;/h3>
&lt;p>By scale, I mean developers scaling out what they have built. Using your product more, using it in different ways, using different parts of it. Taking what they have built and moving it to production.&lt;/p>
&lt;p>Hopefully by this point, your job is pretty much done. The main responsibility you have here is to ensure the content is available to show how to scale. For example, with liblab, scale to me is taking their SDK generation and setting it up in a CI/CD pipeline so that they can forget about it and get new SDKs when they update their API specs. This is a relatively complicated thing to set up (relative to generating an SDK as there are a few moving parts, but not complicated compared to kubernetes).&lt;/p>
&lt;p>For developers to scale like this, they need to know how. Not just the steps to take, but the why of each step so they can apply it to their use case. For example, if you have developers deploying your product to public clouds, then you want docs on how to do it on AWS, Azure and GCP. If you only have AWS docs and they use Azure, then they will struggle to scale.&lt;/p>
&lt;h3 id="whats-after-scale">What&amp;rsquo;s after scale?&lt;/h3>
&lt;p>At this point the developer journey is not done. Yes they have their problem solved and they can go home, but a new day is a new problem. The cycle starts again with whatever new problem they have, or whatever new product you have for them.&lt;/p>
&lt;h2 id="scaling-dev-rel">Scaling dev rel&lt;/h2>
&lt;p>So far I&amp;rsquo;ve talked about the journey developers take and how dev rel fits in. The biggest issue dev rels have with this is one of scale. You likely have a small dev rel team, but a huge user base, so how do you scale?&lt;/p>
&lt;p>As a note, and I did say I won&amp;rsquo;t cover metrics here, you can only scale if you can show you are scaling. And that means metrics and tracking. You do need to be able to show that scaling is working.&lt;/p>
&lt;p>There are a number of ways to scale, and here are a few.&lt;/p>
&lt;h3 id="reduce-reuse-recycle">Reduce, reuse, recycle&lt;/h3>
&lt;p>A lot of dev rel time is spent on content, be that writing talks, creating videos, writing sample code, or writing blog posts. The most effective thing you can do is re-use as much as possible. Spend less time creating, more time sharing. The downside is that a lot of dev rel folks love building the new shiny thing, but you need to avoid the temptation to create a new talk every time.&lt;/p>
&lt;p>For example - back at Microsoft I created a sample mobile app with Xamarin to show some of the Azure AI services. Here&amp;rsquo;s how I scaled it:&lt;/p>
&lt;ul>
&lt;li>A GitHub repo with code samples shared on social and blogs&lt;/li>
&lt;li>Feedback on the docs based off building this app&lt;/li>
&lt;li>A video showing the app and code on a popular show&lt;/li>
&lt;li>A workshop that taught people to build the app.
&lt;ul>
&lt;li>Gave this to team mates to run&lt;/li>
&lt;li>Ran this at multiple events&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>One code sample became a lot of content, reaching probably at least 500 workshop attendees - and if someone is attending a workshop then they are very engaged and less likely to fall out of the funnel. Oh, and in the case of this workshop, one group of attendees went on to build an app in production for &lt;a href="https://devblogs.microsoft.com/xamarin/customer-showcase-the-academy-of-motion-picture-arts-sciences/">the Oscars&lt;/a>!&lt;/p>
&lt;h3 id="online-vs-in-person">Online vs in-person&lt;/h3>
&lt;p>This is a thorny topic as there are very different opinions and data, but online reaches orders of magnitude more people than in-person for the same amount of effort. I can go to a conference, spend 2 days traveling and 2 days at the event to reach maybe 100 people with a talk. Or I can give that same talk 10 times in less time on-line to different communities and reach thousands. Microsoft saw this with MS Build - instead of 6,000 in-person attendees then had 160,000 online.&lt;/p>
&lt;p>Now there are lies, damned lies, and statistics - so how important is this difference?&lt;/p>
&lt;p>Well the jury is still out on that. In person means more engagement. If someone comes to a talk they are genuinely interested. If they are watching online are they actually watching? Or is it on in the background whilst they do something else.&lt;/p>
&lt;p>I wish I had hard data for this, but I don&amp;rsquo;t so my gut feel is a mix of both. Having seen a good ROI from in-person events that are targeted to a relevant audience (for example talking about SDK generation for APIs at an API conference), there is benefit to in-person, but it doesn&amp;rsquo;t scale like on-line.&lt;/p>
&lt;h3 id="reach-more-developers-by-going-where-developers-are">Reach more developers by going where developers are&lt;/h3>
&lt;p>To scale well you need reach. I&amp;rsquo;ve seen for example the same post get 3,000 views on DZone, and less than 25 on dev.to. By putting your content where developers are it helps scale. This also means your content needs to be of the right type for where those developers are. There&amp;rsquo;s always debate on blogs vs video, but my take is both and measure. YouTube is the worlds number 2 search engine, so a well constructed video with a good description and title can reach a massive audience. But then there are those who prefer to read, or skim read, or want a TikTok.&lt;/p>
&lt;p>And when I say measure - try to get good data. Views on a blog may mean a lot of engaged developers, or lots of quick view and bounce. Are you seeing folks following links from the blogs to your properties (you are tracking this right?).&lt;/p>
&lt;p>Same with YouTube views. I remember back at Microsoft a load of congratulatory emails and lots of talk about an amazing video that a colleague did on generative AI that got 40,000 views. Even went way up the chain. Ignoring how 40K is a small number for a multi-trillion dollar company, no-one bothered to validate the views. If they had, they would have noticed that most of the 40k views were around 5 seconds and were from ads. Yup - there was an experiment done to run videos as ads to boost views, and that is why this had so many. Obviously for political reasons, when this was pointed out it was hushed up&amp;hellip;&lt;/p>
&lt;p>So, go where developers are, validate your reach there, and use that data to help scale.&lt;/p>
&lt;h3 id="follow-trends">Follow trends&lt;/h3>
&lt;p>Another way to scale is to create content to &amp;lsquo;go viral&amp;rsquo;, that is follow trends, If a topic is getting a lot of interest, see how you can apply your product to that topic. LLMs and Generative AI is big, so I created a video using a popular AI framework from Microsoft just as that framework was getting promotion by them. It has my highest personal video views! This was simply by riding the promotional wave from Microsoft.&lt;/p>
&lt;h3 id="community">Community&lt;/h3>
&lt;p>Community is how you can really scale! A good community becomes almost like a volunteer dev rel team. Having been a Xamarin MVP and a Microsoft MVP I know well how community will promote a product in their own time and at their own expense - I&amp;rsquo;ve spent my own money on travel just to talk about a technology owned by a trillion dollar company.&lt;/p>
&lt;p>Community helps with the scale simply by shear volume. A community of 10 heros can reach substantially more that 1 dev rel, including reaching geographies and time zones that are not easily available. A community hero in China giving a talk on your product in Mandarin can reach developers an English-only speaking developer advocate in the US simply cannot reach. The more you grow your community, the more they will promote your product.&lt;/p>
&lt;p>The advantage of your community is they are already engaged. people join your community because at the very least they are aware of your product, though more likely a user. Folks don&amp;rsquo;t discover your slack by chance and hang out.&lt;/p>
&lt;p>So how to do you grow your community? Well a &amp;lsquo;community&amp;rsquo; has 3 types of members:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Passive - these are the folks who join your slack to ask a question, maybe follow you on social and leave. You need to support them as they are users, but they won&amp;rsquo;t help you scale. What they are helpful for is product feedback - the questions they are asking, should they be answered in the docs? Are they reporting bugs or fewture requests?. Your goal here is to make them active, but be aware most of them simply won&amp;rsquo;t be.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Active - these are the folks who are active in your community space. They might be answering questions on your Discord, or maybe writing the odd blog post on your product. They can help you scale support, as well as driving some awareness. Your goal here is to convert these to heros.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Heros - these are your very active, highly engaged, community superstars. These are community members who actively promote your product. Maybe then run a user group, or regularly speak at events about your technology. Maybe they write blog posts, or create videos. Their message is the most authentic - they are talking about your product because they like it, not because they are paid (like you). Your goal here is to support them as much as possible. At the very least they should have free access to your product, along with swag. Ideally you should provide swag for them to distribute like bags of stickers, custom rewards like personal shirts, and a public way to highlight them. Recognition is usually the most valuable currency here, not just recognizing then publicly, but by gathering feedback from them. Getting time with product or engineering is a great way to not only make them feel special, but also can give you important feedback. If you have the budget, provide them sponsorship such as paying conference travel, or buying pizza for their user group. You can also help provide them with content, such as demos and slides for a talk.&lt;/p>
&lt;p>Your goal here is to support them as much as possible. You want them to remain heros as long as possible, and not turn them into heros for your competition.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>I was listening to &lt;a href="https://www.youtube.com/live/VZWRLN6K65I?si=TplbU7SrRf0xGAci">an episode of Dev Relish today&lt;/a> that described community as a Tamagotchi. For it to live and thrive it takes regular feeding. Not much effort, but small and continual. You need to build that muscle of regularly &amp;lsquo;feeding&amp;rsquo; your community.&lt;/p>
&lt;h2 id="what-else-is-dev-rel">What else is dev rel?&lt;/h2>
&lt;p>I feel the focus of this post has been more on the advocacy side of dev rel, as that is the area I am in. I do want to acknowledge that there are many other facets to developer relations that help build a relationship with developers:&lt;/p>
&lt;ul>
&lt;li>Technical writing teams - dev rels sometimes own and write docs, other times there are dedicated teams. And this is not just docs, it can be online learning tools or other such learning materials&lt;/li>
&lt;li>Content creators and supporters - some companies have dedicated studio teams, or storytellers, or demo writing teams&lt;/li>
&lt;li>Developer-focused engineers - some engineers focus on helping developers directly, rather then by building products. This includes generating SDKs, or building helper scripts, sample code, or other tools&lt;/li>
&lt;li>Community managers - in an ideal world you would have a community manager to feed the Tamagotchi. These are folks whose skills lie in managing communities, such as program management.&lt;/li>
&lt;li>Marketing - marketing spread the word, and can be your friend. They also usually have money which helps with swag!&lt;/li>
&lt;li>Events teams - if you are running an in-house event, or attending an external one, an event team can make this a much smoother process&lt;/li>
&lt;/ul>
&lt;p>I&amp;rsquo;m sure there are more. I know some will say &amp;rsquo;this is not dev rel&amp;rsquo;, but it is. It may not be dev advocacy, but dev rel is a whole world more than that.&lt;/p>
&lt;h2 id="what-is-not-dev-rel">What is not dev rel?&lt;/h2>
&lt;p>So far I&amp;rsquo;ve talked a lot about what is dev rel and how you can scale. Lets take a second to talk about what is not dev rel. This is another topic where there are many opinions, but my (potentially 🌶️) opinion is:&lt;/p>
&lt;blockquote>
&lt;p>If you are personally responsible for getting money then it is not dev rel&lt;/p>
&lt;/blockquote>
&lt;p>Now we all want to get paid, and really the end outcome of dev rel is more customers, so dev rel is part of the sales funnel. But to me the line is when money is involved, such as negotiating contracts, commissions etc. then that is sales. Help first, sell last - to authentically help someone it needs to come from a place of wanting to help, not from driving more sales. An authentic dev rel should be willing to help you spend less by optimizing what you use, or telling you outright if the product will not help you. Having worked in places where sales will sell something that doesn&amp;rsquo;t exist (yup, happened to me), I&amp;rsquo;ve seen that money and commission are not a good driver of the right behaviors, and do not help with authentic conversations.&lt;/p>
&lt;p>I&amp;rsquo;m not covering metrics here, but dev rel should never be measured sales. Yes - tracking dev rel qualified leads is good, but not &amp;lsquo;dev advocate X made this $100K sale&amp;rsquo;&lt;/p>
&lt;p>Help first, sell last - and let someone else sell.&lt;/p>
&lt;h2 id="conclusion">Conclusion&lt;/h2>
&lt;p>I hope this brain dump sheds some light on what I think dev rel is. As with anything, ask 10 dev rels what it is and you&amp;rsquo;ll get 12 answers at least. There&amp;rsquo;s so much I&amp;rsquo;ve missed - I literally could write a book on this topic, but I won&amp;rsquo;t - I&amp;rsquo;ll save that for the experts.&lt;/p>
&lt;p>Remember: &lt;strong>Help first, sell last&lt;/strong>. Authentically go where developers are and bring them back to your product, content and communities.&lt;/p>
&lt;p>I&amp;rsquo;d love your thoughts in the comments, or reach out to me on social: &lt;a href="https://linktr.ee/jimbobbennett">linktr.ee/jimbobbennett&lt;/a>.&lt;/p></description></item><item><title>How to correctly review a pull request</title><link>https://jimbobbennett.dev/blogs/how-to-review-a-pr/</link><pubDate>Mon, 01 Apr 2024 00:00:00 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/how-to-review-a-pr/</guid><description>&lt;p>One of my popular sayings is that development is a team sport. We don&amp;rsquo;t code in isolation, instead engineers are part of a team that delivers value to users and customers, often made up of software. And for a team to deliver its best code, there needs to be shared ownership of the code. This means that more than one developer is involved in each code change to ensure that it is correct, appropriate, and that the knowledge of this change is shared amongst the team. While there are many techniques for this (such as pair and mob programming), the most popular one is a simple pull request, or PR.&lt;/p>
&lt;h2 id="what-is-a-pull-request">What is a pull request?&lt;/h2>
&lt;p>A pull request, or PR, is a git feature that allows you to request that the owner of some code pulls your changes. You make a code change on a fork or branch, and raise a pull request to merge your code into the golden source, origin, or upstream repo. Essentially this is how you get your code published to the team ready to be deployed to production.&lt;/p>
&lt;p>The aim of a pull request is to get another set of eyes over your code. Before a PR is merged, it is reviewed. The reviewer can check the code for correctness, style, if it actually implements the feature it&amp;rsquo;s meant to, things like that. This is the opportunity for a second pair of eyes to catch any errors, for knowledge sharing so more than one member of the team understands the new code, and a chance for more senior developers to help guide and upskill more junior developers.&lt;/p>
&lt;p>The problem with PRs though, is often the reviews are done badly. The infamous LGTM 👍 (looks good to me). Especially with large PRs that take a lot of time.&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/217029/181068444-9a21be12-9ed3-42cb-95d3-594e75d6192c.png" alt="A twitter post from I am developer saying 10 lines of code = 10 issues. 500 lines of code = looks fine.">&lt;/p>
&lt;h2 id="so-why-are-we-so-bad-at-reviewing-prs">So why are we so bad at reviewing PRs?&lt;/h2>
&lt;p>The reason is simple - time. Reviewing a 5 line change is potentially quick, so a reviewer can check it, and ask for changes in a short space of time. Give a developer 100 files then the review is often little more than a cursory glace as there isn&amp;rsquo;t enough time to do a full review. After all reviewing code isn&amp;rsquo;t delivering features!&lt;/p>
&lt;p>Having seen some very bad PR reviews in my time, and poor code released because of it, I thought I&amp;rsquo;d scribble down some of my top tips for doing PR reviews right. Add any more thoughts to the comments!&lt;/p>
&lt;h2 id="how-to-do-a-better-job-of-reviewing-prs">How to do a better job of reviewing PRs&lt;/h2>
&lt;h3 id="1-allocate-time-to-do-it">1. Allocate time to do it&lt;/h3>
&lt;p>This is often something that you as a reviewer can&amp;rsquo;t do, but something you should advocate for and your leadership needs to understand. PR reviews take time. If you expect an engineer to be 100% on feature work, not only do you risk burnout, but it means there is literally no time to review PRs. Everything, no matter how bad will be LGTM 👍, merged and cause problems downstream.&lt;/p>
&lt;p>This makes sense for engineers - there&amp;rsquo;s not time to review a PR to catch a bug, but it&amp;rsquo;s easy to get time allocated in a sprint to fix the bugs that get through. Your processes drive poor engineering practice.&lt;/p>
&lt;p>Ideally an engineer should be 60% feature work, 20% run the business, 20% spare (vacations, sick time, dealing with weird issues that reduce your ability to work like your OS shitting itself). The 20% run the business should be enough to review PRs, and if not - allocate more time (or move to pair programming, but that takes more to convince management who see people as resources with linear delivery capability).&lt;/p>
&lt;p>Now you have time to do a proper PR review, next you need to review the ticket!&lt;/p>
&lt;h3 id="2-review-the-ticket">2. Review the ticket&lt;/h3>
&lt;p>All good PRs start with a ticket of some description. This is (typically) a ticket in Jira that details the work that is done. But these are not code, so why do you care if you are reviewing a PR? Well the ticket explains the intention of the change. What bug is being fixed, what feature is being added. Without a good detailed ticket, how can you very the code works?&lt;/p>
&lt;p>So what makes a good ticket? This is blog post in its own right, but here are some thoughts:&lt;/p>
&lt;ul>
&lt;li>It exists. Simply having a ticket is a start. No ticket, then no change. All PRs without a ticket should be rejected as how can you ensure the change is correct?&lt;/li>
&lt;li>It explains the why of the change. When you know why you can think about the implementation from the perspective of the end user. Helps when you think about the test cases or ways to test the code.&lt;/li>
&lt;li>It explains the change in as much detail as possible. Move a button? Ok, where, by how much. Add a new API? What endpoint, what is the request and response body?&lt;/li>
&lt;li>It defines some test cases. In a perfect world these should be exhaustive, but it should at least direct some ways to verify the change. Add a feature to calculate X - he are some sample inputs and outputs.&lt;/li>
&lt;li>It defines any impact on other parts of the system. Does it require a downstream change? Should documentation be updated?&lt;/li>
&lt;/ul>
&lt;p>Once you are happy with the ticket you can review the code. Not happy - punt it back to the developer or product owner to get it to a good state. Sometimes just by doing this you will catch things the developer missed and get bugs fixed or missing features implemented before you have even looked at the PR.&lt;/p>
&lt;h3 id="3-does-the-code-work">3. Does the code work?&lt;/h3>
&lt;p>Code should work. The ticket defines the change, and the code should implement it. Before reviewing the code, I like to take it for a spin and see if it actually does what it is meant to do in the context of the whole system. Yes, this usually means some manual testing but again you can catch issues quickly. Not always easy, but there are usually ways and test harnesses to test features in components of a larger system. This is where a good ticket also helps - it can define what you need to test, expected outputs for inputs, and give you a good direction to test edge cases.&lt;/p>
&lt;p>But what about unit tests? I&amp;rsquo;ll cover these next, but the presence of unit tests doesn&amp;rsquo;t always mean tha the code works. I&amp;rsquo;ve had situations when reviewing a PR where all the tests passed but the code didn&amp;rsquo;t do what was needed when I tested the whole system. Multiple times I showed the engineer the issue, they added unit tests, told me it worked because their unit tests passed, but it didn&amp;rsquo;t work.&lt;/p>
&lt;p>For example, if you have an add function and write the following tests: add 2 and 2 to get 4, add 3 and 1 to get 4, and 0 and 4 to get 4. Do these tests show the code works, or that you have a function that always returns 4?&lt;/p>
&lt;p>There&amp;rsquo;s no point in reviewing code if it doesn&amp;rsquo;t work.&lt;/p>
&lt;h3 id="4-does-the-code-have-automated-tests">4. Does the code have automated tests?&lt;/h3>
&lt;p>The next step with testing - what about the automated tests? Does the code have unit test, integration tests, UI tests etc. If not - should it (probably). If yes, do they run, pass, and actually test the code?&lt;/p>
&lt;p>I find reviewing the test code first is a good thing to do. If there are obvious test cases missed, edge cases not considered, or poor tests, then you want these fixed before you review the core code.&lt;/p>
&lt;p>Can you see in the PR that the tests have run and passed? As above - no point in reviewing code that doesn&amp;rsquo;t work. A PR should run as many unit test as is practical, and there should be guards that block merges if any tests fail.&lt;/p>
&lt;h3 id="5-can-you-understand-the-code">5. Can you understand the code?&lt;/h3>
&lt;p>Now it is time to review the code. The first thing to review is do you understand it? If you don&amp;rsquo;t understand the code and what it does then you can&amp;rsquo;t review it. It should be reasonably obvious to someone who understands the system and context of the changes. It should also be readable. Does the code have sensible names for variables, functions, and classes? Are there code comments explaining the why of the code?&lt;/p>
&lt;blockquote>
&lt;p>Anyone who ways code comments are not needed is wrong. Yes - well named things explain what the code does, but comments explain the why. There is no need to comment a getter to say it gets a value, but you want to explain why you are getting that value in the code and doing things with it&lt;/p>
&lt;/blockquote>
&lt;p>Readability is important in code. I know some developers like to play code golf and solve a problem in as few lines as possible, but sacrificing readability is a terrible thing. You are writing code so humans can understand it, so don&amp;rsquo;t be clever, be clear, concise, and obvious. When reviewing code is it clear to the reader what it is doing and why? Your code should be obvious to the most junior developer on the team - remember code is owned by the team, not the engineer who wrote it, so needs to be accessible to everyone.&lt;/p>
&lt;h3 id="6-is-the-code-good">6. Is the code good?&lt;/h3>
&lt;p>Lastly is the code &amp;lsquo;good&amp;rsquo; - and by good I mean following team standards. This could include coding standards (tools help here), but also does it follow conventions, is it implemented in a consistent way with the rest of the code base.&lt;/p>
&lt;p>For example - if your code writes a message to the user, is this message defined in a constants file with other messages for i18n? Does it conform to a11y standards? Is the naming convention consistent?&lt;/p>
&lt;p>This is often subjective, so having a good team agreement with coding standards can help with this.&lt;/p>
&lt;p>if it is all good - approve that PR! Any issues, then it&amp;rsquo;s time to leave review comments.&lt;/p>
&lt;h2 id="commenting-on-prs-and-requesting-changes">Commenting on PRs and requesting changes&lt;/h2>
&lt;p>You&amp;rsquo;ve reviewed the code and it&amp;rsquo;s time to leave some comments. Although this post is about reviewing, here are some thoughts on leaving review comments.&lt;/p>
&lt;ul>
&lt;li>Be kind. Don&amp;rsquo;t be an arse, don&amp;rsquo;t be Linus Torvalds. The person receiving these comments is human and a team mate. Be kind and constructive with all your comments.&lt;/li>
&lt;li>Provide detail in the comments. If something needs to be changed, explain why (e.g. move this to a constants file as per our standards).&lt;/li>
&lt;li>Understand that everyone codes differently and personal opinions have no place. You would have written it differently? Well if the way it is done is ok, then don&amp;rsquo;t impose personal opinions on the implementation. If you ask 20 developers how to do something you&amp;rsquo;ll get 30 responses, not all are wrong.&lt;/li>
&lt;li>For more junior developers, this is an opportunity for learning and growth. Give guidance with changes that help with that growth&lt;/li>
&lt;li>Use things like suggestions for small changes like typos to make it quicker to apply changes&lt;/li>
&lt;/ul>
&lt;h2 id="go-review-prs">Go review PRs&lt;/h2>
&lt;p>This was a quick and dirty post to get some thoughts down on this. Let me know your thoughts in the comments!&lt;/p></description></item><item><title>How to generate pre-signed URLs to get and put objects in S3 with Boto3 in Python</title><link>https://jimbobbennett.dev/blogs/get-put-s3-boto/</link><pubDate>Thu, 01 Feb 2024 00:00:00 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/get-put-s3-boto/</guid><description>&lt;p>&lt;img src="banner.webp" alt="A plushie llama putting blocks into a bucket">&lt;/p>
&lt;blockquote>
&lt;p>TL;DR: If your &lt;code>put_object&lt;/code> boto3 pre-signed URLs are failing with access denied errors, add &lt;code>config=Config(signature_version=&amp;quot;s3v4&amp;quot;)&lt;/code> when creating the boto3 client to get a working URL.&lt;/p>
&lt;/blockquote>
&lt;p>I was recently working on some Python code to interact with S3 buckets, where I needed to be able to generate some pre-signed URLs for S3 objects. These are URLs that contain a built-in time-limited credential to allow access, meaning that you can give this URL to anyone and they can read an object, or write it without access to your AWS account or S3 bucket - they only have access to that one object.&lt;/p>
&lt;p>In Python there is a helpful library called &lt;a href="https://boto3.amazonaws.com/v1/documentation/api/latest/index.html#">boto3 from Amazon&lt;/a> that can be used to interact with AWS services. This includes S3, and it has a method to generate pre-signed URLs for objects.&lt;/p>
&lt;h2 id="get-started-with-boto3">Get started with boto3&lt;/h2>
&lt;h3 id="set-your-credentials">Set your credentials&lt;/h3>
&lt;p>You can only access S3 if you have the correct credentials. These are your AWS access key and secret key, and need to be set in your AWS credentials file using the AWS CLI:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>aws configure
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Or you can edit the &lt;code>~/.aws/credentials&lt;/code> file directly:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-ini" data-lang="ini">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">[default]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">aws_access_key_id&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">YOUR_ACCESS_KEY&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">aws_secret_access_key&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">YOUR_SECRET&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="install-boto3">Install boto3&lt;/h3>
&lt;p>To use boto3, you need to install it in your current Python environment. This can be done with pip:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>pip install boto3
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Obviously using a virtual environment or a development container is a good idea, but I&amp;rsquo;ll leave that up to you 😁.&lt;/p>
&lt;p>Once done, you just need to import boto3 into your Python code:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> boto3
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Then you need to create a client for the service you want to use. In this case, S3:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>region &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#39;us-east-1&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>s3 &lt;span style="color:#f92672">=&lt;/span> boto3&lt;span style="color:#f92672">.&lt;/span>client(&lt;span style="color:#e6db74">&amp;#39;s3&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> region_name&lt;span style="color:#f92672">=&lt;/span>region)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Clients are regional, so you need to specify the region you want to use. In this case, I&amp;rsquo;m using &lt;code>us-east-1&lt;/code>.&lt;/p>
&lt;h2 id="create-pre-signed-urls">Create pre-signed URLs&lt;/h2>
&lt;p>Once the client is created, you can use it to generate pre-signed URLs for objects in your S3 bucket using the &lt;code>generate_presigned_url&lt;/code> method.&lt;/p>
&lt;h3 id="create-a-get-object-pre-signed-url">Create a get object pre-signed URL&lt;/h3>
&lt;p>The first case I needed was for someone to be able to download an object from my S3 bucket. In AWS, this is the &lt;code>get_object&lt;/code> client method.&lt;/p>
&lt;p>Here is the code to generate a pre-signed URL for getting an object in an S3 bucket:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>url &lt;span style="color:#f92672">=&lt;/span> s3&lt;span style="color:#f92672">.&lt;/span>generate_presigned_url(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ClientMethod&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;get_object&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Params&lt;span style="color:#f92672">=&lt;/span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#39;Bucket&amp;#39;&lt;/span>: &lt;span style="color:#e6db74">&amp;#39;my-bucket&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#39;Key&amp;#39;&lt;/span>: &lt;span style="color:#e6db74">&amp;#39;my-object&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> },
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ExpiresIn&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">3600&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This takes the client method - &lt;code>get_object&lt;/code>, the parameters - the bucket and the object key, and the time the URL is valid for in seconds.&lt;/p>
&lt;p>This gives you a working URL that anyone can use for the object &lt;code>my-object&lt;/code> in the bucket &lt;code>my-bucket&lt;/code> that is valid for 3600 seconds, or 1 hour. You share that URL with someone, and they can download that one object only.&lt;/p>
&lt;h3 id="create-a-put-object-pre-signed-url">Create a put object pre-signed URL&lt;/h3>
&lt;p>The second case I needed was for someone to be able to upload an object to my S3 bucket. In AWS, this is the &lt;code>put_object&lt;/code> client method.&lt;/p>
&lt;p>Now, in theory this is the same as the &lt;code>get_object&lt;/code> call just with a different client method:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>url &lt;span style="color:#f92672">=&lt;/span> s3&lt;span style="color:#f92672">.&lt;/span>generate_presigned_url(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ClientMethod&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;put_object&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Params&lt;span style="color:#f92672">=&lt;/span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#39;Bucket&amp;#39;&lt;/span>: &lt;span style="color:#e6db74">&amp;#39;my-bucket&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#39;Key&amp;#39;&lt;/span>: &lt;span style="color:#e6db74">&amp;#39;new-object&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> },
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ExpiresIn&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">3600&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>As we all know, theory and practice are the same in theory, but not in practice. This code will generate a URL, but when you try to use it, you will get an XML document with an access denied error.&lt;/p>
&lt;pre tabindex="0">&lt;code class="language-output" data-lang="output">The request signature we calculated does not match the signature
&lt;/code>&lt;/pre>&lt;p>This took hours to get to the bottom of, but after plenty of S3 reconfiguration and some googling, I found the solution in &lt;a href="https://stackoverflow.com/a/63791634/1034742">an answer buried in this stack overflow question&lt;/a>&lt;/p>
&lt;p>&lt;img src="so-answer.webp" alt="A stack overflow answer saying For Python set - signature_version s3v4">&lt;/p>
&lt;p>It seems this configuration option is not well documented. It is mentioned in the &lt;a href="https://botocore.amazonaws.com/v1/documentation/api/latest/reference/config.html">boto config docs&lt;/a> but without any details on why you need a different signature version for &lt;code>put_object&lt;/code> URLs, or what the default is.&lt;/p>
&lt;p>So, to generate a working pre-signed URL for &lt;code>put_object&lt;/code> in S3, you need to add the &lt;code>signature_version&lt;/code> to the &lt;code>Config&lt;/code> object when creating the client:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> botocore.config &lt;span style="color:#f92672">import&lt;/span> Config
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>s3 &lt;span style="color:#f92672">=&lt;/span> boto3&lt;span style="color:#f92672">.&lt;/span>client(&lt;span style="color:#e6db74">&amp;#39;s3&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> region_name&lt;span style="color:#f92672">=&lt;/span>region,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> config&lt;span style="color:#f92672">=&lt;/span>Config(signature_version&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;s3v4&amp;#34;&lt;/span>))
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Once you have done this, the code above to generate a pre-signed URL for &lt;code>put_object&lt;/code> will create a URL that works as expected. You can now share this with anyone and they will be able to upload a new object to your S3 bucket, with the key given in the params.&lt;/p>
&lt;p>In the example above, they would be able to upload an object to the bucket &lt;code>my-bucket&lt;/code> with the key &lt;code>new-object&lt;/code>. Again, the URL has an expiry, so is valid for 3600 seconds, or 1 hour.&lt;/p>
&lt;h2 id="conclusion">Conclusion&lt;/h2>
&lt;p>&lt;a href="https://stackoverflow.com/users/6514028/saurav-sarkar">Saurav Sakar&lt;/a>, you are my hero! If you are creating re-signed URLs, make sure to set the &lt;code>signature_version&lt;/code> to &lt;code>s3v4&lt;/code> in the &lt;code>Config&lt;/code> object when creating the client.&lt;/p></description></item><item><title>Connect to localhost from inside a dev container</title><link>https://jimbobbennett.dev/blogs/access-localhost-from-dev-container/</link><pubDate>Mon, 20 Nov 2023 00:00:00 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/access-localhost-from-dev-container/</guid><description>&lt;p>I do a lot of work in dev containers (for example, using &lt;a href="https://jimbobbennett.dev/blogs/liblab-in-a-devcontainer/">liblab inside of one&lt;/a>), often hosting APIs. One problem I used to often hit is how can I host an API in one container, and access it from another dev container? This post shows you how.&lt;/p>
&lt;h2 id="the-problem---localhost-in-a-container">The problem - &amp;rsquo;localhost&amp;rsquo; in a container&lt;/h2>
&lt;p>So the issue is this:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Dev container A&lt;/strong> exposes an API on port 8000, and this is forwarded to localhost&lt;/li>
&lt;li>I can access this port at &lt;code>localhost:8000&lt;/code> either inside &lt;strong>dev container A&lt;/strong>, or from my local machine as the dev container forwards the port&lt;/li>
&lt;li>&lt;strong>Dev container B&lt;/strong> needs to access the API&lt;/li>
&lt;/ul>
&lt;p>The problem here is &lt;strong>dev container B&lt;/strong> has no access to my local machine. Docker forwards the ports from &lt;strong>dev container A&lt;/strong> to localhost automatically as soon as I run the API. But ports from my local machine are not forwarded into dev containers.&lt;/p>
&lt;ul>
&lt;li>If &lt;strong>Dev container A&lt;/strong> accesses &lt;code>localhost:8000&lt;/code>, it gets the API running on &lt;strong>Dev container A&lt;/strong>&lt;/li>
&lt;li>If my local machine accesses &lt;code>localhost:8000&lt;/code>, it gets the API running on &lt;strong>Dev container A&lt;/strong> because the port on &lt;strong>Dev container A&lt;/strong> is forwarded to localhost, as far as the local machine is concerned, 8000 is open and accepting requests.&lt;/li>
&lt;li>If &lt;strong>Dev container B&lt;/strong> accesses &lt;code>localhost:8000&lt;/code> it will fail, as there is nothing running on port 8000 inside that container.&lt;/li>
&lt;/ul>
&lt;p>So how can one dev container access ports exposed by another?&lt;/p>
&lt;h2 id="enter-the-hostdockerinternal-network">Enter the host.docker.internal network&lt;/h2>
&lt;p>Docker has a fix for this! It exposes a &amp;lsquo;special&amp;rsquo; &lt;a href="https://docs.docker.com/desktop/networking/#i-want-to-connect-from-a-container-to-a-service-on-the-host">DNS called &lt;code>host.docker.internal&lt;/code>&lt;/a> that essentially gives to access to the local machines network. Rather than access localhost, you access this named device instead.&lt;/p>
&lt;p>So from &lt;strong>Dev container B&lt;/strong>, you access &lt;code>host.docker.internal:8000&lt;/code> and boom! &lt;strong>Dev container B&lt;/strong> can access the API from &lt;strong>Dev container A&lt;/strong>!&lt;/p>
&lt;p>For example, you are testing out an SDK created against an API you are running on port 8000 via a dev container (for example, the &lt;a href="https://github.com/liblaber/llama-store">liblab llama store&lt;/a>), and you want to take advantage of the &lt;a href="https://developers.liblab.com/cli/config-file-overview-customizations/#devcontainer">dev containers feature of liblab to open our SDK in a container&lt;/a>. You can set the &lt;code>baseUrl&lt;/code> in your &lt;code>liblab.config.json&lt;/code> file to &lt;code>http://host.docker.internal:8000&lt;/code>, then open the generated SDK in its dev container!&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-json" data-lang="json">&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;sdkName&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;llama-game&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;specFilePath&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;http://localhost:8000/openapi.json&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;baseUrl&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;http://host.docker.internal:8000&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;languages&amp;#34;&lt;/span>: [
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;python&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;createDocs&amp;#34;&lt;/span>: &lt;span style="color:#66d9ef">true&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;customizations&amp;#34;&lt;/span>: {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;devContainer&amp;#34;&lt;/span>: &lt;span style="color:#66d9ef">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Done! The SDK now defaults to use the docker internal network for testing.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">Environment&lt;/span>(Enum):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;&amp;#34;&amp;#34;The environments available for this SDK&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> DEFAULT &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;http://host.docker.internal:8000&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Don&amp;rsquo;t forget to set it to your production URL once you are ready to publish.&lt;/p></description></item><item><title>Avoiding automation to keep your job</title><link>https://jimbobbennett.dev/blogs/fear-of-automation/</link><pubDate>Mon, 06 Nov 2023 00:00:00 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/fear-of-automation/</guid><description>&lt;p>Will technology, automation, or AI take our jobs? This is something we hear a lot at the moment - but it&amp;rsquo;s always been this way. Right back at the start of my career I automated something that was canned the moment I left as folks were afraid of their job.&lt;/p>
&lt;p>Some background to why I am writing this post. I was reading a tweet today from &lt;a href="https://twitter.com/MichelleBakels">Michelle Bakels&lt;/a> that was a cautionary tale from her enterprise days.&lt;/p>
&lt;blockquote class="twitter-tweet">&lt;p lang="en" dir="ltr">Cautionary tale from enterprise days re: AI/automation:&lt;br>&lt;br>Company touted big Innovation Week where IT interviewed other depts (accounting, marketing, etc.) to find workflow optimizations for the business.&lt;br>&lt;br>After 3 years, the other depts shut down when IT would come for interviews.…&lt;/p>&amp;mdash; Michelle Bakels (@MichelleBakels) &lt;a href="https://twitter.com/MichelleBakels/status/1721597776893489190?ref_src=twsrc%5Etfw">November 6, 2023&lt;/a>&lt;/blockquote> &lt;script async src="https://platform.twitter.com/widgets.js" charset="utf-8">&lt;/script>
&lt;p>I&amp;rsquo;m not going to dump the entire text here - go read the tweet as it&amp;rsquo;s fascinating, but the TL;DR is folks are scared of telling IT what they do in case it is automated and they are out of a job.&lt;/p>
&lt;h2 id="will-technology-replace-thing">Will technology replace &amp;lt;thing&amp;gt;?&lt;/h2>
&lt;p>This is something that is constantly talked about in the tech world, though feels like it has really come to the surface recently with the rise of AI. Will technology replace us? Will AI take our jobs (one of the catalysts of the recent SAG-AFTRA strikes in the TV and movie industry)? Will self-driving cars replace taxies? Will cars replace horses? Will movable type replace handwritten books? The list goes on.&lt;/p>
&lt;p>Rather than dive into this discussion, I thought it would be fun to tell a story of my own - of how I automated something during an internship, and how it got killed the minute I left as folks were worried it would replace their jobs.&lt;/p>
&lt;h2 id="jim-gets-an-internship-at-marconi">Jim gets an internship at Marconi&lt;/h2>
&lt;p>This was just after I graduated in 1999 - I started working on a summer internship at Marconi (&lt;a href="https://youtu.be/K1b8AhIsSYQ?si=i5wCmF8Y2Vbin0cn">plays the mamba, listen to the radio&lt;/a>) in their underwater weapons division. This was probably the start of my route towards being a pacifist and hating all weapons and the military industrial complex.&lt;/p>
&lt;p>&lt;img src="spearfish-torpedo.webp" alt="A spearfish torpedo">&lt;/p>
&lt;p>My job was to analyze torpedo data. Marconi built these $1M Spearfish torpedoes that didn&amp;rsquo;t work very well, and they would do trials on them in various parts of the world (Faslane in Scotland, deep water testing in the Caribbean). The testing torpedoes would record data about their decisions, as well as telemetry such as depth, speed, location etc. They would also record radar data and what they identified in the way of ships. The goal was to drop a torpedo in the water and send it at a ship, then gather the data afterwards to see if it did the right thing. Not quite testing in production as the torpedoes had no explosives, but the closest you can get.&lt;/p>
&lt;h3 id="the-reporting-process">The reporting process&lt;/h3>
&lt;p>Once the trails were over, someone had to analyze the results, and this was the team I was on. The process was horribly manual:&lt;/p>
&lt;ul>
&lt;li>Remotely log into a mainframe and request a printout of the data from the torpedo trial as a hex dump on green and white continuous feed paper.&lt;/li>
&lt;li>Work through the hex dump using highlighters to &amp;lsquo;read&amp;rsquo; what was happening. Hex codes marked the steps in the output, and each one had so many bytes of information. For example, one hex code was for direction and you knew that meant the next X bytes were the direction information, then the next character was the next set of data. Very laborious and error prone&lt;/li>
&lt;li>Enter all this data into an Excel spreadsheet showing each step&lt;/li>
&lt;li>Extract location and direction data and put this into another page on the spreadsheet&lt;/li>
&lt;li>Generate a chart to show the torpedo&amp;rsquo;s movements&lt;/li>
&lt;li>Create a word doc with all the steps that the torpedo did, along with the charts.&lt;/li>
&lt;li>Actually do the analysis and look for issues for the software teams to investigate&lt;/li>
&lt;/ul>
&lt;p>(There are probably more steps which I have forgotten as it was 24 years ago)&lt;/p>
&lt;p>Apart from the last step which actually used your brain, the rest was repetitive and dull. It could easily take a week or to to get a report ready to be able to do the final analysis step. And there was a whole team doing this, most of them ex-Ministry of Defense folks who just wanted to get their pension.&lt;/p>
&lt;h3 id="in-comes-jim-with-an-idea">In comes Jim with an idea!&lt;/h3>
&lt;p>So I had an idea! I was an engineer after all. I could automate all the things, I&amp;rsquo;d be the hero, save the company money and everyone would love me.&lt;/p>
&lt;iframe src="https://giphy.com/embed/PoHTJgxBHCCJ2zCbvf" width="480" height="480" frameBorder="0" class="giphy-embed" allowFullScreen>&lt;/iframe>&lt;p>&lt;a href="https://giphy.com/gifs/outlander-season-4-starz-PoHTJgxBHCCJ2zCbvf">via GIPHY&lt;/a>&lt;/p>
&lt;p>So I set about doing this whilst I was working on a report.&lt;/p>
&lt;h3 id="automate-all-the-things">Automate all the things&lt;/h3>
&lt;p>Firstly I had to automate getting the data - can&amp;rsquo;t do this from a printer. Luckily the mainframe that I logged into to print could just dump the data to the screen. How could I get this in a way I could do things with it? Excel!&lt;/p>
&lt;p>So I wrote some good old VBA in Excel to connect over SSH to the mainframe and download all the data. I had one control sheet that you enter the trial number into, a button to click and away it would go downloading the data and filling out a second sheet.&lt;/p>
&lt;p>Next was replacing the highlighter pen! Easy to do in Excel, work through each cell to get the action for each step, highlight the cells as if I was using a highlighter pen and paper, and extract the data for each action.&lt;/p>
&lt;p>Once I had the actions, it was easy to convert from the hex codes to the steps information that was wanted. Same with locations - easy to extract and plot the chart.&lt;/p>
&lt;p>Finally it was time to create a word doc - and VBA can do this nicely.&lt;/p>
&lt;h3 id="the-result">The result&lt;/h3>
&lt;p>All in all I spent about 4 weeks on this, and was able to generate a report ready for analysis in about 10 minutes, as opposed to 1-2 weeks. I packaged this as an add-in, so anyone could use it - just add the add-in, enter the trial number and away it went and spat out the doc.&lt;/p>
&lt;p>I even gave it a cool name: Spearfish Trials Analysis Report Writers Automated Reporting Suite - or STAR WARS for short (this was a few months after Episode 1 came out after all).&lt;/p>
&lt;p>I was impressed, I could save everyone time!&lt;/p>
&lt;h3 id="the-reception">The reception&lt;/h3>
&lt;p>Everyone hated it. Simple as that. I was told there was no way it could be better than a human, and one of the top report writers challenged me to produce a better report. In 10 minutes I had one, in 4 days she had her version, and she&amp;rsquo;d made some mistakes - which made her hate it (and me) even more.&lt;/p>
&lt;p>After I left, it was deleted and everyone forgot about its existence. It took me a while to figure out why - everyone was afraid. This one spreadsheet could replace almost the entire team of 7 people. You&amp;rsquo;d just need this spreadsheet and 1 person to do the analysis as the bulk of the job was manually processing reports. I could have put 6 people out of work in just 4 weeks.&lt;/p>
&lt;p>Regardless of how you feel about waste in enterprises, this was 6 humans, with families who had houses, mortgages, rent, bills, who needed to eat and to live. The lives of 6 families who could have been destroyed with one spreadsheet.&lt;/p>
&lt;h2 id="conclusion">Conclusion&lt;/h2>
&lt;p>Yes, automation is coming. Yes, technology can solve so many things. Yes, in theory if a job is replaced by automation then folks can focus their knowledge and energy onto solving bigger problems. But the reality is business is run by people who want to make as much money as possible, so automation is a way they can cut jobs and boost shareholder value, whatever that is (I&amp;rsquo;m guessing making rich folks richer).&lt;/p>
&lt;p>This is not always the case, and this is a very cynical and dystopian view, but in most cases this is the truth. Even in the high-paying tech world of multi-trillion dollar companies, folks are dropped in an instant to boost share prices.&lt;/p>
&lt;p>So it&amp;rsquo;s not surprising folks are worried about computers taking their jobs. If we are in the throes of an AI revolution, then maybe we need to really push the conversations around &lt;a href="https://en.wikipedia.org/wiki/Universal_basic_income">universal basic income&lt;/a>, and taxing large corporations and billionaires to pay for it.&lt;/p></description></item><item><title>Installing liblab into a devcontainer using NPM</title><link>https://jimbobbennett.dev/blogs/liblab-in-a-devcontainer/</link><pubDate>Fri, 04 Aug 2023 00:00:00 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/liblab-in-a-devcontainer/</guid><description>&lt;blockquote>
&lt;p>In this post we look at how to add NPM packages to a devcontainer to use in VS Code locally or in a GitHub codespace&lt;/p>
&lt;/blockquote>
&lt;p>I recently started at &lt;a href="https://liblab.com">liblab&lt;/a> as a Principal Developer Advocate. liblab is a tool that converts APIs into language SDKs, something I&amp;rsquo;m a big fan of as I love typesafety and the inherent documentation that comes with a good SDK. Obviously my first job was to dive into building out an API and creating an SDK from it.&lt;/p>
&lt;h2 id="devcontainers">Devcontainers&lt;/h2>
&lt;p>I love &lt;a href="https://containers.dev/">devcontainers&lt;/a> - they allow me to create a repo that anyone can open and instantly have a fully configured environment that just works! My standard process when creating any sample code is to start with a devcontainer. In this case, I&amp;rsquo;m creating a &lt;a href="https://fastapi.tiangolo.com/">FastAPI&lt;/a> application, and building an SDK from that.&lt;/p>
&lt;p>I start with a Python container - this is a pre-configured container that I can just spin up inside VS Code.&lt;/p>
&lt;p>&lt;img src="python3-devcontainer.png" alt="The Python 3 devcontainers option in the vs code select dev container configuration">&lt;/p>
&lt;p>Once in this container I can create my API, then build the SDK using liblab.&lt;/p>
&lt;h2 id="add-liblab-to-the-container">Add liblab to the container&lt;/h2>
&lt;p>liblab is available as a &lt;a href="https://developers.liblab.com/docs/getting-started">CLI that you install via NPM&lt;/a>. There are a number of ways you can install NPM packages in the container:&lt;/p>
&lt;ul>
&lt;li>Install it manually in the &lt;code>postCreateCommand&lt;/code>&lt;/li>
&lt;li>Use a &lt;code>DOCKERFILE&lt;/code> and install it there&lt;/li>
&lt;li>Use the NPM package feature&lt;/li>
&lt;/ul>
&lt;p>I went for option 3 - use the NPM package feature. This avoids having to create a &lt;code>DOCKERFILE&lt;/code> and configure my &lt;code>devcontainer.json&lt;/code> to use it, and means I don&amp;rsquo;t have to add more to my &lt;code>postCreateCommand&lt;/code> which already installs pip packages.&lt;/p>
&lt;p>You can add this feature manually into the &lt;code>devcontainer.json&lt;/code> file, or use the command palette:&lt;/p>
&lt;p>&lt;img src="devcontainer-feature-command-palette.png" alt="The configure container features command palette option">&lt;/p>
&lt;p>&lt;img src="devcontainer-add-feature.png" alt="Selecting the NPM package feature from the command palette">&lt;/p>
&lt;p>To add manually, add the &lt;code>ghcr.io/devcontainers-contrib/features/npm-package:1&lt;/code> feature:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-json" data-lang="json">&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#960050;background-color:#1e0010">...&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;features&amp;#34;&lt;/span>: {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;ghcr.io/devcontainers-contrib/features/npm-package:1&amp;#34;&lt;/span>: {}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Once added, the feature is configured using the &lt;code>package&lt;/code> and &lt;code>version&lt;/code> parameters. THe &lt;code>package&lt;/code> should be set to &lt;code>liblab&lt;/code>, the name of the NPM package for liblab. The &lt;code>version&lt;/code> parameter defaults to &lt;code>latest&lt;/code> and I always want the latest liblab CLI installed, so this can be left out.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-json" data-lang="json">&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#960050;background-color:#1e0010">...&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;features&amp;#34;&lt;/span>: {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;ghcr.io/devcontainers-contrib/features/npm-package:1&amp;#34;&lt;/span>: {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;package&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;liblab&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="rebuild-the-container">Rebuild the container&lt;/h2>
&lt;p>Once this is set up you can rebuild the container and the liblab SDK will be available in your terminal!&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>vscode ➜ /workspaces/python $ liblab
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>The offical liblab CLI
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>VERSION
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> liblab/0.9.20 linux-arm64 node-v18.17.0
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>USAGE
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> $ liblab &lt;span style="color:#f92672">[&lt;/span>COMMAND&lt;span style="color:#f92672">]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>TOPICS
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> hooks Bootstrap an SDKs hooks.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>COMMANDS
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> build Build SDK&lt;span style="color:#f92672">(&lt;/span>s&lt;span style="color:#f92672">)&lt;/span> and Docs &lt;span style="color:#66d9ef">for&lt;/span> your API.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> help Display help &lt;span style="color:#66d9ef">for&lt;/span> liblab.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> init Create a liblab folder &lt;span style="color:#66d9ef">for&lt;/span> housing files relevant to SDK and Doc generation.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> login Login to your account.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> logout Logout of your account.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> post-build Run extra tasks after code generation.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> pr Create a PR &lt;span style="color:#66d9ef">for&lt;/span> all the generated SDKs.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> register Register &lt;span style="color:#66d9ef">for&lt;/span> a new liblab account.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> reset-password Reset your password.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> token Create a new login token &lt;span style="color:#66d9ef">for&lt;/span> CI/CD.
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="learn-more">Learn more&lt;/h2>
&lt;p>Want to learn more about liblab for automating the generation of SDKs from your APIs? Get in touch.&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://linktr.ee/JimBobBennett">Contact me via social&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://discord.gg/F8aECHbRkV">Join our Discord&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Let's get personal: computing has won a Telly award</title><link>https://jimbobbennett.dev/blogs/telly-award/</link><pubDate>Thu, 01 Jun 2023 00:00:00 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/telly-award/</guid><description>&lt;p>This year is the 44th annual &lt;a href="https://www.tellyawards.com">Telly Awards&lt;/a>. The Telly Awards honor excellence in video and television across all screens.&lt;/p>
&lt;p>The Telly Awards was founded in 1979 to honor excellence in local, regional and cable television commercials with non-broadcast video and television programming added soon after. With the recent evolution and rise of digital video (web series, VR, 360 and beyond), the Telly Awards today also reflects and celebrates this exciting new era of the moving image on and offline.&lt;/p>
&lt;p>The Telly Awards annually showcases the best work created within television and across video, for all screens. Receiving over 12,000 entries from all 50 states and 5 continents, Telly Award winners represent work from some of the most respected advertising agencies, television stations, production companies and publishers from around the world. The Telly Awards recognizes work that has been created on the behalf of a client, for a specific brand and/or company (including your own) or self-directed as a creative endeavor.&lt;/p>
&lt;p>This year we entered the &lt;strong>Build a 3D Printed Clippy Powered by ChatGPT from OpenAI, Azure Cognitive Services&lt;/strong> episode of Let&amp;rsquo;s get personal: computing, and we won a &lt;a href="https://www.tellyawards.com/winners/2023/online/general-talk-show-interview">Silver award in the online talk show/interview category&lt;/a>!&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/6OYGeOwd6RY" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div></description></item><item><title>Run Azure Functions with Python on Apple Silicon</title><link>https://jimbobbennett.dev/blogs/azure-functions-python-m1/</link><pubDate>Mon, 08 May 2023 00:00:00 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/azure-functions-python-m1/</guid><description>&lt;p>If you are an Apple user and you want to build Azure Functions using Python, then you&amp;rsquo;ve been out of luck. The Azure Functions core tools don&amp;rsquo;t support Python functions on Arm64. There is a workaround, and this post shows you how.&lt;/p>
&lt;h2 id="arm64-support-in-azure-functions">Arm64 support in Azure Functions&lt;/h2>
&lt;p>Apple moved to an Arm64 architecture with their Apple Silicon processors (currently M1 and M2) back in November 2020, with their entire linup now using Apple Silicon, except for the rather outdated Mac Pro. Despite this, support for running Python functions on Arm64 has not yet materialized. You can create functions with &lt;code>func init&lt;/code> and &lt;code>func new&lt;/code>, but when you run them, you get an error:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>➜ functions-m1 func start
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Found Python version 3.10.11 &lt;span style="color:#f92672">(&lt;/span>python3&lt;span style="color:#f92672">)&lt;/span>.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Azure Functions Core Tools
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Core Tools Version: 4.0.5095 Commit hash: N/A &lt;span style="color:#f92672">(&lt;/span>64-bit&lt;span style="color:#f92672">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Function Runtime Version: 4.16.5.20396
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">[&lt;/span>2023-05-08T21:29:33.030Z&lt;span style="color:#f92672">]&lt;/span> Failed to initialize worker provider &lt;span style="color:#66d9ef">for&lt;/span>: /opt/homebrew/Cellar/azure-functions-core-tools@4/4.0.5095/workers/python
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">[&lt;/span>2023-05-08T21:29:33.030Z&lt;span style="color:#f92672">]&lt;/span> Microsoft.Azure.WebJobs.Script: Architecture Arm64 is not supported &lt;span style="color:#66d9ef">for&lt;/span> language python.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">[&lt;/span>2023-05-08T21:29:33.409Z&lt;span style="color:#f92672">]&lt;/span> Failed to initialize worker provider &lt;span style="color:#66d9ef">for&lt;/span>: /opt/homebrew/Cellar/azure-functions-core-tools@4/4.0.5095/workers/python
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">[&lt;/span>2023-05-08T21:29:33.409Z&lt;span style="color:#f92672">]&lt;/span> Microsoft.Azure.WebJobs.Script: Architecture Arm64 is not supported &lt;span style="color:#66d9ef">for&lt;/span> language python.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">[&lt;/span>2023-05-08T21:29:33.558Z&lt;span style="color:#f92672">]&lt;/span> A host error has occurred during startup operation &lt;span style="color:#e6db74">&amp;#39;2a13f8c8-f2e4-4da0-a88c-205dbd3065c2&amp;#39;&lt;/span>.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">[&lt;/span>2023-05-08T21:29:33.558Z&lt;span style="color:#f92672">]&lt;/span> Microsoft.Azure.WebJobs.Script: Did not find functions with language &lt;span style="color:#f92672">[&lt;/span>python&lt;span style="color:#f92672">]&lt;/span>.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">[&lt;/span>2023-05-08T21:29:33.564Z&lt;span style="color:#f92672">]&lt;/span> Failed to stop host instance &lt;span style="color:#e6db74">&amp;#39;1e7799d1-a87f-404a-9bc1-858c7724aeec&amp;#39;&lt;/span>.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">[&lt;/span>2023-05-08T21:29:33.564Z&lt;span style="color:#f92672">]&lt;/span> Microsoft.Azure.WebJobs.Host: The host has not yet started.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Value cannot be null. &lt;span style="color:#f92672">(&lt;/span>Parameter &lt;span style="color:#e6db74">&amp;#39;provider&amp;#39;&lt;/span>&lt;span style="color:#f92672">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Microsoft originally targeted support for their Python 3.10 release, but missed this. Currently they are saying it will come with Python 3.11 support, as documented in &lt;a href="https://github.com/Azure/azure-functions-python-worker/issues/915">this GitHub issue&lt;/a>. Their suggested workaround involves changing your Terminal to always run under Rosetta 2 which feels like a bad way to do things. There is a better workaround, leveraging dev containers.&lt;/p>
&lt;h2 id="dev-containers">Dev containers&lt;/h2>
&lt;p>Dev containers are docker containers that you run and connect to from VS Code. As a user these are seamless - you can still access the file system from outside of VS Code, but internally the dev environment runs in the container, with all your dependencies installed in the container instead of on your host OS. You can read about these on &lt;a href="https://code.visualstudio.com/docs/devcontainers/containers">the VS Code developing inside containers documentation&lt;/a>.&lt;/p>
&lt;p>Docker supports running x86 and x64 containers on Apple Silicon Macs using either QEMU emulation, or using Rosetta 2. This means you can create an x64 container and run this on your Mac, running the Azure Functions core tools inside the container! Pretty cool, hey!&lt;/p>
&lt;h2 id="configure-docker">Configure docker&lt;/h2>
&lt;p>You need &lt;a href="https://www.docker.com">docker&lt;/a> installed, so get this installed first. Once installed, you need to configure a few things.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>From the docker menu item, select &lt;strong>Settings&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>From the &lt;strong>General&lt;/strong> section, ensure &lt;em>Use Virtualization framework&lt;/em> is selected&lt;/p>
&lt;p>&lt;img src="docker-general-virtualization.png" alt="The Use Virtualization framework in the general tab of the settings dialog">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>From the &lt;strong>Features in development&lt;/strong> section, select the &lt;strong>Beat Features&lt;/strong> and select &lt;em>Use Rosetta for x86/amd64 emulation on Apple Silicon&lt;/em>&lt;/p>
&lt;p>&lt;img src="docker-rosetta.png" alt="The Use Rosetta for x86/amd64 emulation on Apple Silicon setting from the Features in development section">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Apply these changes and docker desktop will restart.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="create-the-dev-container">Create the dev container&lt;/h2>
&lt;p>The default Azure Functions and Python3 dev container is ideal for this as it is an x86/x64 container.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Make sure docker is running.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Create a folder for your Azure Functions app and open it in VS Code (or open the one you already have created)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Ensure you have the &lt;a href="https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers">Dev Containers extension&lt;/a> installed. This also comes with the &lt;a href="https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.vscode-remote-extensionpack">Remote Development extension Pack&lt;/a>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Open the command palette and select &lt;em>Dev Containers: Add Dev Container configuration files&amp;hellip;&lt;/em>&lt;/p>
&lt;p>&lt;img src="dev-containers-add-files.png" alt="The Dev Containers: Add Dev Container configuration files command palette option">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Select &lt;em>Show all definitions&lt;/em> to see all the dev container options&lt;/p>
&lt;p>&lt;img src="dev-containers-show-all.png" alt="The show all definitions option">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Search for and select &lt;em>Azure Functions &amp;amp; Python 3&lt;/em>&lt;/p>
&lt;p>&lt;img src="dev-containers-func-python.png" alt="The definitions filtered by Azure Functions with the cursor over Azure Functions &amp;amp; Python 3">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Select any other features you want. You don&amp;rsquo;t need any for Azure Functions to work.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The container files will be built, and an option will pop up to re-open the folder in the container. Select &lt;strong>Reopen in Container&lt;/strong>&lt;/p>
&lt;p>&lt;img src="reopen-in-container.png" alt="The reopen in container popup">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Once the repo has been re-opened in the container, open the terminal and you will see it marked as running under Rosetta&lt;/p>
&lt;p>&lt;img src="rosetta-terminal.png" alt="The terminal with an indicator on the toolbar showing it is running under Rosetta">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>If you don&amp;rsquo;t already have an Azure Functions app, you can now create one.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Run your Azure Functions app!&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>vscode ➜ /workspaces/functions-arm $ func start
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Found Python version 3.9.16 &lt;span style="color:#f92672">(&lt;/span>python3&lt;span style="color:#f92672">)&lt;/span>.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Azure Functions Core Tools
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Core Tools Version: 4.0.5148 Commit hash: N/A &lt;span style="color:#f92672">(&lt;/span>64-bit&lt;span style="color:#f92672">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Function Runtime Version: 4.17.3.20392
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Functions:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> HttpTrigger: &lt;span style="color:#f92672">[&lt;/span>GET,POST&lt;span style="color:#f92672">]&lt;/span> http://localhost:7071/api/HttpTrigger
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>For detailed output, run func with --verbose flag.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">[&lt;/span>2023-05-08T22:07:35.900Z&lt;span style="color:#f92672">]&lt;/span> Worker process started and initialized.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">[&lt;/span>2023-05-08T22:07:38.282Z&lt;span style="color:#f92672">]&lt;/span> Host lock lease acquired by instance ID &lt;span style="color:#e6db74">&amp;#39;0000000000000000000000008A10FEBD&amp;#39;&lt;/span>.
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;/ul>
&lt;p>Once you commit the devcontainer files to GitHub, you will also be able to open this in a Codespace and have it pre-configured with everything you need. You can also add more things to the container depending on your needs, such as extensions that are automatically loaded when the container is loaded, install things, whatever you need! Check out the &lt;a href="https://code.visualstudio.com/docs/devcontainers/containers">the VS Code developing inside containers documentation&lt;/a> to learn more.&lt;/p></description></item><item><title>Build a ChatGPT clone in .NET using OpenAI and Semantic Kernel</title><link>https://jimbobbennett.dev/blogs/chatgpt-with-semantic-kernel/</link><pubDate>Tue, 11 Apr 2023 00:00:00 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/chatgpt-with-semantic-kernel/</guid><description>&lt;p>ChatGPT is the latest big thing, reaching over 100 million users in just 2 months. It&amp;rsquo;s being used by millions of people for all manner of tasks, and it feels like every day there are 10 new startups leveraging either ChatGPT or the large language models (LLMs) that power it.&lt;/p>
&lt;p>&lt;img src="chat-gpt-hot.png" alt="Mugatu meme of Chat GPT, so hot right now">&lt;/p>
&lt;p>So what if you want to build your own version of ChatGPT, or another app that leverages an LLM? Out of the box, LLMs just provide an API to send a prompt and get a response, so what tools are there to help?&lt;/p>
&lt;p>One tool is Semantic Kernel, an open source .NET library from Microsoft that is designed to do a lot of the heavy lifting when it comes to interacting with LLMs.&lt;/p>
&lt;p>&lt;img src="skpatternlarge.png" alt="THe sematic kernel pattern of pink circles with different shades for each quadrant">&lt;/p>
&lt;p>&lt;strong>If you prefer video, here&amp;rsquo;s a 10 minute video version of this blog post&lt;/strong>&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/Pg-9W0a1OXw" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;h2 id="how-does-chatgpt-work-with-an-llm">How does ChatGPT work with an LLM?&lt;/h2>
&lt;p>ChatGPT allows you to have a conversation with a large language model, with ChatGPT being able to base the response to one question on the results of previous questions.&lt;/p>
&lt;p>For example, if you ask it:&lt;/p>
&lt;blockquote>
&lt;p>What is the most recent star wars movie?&lt;/p>
&lt;/blockquote>
&lt;p>It will respond something like:&lt;/p>
&lt;blockquote>
&lt;p>The most recent Star Wars movie is &amp;ldquo;Star Wars: The Rise of Skywalker,&amp;rdquo; which was released in December 2019. It is the ninth and final installment in the Skywalker saga.&lt;/p>
&lt;/blockquote>
&lt;p>If you then ask a follow up question such as:&lt;/p>
&lt;blockquote>
&lt;p>Who is the main character?&lt;/p>
&lt;/blockquote>
&lt;p>The response will &amp;lsquo;know&amp;rsquo; that the question refers to the movie the Rise of Skywalker:&lt;/p>
&lt;blockquote>
&lt;p>The main character in &amp;ldquo;Star Wars: The Rise of Skywalker&amp;rdquo; is Rey, played by Daisy Ridley. She is a powerful Jedi who is trying to find her place in the galaxy and confronts the evil First Order, led by Kylo Ren, played by Adam Driver. The movie also features other beloved characters from the Star Wars franchise, such as Finn, Poe Dameron, Chewbacca, and C-3PO.&lt;/p>
&lt;/blockquote>
&lt;p>LLMs, the core technology behind ChatGPT, don’t chat – they take a prompt and return a response, that’s all. To chat, they need to be guided by having access to the previous questions and responses.&lt;/p>
&lt;p>ChatGPT works by doing the following:&lt;/p>
&lt;ul>
&lt;li>The user enters a question, referred to as a prompt&lt;/li>
&lt;li>This prompt is enriched by a system prompt that helps guide the LLM, such as &amp;lsquo;you are a helpful chatbot&amp;rsquo;&lt;/li>
&lt;li>The prompt is sent to the LLM and the response is returned to the user&lt;/li>
&lt;li>The user enters a second question&lt;/li>
&lt;li>This time the prompt is enriched by the system prompt as well as the previous question and response&lt;/li>
&lt;li>The prompt is sent to the LLM and the response is returned to the user&lt;/li>
&lt;/ul>
&lt;p>For example, when the second question is sent, the full prompt might be:&lt;/p>
&lt;blockquote>
&lt;p>You are a helpful chatbot. You were asked &amp;lsquo;What is the most recent star wars movie?&amp;rsquo; and you answered &amp;lsquo;The most recent Star Wars movie is &amp;ldquo;Star Wars: The Rise of Skywalker,&amp;rdquo; which was released in December 2019. It is the ninth and final installment in the Skywalker saga&amp;rsquo;. Who is the main character?&lt;/p>
&lt;/blockquote>
&lt;p>To implement your own ChatGPT you need to implement code to get the prompt from the user, enrich it with a system prompt, send it to the LLM, get the response, then enrich further questions with the previous questions and responses.&lt;/p>
&lt;h2 id="how-can-semantic-kernel-help">How can semantic kernel help?&lt;/h2>
&lt;p>Semantic Kernel provides a load of features to help you implement this:&lt;/p>
&lt;ul>
&lt;li>Services to interact with LLMs from OpenAI either directly or via the Azure OpenAI service&lt;/li>
&lt;li>System prompts to pre-configure the conversation&lt;/li>
&lt;li>Chat history, or &amp;lsquo;memory&amp;rsquo;&lt;/li>
&lt;li>Semantic functions that can be defined in code such as getting user input and returning the response, or defined as prompts that can be sent to the LLM&lt;/li>
&lt;li>Function pipelines to chain semantic functions&lt;/li>
&lt;li>Core skills such as interacting with HTTP APIs or files.&lt;/li>
&lt;/ul>
&lt;h3 id="semantic-functions-and-pipelines">Semantic functions and pipelines&lt;/h3>
&lt;p>The core of semantic kernel is a pipeline that runs a series of functions. These functions either take text, return text, or both. Large language models work with text, so text is the main way to interact. The idea of the pipeline is text is passed through from function to function.&lt;/p>
&lt;p>For example, for a ChatGPT clone, you could have a pipeline that gets input from the user, sends it to the LLM with the previous questions and responses, then send the response back to the user.&lt;/p>
&lt;p>For a sample project, check out &lt;a href="https://github.com/jimbobbennett/console-gpt">github.com/jimbobbennett/console-gpt&lt;/a>.&lt;/p>
&lt;p>In this code, there is a &lt;code>ConsoleGPTService&lt;/code> that has a pipeline:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="display:flex;">&lt;span>ISKFunction[] pipeline = {_speechSkill[&lt;span style="color:#e6db74">&amp;#34;Listen&amp;#34;&lt;/span>], _chatSkill[&lt;span style="color:#e6db74">&amp;#34;Prompt&amp;#34;&lt;/span>], _speechSkill[&lt;span style="color:#e6db74">&amp;#34;Respond&amp;#34;&lt;/span>]};
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">await&lt;/span> _semanticKernel.RunAsync(pipeline);
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This pipeline runs 3 semantic functions, routing the output of one into the input of the other. Semantic functions are C# functions that are marked with an attribute and loaded into the pipeline.&lt;/p>
&lt;p>The &lt;code>Listen&lt;/code> function in this code is defined in the &lt;code>ConsoleSkill&lt;/code> and gets data from the console:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">[SKFunction(&amp;#34;Get console input.&amp;#34;)]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">[SKFunctionName(&amp;#34;Listen&amp;#34;)]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">public&lt;/span> Task&amp;lt;&lt;span style="color:#66d9ef">string&lt;/span>&amp;gt; Listen(SKContext context)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> Task.Run(() =&amp;gt; Console.ReadLine());
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This returns what the used inputs, and this is passed to the &lt;code>Prompt&lt;/code> semantic function in the &lt;code>ChatSkill&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">[SKFunction(&amp;#34;Send a prompt to the LLM.&amp;#34;)]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">[SKFunctionName(&amp;#34;Prompt&amp;#34;)]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">async&lt;/span> Task&amp;lt;&lt;span style="color:#66d9ef">string&lt;/span>&amp;gt; Prompt(&lt;span style="color:#66d9ef">string&lt;/span> prompt)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> _chatHistory.AddUserMessage(prompt);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">var&lt;/span> reply = &lt;span style="color:#66d9ef">await&lt;/span> _chatCompletion.GenerateMessageAsync(_chatHistory, _chatRequestSettings);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// Add the interaction to the chat history.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> _chatHistory.AddAssistantMessage(reply);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> reply;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This uses the &lt;code>AddOpenAIChatCompletionService&lt;/code>, a service provided by the semantic kernel to interact with OpenAI. This service is a chat service, so manages history - when you call it you pass the complete chat history including a system prompt that sets up the conversation, and all the prompts and responses.&lt;/p>
&lt;p>The output of this is then passed to a &lt;code>Respond&lt;/code> semantic function to write it to the console:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">[SKFunction(&amp;#34;Write a response to the console.&amp;#34;)]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">[SKFunctionName(&amp;#34;Respond&amp;#34;)]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">public&lt;/span> Task&amp;lt;&lt;span style="color:#66d9ef">string&lt;/span>&amp;gt; Respond(&lt;span style="color:#66d9ef">string&lt;/span> message, SKContext context)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> Task.Run(() =&amp;gt; Console.WriteLine(message));
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>By using semantic functions you can quickly swap out functions by implementing the same signature in multiple places and bringing the one you want into the semantic kernel. You can also construct pipelines on the fly, adding sections if you need.&lt;/p>
&lt;p>Semantic functions can also be created using prompts rather than code. For example:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> poemPrompt = &lt;span style="color:#e6db74">&amp;#34;&amp;#34;&amp;#34;
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">&lt;/span> Take &lt;span style="color:#66d9ef">this&lt;/span> &lt;span style="color:#e6db74">&amp;#34;{{$INPUT}}&amp;#34;&lt;/span> and convert it to a poem &lt;span style="color:#66d9ef">in&lt;/span> iambic pentameter.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;&amp;#34;&amp;#34;;
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>_poemFunction = _semanticKernel.CreateSemanticFunction(poemPrompt);
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>You can then add this to the pipeline, and the output from the previous function in the pipeline is passed to the &lt;code>{{$INPUT}}&lt;/code> variable in the prompt. In this case using the LLM to convert to a poem.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="display:flex;">&lt;span>ISKFunction[] pipeline = {_speechSkill[&lt;span style="color:#e6db74">&amp;#34;Listen&amp;#34;&lt;/span>], _chatSkill[&lt;span style="color:#e6db74">&amp;#34;Prompt&amp;#34;&lt;/span>], _poemFunction, _speechSkill[&lt;span style="color:#e6db74">&amp;#34;Respond&amp;#34;&lt;/span>]};
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">await&lt;/span> _semanticKernel.RunAsync(pipeline);
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This means for the prompt:&lt;/p>
&lt;blockquote>
&lt;p>What is the most recent star wars movie?&lt;/p>
&lt;/blockquote>
&lt;p>You might get this poem:&lt;/p>
&lt;blockquote>
&lt;p>The Force of Fate has brought us here,&lt;/p>
&lt;p>To see the Rise of Skywalker near,&lt;/p>
&lt;p>The ninth and final part of this tale,&lt;/p>
&lt;p>Released in December, &amp;rsquo;twas no fail.&lt;/p>
&lt;p>Star Wars, the movie, we all know,&lt;/p>
&lt;p>The saga of the Skywalkers show,&lt;/p>
&lt;p>The Force will live on, we can see,&lt;/p>
&lt;p>In this movie, &amp;rsquo;tis our destiny.&lt;/p>
&lt;/blockquote>
&lt;h2 id="get-the-code">Get the code&lt;/h2>
&lt;p>You can get the code on my &lt;a href="https://github.com/jimbobbennett/console-gpt">console-gpt repo on GitHub&lt;/a>.&lt;/p>
&lt;div class="github-card" data-github="jimbobbennett/console-gpt" data-width="400" data-height="" data-theme="default">&lt;/div>
&lt;script src="//cdn.jsdelivr.net/github-cards/latest/widget.js">&lt;/script>
&lt;h2 id="learn-more">Learn more&lt;/h2>
&lt;p>Here are some more resources for Semantic Kernel&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://learn.microsoft.com/semantic-kernel">The Semantic Kernel documentation on Microsoft Learn&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/microsoft/semantic-kernel">The Semantic Kernel repo on GitHub&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://aka.ms/sk/discord">The Semantic Kernel Discord&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://devblogs.microsoft.com/semantic-kernel/">The Semantic Kernel blog&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>An intro to generative AI created by generative AI!</title><link>https://jimbobbennett.dev/blogs/an-intro-to-generative-ai/</link><pubDate>Fri, 31 Mar 2023 00:00:00 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/an-intro-to-generative-ai/</guid><description>&lt;p>Generative AI is the new hotness - using AI models trained on a huge amount of data that can generate new data. This includes generating text or images. I decided to create a video giving an explanation of generative AI using - you guessed it, generative AI!&lt;/p>
&lt;p>Check out the video here:&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/OUpW9O3zabs" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;h2 id="creating-this-video">Creating this video&lt;/h2>
&lt;p>To create this video I needed a few things:&lt;/p>
&lt;ul>
&lt;li>An image of a person to use for the presenter&lt;/li>
&lt;li>A script&lt;/li>
&lt;li>A way to convert the script to spoken audio&lt;/li>
&lt;li>A way to make the image move in time with the audio&lt;/li>
&lt;li>A YouTube description&lt;/li>
&lt;/ul>
&lt;p>My plan was to do all of this using AI.&lt;/p>
&lt;h3 id="create-the-image">Create the image&lt;/h3>
&lt;p>To create the image, I decided to use &lt;a href="https://openai.com/product/dall-e-2">DALL-E-2&lt;/a>, the latest image generation model from OpenAI. This model takes a prompt and generates an image. You can either use it through their website at &lt;a href="https://labs.openai.com/">labs.openai.com&lt;/a>, or you can generate images using their &lt;a href="https://platform.openai.com/docs/api-reference/images">API&lt;/a>.&lt;/p>
&lt;p>When creating a prompt you need to be as descriptive as possible so that the AI can generate the image. The website generates 4 images for each prompt, all different.&lt;/p>
&lt;p>This is the prompt I used:&lt;/p>
&lt;blockquote>
&lt;p>A hyper realistic bust upwards portrait of a classically beautiful mid-20s woman of indeterminate race with rainbow hair, who looks like a cross between a CEO and an opera singer and is posed facing the camera. She is wearing a colorful dress and is standing in front of a plain black backdrop.&lt;/p>
&lt;/blockquote>
&lt;p>These are the 4 images created:&lt;/p>
&lt;p>&lt;img src="./4-images.jpg" alt="4 images of women with rainbow hair and colorful dresses">&lt;/p>
&lt;p>I picked the one with the full head as I wanted to animate the full face.&lt;/p>
&lt;p>This took a few iterations to get a prompt that created images I liked, such as age, outfit and style of dress. Most of the images were of the right quality, but some had a few quirks. For example, the eyes in this image were not well generated:&lt;/p>
&lt;p>&lt;img src="weird-eyes.png" alt="A womans face with mismatched eye size and color, with artifacts on the eyes">&lt;/p>
&lt;p>DALL-E creates square images, at a default of 1024x1024, so I knew I would need to add extra sizing on the sides or top and bottom to get the right aspect ratio. THis is why I added &lt;strong>standing in front of a plain black backdrop&lt;/strong> to the prompt, so I could fill out the extra space with a single color.&lt;/p>
&lt;p>Once generated, I downloaded the image, and then resized it to a higher resolution using the &lt;a href="https://www.pixelmator.com/blog/2019/12/17/all-about-the-new-ml-super-resolution-feature-in-pixelmator-pro/">ML super resolution feature of Pixelmator Pro&lt;/a>.&lt;/p>
&lt;h3 id="create-the-script">Create the script&lt;/h3>
&lt;p>Next up was something for the generated AI character to say. For this I decided to use &lt;a href="https://chat.openai.com">ChatGPT&lt;/a> with the &lt;a href="https://openai.com/research/gpt-4">GPT4 model&lt;/a>. I decided to sign up for this at US$20 a month rather than wait, so will see if it is a worthwhile investment.&lt;/p>
&lt;p>ChatGPT generates text for you based of textual prompts, and has a &amp;lsquo;memory&amp;rsquo; to remember your conversation and use this as the input to the next prompts, allowing you to have a conversation-like discussion.&lt;/p>
&lt;p>This is the prompt I used:&lt;/p>
&lt;blockquote>
&lt;p>You are Ganya, the CEO of an AI company and your company is called Alvie. Write a 5 minute talk that covers an introduction to generative AI and how it can benefit businesses. This talk needs to be entertaining with a couple of jokes, but also informative. The audience for this talk is a group of students who don&amp;rsquo;t have strong technical knowledge.&lt;/p>
&lt;/blockquote>
&lt;p>The name Ganya is a unisex name used with Hebrew origins, and means clever. Alvie is a English female name, and is short for Alvina. It is a name which means wise friend. I picked these names at random from a baby name site listing names that mean intelligent.&lt;/p>
&lt;p>This is the output it generated:&lt;/p>
&lt;blockquote>
&lt;p>Ladies and gentlemen, future tech wizards, and brilliant entrepreneurs, thank you for inviting me to speak today. I am Ganya, the CEO of Alvie, and I&amp;rsquo;ll be your digital tour guide on this wild journey through the fascinating world of generative AI. So, buckle up, because we&amp;rsquo;re about to embark on an adventure that&amp;rsquo;s more thrilling than binge-watching a season of your favorite sci-fi show!&lt;/p>
&lt;p>Now, you might be wondering, &amp;ldquo;What the heck is generative AI?&amp;rdquo; Well, you know how your phone&amp;rsquo;s predictive text often tries to guess what you&amp;rsquo;re typing before you even finish typing it? Yeah, that&amp;rsquo;s a tiny taste of generative AI! It&amp;rsquo;s like a mind-reading superpower, but for machines. And it&amp;rsquo;s not only limited to text, it can be used for images, music, and even entire virtual worlds.&lt;/p>
&lt;p>You see, generative AI is the cool cousin of traditional AI. Instead of being the nerdy, know-it-all who&amp;rsquo;s good at math, generative AI is the creative type who spends their time painting, writing poetry, or designing websites. It&amp;rsquo;s the kind of AI that dares to dream, and it&amp;rsquo;s revolutionizing the way we think about technology.&lt;/p>
&lt;p>But let&amp;rsquo;s take a step back and look at the big picture. Generative AI is like a chef, and data is its secret ingredient. It takes massive amounts of data, mixes it all up, and uses this delicious concoction to create brand-new content, whether that&amp;rsquo;s text, images, or music. Essentially, it&amp;rsquo;s a digital Picasso with a dash of Shakespeare and a sprinkle of Mozart.&lt;/p>
&lt;p>Now, I know what you&amp;rsquo;re thinking: &amp;ldquo;That&amp;rsquo;s all great, Ganya, but how can generative AI help my business? I&amp;rsquo;m not running an art gallery or a concert hall!&amp;rdquo; Well, fear not! Generative AI is a versatile beast and can benefit businesses in many ways.&lt;/p>
&lt;p>For example, take customer service. We all know how frustrating it can be to deal with a grumpy customer service rep who clearly didn&amp;rsquo;t have their morning coffee. Enter generative AI: it can be used to create friendly, informative, and highly responsive chatbots that can handle thousands of customer inquiries at once, without ever needing a caffeine fix. That&amp;rsquo;s what I call efficiency!&lt;/p>
&lt;p>Speaking of efficiency, generative AI can also help companies optimize their workflow. Imagine having a smart algorithm that can analyze complex data sets and automatically generate insightful reports for your team. It&amp;rsquo;s like having an intern who never gets tired, never complains, and doesn&amp;rsquo;t need a salary. The only downside? You can&amp;rsquo;t send it out to fetch you coffee, but hey, nobody&amp;rsquo;s perfect!&lt;/p>
&lt;p>Now, I can&amp;rsquo;t let you leave without a joke or two, can I? So, here&amp;rsquo;s one for you: Why did the generative AI go to therapy? Because it had deep learning issues! (Pause for laughter) Okay, okay, I promise I won&amp;rsquo;t quit my day job.&lt;/p>
&lt;p>But in all seriousness, folks, generative AI is an incredible tool that can transform the way we do business. It can help companies save time, money, and resources, while also enabling us to create new, innovative products and services. As we embark on this exciting journey together, let&amp;rsquo;s remember that the future of AI is not just about cold, hard numbers; it&amp;rsquo;s about tapping into the boundless creativity that lies within each and every one of us.&lt;/p>
&lt;p>Thank you for your time, and I hope this little chat has sparked your imagination and inspired you to explore the fantastic world of generative AI!&lt;/p>
&lt;/blockquote>
&lt;h3 id="convert-the-script-to-spoken-audio">Convert the script to spoken audio&lt;/h3>
&lt;p>There are a number of tools that can take text and create spoken audio. The best ones use AI to make the voice sound lifelike with changes in timing and intonation that mimic how a real person would speak. As a Microsoft person I could have used the &lt;a href="https://speech.microsoft.com/">Cognitive services speech service&lt;/a> but this would have meant writing code, and I couldn&amp;rsquo;t be bothered&amp;hellip;&lt;/p>
&lt;p>Instead I used &lt;a href="https://elevenlabs.io">Eleven Labs&lt;/a> which has a free tier for up to 10,000 characters per month. You can select from a range of different voices, paste in your text and it creates the audio as an MP3 file. There is a limit of 2,500 characters per conversion, so I had to do it in 2 chunks as my text was 3,335 characters long, then use Camtasia to stitch the audio files together.&lt;/p>
&lt;p>Here is the generated audio:&lt;/p>
&lt;audio controls preload="auto">
&lt;source src="intro-to-generative-ai.m4a">
&lt;/audio>
&lt;h3 id="create-a-video-speaking-the-audio">Create a video speaking the audio&lt;/h3>
&lt;p>The next step was to create the video by mashing up the audio and the image, and animating the image to speak the words. There are a number of tools that could contribute to this, such as &lt;a href="https://github.com/adobe-research/MakeItTalk">Make it talk from Adobe research&lt;/a>, but I wanted a solution that I didn&amp;rsquo;t need to run myself.&lt;/p>
&lt;p>I ended up using &lt;a href="https://www.d-id.com">D-ID&lt;/a> which is not cheap! They have a 14 day free tier for up to 5 minutes of video, but beyond that it gets very expensive. It works really well though! You can either use one of their avatars, or upload an image yourself. Once they have the image, you provide either the script and it will generate the audio for you (using the Microsoft Cognitive services under the hood), or upload the audio.&lt;/p>
&lt;p>It then allows you to download the final video, and because I had a square image it sized it to 1280x1280. I then open up Camtasia one more time to create 2 videos with this - one at 1920x1080 for YouTube, and one at 1080x1920 for Instagram, filling the extra space around the video with the background color which was slightly off-black.&lt;/p>
&lt;h3 id="create-a-youtube-video">Create a YouTube video&lt;/h3>
&lt;p>Now I had my video, it was time to upload to YouTube. I uploaded the video and knocked up a simple thumbnail with text for the video name manually. Tools like DALL-E are not good for adding text to images, so something to research is a tool for this.&lt;/p>
&lt;p>I then needed a description, so it was time to go back to ChatGPT! The prompt I used was:&lt;/p>
&lt;blockquote>
&lt;p>Generate a YouTube description for a video with the following text:&lt;/p>
&lt;p>&amp;lt;the script&amp;gt;&lt;/p>
&lt;/blockquote>
&lt;p>I then added the complete script to the prompt (I cut it off here for brevity). ChatGPT then generated the following:&lt;/p>
&lt;blockquote>
&lt;p>Title: Exploring the World of Generative AI with Alvie CEO Ganya&lt;/p>
&lt;p>Description:&lt;/p>
&lt;p>🚀 Join Ganya, the CEO of Alvie, as she takes you on an exciting and informative journey through the world of generative AI! In this video, Ganya breaks down what generative AI is, how it works, and its potential to revolutionize the way we do business. From creative applications like art, music, and writing to practical uses in customer service and workflow optimization, generative AI offers a world of possibilities.&lt;/p>
&lt;p>🤖 Key Points:
0:00 - Introduction and Welcome
1:05 - What is Generative AI?
2:38 - How Generative AI Works: Data and Creativity
4:15 - Benefits of Generative AI for Businesses
6:45 - The Future of AI and Creativity
8:30 - Jokes and Closing Remarks&lt;/p>
&lt;p>🔮 Don&amp;rsquo;t miss this opportunity to learn about the fantastic world of generative AI and its potential to unlock boundless creativity in technology and business. Hit the subscribe button to stay updated on the latest advancements and insights from Alvie!&lt;/p>
&lt;p>#GenerativeAI #Alvie #AIinBusiness&lt;/p>
&lt;/blockquote>
&lt;p>Pretty good stuff! I removed the &lt;code>#Alvie&lt;/code> tag as this makes no sense as Alvie doesn&amp;rsquo;t exist, and had to re-do the time stamps for the chapter markers as ChatGPT has no way of knowing the timings. But otherwise it was perfect!&lt;/p>
&lt;p>I added a disclaimer at the start of the description to say this was AI generated, and listed the tools.&lt;/p>
&lt;p>And I was done! Video created and uploaded all powered by generative AI!&lt;/p>
&lt;h3 id="whats-next">What&amp;rsquo;s next?&lt;/h3>
&lt;p>My next job is to try to automate all this into a tool so I can give it a prompt and have it create and upload the full video without any manual intervention.&lt;/p></description></item><item><title>Embedding audio files in a Hugo site</title><link>https://jimbobbennett.dev/blogs/playing-audio-files-hugo/</link><pubDate>Fri, 31 Mar 2023 00:00:00 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/playing-audio-files-hugo/</guid><description>&lt;p>I was writing a post today and wanted to embed an mp3 file of some text to speech output. Hugo doesn&amp;rsquo;t support this natively using shortcodes, so I needed a way to add these, ideally without adding any HTML.&lt;/p>
&lt;p>To do this, I needed to create my own shortcode implementation. As it turns out, based on the &lt;a href="https://gohugo.io/templates/shortcode-templates/">Hugo shortcode guide&lt;/a>, these are not to complicated.&lt;/p>
&lt;h2 id="create-the-shortcode">Create the shortcode&lt;/h2>
&lt;p>Shortcodes live in a folder called &lt;code>shortcodes&lt;/code> in your &lt;code>layout&lt;/code> folder and are implemented as HTML files, named as &lt;code>&amp;lt;shortcode&amp;gt;.html&lt;/code>. For example, if you wanted to create a shortcode called &lt;code>audio&lt;/code> you would create the file &lt;code>layout/shortcodes/audio.html&lt;/code>.&lt;/p>
&lt;p>Shortcodes are snippets of HTML that can be passed named parameters. The HTML for an HTML audio player is:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-html" data-lang="html">&lt;span style="display:flex;">&lt;span>&amp;lt;&lt;span style="color:#f92672">audio&lt;/span> &lt;span style="color:#a6e22e">controls&lt;/span> &lt;span style="color:#a6e22e">preload&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;auto&amp;#34;&lt;/span>&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;lt;&lt;span style="color:#f92672">source&lt;/span> &lt;span style="color:#a6e22e">src&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;file.mp3&amp;#34;&lt;/span>&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&amp;lt;/&lt;span style="color:#f92672">audio&lt;/span>&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Shortcodes can also be parameterized with name parameters that you can get using the &lt;code>{{ .Get &amp;quot;name&amp;quot; }}&lt;/code> method, passing the name of the parameter. For the audio shortcode, I need to pass in the audio file, so this can be a parameter. This is set in the &lt;code>src&lt;/code> field, so I called this parameter &lt;code>src&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-html" data-lang="html">&lt;span style="display:flex;">&lt;span>&amp;lt;&lt;span style="color:#f92672">audio&lt;/span> &lt;span style="color:#a6e22e">controls&lt;/span> &lt;span style="color:#a6e22e">preload&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;auto&amp;#34;&lt;/span>&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;lt;&lt;span style="color:#f92672">source&lt;/span> &lt;span style="color:#a6e22e">src&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;{{ .Get &amp;#34;&lt;/span>&lt;span style="color:#a6e22e">src&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">&amp;#34;&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">}}&amp;#34;&lt;/span>&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&amp;lt;/&lt;span style="color:#f92672">audio&lt;/span>&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Done! This is my entire shortcode.&lt;/p>
&lt;h2 id="use-the-shortcode">Use the shortcode&lt;/h2>
&lt;p>Once my shortcode was written, it was easy to use. I added the mp3 file I want to play to the folder for my blog post, and added the shortcode tag in the markdown file for the post:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-md" data-lang="md">&lt;span style="display:flex;">&lt;span>{{&amp;lt; &lt;span style="color:#f92672">audio&lt;/span> &lt;span style="color:#a6e22e">src&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;intro-to-generative-ai.m4a&amp;#34;&lt;/span> &amp;gt;}}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Once done, the audio player appears on my page:&lt;/p>
&lt;p>&lt;img src="./audio-player-in-post.png" alt="The audio player on a blog post page">&lt;/p>
&lt;h2 id="use-this-yourself">Use this yourself&lt;/h2>
&lt;p>If you want to use this shortcode, you can find it &lt;a href="https://github.com/jimbobbennett/jims-blog/blob/main/blog/layouts/shortcodes/audio.html">on the GitHub repo for this site&lt;/a>.&lt;/p></description></item><item><title>A 2-day open source bootcamp in a box</title><link>https://jimbobbennett.dev/blogs/announcing-open-source-bootcamp/</link><pubDate>Thu, 30 Mar 2023 00:00:00 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/announcing-open-source-bootcamp/</guid><description>&lt;p>I&amp;rsquo;m excited to announce the publication of a 2-day open source bootcamp in a box!&lt;/p>
&lt;div class="github-card" data-github="open-source-bootcamp" data-width="400" data-height="" data-theme="default">&lt;/div>
&lt;script src="//cdn.jsdelivr.net/github-cards/latest/widget.js">&lt;/script>
&lt;p>This boot camp was put together by &lt;a href="https://hachyderm.io/@runewake2">Sam Wronski&lt;/a>, &lt;a href="https://twitter.com/tweetmonster999">Austin Akers&lt;/a> and I, with help and support from GitHub, GitHub campus experts, and others from the open source community.&lt;/p>
&lt;h2 id="goals">Goals&lt;/h2>
&lt;p>The goal of this bootcamp is to take attendees from a very basic to no understanding of GitHub on a journey to not only being comfortable with collaborating on GitHub, but being ready to actively contributing to public open source projects, or to collaborate on code in the workplace. This bootcamp is structured as an in-person event.&lt;/p>
&lt;p>The code the attendees will be working on is relatively basic JavaScript, and attendees without JavaScript knowledge but with some knowledge of programming should still be able to successfully complete this bootcamp.&lt;/p>
&lt;h2 id="running-this-event">Running this event&lt;/h2>
&lt;div class="github-card" data-github="open-source-bootcamp/bootcamp-guide" data-width="400" data-height="" data-theme="default">&lt;/div>
&lt;script src="//cdn.jsdelivr.net/github-cards/latest/widget.js">&lt;/script>
&lt;p>&lt;a href="https://github.com/open-source-bootcamp/bootcamp-guide">This GitHub repo&lt;/a> contains the full instructions on how to run this event, with guides for the day, slide decks, a sample project to work on with full instructions, videos of the sessions, and plenty of suggestions on how to make this day a success. This bootcamp is fully open source and MIT licensed, so you can take it and run it at your own event without cost or attribution.&lt;/p>
&lt;p>When we have run this event in the past (such as at the &lt;a href="https://www.meetup.com/microsoft-reactor-redmond/events/287024832/">In-person Student Open Source Bootcamp&lt;/a>, &lt;a href="https://www.meetup.com/microsoft-reactor-redmond/events/288635090/">Hacktoberfest in-person open source bootcamp&lt;/a>, and the &lt;a href="https://www.meetup.com/microsoft-reactor-redmond/events/290700609/">Fall in love with Open Source bootcamp&lt;/a>, all hosted at the &lt;a href="https://www.meetup.com/microsoft-reactor-redmond/events/287024832/">Microsoft Reactor in Redmond&lt;/a>). The attendees have all given feedback that networking is important, therefore this event includes opportunities for attendees to work together on code, be involved in networking&lt;/p>
&lt;h2 id="let-me-know-what-you-think">Let me know what you think!&lt;/h2>
&lt;p>If this bootcamp is of use to you, please let me know! If you have any questions or suggestions for improvements, please start a &lt;a href="https://github.com/orgs/open-source-bootcamp/discussions">discussion in the GitHub org&lt;/a>.&lt;/p></description></item><item><title>Install the Azure CLI on a Raspberry Pi</title><link>https://jimbobbennett.dev/blogs/az-cli-rpi/</link><pubDate>Wed, 08 Mar 2023 00:00:00 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/az-cli-rpi/</guid><description>&lt;p>I do a lot with Raspberry Pis, and sometimes I want all my tools installed in one place so I can use my Pi for everything, rather than flipping back to my Mac.&lt;/p>
&lt;p>One thing I use a lot is Azure - funny really as I work for Microsoft! I often use the Azure portal as I prefer UIs to CLIs, but when working on a Pi I regularly use Raspberry Pi OS Lite, so don&amp;rsquo;t have a browser to use as I&amp;rsquo;m always in the terminal or VS Code. So I needed the Azure CLI on my Pi.&lt;/p>
&lt;h2 id="hardware">Hardware&lt;/h2>
&lt;p>I&amp;rsquo;m currently doing everything on a Raspberry Pi 4 as I have a few of them (will trade one for a Lamborghini - no low ballers, I know what I have), so have one of these set up with Raspberry Pi OS Lite 32-bit. I&amp;rsquo;ve not tested this on 64-bit, but I&amp;rsquo;m guessing it should work.&lt;/p>
&lt;h2 id="pre-requisites">Pre-requisites&lt;/h2>
&lt;p>To install the CLI, you can&amp;rsquo;t just use the apt package - this only currently supports x86, not armhf. Instead it needs to be installed from an install script that installs a raw Python CLI. This has a few dependencies:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://sourceware.org/libffi/">libffi&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://python.org">Python 3.6 or later&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.openssl.org/source/">OpenSSL&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>Run the following to ensure everything is installed:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>sudo apt install libffi-dev python3-dev python3-pip openssl
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="install-the-azure-cli">Install the Azure CLI&lt;/h2>
&lt;p>Once the pre-requisites are installed, you can use a handy script from Microsoft to install the CLI:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>curl -L https://aka.ms/InstallAzureCli | bash
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Run this with all the defaults.&lt;/p>
&lt;p>This adds the &lt;code>az&lt;/code> command to the &lt;code>/home/pi/bin/&lt;/code> folder, and gives you an option to add this to your path, which you should accept. You&amp;rsquo;ll then need to manually restart your shell or run &lt;code>exec -l $SHELL&lt;/code> to restart it.&lt;/p>
&lt;h2 id="login">Login&lt;/h2>
&lt;p>Once installed, you can log in with &lt;code>az login&lt;/code>. It&amp;rsquo;s smart enough to realize you don&amp;rsquo;t have a web browser, and take you through the device login path, giving you a code. Head to &lt;a href="https://microsoft.com/devicelogin">https://microsoft.com/devicelogin&lt;/a> and enter the code given to get logged in!&lt;/p></description></item><item><title>Run Appwrite on a Raspberry Pi</title><link>https://jimbobbennett.dev/blogs/install-appwrite-rpi/</link><pubDate>Thu, 02 Mar 2023 00:00:00 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/install-appwrite-rpi/</guid><description>&lt;blockquote>
&lt;p>TL;DR - use Raspberry Pi OS 64-bit if you want to run Appwrite on a Pi&lt;/p>
&lt;/blockquote>
&lt;p>I&amp;rsquo;ve started working on a personal project, so thought it might be fun to give &lt;a href="https://appwrite.io">Appwrite&lt;/a> a spin. Appwrite is an open-source app backend for web and mobile projects, you can think of it as a competitor to Firebase.&lt;/p>
&lt;p>Rather than use a hosted version, or try to run it on Azure and burn through my credits, I decided to run it on a local server. I have a few Raspberry Pi&amp;rsquo;s kicking round, so thought Id try running it on there.&lt;/p>
&lt;h2 id="hardware">Hardware&lt;/h2>
&lt;p>Appwrite claims to run on as little as 1 CPU and 2GB of RAM, so a Pi 4 with 4GB should be more than enough. I have one spare, so set it up.&lt;/p>
&lt;h2 id="raspberry-pi-os">Raspberry Pi OS&lt;/h2>
&lt;p>The first thing to note is that Appwrite does run on Arm, but only Arm64. The &amp;lsquo;default&amp;rsquo; Raspberry Pi OS is the 32-bit version, and Appwrite will not run on this. Instead, when you set up your SD card, you need to use Raspberry Pi OS 64-bit. In my case I&amp;rsquo;m using the lite version as I want to run this as a headless server.&lt;/p>
&lt;p>&lt;img src="rpi-os-lite.png" alt="The Raspberry pi OS lite 64-bit option in the imager">&lt;/p>
&lt;p>I installed this on an SD card, then booted up my Pi 4.&lt;/p>
&lt;h2 id="configuring-the-software">Configuring the software&lt;/h2>
&lt;p>Appwrite runs as a docker container, so the first thing to do is install docker. The &lt;a href="https://docs.docker.com/engine/install/debian/#install-using-the-convenience-script">convenience script&lt;/a> from docker works perfectly on the Pi:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>curl -fsSL https://get.docker.com -o get-docker.sh
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sudo sh ./get-docker.sh
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Takes a while, but this sets up docker. I then like to add the current user to the &lt;code>docker&lt;/code> group to save &lt;code>sudo&lt;/code>ing all the things.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>sudo usermod -aG docker $USER
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Now docker is installed, you can install Appwrite. Appwrite has 2 ways to do this - a quick install and a manual install. I decided to do the manual install in case I needed to configure things later.&lt;/p>
&lt;p>You start by creating a folder to run from on your Pi, then downloading a docker compose and .env file:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>mkdir appwrite
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>cd appwrite
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>curl -o docker-compose.yaml https://appwrite.io/install/compose
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>curl -o .env https://appwrite.io/install/env
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>From here, you can build the container and start it up:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>docker compose up -d
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This runs the container detached - as in it runs in the background, returning to the current session. If you close your shell it will stay running.&lt;/p>
&lt;p>Once I had this running, I could then open Appwrite by accessing my Pi from a browser. Appwrite runs on port 80, so listens to default HTTP requests on the Pi. From there, create a new account to access the server.&lt;/p>
&lt;p>&lt;img src="appwrite-sign-in.png" alt="The appwrite login screen">&lt;/p></description></item><item><title>Control Microsoft Teams with a Stream Deck</title><link>https://jimbobbennett.dev/blogs/teams-streamdeck/</link><pubDate>Thu, 02 Feb 2023 00:00:00 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/teams-streamdeck/</guid><description>&lt;blockquote>
&lt;p>Already have a Stream Deck and just want to get it working with Teams? &lt;a href="#set-up-your-stream-deck-for-teams">Jump to the instructions to set this up&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>Like a lot of folks, I spend time in Microsoft Teams. It&amp;rsquo;s where I chat to my team and others at Microsoft, and it&amp;rsquo;s where I take most of my meetings.&lt;/p>
&lt;p>Although Teams has a lot of good features, the UI can sometimes be a pain to use in meetings - especially as a Microsoft employee where we get to try the dogfood versions and things move all the time. There have been loads of occasions where I have tried to give a reaction and put up my hand by mistake, or tried to mute and left the call. WHat I really need is a tool to allow me to control teams without using the UI.&lt;/p>
&lt;p>Makers have worked on hacks for this. For example, the key combination &lt;code>ctrl+shift+m&lt;/code> toggles muting on teams. Add a big red button that simulates this key press and you have a quick way to mute or unmute. Here&amp;rsquo;s one example of this from &lt;a href="https://www.hackster.io/jenfoxbot/microsoft-teams-mute-button-7e9186">Jen Fox on Hackster&lt;/a>.&lt;/p>
&lt;p>&lt;img src="https://hackster.imgix.net/uploads/attachments/1234030/_5g18grpTco.blob?auto=compress%2Cformat&amp;amp;w=900&amp;amp;h=675&amp;amp;fit=min" alt="A white box with a big red button on top with a hand about to press the button. On the front of the bix is a circuit playground express with crocodile clips connecting it to the white box. In the background is a laptop showing a Microsoft teams meeting">&lt;/p>
&lt;p>For those with a less maker mindset, there&amp;rsquo;s now a new way to do this - using a Stream deck!&lt;/p>
&lt;p>&lt;img src="stream-deck-teams.png" alt="A stream deck with Teams buttons">&lt;/p>
&lt;p>If you&amp;rsquo;ve not come across a Stream Deck before, its a neat little gadget that comes in different sizes and has an array of LCD buttons. You can set these buttons up to do things like control apps, or make REST requests, and as each button is an LCD screen you can fully customize what is displayed. For example, you can use one of these to control apps like OBS to switch scenes, or start streaming to Twitch.&lt;/p>
&lt;p>There&amp;rsquo;s a whole Stream Deck store with plugins to extend the capabilities by controlling other apps or hardware (such as Phillips Hue lights). A Teams plugin has just been released!&lt;/p>
&lt;h2 id="set-up-your-stream-deck-for-teams">Set up your Stream Deck for Teams&lt;/h2>
&lt;p>To set up the Stream Deck, you need an API key for Teams to allow external apps to control it - makes sense really as Teams gives access to confidential work stuff, so you don&amp;rsquo;t want any app to be able to get access. Then you install the plug in, and set it up.&lt;/p>
&lt;h3 id="get-an-api-key">Get an API key&lt;/h3>
&lt;p>To get an API key:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Select the ellipses from the top-right corner of Teams, then select &lt;strong>Settings&lt;/strong>&lt;/p>
&lt;p>&lt;img src="./teams-elipses.png" alt="The settings menu in Teams under the ellipses">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Select the &lt;em>Privacy&lt;/em> tab, then scroll down to the &lt;em>Third-party app API section&lt;/em> and select &lt;strong>Manage API&lt;/strong>&lt;/p>
&lt;p>&lt;img src="./teams-privacy-tab.png" alt="The privacy tab">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>From the API settings, copy the API token. Use the &lt;strong>Generate&lt;/strong> button to generate a new API key if needed. And yes, the UI is terrible and the key wraps out of the text box&amp;hellip; 🤷&lt;/p>
&lt;p>&lt;img src="./teams-api-key.png" alt="The Teams API key dialog">&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>Now you have your key, you can set up your Stream Deck!&lt;/p>
&lt;h3 id="set-up-the-stream-deck">Set up the Stream Deck&lt;/h3>
&lt;p>Teams is managed from a plugin from the Stream Deck store.&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Open the Stream Deck store from the menu/taskbar icon&lt;/p>
&lt;p>&lt;img src="stream-deck-store.png" alt="The store menu item">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Search for Teams in the store, and install the Microsoft Teams plugin with the &lt;strong>install&lt;/strong> button&lt;/p>
&lt;p>&lt;img src="stream-deck-store-teams.png" alt="The Teams item in the store">&lt;/p>
&lt;p>You might also see this on the Store discover page - at the time of writing it&amp;rsquo;s the first item there.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Once installed, configure your Stream Deck using the Teams options. I did mine by creating a new profile that is activated when Teams is active.&lt;/p>
&lt;p>&lt;img src="./stream-deck-teams-profile.png" alt="Stream deck configuration showing a profile called Teams that is set to activate when Microsoft Teams is active">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Once your profile is ready, select it then add buttons by dragging them from the Microsoft Teams group in the menu. After adding each button, you will need to set the &lt;em>API token&lt;/em> field to the API key you copied from Teams.&lt;/p>
&lt;p>&lt;img src="stream-deck-teams-profile-buttons.png" alt="">&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>Done! You can now control Teams using your Stream Deck.&lt;/p></description></item><item><title>Format Rust code with cargo format</title><link>https://jimbobbennett.dev/blogs/cargo-fmt/</link><pubDate>Thu, 26 Jan 2023 00:00:00 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/cargo-fmt/</guid><description>&lt;blockquote>
&lt;p>This blog post was a fun one to write - cos I didn&amp;rsquo;t! I actually learned about &lt;code>cargo fmt&lt;/code> on a recent &lt;a href="https://www.youtube.com/watch?v=2Dd6wACDna8">Crack the code interview with Rust live stream&lt;/a> and decided a quick blog post would be fun.&lt;/p>
&lt;p>So I launched &lt;a href="https://chat.openai.com/chat">ChatGPT&lt;/a> and asked it to write this post! This is one of 2 posts written this way, so you will notice how similar this is to my &lt;a href="https://jimbobbennett.dev/blogs/cargo-clippy">&lt;code>cargo clippy&lt;/code>&lt;/a> post.&lt;/p>
&lt;/blockquote>
&lt;p>Rust is a popular programming language known for its safety and performance. One of the great things about Rust is the abundance of tools available to make development easier and more efficient. One such tool is cargo fmt, which is a command line utility for formatting Rust code. In this blog post, we&amp;rsquo;ll show you how to use cargo fmt to make your Rust code more readable and consistent.&lt;/p>
&lt;p>First, make sure that you have Rust and Cargo installed on your machine. If you don&amp;rsquo;t, you can download and install them from the official Rust website. Once you have Rust and Cargo set up, you can use the cargo fmt command to format your code.&lt;/p>
&lt;p>To format a specific file, navigate to the root directory of your project in the command line and run the following command:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>cargo fmt --file&lt;span style="color:#f92672">=&lt;/span>path/to/file.rs
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This will format the file located at path/to/file.rs.&lt;/p>
&lt;p>If you want to format all the files in your project, navigate to the root directory of your project in the command line and run the following command:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>cargo fmt
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This will format all the files in your project.&lt;/p>
&lt;p>You can also format all the files in your project and check for formatting errors by running the following command:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>cargo fmt --check
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This will check for formatting errors and display them in the command line. If there are no errors, the command will exit with a &lt;code>0&lt;/code> status code, otherwise it will exit with a non-zero status code.&lt;/p>
&lt;p>In addition to formatting files, cargo fmt also provides options to configure the formatting behavior. For example, you can configure the number of spaces used for indentation or the maximum line width. You can find more information about these options in the official Cargo documentation.&lt;/p>
&lt;p>In conclusion, cargo fmt is a powerful tool that can help you to make your Rust code more readable and consistent. It&amp;rsquo;s easy to use and provides a lot of options to customize the formatting behavior. By using cargo fmt, you can spend less time worrying about formatting and more time focusing on writing great code.&lt;/p></description></item><item><title>Lint Rust code with cargo clippy</title><link>https://jimbobbennett.dev/blogs/cargo-clippy/</link><pubDate>Thu, 26 Jan 2023 00:00:00 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/cargo-clippy/</guid><description>&lt;blockquote>
&lt;p>This blog post was a fun one to write - cos I didn&amp;rsquo;t! I actually learned about &lt;code>cargo clippy&lt;/code> on a recent &lt;a href="https://www.youtube.com/watch?v=2Dd6wACDna8">Crack the code interview with Rust live stream&lt;/a> and decided a quick blog post would be fun.&lt;/p>
&lt;p>So I launched &lt;a href="https://chat.openai.com/chat">ChatGPT&lt;/a> and asked it to write this post! This is one of 2 posts written this way, so you will notice how similar this is to my &lt;a href="https://jimbobbennett.dev/blogs/cargo-fmt">&lt;code>cargo fmt&lt;/code>&lt;/a> post.&lt;/p>
&lt;/blockquote>
&lt;p>Rust is a powerful programming language known for its safety and performance. One of the great things about Rust is the abundance of tools available to make development easier and more efficient. One such tool is cargo clippy, which is a command-line utility for linting Rust code. In this blog post, we&amp;rsquo;ll show you how to use cargo clippy to identify and fix potential errors in your Rust code.&lt;/p>
&lt;p>First, make sure that you have Rust and Cargo installed on your machine. If you don&amp;rsquo;t, you can download and install them from the official Rust website. Once you have Rust and Cargo set up, you can use the cargo clippy command to lint your code.&lt;/p>
&lt;p>To lint a specific file, navigate to the root directory of your project in the command line and run the following command:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>cargo clippy --file&lt;span style="color:#f92672">=&lt;/span>path/to/file.rs
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This will lint the file located at &lt;code>path/to/file.rs&lt;/code>.&lt;/p>
&lt;p>If you want to lint all the files in your project, navigate to the root directory of your project in the command line and run the following command:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>cargo clippy
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This will lint all the files in your project.&lt;/p>
&lt;p>Cargo clippy will provide suggestions and warnings for potential errors in your code, such as unused variables, unnecessary operations, and more. For example, it will suggest more efficient ways of writing your code and point out common pitfalls that could lead to runtime errors.&lt;/p>
&lt;p>You can also configure cargo clippy to check for specific types of errors. For example, you can use the &lt;code>-A&lt;/code> flag to check for specific lints or use &lt;code>-W&lt;/code> flag to check for warnings. You can find more information about these options in the official Cargo Clippy documentation.&lt;/p>
&lt;p>In addition to linting your code, cargo clippy also provides options to customize its behavior. For example, you can configure the level of verbosity or the maximum number of suggestions to display. You can find more information about these options in the official Cargo Clippy documentation.&lt;/p>
&lt;p>In conclusion, cargo clippy is a powerful tool that can help you to identify and fix potential errors in your Rust code. It&amp;rsquo;s easy to use and provides a lot of options to customize its behavior. By using cargo clippy, you can spend less time worrying about errors and more time focusing on writing great code.&lt;/p></description></item><item><title>Run an Ubuntu VM on your Mac with a single command</title><link>https://jimbobbennett.dev/blogs/running-ubuntu-on-a-mac/</link><pubDate>Tue, 24 Jan 2023 00:00:00 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/running-ubuntu-on-a-mac/</guid><description>&lt;p>I recently needed to run Linux so I could test out what Python version was installed, and how to upgrade it for some documentation I&amp;rsquo;m creating.&lt;/p>
&lt;p>I don&amp;rsquo;t have a spare machine to set up as a Linux box, and didn&amp;rsquo;t want to use a Raspberry Pi, I wanted a clean Ubuntu install.&lt;/p>
&lt;p>My original thought was to use VMWare Fusion Player, and spin up a VM, but things got a bit tricky - I installed it, created a new Ubuntu VM, and it just didn&amp;rsquo;t work. It didn&amp;rsquo;t have any install media, and just failed to boot. I&amp;rsquo;m not sure why, I just assumed &amp;lsquo;Create an Ubuntu VM&amp;rsquo; would just work&amp;hellip;&lt;/p>
&lt;p>So digging for an ISO, I cam across another method to install - &lt;a href="https://multipass.run">Multipass from Canonical&lt;/a>. No, this isn&amp;rsquo;t cheap movie tickets, instead its a free way to manage VMs using the hypervisor built into your OS - Hyper-V on Windows, QEMU and HyperKit on macOS and LXD on Linux.&lt;/p>
&lt;h2 id="installing-multipass">Installing Multipass&lt;/h2>
&lt;p>Multipass was easy to install on my Mac - it can be installed via homebrew:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>brew install --cask multipass
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre tabindex="0">&lt;code class="language-output" data-lang="output">==&amp;gt; Downloading https://github.com/canonical/multipass/releases/download/v1.11.0
==&amp;gt; Downloading from https://objects.githubusercontent.com/github-production-rel
######################################################################## 100.0%
==&amp;gt; Installing Cask multipass
==&amp;gt; Running installer for multipass; your password may be necessary.
Package installers may write to any location; options such as `--appdir` are ignored.
Password:
installer: Package name is multipass
installer: Installing at base path /
installer: The install was successful.
🍺 multipass was successfully installed!
&lt;/code>&lt;/pre>&lt;p>I had to enter my password (which makes sense as this installs some OS level stuff), but in a few seconds it was installed.&lt;/p>
&lt;h2 id="creating-a-vm">Creating a VM&lt;/h2>
&lt;p>Creating a new VM is easy - just one command to create and launch it:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>multipass launch
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This takes a loooooooong time the first time as it needs to download an image and create the new VM. Once the VM is created it will launched given a two-word name.&lt;/p>
&lt;pre tabindex="0">&lt;code class="language-output" data-lang="output">➜ ~ multipass launch
Launched: disarming-woodcock
&lt;/code>&lt;/pre>&lt;p>You can get more info on the VM using the &lt;code>info&lt;/code> command with the instance name:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>➜ ~ multipass info disarming-woodcock
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre tabindex="0">&lt;code class="language-output" data-lang="output">Name: disarming-woodcock
State: Running
IPv4: 192.168.64.2
Release: Ubuntu 22.04.1 LTS
Image hash: 8593ce1c6bbd (Ubuntu 22.04 LTS)
CPU(s): 1
Load: 0.27 0.17 0.07
Disk usage: 1.4GiB out of 4.7GiB
Memory usage: 149.2MiB out of 962.7MiB
Mounts: --
&lt;/code>&lt;/pre>&lt;p>Once the VM is running, you can log in to it using the &lt;code>shell&lt;/code> command with the instance name:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>multipass shell disarming-woodcock
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Done! I now have an Ubuntu VM ready to play with.&lt;/p></description></item><item><title>Subscribe to messages from an iRobot Create3 using ROS</title><link>https://jimbobbennett.dev/blogs/irobot-create3-subscribe-to-messages/</link><pubDate>Thu, 22 Sep 2022 00:00:00 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/irobot-create3-subscribe-to-messages/</guid><description>&lt;p>&lt;img src="banner.png" alt="An iRobot create with a Raspberry Pi">&lt;/p>
&lt;p>In my &lt;a href="../irobot-create3-connect-a-pi/">last post&lt;/a> I showed how I connected a Raspberry Pi to an iRobot Crete3 robot. In this post I show how to subscribe to messages sent by the robot to the Pi using &lt;a href="https://github.com/ros2/rclpy">rclpy&lt;/a>, the ROS Python library.&lt;/p>
&lt;blockquote>
&lt;p>One downside to ROS is that the documentation needs some love. It covers in great detail how to do things, but not the why, so anything I write in this post is based off my understanding from my couple of days working with ROS, and could be completely wrong! If so, please correct me in the comments.&lt;/p>
&lt;/blockquote>
&lt;h2 id="ros2-applications">ROS2 applications&lt;/h2>
&lt;p>ROS applications are based around a graph of &lt;em>nodes&lt;/em> that can publish and subscribe to messages on different topics. Each node can be a separate process, can run on a separate machine connected to the network, or you can have multiple nodes running in the same process.&lt;/p>
&lt;p>The robot is a node that published messages on various topics, and can listen to messages on other topics. If you read the last post, you will know that the robot has a range of topics that you can see by running &lt;code>ros2 topic list&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>/battery_state
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/cmd_audio
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/cmd_lightring
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/cmd_vel
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/dock
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/hazard_detection
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/imu
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/interface_buttons
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/ir_intensity
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/ir_opcode
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/kidnap_status
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/mobility_monitor/transition_event
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/mouse
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/odom
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/parameter_events
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/robot_state/transition_event
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/rosout
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/slip_status
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/static_transform/transition_event
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/stop_status
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/tf
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/tf_static
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/wheel_status
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/wheel_ticks
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/wheel_vels
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The majority of these topics contain sensor data published by the robot with the exception of the 3 &lt;code>cmd&lt;/code> topics - &lt;code>cmd_audio&lt;/code>, &lt;code>cmd_lightring&lt;/code> and &lt;code>cmd_vel&lt;/code>. You can publish data to these topics to play audio, configure the light ring, or move the robot.&lt;/p>
&lt;p>Topics are designed to have continuous streams of data. For example if you subscribe to the &lt;code>/battery_state&lt;/code> topic, you will get a continuous stream of battery data updated every few seconds.&lt;/p>
&lt;p>Robots can also have services and actions. These are abstractions that make it easier to program a robot. Services are designed for quick calls to do calculations or get states, maybe to query a sensor or take advantage of onboard processing such as a built-in image processor. Actions are commands you can send to a robot to do something, for example with the Create3 there are actions to dock and undock, so drive the robot to the docking station and connect it to recharge, or drive off the docking station.&lt;/p>
&lt;p>You can test the actions using the following run from your Raspberry Pi.&lt;/p>
&lt;p>Run this command to undock the robot:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>ros2 action send_goal /undock irobot_create_msgs/action/Undock &lt;span style="color:#e6db74">&amp;#34;{}&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Then run this command to re-dock the robot:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>ros2 action send_goal /dock irobot_create_msgs/action/DockServo &lt;span style="color:#e6db74">&amp;#34;{}&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>All the topics, services and actions are documented in the &lt;a href="https://iroboteducation.github.io/create3_docs/api/ros2/">iRobot ROS2 API docs&lt;/a>.&lt;/p>
&lt;h2 id="subscribing-to-messages-using-rclpy">Subscribing to messages using rclpy&lt;/h2>
&lt;p>&lt;a href="https://github.com/ros2/rclpy">rclpy&lt;/a> is the ROS Python library and has all the functionality you need to interact with a robot. But there is a catch - you can&amp;rsquo;t just create a Python script and use rclpy, you have to build a ROS2 application inside a ROS2 workspace.&lt;/p>
&lt;h3 id="ros2-workspaces">ROS2 workspaces&lt;/h3>
&lt;p>ROS applications are compiled inside a workspace - a folder with a predefined structure containing your code. You write your code, compile a ROS application using a tool called &lt;a href="https://colcon.readthedocs.io/en/released/">&lt;code>colcon&lt;/code>&lt;/a>, configure your environment by sourcing a file created by the build, then run your code using ROS.&lt;/p>
&lt;p>There is a core ROS workspace provided by the install, known as an underlay, and you can have multiple versions installed. You then stack additional workspaces on top with your own code, called overlays. No, I still don&amp;rsquo;t understand this and I can&amp;rsquo;t find good documentation to explain why.&lt;/p>
&lt;p>To use Python to developer ROS applications, you need to create a Python package inside your workspace, and this package contains the code for your executable. This is similar to creating a pip package, with &lt;code>setup.py&lt;/code> and &lt;code>setup.cfg&lt;/code> files, but with the addition of a &lt;code>package.xml&lt;/code> file to help &lt;code>colcon&lt;/code> build the package.&lt;/p>
&lt;p>You can find an example as a template repo on my GitHub at &lt;a href="https://github.com/jimbobbennett/irobot_create3_ros_workspace">github.com/jimbobbennett/irobot_create3_ros_workspace&lt;/a>. You can use this as a template to create your own workspace.&lt;/p>
&lt;h3 id="structure-of-the-workspace">Structure of the workspace&lt;/h3>
&lt;p>You can see the structure detailed blow by creating a new repo using the &lt;a href="https://github.com/jimbobbennett/irobot_create3_ros_workspace">github.com/jimbobbennett/irobot_create3_ros_workspace&lt;/a> template repo.&lt;/p>
&lt;p>The workspace consists of a &lt;code>src&lt;/code> folder where the source code for your application lives. This &lt;code>src&lt;/code> folder contains the Python package as a folder. This package folder contains &lt;code>setup.py&lt;/code> and &lt;code>setup.cfg&lt;/code> files. These files define any extra pip packages needed by your code, the location of the &lt;code>package.xml&lt;/code> file needed by &lt;code>colcon&lt;/code>, and the entry point for the ROS application.&lt;/p>
&lt;p>The &lt;code>package.xml&lt;/code> file details the ROS package, including dependencies on other packages. These include the ROS packages that define message formats. For example:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-xml" data-lang="xml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;lt;depend&amp;gt;&lt;/span>rclpy&lt;span style="color:#f92672">&amp;lt;/depend&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;lt;depend&amp;gt;&lt;/span>geometry_msgs&lt;span style="color:#f92672">&amp;lt;/depend&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;lt;depend&amp;gt;&lt;/span>sensor_msgs&lt;span style="color:#f92672">&amp;lt;/depend&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;lt;depend&amp;gt;&lt;/span>irobot_create_msgs&lt;span style="color:#f92672">&amp;lt;/depend&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This dependency list shows a dependency on the &lt;code>rclpy&lt;/code> ROS python package, as well as the packages for the generic geometry messages used to control a robot (&lt;code>geometry_msgs&lt;/code>), generic sensor messages used to gather standard sensor data such as battery state (&lt;code>sensor_msgs&lt;/code>), and the specific messages for the iRobot Create3 (&lt;code>irobot_create_msgs&lt;/code>).&lt;/p>
&lt;p>Inside the package folder is a folder containing your code, along with a &lt;code>resource&lt;/code> folder with a single file with the same name as the folder containing your code. No idea why, but it seems to be needed&amp;hellip;&lt;/p>
&lt;p>The code folder is a Python package, and needs an &lt;code>__init__.py&lt;/code> file, though this can be empty. Inside the code folder is another folder with your actual package code, again containing an &lt;code>__init__.py&lt;/code> file that can be empty, and a code file that contains your &lt;code>main&lt;/code> method, along with any other code files you need. Your &lt;code>setup.py&lt;/code> needs to point to this &lt;code>main&lt;/code> method as its entry point.&lt;/p>
&lt;h3 id="subscribing-to-messages">Subscribing to messages&lt;/h3>
&lt;p>If you look at the template repo, particularly the &lt;a href="https://github.com/jimbobbennett/irobot_create3_ros_workspace/blob/main/src/irobot_create3_example_py/irobot_create3_example_py/control_robot/control_robot.py">&lt;code>control_robot.py&lt;/code> file&lt;/a> you will see an example &lt;code>main&lt;/code> method.&lt;/p>
&lt;p>This method starts by initializing the ROS application with &lt;code>rclpy.init(args=args)&lt;/code>, passing any args sent to the application. It then creates a subscriber, in this case a subscriber to the battery state to get the percentage charge in the robots battery.&lt;/p>
&lt;p>Subscribers are ROS nodes - ROS applications are graphs of nodes that publish and subscribe messages, and your application can contain one oe more nodes, and nodes can publish and subscribe to as many topics as needed. In the template repo, the node in question is a battery state subscriber, implemented in the &lt;code>BatteryStateSubscriber&lt;/code> class:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">BatteryStateSubscriber&lt;/span>(Node):
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>All nodes need to derive from the &lt;code>rclpy.node.Node&lt;/code> base class, and this has functionality to manage subscriptions, logging, execution and more.&lt;/p>
&lt;p>In the &lt;code>__init__&lt;/code> method, the node creates a subscription to the battery state:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>self&lt;span style="color:#f92672">.&lt;/span>subscription_battery_state &lt;span style="color:#f92672">=&lt;/span> self&lt;span style="color:#f92672">.&lt;/span>create_subscription(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> BatteryState,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#39;/battery_state&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>get_battery_state,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> qos_profile)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The &lt;code>create_subscription&lt;/code> method on the base &lt;code>Node&lt;/code> class takes a number of options:&lt;/p>
&lt;ul>
&lt;li>&lt;code>BatteryState&lt;/code> - This is the message type. Messages can be raw strings, or typed. The &lt;code>sensor_msgs&lt;/code>, &lt;code>sensor_msgs&lt;/code> and &lt;code>irobot_create_msgs&lt;/code> packages described earlier contain the types for these messages. In this case, we want battery information, so the type is &lt;code>sensor_msgs.msg.BatteryState&lt;/code>, a ROS defined message for battery states.&lt;/li>
&lt;li>&lt;code>'/battery_state'&lt;/code> - This is the topic name used by the robot to publish the battery state&lt;/li>
&lt;li>&lt;code>self.get_battery_state&lt;/code> - This is the callback method called whenever a message is received by the subscription&lt;/li>
&lt;li>&lt;code>qos_profile&lt;/code> - This is the quality of service profile defined by the subscriber. This is covered &lt;a href="#quality-of-service">below&lt;/a>.&lt;/li>
&lt;/ul>
&lt;p>Once this subscription is created, every time a message is published on this topic, the callback method is called. The callback method has this signature:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">get_battery_state&lt;/span>(self, msg: BatteryState):
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The &lt;code>msg&lt;/code> passed is an instance of &lt;code>sensor_msgs.msg.BatteryState&lt;/code>, so the properties on this message can be queried to get the state of the battery. For example:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>self&lt;span style="color:#f92672">.&lt;/span>get_logger()&lt;span style="color:#f92672">.&lt;/span>info(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#39;Battery percentage:&lt;/span>&lt;span style="color:#e6db74">{:.0%}&lt;/span>&lt;span style="color:#e6db74">&amp;#39;&lt;/span>&lt;span style="color:#f92672">.&lt;/span>format(msg&lt;span style="color:#f92672">.&lt;/span>percentage))
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>uses the logger on the node to log out the current percentage charge on the battery.&lt;/p>
&lt;pre tabindex="0">&lt;code class="language-output" data-lang="output">[INFO] [1663974929.958794823] [battery_state_subscriber]: Subscribing to battery state
[INFO] [1663974930.072528455] [battery_state_subscriber]: Subscribed!
[INFO] [1663974931.658984386] [battery_state_subscriber]: Battery percentage:98%
&lt;/code>&lt;/pre>&lt;h3 id="quality-of-service">Quality of service&lt;/h3>
&lt;p>ROS ia based around sending messages to topics, and can be considered to be a message broker. Like all message brokers, there is a quality of service (QoS) that defines when a topic can be considered stale, how messages are stored if a subscriber is offline, things like that. You can read more in the &lt;a href="https://docs.ros.org/en/galactic/Concepts/About-Quality-of-Service-Settings.html">ROS quality of service documentation&lt;/a>, but the important point is that the subscriber &lt;strong>must&lt;/strong> subscribe with the same quality of service settings as the publisher or no messages will be received.&lt;/p>
&lt;p>You can find the QoS settings from a topic using this command:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>ros2 topic info -v &amp;lt;topic&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Where &lt;code>&amp;lt;topic&amp;gt;&lt;/code> is the name of the topic to query. In the case of the &lt;code>/battery_state&lt;/code> topic, the results of this call are:&lt;/p>
&lt;pre tabindex="0">&lt;code class="language-output" data-lang="output">Type: sensor_msgs/msg/BatteryState
Publisher count: 1
Node name: robot_state
Node namespace: /
Topic type: sensor_msgs/msg/BatteryState
Endpoint type: PUBLISHER
GID: 01.0f.34.90.5c.09.ad.d2.01.00.00.00.00.01.4f.03.00.00.00.00.00.00.00.00
QoS profile:
Reliability: BEST_EFFORT
Durability: VOLATILE
Lifespan: 9223372036854775807 nanoseconds
Deadline: 9223372036854775807 nanoseconds
Liveliness: AUTOMATIC
Liveliness lease duration: 9223372036854775807 nanoseconds
Subscription count: 0
&lt;/code>&lt;/pre>&lt;p>The relevant details are the &lt;code>QoS profile&lt;/code>, particularly the &lt;code>Reliability&lt;/code>, &lt;code>Durability&lt;/code>, and the &lt;code>Liveliness&lt;/code>. To subscribe to these messages, the subscriber needs to create a &lt;code>QoSProfile&lt;/code> object with the same settings, and pass this to the &lt;code>create_subscription&lt;/code> call:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> rclpy.qos &lt;span style="color:#f92672">import&lt;/span> QoSProfile, ReliabilityPolicy, LivelinessPolicy, DurabilityPolicy
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>qos_profile &lt;span style="color:#f92672">=&lt;/span> QoSProfile(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> reliability&lt;span style="color:#f92672">=&lt;/span>ReliabilityPolicy&lt;span style="color:#f92672">.&lt;/span>BEST_EFFORT,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> liveliness&lt;span style="color:#f92672">=&lt;/span>LivelinessPolicy&lt;span style="color:#f92672">.&lt;/span>AUTOMATIC,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> durability&lt;span style="color:#f92672">=&lt;/span>DurabilityPolicy&lt;span style="color:#f92672">.&lt;/span>VOLATILE,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> depth&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> )
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>self&lt;span style="color:#f92672">.&lt;/span>subscription_battery_state &lt;span style="color:#f92672">=&lt;/span> self&lt;span style="color:#f92672">.&lt;/span>create_subscription(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> BatteryState,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#39;/battery_state&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>get_battery_state,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> qos_profile)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;blockquote>
&lt;p>If you subscribe to a ROS topic and don&amp;rsquo;t receive any messages, check your QoS settings&lt;/p>
&lt;/blockquote>
&lt;h2 id="running-the-ros-application">Running the ROS application&lt;/h2>
&lt;p>Once you have your ROS workspace with your code, you can run it.&lt;/p>
&lt;p>The first step is to build the workspace:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>colcon build
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This command builds the package and creates 3 directories:&lt;/p>
&lt;ul>
&lt;li>&lt;code>build&lt;/code> - This contains the compiled Python package&lt;/li>
&lt;li>&lt;code>install&lt;/code> - This contains the application that can be installed and run on another device&lt;/li>
&lt;li>&lt;code>log&lt;/code> - This contains the build logs&lt;/li>
&lt;/ul>
&lt;p>To run the code, first you need to source an install script to set the environment:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>source ./install/local_setup.sh
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Finally run the ROS package:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>ros2 run &amp;lt;package name&amp;gt; &amp;lt;application&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>For example, if you use the template repo mentioned earlier in this post, you can run with:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>ros2 run irobot_create3_example_py control_robot
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This will run the &lt;code>control_robot&lt;/code> module in the &lt;code>irobot_create3_example_py&lt;/code> package, subscribing to the battery state and printing it to the console:&lt;/p>
&lt;pre tabindex="0">&lt;code class="language-output" data-lang="output">ubuntu@ubuntu:~/irobot_create3_ros_workspace$ ros2 run irobot_create3_example_py control_robot
[INFO] [1663974929.958794823] [battery_state_subscriber]: Subscribing to battery state
[INFO] [1663974930.072528455] [battery_state_subscriber]: Subscribed!
&lt;/code>&lt;/pre></description></item><item><title>Connect a Raspberry Pi to an iRobot Create 3</title><link>https://jimbobbennett.dev/blogs/irobot-create3-connect-a-pi/</link><pubDate>Wed, 21 Sep 2022 00:00:00 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/irobot-create3-connect-a-pi/</guid><description>&lt;p>&lt;img src="banner.png" alt="An iRobot create with a Raspberry Pi">&lt;/p>
&lt;p>iRobot, the makers of robotic vacuum cleaners also make educational robots designed for learning how to do robotics programming. I recently managed to get my hands on one of their &lt;a href="https://edu.irobot.com/what-we-offer/create3">new Create3 robots&lt;/a> as part of the Microsoft Global Hackathon, one of the cool perks of working for Microsoft.&lt;/p>
&lt;p>These robots are the same as the vacuum cleaners, except without the vacuum part. They have all the same sensors, with extra connectivity for you to program yourself. The beginner option is to program them in Python using their browser-based tooling that connects using bluetooth, but I wanted to do something more advanced and learn a bit about ROS!&lt;/p>
&lt;h2 id="ros">ROS&lt;/h2>
&lt;p>&lt;a href="https://www.ros.org">ROS, short for Robot Operating System&lt;/a> is, as the name suggests, an &amp;lsquo;operating system&amp;quot; for robots. Despite the name, it&amp;rsquo;s not so much an operating system, more a set of software libraries and tools for building and controlling robots that runs on top of Windows or Linux. It&amp;rsquo;s fully open source and free to use.&lt;/p>
&lt;blockquote>
&lt;p>The downside to ROS is that the documentation needs some love. It covers in great detail how to do things, but not the why, so anything I write in this post is based off my understanding from my couple of days working with ROS, and could be completely wrong! If so, please correct me in the comments.&lt;/p>
&lt;/blockquote>
&lt;p>ROS has a concept of a graph of nodes that connect to each other, nodes can be actuators, sensors, or parts of the control code. Nodes communicate by sending messages on named topics to any other node that is listening.&lt;/p>
&lt;p>The iRobot Create3 runs ROS2, the current version of ROS. ROS has version names for the minor versions, and my Create3 runs &lt;a href="https://docs.ros.org/en/galactic/index.html">Galactic Geochelone&lt;/a> 🤷. The Create3 can connect to a compute board running ROS that can be programmed to receive messages from the sensors on the Create3, or send messages to the actuators. The compute board can be a Raspberry Pi, a NVIDIA Jetson Nano, or an NXP NavQ+. This compute board can then connect to additional sensors or actuators (for example LIDAR or a camera), add control logic for the robot, and connect to the internet such as to IoT or AI services.&lt;/p>
&lt;p>In my case, I want to connect a Raspberry Pi 4. The goal is to start by sending status data to an IoT Central dashboard, then expand to add a camera and code to detect and find objects using image-based AI. Maybe get it to play chase with my daughters cats.&lt;/p>
&lt;h2 id="connect-a-raspberry-pi-4">Connect a Raspberry Pi 4&lt;/h2>
&lt;p>To connect a Raspberry Pi, first you need to install Ubuntu, then connect it over USB-C, then configure the robot. All the instructions are in the &lt;a href="https://iroboteducation.github.io/create3_docs/hw/rpi_hookup/">Create3 compute board documentation&lt;/a>, but I&amp;rsquo;ve included a basic run through here with some additional observations of things that caught me out!&lt;/p>
&lt;h3 id="install-and-configure-ubuntu">Install and configure Ubuntu&lt;/h3>
&lt;p>ROS runs on Ubuntu, not on the default Raspberry Pi OS, so you need to start with a clean install of Ubuntu server on an SD card. From the Raspberry Pi imager you can create an image of Ubuntu Server 20.04. As I am using a Raspberry Pi 4, I used the 64-bit version. You can find this under &lt;em>Other general purpose OS -&amp;gt; Ubuntu&lt;/em>&lt;/p>
&lt;p>&lt;img src="rpi-imager-ubuntu.png" alt="Selecting the Ubuntu image">&lt;/p>
&lt;p>Once the image is created, you need to update some configuration on the image before you insert it into your Pi. The &lt;a href="https://iroboteducation.github.io/create3_docs/setup/pi4/">documentation&lt;/a> tells you the changes to make, but the important gotcha is that the &lt;code>network-config&lt;/code> file that you update to set your WiFi details will get copied on first boot into a &lt;code>yaml&lt;/code> file, so you &lt;strong>must&lt;/strong> get the indentation correct:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">network&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">ethernets&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">eth0&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">dhcp4&lt;/span>: &lt;span style="color:#66d9ef">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">optional&lt;/span>: &lt;span style="color:#66d9ef">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">usb0&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">addresses&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">192.168.186.3&lt;/span>&lt;span style="color:#ae81ff">/24&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">dhcp4&lt;/span>: &lt;span style="color:#66d9ef">false&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">optional&lt;/span>: &lt;span style="color:#66d9ef">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">version&lt;/span>: &lt;span style="color:#ae81ff">2&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">wifis&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">wlan0&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">access-points&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;SSID&amp;#34;&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">password&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;password&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">dhcp4&lt;/span>: &lt;span style="color:#66d9ef">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">optional&lt;/span>: &lt;span style="color:#66d9ef">true&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>I found the first time the Pi boots it won&amp;rsquo;t connect, it needs to boot a second time. Not sure why or if you will get the same.&lt;/p>
&lt;p>It&amp;rsquo;s worth having a monitor and keyboard at the ready in case the Pi doesn&amp;rsquo;t automatically connect to your network. If it doesn&amp;rsquo;t, you will need to update the network configuration. To do this from the Pi, edit the &lt;code>/etc/netplan/50-cloud-init.yaml&lt;/code> file, &lt;strong>not&lt;/strong> the &lt;code>network-config&lt;/code> in the root of the SD card - this file is only read the first time. Once you have updated the &lt;code>/etc/netplan/50-cloud-init.yaml&lt;/code> file, reload the network plan using this command:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>sudo netplan apply
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>If you configured everything correctly you should be able to connect to the internet. You can test this out by pinging a website.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>ubuntu@ubuntu:~$ ping google.com
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>PING google.com &lt;span style="color:#f92672">(&lt;/span>142.251.211.238&lt;span style="color:#f92672">)&lt;/span> 56&lt;span style="color:#f92672">(&lt;/span>84&lt;span style="color:#f92672">)&lt;/span> bytes of data.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">64&lt;/span> bytes from sea30s13-in-f14.1e100.net &lt;span style="color:#f92672">(&lt;/span>142.251.211.238&lt;span style="color:#f92672">)&lt;/span>: icmp_seq&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span> ttl&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">117&lt;/span> time&lt;span style="color:#f92672">=&lt;/span>9.30 ms
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">64&lt;/span> bytes from sea30s13-in-f14.1e100.net &lt;span style="color:#f92672">(&lt;/span>142.251.211.238&lt;span style="color:#f92672">)&lt;/span>: icmp_seq&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span> ttl&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">117&lt;/span> time&lt;span style="color:#f92672">=&lt;/span>7.76 ms
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">64&lt;/span> bytes from sea30s13-in-f14.1e100.net &lt;span style="color:#f92672">(&lt;/span>142.251.211.238&lt;span style="color:#f92672">)&lt;/span>: icmp_seq&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">3&lt;/span> ttl&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">117&lt;/span> time&lt;span style="color:#f92672">=&lt;/span>8.48 ms
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Once you have network connectivity, continue installing all the required software listed in the &lt;a href="https://iroboteducation.github.io/create3_docs/setup/pi4/">documentation&lt;/a>.&lt;/p>
&lt;h3 id="configure-the-ros-middleware-rmw">Configure the ROS middleware (RMW)&lt;/h3>
&lt;p>One of the last steps is to configure the ROS middleware, known as the RMW. This middleware is responsible for networking, and transmitting messages around. There are 2 options that the Create supports - CycloneDDS and FastDDS. I&amp;rsquo;d recommend FastDDS as it works with multiple networks out of the box. Your Pi will be configured with 2 network connections - a WiFi connection so you can program it, and a USB connection so it can talk to the Create3 robot. Out the box FastDDS can work with both of these, CycloneDDS does not unless you configure it.&lt;/p>
&lt;p>Run this command to configure the Pi to use FastDDS.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>echo &lt;span style="color:#e6db74">&amp;#34;export RMW_IMPLEMENTATION=rmw_fastrtps_cpp&amp;#34;&lt;/span> &amp;gt;&amp;gt; ~/.bashrc
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Once the Pi is configured, you will need to configure the RMW on the Create3. To do this:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Set the robot into WiFi access point mode by pressing and holding buttons 1 and 2 at the same time till the LED flashed blue and the robot plays its happy noise.&lt;/p>
&lt;p>&lt;img src="irobot-wifi-mode.gif" alt="Putting the Create 3 in WiFi mode">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Connect your computer to the WiFi from the Create3. It will be called &lt;code>Create-xxxx&lt;/code> where &lt;code>xxxx&lt;/code> is a mix of numbers and letters. The robot will play its happy noise when you connect.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Navigate to &lt;code>192.168.10.1&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Select &lt;strong>Connect&lt;/strong> and set the WiFi so the Robot can connect to the internet. If you don&amp;rsquo;t do this, you will need to install an NTP server on your Pi to ensure the robot has the correct time. Messages are time based, so the robot and the Pi needs to have the same time. The &lt;a href="https://iroboteducation.github.io/create3_docs/setup/compute-ntp/">network time documentation&lt;/a> has the instructions for setting this up if needed. Note that running &lt;code>sudo chronyc clients&lt;/code> to see the connected clients will return nothing if the Pi is not plugged in to the robot, and may take a while to show a connection the first time.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Select &lt;em>Application -&amp;gt; Configuration&lt;/em>&lt;/p>
&lt;p>&lt;img src="irobot-app-config.png" alt="The configuration option in the application menu">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Set the value of &lt;code>RMW_IMPLEMENTATION&lt;/code> to &lt;code>rwm_fastrtps_cpp&lt;/code>&lt;/p>
&lt;p>&lt;img src="irobot-ros-rmw.png" alt="The RWM settings">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Select &lt;strong>Save&lt;/strong> then &lt;strong>Restart Application&lt;/strong>. The robot will reboot.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h3 id="connect-and-test-the-pi">Connect and test the Pi&lt;/h3>
&lt;p>Once the robot reboots, you can connect the Pi using a USB-C cable.&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Open the top of the robot and ensure the USB/Bluetooth switch is set to USB. Then close the top.&lt;/p>
&lt;p>&lt;img src="irobot-usb-switch.png" alt="The USB bluetooth switch set to USB">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Open the cargo bay to access the USB-C socket, and insert a USB-C cable.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Connect the other end of the cable to the USB-C socket on the Pi. This socket provides both power and connectivity.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>If you want the Pi to be screwed in place, you can &lt;a href="https://iroboteducation.github.io/create3_docs/hw/print_compute/#large-mount">3D print a caddy&lt;/a> that the Pi connects to.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Close the cargo bay and wait for the Pi to boot up.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>The default hostname for the Pi is &lt;code>ubuntu&lt;/code>, but I&amp;rsquo;ve not been able to connect from macOS by sshing into &lt;code>ubuntu.local&lt;/code>, so you will need the IP address. Either using your routers software to find it, or connect the Pi to a monitor/keyboard, boot it up and run &lt;code>ip a&lt;/code> to get the IP address of the &lt;code>wlan0&lt;/code> network.&lt;/p>
&lt;p>Connect to the Pi over SSH using the username &lt;code>ubuntu&lt;/code> and password &lt;code>ubuntu&lt;/code>. You will need to change the password the first time you log in.&lt;/p>
&lt;p>Once you are in, you can verify the Pi is talking to the robot successfully buy running the following command:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>ros2 topic list
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This command lists all the topics that the Pi is able to see from the robot. These topics are how you can receive sensor data by subscribing to messages, and send commands to actuators.&lt;/p>
&lt;p>The output should be:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>/battery_state
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/cmd_audio
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/cmd_lightring
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/cmd_vel
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/dock
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/hazard_detection
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/imu
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/interface_buttons
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/ir_intensity
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/ir_opcode
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/kidnap_status
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/mobility_monitor/transition_event
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/mouse
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/odom
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/parameter_events
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/robot_state/transition_event
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/rosout
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/slip_status
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/static_transform/transition_event
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/stop_status
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/tf
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/tf_static
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/wheel_status
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/wheel_ticks
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/wheel_vels
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The Pi can only see the topics if it was connected and booted when the robot boots up. If most of the topics are missing and you only see this list of topics:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>/parameter_events
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/rosout
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Then you need to reboot your robot. The easiest way is to press buttons 1 and 2 to start the WiFi access point, then connect to it and select &lt;em>Application -&amp;gt; Reboot robot&lt;/em>.&lt;/p>
&lt;p>Your Pi is now connected and ready to program your first ROS application!&lt;/p></description></item><item><title>Led Ticker Tape</title><link>https://jimbobbennett.dev/blogs/led-ticker-tape/</link><pubDate>Fri, 25 Feb 2022 17:01:05 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/led-ticker-tape/</guid><description>&lt;p>&lt;img src="hello-lights.png" alt="An LED panel showing Hello in green">&lt;/p>
&lt;p>Anyone who knows me knows I&amp;rsquo;m a big fan of IoT and LEDs. I love using IoT devices to control lights, from the LEDs behind my desk to &lt;a href="https://www.youtube.com/watch?v=h5ETn4PTdQA">smart pumpkins&lt;/a>!&lt;/p>
&lt;p>I&amp;rsquo;ve been giving the .NET IoT libraries a spin for an upcoming project using a Raspberry Pi Zero W 2. I&amp;rsquo;m usually a Python person when using a Pi, but the project I&amp;rsquo;m working on needs a service that doesn&amp;rsquo;t have Python libraries that run on a Pi. Instead it has a .NET library, so it was time to break out my C# skills for the first time in years.&lt;/p>
&lt;p>I wanted to build an LED panel that can display text, either static text or scrolling text. So I picked up this &lt;a href="https://amzn.to/3sVjF7M">WS2812B panel from Amazon (affiliate link)&lt;/a>, and started to dig into the .NET IoT libraries. WS2818b LEDs are also known as NeoPixels, and are addressable multicolor LEDs, so you can light up individual ones in any color you like. They are addressed based on the order they are connected to your device, so the first pixel in a string of LEDs is 0, the next is 1 and so on. You can add as many as you like, and the addresses just keep going up.&lt;/p>
&lt;p>The .NET IoT libraries are on GitHub at &lt;a href="https://github.com/dotnet/iot">github.com/dotnet/iot&lt;/a> and available as a NuGet. They support a wide range of boards including the Raspberry Pi.&lt;/p>
&lt;h2 id="lighting-leds-in-c">Lighting LEDs in C#&lt;/h2>
&lt;p>I started as I usually do with a clean install of Raspberry Pi OS Lite. I use the Lite version as I access my Pi remotely using VS Code for all my development. You can read more on how I do this on &lt;a href="https://www.raspberrypi.com/news/coding-on-raspberry-pi-remotely-with-visual-studio-code/">my blog post on the Raspberry Pi blog&lt;/a>. When I connected to my Pi I installed .NET 6, and the C# extension in VS Code.&lt;/p>
&lt;blockquote>
&lt;p>One thing to note for the C# extension is it doesn&amp;rsquo;t support remote debugging on the Pi Zero W 2.&lt;/p>
&lt;/blockquote>
&lt;p>The .NET IoT libraries have a small amount of documentation and samples, so it wasn&amp;rsquo;t too much effort to get the LEDs lighting up.&lt;/p>
&lt;p>The .NET libraries control these pixels over SPI, so they need to be connected to an SPI pin and ground on the Pi, as well as to a 5V power supply. You can&amp;rsquo;t use the 5V pins on the Pi as the panel can draw too much power and burn your Pi out, it&amp;rsquo;s best to use an external 5V power supply, either from a USB connection or a power converter plugged into the mains.&lt;/p>
&lt;p>You also need to do a bit of SPI configuration, and this is documented in the &lt;a href="https://github.com/dotnet/iot/tree/main/src/devices/Ws28xx">GitHub source code for the WS2812B device code&lt;/a>.&lt;/p>
&lt;blockquote>
&lt;p>This is different to using the Adafruit NeoPixel libraries from Python, where you use different pins and don&amp;rsquo;t need any SPI configuration.&lt;/p>
&lt;/blockquote>
&lt;p>To use the .NET libraries, you start by creating an SPI configuration, then use that to create the pixels:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">// Create connection settings to connect to the panel using SPI&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>SpiConnectionSettings settings = &lt;span style="color:#66d9ef">new&lt;/span>(&lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ClockFrequency = &lt;span style="color:#ae81ff">2_400_000&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Mode = SpiMode.Mode0,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> DataBitLength = &lt;span style="color:#ae81ff">8&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>};
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">// Create an SPI device&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> spi = SpiDevice.Create(settings);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">// Use the SPI device to connect to the LEDs&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">// and pass the number of LEDs&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> neoPixels = &lt;span style="color:#66d9ef">new&lt;/span> Ws2812b(spi, &lt;span style="color:#ae81ff">256&lt;/span>);
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>When you create the pixels, you pass in the length of the strip. I&amp;rsquo;ve been using a 8x32 panel, which is actually a 256 pixel long strip arranged in and up/down pattern.&lt;/p>
&lt;p>Once created, you light pixels by getting a &lt;code>BitmapImage&lt;/code> from them, and setting colors on that. This image is a &lt;code>length x 1&lt;/code> image, so 1 pixel tall, and as wide as the length of the LEDs. For example, my 8x32 panel is 256 pixels long, so is a bitmap of 256x1.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> img = neoPixels.Image;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>You can then set pixels in this image to the color you want. The color is set using the &lt;code>System.Drawing.Color&lt;/code> struct, which wraps ARGB values. The A (alpha channel) is ignored, so you set pixel brightness by reducing the value of the R, G, and B.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="display:flex;">&lt;span>img.SetPixel(&lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, Color.Red);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>img.SetPixel(&lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, Color.Green);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>img.SetPixel(&lt;span style="color:#ae81ff">2&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, Color.Blue);
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Once the pixels are set in the image, it is committed and the LEDs updated.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="display:flex;">&lt;span>neoPixels.Update();
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>One quirk of the bitmaps, is you have to set all the pixels up to the last one you want set. So if you want to set pixel 10 to be red, you have to also set pixels 0-9 to something, even if it is &lt;code>Color.Black&lt;/code> (off). The first pixel you set is mapped to the first LED in the strip, so if you just set pixels 10-20, then the strip is set as if the first LED was pixel 10.&lt;/p>
&lt;p>For example, if you just want to set pixel 2 to blue, you can&amp;rsquo;t do this:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> img = neoPixels.Image;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>img.SetPixel(&lt;span style="color:#ae81ff">2&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, Color.Blue);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>neoPixels.Update();
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>What will happen here is pixel 2 is the first one with a value, so that will be considered the first pixel in the strip, so the first LED will light up blue.
What you need to do is:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> img = neoPixels.Image;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>img.SetPixel(&lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, Color.Black);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>img.SetPixel(&lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, Color.Black);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>img.SetPixel(&lt;span style="color:#ae81ff">2&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, Color.Blue);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>neoPixels.Update();
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This will set the pixels 0 and 1 to off, and pixel 2 to blue.&lt;/p>
&lt;h2 id="writing-text">Writing text&lt;/h2>
&lt;p>I wanted to make my panel show text, either short static text, or scrolling text. The first thing I needed was a font - something that defines how to create letters from pixels. I found a similar project based on Arduino in a &lt;a href="https://github.com/bigjosh/SimpleTickerTape/tree/main/fonts">GitHub project from Josh Levine&lt;/a> so leveraged this code for a font and re-wrote it in C#.&lt;/p>
&lt;p>Next I needed the mapping code. These fonts are defined as columns of binary data, so the bits to set. Each character is 8 bits tall (the size of my panel), and 6 bits wide. This mapping code was a bit of fun as I not only needed to divide up my pixels into columns, and map from a pixel in the 1 dimensional strip to a character pixel, but the strips go up and down!&lt;/p>
&lt;p>The way this panel is made is by weaving an LED strip up and down, so the pixels start at 0 on the top left, go down to 7 on the left-most column, then across one pixel to the right to 8, then up to 15.&lt;/p>
&lt;p>This gives for the first few columns:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">0&lt;/span> &lt;span style="color:#ae81ff">15&lt;/span> &lt;span style="color:#ae81ff">16&lt;/span> &lt;span style="color:#ae81ff">31&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#ae81ff">14&lt;/span> &lt;span style="color:#ae81ff">17&lt;/span> &lt;span style="color:#ae81ff">30&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">2&lt;/span> &lt;span style="color:#ae81ff">13&lt;/span> &lt;span style="color:#ae81ff">18&lt;/span> &lt;span style="color:#ae81ff">29&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">3&lt;/span> &lt;span style="color:#ae81ff">12&lt;/span> &lt;span style="color:#ae81ff">19&lt;/span> &lt;span style="color:#ae81ff">28&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">4&lt;/span> &lt;span style="color:#ae81ff">11&lt;/span> &lt;span style="color:#ae81ff">20&lt;/span> &lt;span style="color:#ae81ff">27&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">5&lt;/span> &lt;span style="color:#ae81ff">10&lt;/span> &lt;span style="color:#ae81ff">21&lt;/span> &lt;span style="color:#ae81ff">26&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">6&lt;/span> &lt;span style="color:#ae81ff">9&lt;/span> &lt;span style="color:#ae81ff">22&lt;/span> &lt;span style="color:#ae81ff">25&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">7&lt;/span> &lt;span style="color:#ae81ff">8&lt;/span> &lt;span style="color:#ae81ff">23&lt;/span> &lt;span style="color:#ae81ff">24&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This means that the mapping code needs to alternate - for 0dd numbered columns the pixels go down, for even numbered the pixels go up so the mapping has to be reversed!&lt;/p>
&lt;p>I&amp;rsquo;m not going to dive into all this mapping here, but you can find the code with full documentation in my &lt;a href="https://github.com/jimbobbennett/NeoPixelTickerTape">NeoPixelTickerTape GitHub repo&lt;/a>.&lt;/p>
&lt;p>I then added scrolling code that writes text starting at the right-most column, then re-writes it shifting left a column at a time.&lt;/p>
&lt;p>&lt;img src="tickertape.gif" alt="Hello world scrolling across the ticker tape">&lt;/p>
&lt;h2 id="check-out-the-code">Check out the code&lt;/h2>
&lt;p>You can find the code with full documentation in my &lt;a href="https://github.com/jimbobbennett/NeoPixelTickerTape">NeoPixelTickerTape GitHub repo&lt;/a>.&lt;/p>
&lt;p>You can also download a NuGet package to use in your apps:&lt;/p>
&lt;p>&lt;img src="https://img.shields.io/nuget/v/JimBobBennett.NeoPixelTickerTape.svg?style=flat&amp;amp;logo=nuget" alt="Select this to access the nuget">&lt;/p></description></item><item><title>Auto-posting to dev.to using a GitHub action</title><link>https://jimbobbennett.dev/blogs/auto-posting-to-dev-to/</link><pubDate>Thu, 03 Feb 2022 00:00:00 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/auto-posting-to-dev-to/</guid><description>&lt;p>&lt;img src="stream-screenshot.png" alt="A screenshot from teh live stream mentioned here">&lt;/p>
&lt;p>I&amp;rsquo;ve been wanting to build a tool to post markdown automatically to blogging platforms. That way I (or anyone else) can write a blog post in markdown, save it in a &lt;a href="https://github.com">GitHub&lt;/a> repo, and have it automatically posted to a blogging platform of their choice.&lt;/p>
&lt;p>I&amp;rsquo;ve created a small Python app to do this, and you can find it on GitHub at &lt;a href="https://github.com/jimbobbennett/auto-blog-poster">github.com/jimbobbennett/auto-blog-poster&lt;/a>. You add some special folders to any folders containing README.md files, and it will create a blog post from the markdown. It will also track when the README file changes and update the blog post.&lt;/p>
&lt;p>It&amp;rsquo;s slightly annoying to have to remember to run this every time you create or update a post, so I wanted to make it so it could be run automatically. GitHub actions are the perfect way to do this.&lt;/p>
&lt;h2 id="what-are-github-actions">What are GitHub actions?&lt;/h2>
&lt;p>GitHub actions is GitHubs CI/CD solution. CI is continuous integration, meaning every time code changes, your code can be built and tested. CD is continuous deployment, so once code is tested it can be deployed automatically.&lt;/p>
&lt;p>Essentially you can specify code that is run whenever someone checks in any changes, merges a branch or PR, or raises issues, creates PRs, any task really that you can do in GitHub. GitHub manages spinning up a VM to run everything, all you have to do is write your action, and pay (obviously - the best things in life are not always free).&lt;/p>
&lt;p>GitHub actions are defined using YAML inside your repository (in a &lt;code>.github\workflows&lt;/code> folder), and you can call out to &lt;em>actions&lt;/em> that do things, such as checking out code, tagging, running scripts, anything you need. You can also build custom actions.&lt;/p>
&lt;h2 id="custom-actions">Custom actions&lt;/h2>
&lt;p>A custom action is one you write yourself to do whatever you need. In my case, I want my posting code to be run every time I update a markdown file in another repo, and this is something I can do with a custom action.&lt;/p>
&lt;p>Custom actions are either written in JavaScript/TypeScript, or run from a Docker container. My app is Python, so I need to use Docker.&lt;/p>
&lt;h3 id="creating-a-docker-custom-action">Creating a Docker custom action&lt;/h3>
&lt;p>Docker custom actions are Docker containers that can be run, and will stop when they are complete - you package up your app in a container, and provide it with an &lt;code>ENTRYPOINT&lt;/code> so that Docker can run something.&lt;/p>
&lt;p>I created a Dockerfile for my auto post tool, along with a shell script as the entrypoint:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Create this docker file based off a Python 3.9 Linux image&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>FROM python:3.9-slim-buster
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Run everything from /app&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>WORKDIR /app
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Copy over the files&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>COPY requirements.txt requirements.txt
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>COPY app.py app.py
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>COPY dev_to.py dev_to.py
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>COPY github_access.py github_access.py
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>COPY entrypoint.sh entrypoint.sh
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Install the Python requirements&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>RUN pip3 install -r requirements.txt
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Execute the shell script as the entrypoint&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ENTRYPOINT /app/entrypoint.sh &lt;span style="color:#e6db74">${&lt;/span>@&lt;span style="color:#e6db74">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This Dockerfile creates a container using a Python base image, copies all my files over, installs my Pip package dependencies, then sets the entrypoint.&lt;/p>
&lt;p>The interesting thing to note here is the parameter passed to the &lt;code>entrypoint.sh&lt;/code> script - &lt;code>${0}&lt;/code>. My app needs some secrets passed to it - an API key for Dev.to to allow it to post, the repo to post from, and a GitHub token to allow it to update the repo once the post is up. I don&amp;rsquo;t want these embedded in the container as I want to be able to use this action from different repositories (and allow others to use it), so I want these passed when the action is run. The &lt;code>${0}&lt;/code> syntax means everything that is set as an environment variable when running the container, so this passes all the environment variables to the shell script, where they can be used in the app.&lt;/p>
&lt;p>This means running the container like this:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>docker run ghcr.io/jimbobbennett/auto-blog-poster:main
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> --env DEV_TO_API_KEY&lt;span style="color:#f92672">=&lt;/span>xxx
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> GITHUB_ACCESS_TOKEN&lt;span style="color:#f92672">=&lt;/span>xxx
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> REPO&lt;span style="color:#f92672">=&lt;/span>xxx/yyy
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Will pass &lt;code>DEV_TO_API_KEY=xxx GITHUB_ACCESS_TOKEN=xxx REPO=xxx/yyy&lt;/code> to the shell script, and this can be set as a local environment variable in the container.&lt;/p>
&lt;p>Once created, I can build this container and publish it to the GitHub container registry from an action inside the repo for my post tool.&lt;/p>
&lt;p>This is my action to publish my Docker container:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">Docker Image CI&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">on&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">push&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">branches&lt;/span>: [ &lt;span style="color:#ae81ff">main ]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">pull_request&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">branches&lt;/span>: [ &lt;span style="color:#ae81ff">main ]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">env&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">REGISTRY&lt;/span>: &lt;span style="color:#ae81ff">ghcr.io&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">IMAGE_NAME&lt;/span>: &lt;span style="color:#ae81ff">${{ github.repository }}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">jobs&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">build&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">runs-on&lt;/span>: &lt;span style="color:#ae81ff">ubuntu-latest&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">steps&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">Log in to the Container registry&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">uses&lt;/span>: &lt;span style="color:#ae81ff">docker/login-action@f054a8b539a109f9f41c372932f1ae047eff08c9&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">with&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">registry&lt;/span>: &lt;span style="color:#ae81ff">${{ env.REGISTRY }}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">username&lt;/span>: &lt;span style="color:#ae81ff">${{ github.actor }}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">password&lt;/span>: &lt;span style="color:#ae81ff">${{ secrets.GITHUB_TOKEN }}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">uses&lt;/span>: &lt;span style="color:#ae81ff">actions/checkout@v2&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">Extract metadata (tags, labels) for Docker&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">id&lt;/span>: &lt;span style="color:#ae81ff">meta&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">uses&lt;/span>: &lt;span style="color:#ae81ff">docker/metadata-action@98669ae865ea3cffbcbaa878cf57c20bbf1c6c38&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">with&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">images&lt;/span>: &lt;span style="color:#ae81ff">${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">Build and push Docker image&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">uses&lt;/span>: &lt;span style="color:#ae81ff">docker/build-push-action@ad44023a93711e3deb337508980b4b5e9bcdc5dc&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">with&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">context&lt;/span>: &lt;span style="color:#ae81ff">.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">push&lt;/span>: &lt;span style="color:#66d9ef">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">tags&lt;/span>: &lt;span style="color:#ae81ff">${{ steps.meta.outputs.tags }}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">labels&lt;/span>: &lt;span style="color:#ae81ff">${{ steps.meta.outputs.labels }}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This action is run on a push or PR on the main branch. It runs on an Ubuntu VM, logs into the GitHub container registry, checks out my code, gets the tag for the package, builds it and pushed it to the registry.&lt;/p>
&lt;p>This code has some variables that come from GitHub. Any variable that starts &lt;code>${{ github.xxx }}&lt;/code> is set automatically by GitHub to a relevant value such as the repo name. &lt;code>${{ steps.meta.outputs.xxx }}&lt;/code> are set as outputs of certain steps, and &lt;code>${{ secrets.xxx }}&lt;/code> are secrets you can set on your repo. &lt;code>${{ secrets.GITHUB_TOKEN }}&lt;/code> is a special secret you don&amp;rsquo;t need to set that provides an API token to interact with the current repo.&lt;/p>
&lt;p>Once this container is pushed, I can use it from an action inside my blog repo!&lt;/p>
&lt;h3 id="using-a-docker-custom-action">Using a Docker custom action&lt;/h3>
&lt;p>To use a Docker custom action, I can just pull it from inside my blog repo action and run it. Here&amp;rsquo;s the action YAML:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">on&lt;/span>: [&lt;span style="color:#ae81ff">push]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">env&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">REGISTRY&lt;/span>: &lt;span style="color:#ae81ff">ghcr.io&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">jobs&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">build&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">runs-on&lt;/span>: &lt;span style="color:#ae81ff">ubuntu-latest&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">steps&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">Log in to the Container registry&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">uses&lt;/span>: &lt;span style="color:#ae81ff">docker/login-action@f054a8b539a109f9f41c372932f1ae047eff08c9&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">with&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">registry&lt;/span>: &lt;span style="color:#ae81ff">${{ env.REGISTRY }}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">username&lt;/span>: &lt;span style="color:#ae81ff">${{ github.actor }}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">password&lt;/span>: &lt;span style="color:#ae81ff">${{ secrets.GITHUB_TOKEN }}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">Use Docker CLI&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">uses&lt;/span>: &lt;span style="color:#ae81ff">actions-hub/docker/cli@master&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">env&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">SKIP_LOGIN&lt;/span>: &lt;span style="color:#66d9ef">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">run&lt;/span>: &lt;span style="color:#ae81ff">docker pull ghcr.io/jimbobbennett/auto-blog-poster:main&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">run&lt;/span>: &amp;gt;&lt;span style="color:#e6db74">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> docker run ghcr.io/jimbobbennett/auto-blog-poster:main
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> --env DEV_TO_API_KEY=${{ secrets.DEV_TO_API_KEY }}
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> GITHUB_ACCESS_TOKEN=${{ secrets.GITHUB_TOKEN }}
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> REPO=${{ github.repository }}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This action uses a docker custom action to log in to the GitHub container registry, pull my container, then run it, passing in an API key for Dev.to, the GitHub token and the current repository.&lt;/p>
&lt;p>That&amp;rsquo;s it - now every time the blog post markdown changes in my repo, it is automatically deployed to Dev.to.
At the moment this is just a playground, but the plan is to build out a new blog that uses this - all the posts will be in GitHub, and it will post to another blogging platform and Dev.to at every checkin.&lt;/p>
&lt;h2 id="learn-more">Learn more&lt;/h2>
&lt;p>GitHub actions are a lot of fun, and a great way to set up CI/CD. I did a live stream where I worked all this out here:&lt;/p>
&lt;p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/MSfeKTOO1Tc" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;br>
You can also read more on the great &lt;a href="https://docs.github.com/actions">GitHub Actions docs&lt;/a>.&lt;/p></description></item><item><title>Getting started with GitHub Codespaces</title><link>https://jimbobbennett.dev/blogs/github-codespaces/</link><pubDate>Thu, 27 Jan 2022 00:00:00 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/github-codespaces/</guid><description>&lt;p>&lt;img src="banner.png" alt="VS Code running a code space">&lt;/p>
&lt;p>The bane of every new developers life is getting your environment set up to be productive. And when I say new developer - I don&amp;rsquo;t just mean a dev who is new to a team, but every developer who needs to work on a project they haven&amp;rsquo;t worked on before.&lt;/p>
&lt;p>Each project has it&amp;rsquo;s own dependencies, required tools, required libraries, a whole swathe of things that need to be installed, and can in some cases cause problems when projects have conflicting requirements. I certainly remember having to uninstall/reinstall different tooling versions when switching projects, sometimes multiple times a day 😱.&lt;/p>
&lt;p>What if there was a way to fix this? If we could instantly have a pre-configured developer machine with the right tools that we need available at the click of a button? Even better one powered by the cloud so we don&amp;rsquo;t even need to worry about the power of our local machine, or even be able to access from a tablet or phone? This is where &lt;a href="https://github.com/features/codespaces">Codespaces&lt;/a> comes in.&lt;/p>
&lt;p>&lt;a href="https://github.com/features/codespaces">GitHub Codespaces&lt;/a> are virtual developer machines in the cloud that you access through VS Code, running either on your desktop or in a browser. You can launch any GitHub repo inside a Codespace, with everything you do running in that Codespace - your code lives there, your debug sessions run there, your terminal runs commands there, it&amp;rsquo;s as if someone teleported a dev machine into your office!&lt;/p>
&lt;h2 id="setting-up-a-codespace">Setting up a Codespace&lt;/h2>
&lt;p>I&amp;rsquo;ve been recently working on a project for my team that consists of a Python app that I want to run as a Docker container, so I thought it would be fun to configure the repo for this to run inside a Codespace so when anyone else on the team wants to work on it, they won&amp;rsquo;t have any local configuration to do.&lt;/p>
&lt;h3 id="sign-up-for-codespaces">Sign up for Codespaces&lt;/h3>
&lt;p>Codespaces needs to be set up for a team or organization - mainly so someone can pay! Despite the claims that the best things in life are free, you do need to pay for Codespace.&lt;/p>
&lt;h3 id="open-your-repo-in-a-codespace">Open your repo in a Codespace&lt;/h3>
&lt;p>The first step is to open the repo in Codespaces. From the repo in GitHub, select &lt;strong>Codespaces&lt;/strong> from the &lt;strong>Code&lt;/strong> button, then select &lt;strong>New codespace&lt;/strong>.&lt;/p>
&lt;p>&lt;img src="image-2.png" alt="The new codespace button">&lt;/p>
&lt;p>This will set up your code in a new Codespace - essentially a blank VM using a default image from GitHub. This image is based off Ubuntu, and comes pre-configured with Python. Node, Docker and other stuff. You can read up on this default image at &lt;a href="https://aka.ms/ghcs-default-image">aka.ms/ghcs-default-image&lt;/a>.&lt;/p>
&lt;p>This image contains almost everything I need - the tools are all installed, and VS Code is running with my code in it.&lt;/p>
&lt;p>&lt;img src="image-3.png" alt="VS Code running in a browser under Codespaces">&lt;/p>
&lt;p>My code is in Python, and this image comes with Python 3.8 installed. It means I can create a Codespace, and run my code in only a few seconds!&lt;/p>
&lt;h2 id="configure-your-codespace">Configure your Codespace&lt;/h2>
&lt;p>The good news is Codespaces are configurable - you can define the details for the container in which your Codespace runs in a &lt;code>devcontainer.json&lt;/code> file. I can use this to change the image used, configure what tools are installed, that sort of thing. The big upside of this is to ensure I have the right versions - the default container currently has Python 3.8 installed, but I can create a devcontainer file to set another version.&lt;/p>
&lt;p>I&amp;rsquo;ll start by creating a devcontainer file. The Codespaces extension is installed for you in VS Code, so you can use the command palette to access options to configure the devcontainer file.&lt;/p>
&lt;p>I started by selecting &lt;strong>Codespaces: Add Development Container Configuration Files&amp;hellip;.&lt;/strong>&lt;/p>
&lt;p>&lt;img src="image-4.png" alt="The Codespaces: Add Development Container Configuration Files command palette option">&lt;/p>
&lt;p>From there I selected &lt;strong>From a predefined container configuration definition&amp;hellip;&lt;/strong> to use a pre-defined image. I could also use any container I have in my container registry.&lt;/p>
&lt;p>&lt;img src="image-5.png" alt="The From a predefined container configuration definition option">&lt;/p>
&lt;p>From the images I chose a Python 3 image, and selected Python 3.10.&lt;/p>
&lt;p>&lt;img src="image-6.png" alt="The image options with a range of images to choose from">&lt;/p>
&lt;p>&lt;img src="image-9.png" alt="The python 3 version options">&lt;/p>
&lt;p>I then had an option to add a Node version, so selected None as I don&amp;rsquo;t want Node.&lt;/p>
&lt;p>&lt;img src="image-10.png" alt="Node version selection">&lt;/p>
&lt;p>Next I could select features to pre-install. I selected Docker as I need support for that.&lt;/p>
&lt;p>&lt;img src="image-11.png" alt="Selecting the docker option for the container">&lt;/p>
&lt;p>2 things now happen. 2 new files are created in my explorer, &lt;code>devcontainer.json&lt;/code> and &lt;code>Dockerfile&lt;/code> in a folder called &lt;code>.devcontainer&lt;/code>, and a toast will popup suggesting I rebuild the container. When I do this, Codespaces will restart with a new image based off my selections. It takes a while the first time as the container needs to be built.&lt;/p>
&lt;p>&lt;img src="image-12.png" alt="The toast popup">&lt;/p>
&lt;p>The devcontainer.json file directs the Codespace to use the Dockerfile that was created to define the image. It then includes things like a list of extensions that VS Code will need - in my case PyLance.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-json" data-lang="json">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">&amp;#34;extensions&amp;#34;&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">:&lt;/span> [
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;ms-python.python&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;ms-python.vscode-pylance&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>]&lt;span style="color:#960050;background-color:#1e0010">,&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>I could and any more extensions here if I wanted, such as the Docker extension.&lt;/p>
&lt;p>I could also edit these files to create a virtual environment, install Python packages, that sort of thing - though I&amp;rsquo;m not sure I&amp;rsquo;d need a virtual environment as my container will only be used to develop from this repo, so I could install packages globally and not worry.&lt;/p>
&lt;h3 id="check-in-your-files">Check in your files&lt;/h3>
&lt;p>Once you are happy with your dev container setup, you can then check the .devcontainer folder and all it&amp;rsquo;s contents into your repo. This will then be used by anyone who creates a Codespace for your repo!&lt;/p>
&lt;h2 id="learn-more">Learn more&lt;/h2>
&lt;p>If you want to learn more, check out the Codespaces docs - &lt;a href="https://docs.github.com/codespaces">docs.github.com/codespaces&lt;/a>. There was also some great videos on it from GitHub Universe, this particular one by &lt;a href="https://twitter.com/2PercentSilk">Allison Weins&lt;/a> and Bailey Brooks works through the configuration of Codespaces.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/X9Z-rUixnzk" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div></description></item><item><title>New year - new me!</title><link>https://jimbobbennett.dev/blogs/new-year-new-me/</link><pubDate>Fri, 14 Jan 2022 22:44:32 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/new-year-new-me/</guid><description>&lt;p>🧀 Ah yes, a post title that&amp;rsquo;s cheesier than the best Parisian Fromageries.&lt;/p>
&lt;p>Actually it&amp;rsquo;s not a new me, I&amp;rsquo;m still the same old me, but I have changed jobs! I&amp;rsquo;ve just started as a Regional Cloud Advocate working for the Microsoft Reactor team, based in Redmond, WA, USA.&lt;/p>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/new-year-new-me/IMG_6008.png"
alt="A red neon sign saying Reactor Fun Zone">&lt;figcaption>
&lt;p>A red neon sign saying Reactor Fun Zone&lt;/p>
&lt;/figcaption>
&lt;/figure>
&lt;h2 id="what-is-a-microsoft-reactor">What is a &amp;lsquo;Microsoft Reactor&amp;rsquo;?&lt;/h2>
&lt;p>The &lt;a href="https://developer.microsoft.com/reactor/?WT.mc_id=academic-0000-jabenn">Microsoft Reactors&lt;/a> are our community spaces. We have 12 Reactors around the world, and we use these spaces to run events and bring communities together. We see these as spaces to learn and grow, to build your networks and build your skills.&lt;/p>
&lt;p>The video below was filmed at the launch party for the Reactor London. The most important line in that video comes from &lt;a href="https://twitter.com/jeffsand">Jeff Sandquist&lt;/a>, the head of Developer Relations at Microsoft who says &amp;ldquo;I really hope that you don&amp;rsquo;t look at this space as a Microsoft facility, that you actually look at it as yours&amp;rdquo;.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/8UxxOT5iZNw" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;h2 id="but-theres-no-masks-in-that-video">But there&amp;rsquo;s no masks in that video?&lt;/h2>
&lt;p>Don&amp;rsquo;t worry, we&amp;rsquo;re all safe. That video was recorded pre-COVID, and to ensure the safety of our communities our Reactor spaces have pivoted to on-line. You may have watched some of our events already streamed on our &lt;a href="https://www.youtube.com/channel/UCkm6luGCS3hD25jcEhvRMIA/playlists">YouTube&lt;/a> or &lt;a href="https://www.twitch.tv/microsoftdeveloper">Twitch&lt;/a> channels, or on &lt;a href="https://docs.microsoft.com/learn/tv/?WT.mc_id=academic-0000-jabenn">LearnTV&lt;/a>. Currently our locations are closed, but we are very much on-line, streaming a huge range of content from both Microsoft folks and community members.&lt;/p>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/new-year-new-me/image-1.png"
alt="Reactor landing page for a live streamed Global AI bootcamp in Toronto">&lt;figcaption>
&lt;p>Reactor landing page for a live streamed Global AI bootcamp in Toronto&lt;/p>
&lt;/figcaption>
&lt;/figure>
&lt;h2 id="so-whats-the-new-job-about">So what&amp;rsquo;s the new job about?&lt;/h2>
&lt;p>My new job is to support communities, both on-line and in the local area. Redmond in Washington State, USA is the home of Microsoft, but in the surrounding Seattle area and beyond there are a huge array of tech communities thanks to the draw of tech companies both large and small, from Amazon to Zulily.&lt;/p>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/new-year-new-me/BIT_COMMUNITY-copy.png"
alt="Cartoon racoons holding a laptop saying Community">&lt;figcaption>
&lt;p>Cartoon racoons holding a laptop saying Community&lt;/p>
&lt;/figcaption>
&lt;/figure>
&lt;p>I&amp;rsquo;ll be doing this in a number of ways. I&amp;rsquo;ll be running on-line streams to grow our Reactor meetup channel, with me learning or building with various technologies, I&amp;rsquo;ll be hosting community members and supporting their events, and I&amp;rsquo;ll be helping to grow out our Reactor as a space for communities to come together. I believe the the move from in-person to virtual, and the current thoughts on hybrid has given us the perfect opportunity to reset the traditional Meetup model, and build truly inclusive experiences for everyone - not just those who can make it to a venue at 6pm to drink beer, eat pizza and talk tech. I&amp;rsquo;ve had &lt;a href="https://github.com/jimbobbennett/MakingMeetupsMoreAccessible">thoughts on this in the past&lt;/a>, but really feel now we can all build more inclusive communities.&lt;/p>
&lt;h2 id="reactor-redmond">Reactor Redmond&lt;/h2>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/new-year-new-me/IMG_6028.png"
alt="The Reactor logo on the door of the Reactor in Redmond">&lt;figcaption>
&lt;p>The Reactor logo on the door of the Reactor in Redmond&lt;/p>
&lt;/figcaption>
&lt;/figure>
&lt;p>The Reactor in Redmond, in Building 20 on the Microsoft campus is my home base. It&amp;rsquo;s a great space for events both small and medium sized, with a range of options for space to use. As we get more of a plan on re-opening I&amp;rsquo;ll post more with details on how you can sign up to use the space.&lt;/p>
&lt;h2 id="how-can-i-use-the-reactors">How can I use the Reactors?&lt;/h2>
&lt;p>Right now the Reactors are closed for events, but what we can offer is world class streaming facilities! We&amp;rsquo;ve been building out our AV (audio visual) tech to support streaming, so although we can&amp;rsquo;t bring your communities into our space, we can broadcast you from there to your communties. Get in touch if you live near a Reactor and want to discuss how we can support your streaming.&lt;/p>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/new-year-new-me/IMG_6014.png"
alt="A panoramic view of the Reactor showing desks and Surface Hubs">&lt;figcaption>
&lt;p>A panoramic view of the Reactor showing desks and Surface Hubs&lt;/p>
&lt;/figcaption>
&lt;/figure>
&lt;p>We&amp;rsquo;d also love to host you on one of our streams. If you want to stream through the Reactor meetup group, again get in touch and we&amp;rsquo;ll get you schedued. We have Reactors around the world, so we can fit into your time zone.&lt;/p>
&lt;h2 id="what-about-iot">What about IoT?&lt;/h2>
&lt;p>Don&amp;rsquo;t worry, I still love IoT and I&amp;rsquo;ll be streaming a load of IoT content. This new role won&amp;rsquo;t change my technical focus, it just means I can work with a wider audience.&lt;/p>
&lt;h2 id="join-us">Join us!&lt;/h2>
&lt;p>Come join our meetup group - you can sign up on Meetup.com:&lt;/p>
&lt;p>&lt;a href="https://www.meetup.com/pro/microsoft-reactor">https://www.meetup.com/pro/microsoft-reactor&lt;/a>&lt;/p></description></item><item><title>Announcing a New Free Curriculum: IoT for Beginners</title><link>https://jimbobbennett.dev/blogs/announcing-iot-for-beginners/</link><pubDate>Fri, 09 Jul 2021 00:00:00 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/announcing-iot-for-beginners/</guid><description>&lt;p>It is our very great pleasure to announce the release of a new, free, MIT-licensed open-source curriculum all about the Internet of Things: &lt;a href="https://aka.ms/iot-beginners">IoT for Beginners&lt;/a>. Brought to you by a team of Azure Cloud Advocates, Program Managers, and &lt;a href="https://studentambassadors.microsoft.com/">Microsoft Learn Student Ambassadors&lt;/a>, we hope to empower students of all ages to learn the basics of IoT. Presuming no knowledge of IoT, we offer a free 12-week, 24-lesson curriculum to help you dive into this amazing field.&lt;/p>
&lt;p>If you liked our first two curricula, &lt;a href="https://aka.ms/webdev-beginners">Web Dev for Beginners&lt;/a> and &lt;a href="https://aka.ms/ml-beginners">Machine Learning for beginners&lt;/a>, you will love IoT for Beginners!&lt;/p>
&lt;h2 id="join-us-on-the-journey-of-your-food-from-farm-to-table">Join us on the journey of your food, from farm to table!&lt;/h2>
&lt;p>🌽 Join us as we take the same journey as your food as it travels from farm to table, taking advantage of IoT on the way to improve farming, transport, manufacturing and food processing, retail and smart homes. 🌽&lt;/p>
&lt;p>Our curricula are structured with a modified Project-Based pedagogy and include:&lt;/p>
&lt;ul>
&lt;li>a pre-lesson warmup quiz&lt;/li>
&lt;li>a written lesson&lt;/li>
&lt;li>video&lt;/li>
&lt;li>knowledge checks&lt;/li>
&lt;li>a project to build&lt;/li>
&lt;li>infographics, sketchnotes, and visuals&lt;/li>
&lt;li>a challenge&lt;/li>
&lt;li>an assignment&lt;/li>
&lt;li>a post-lesson quiz&lt;/li>
&lt;li>opportunities to deepen your knowledge on Microsoft Learn&lt;/li>
&lt;/ul>
&lt;h2 id="what-will-you-learn">What will you learn?&lt;/h2>
&lt;p>&lt;img src="Roadmap.jpg" alt="The curriculum roadmap">&lt;/p>
&lt;p>The lessons are grouped so that you can deep-dive into use cases of IoT. We start with an introduction to IoT, covering devices, sensors, actuators and cloud connectivity, where you will build an internet connected version of the &amp;ldquo;Hello world&amp;rdquo; or IoT, an LED. We then move on to farming, learning about digital agriculture and feedback loops to control automated watering systems. Your food then leaves the farm on trucks, and you learn how to track vehicles using GPS, visualize their journeys and get alerts when a truck approaches a processing plant. Once in the plant, we move to AIoT, learning how to distinguish between ripe and unripe fruit using AI models running from IoT devices and on the edge. Next we move to the supermarket, using IoT to manage stock levels. Finally we take the food home to cook, and learn about consumer smart devices, building a voice controlled smart timer that can even speak multiple languages.&lt;/p>
&lt;h2 id="hardware">Hardware&lt;/h2>
&lt;p>The hard part (pun intended) for IoT is hardware, so we&amp;rsquo;ve designed this curriculum to be as accessible as possible. We want you to Learn IoT, not learn how to solder, know how to read resistor color codes, or know what a microfarad is, so we&amp;rsquo;ve made hardware choices to make things easier.&lt;/p>
&lt;p>You can choose to learn using microcontrollers using Arduino with a &lt;a href="https://www.seeedstudio.com/Wio-Terminal-p-4509.html">Wio Terminal&lt;/a>, or single board computers using a &lt;a href="https://www.raspberrypi.org/products/raspberry-pi-4-model-b/">Raspberry Pi&lt;/a>. We&amp;rsquo;ve also added a &lt;a href="https://github.com/CounterFit-IoT">virtual hardware option&lt;/a> so you can learn without having to purchase anything!&lt;/p>
&lt;p>For sensors and actuators, we&amp;rsquo;ve gone with the &lt;a href="https://www.seeedstudio.com/category/Grove-c-1003.html">Grove kit&lt;/a> from &lt;a href="https://www.seeedstudio.com/">Seeed Studio&lt;/a>, with easy to connect sensors and actuators.&lt;/p>
&lt;p>&lt;img src="seeed.png" alt="The Seeed studio logo">&lt;/p>
&lt;p>Our friends at Seeed have made it easy to buy the hardware, with packages containing all of the kit you need.&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://www.seeedstudio.com/IoT-for-beginners-with-Seeed-and-Microsoft-Wio-Terminal-Starter-Kit-p-5006.html">IoT for beginners with Seeed and Microsoft - Wio Terminal Starter Kit&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.seeedstudio.com/IoT-for-beginners-with-Seeed-and-Microsoft-Raspberry-Pi-Starter-Kit.html">IoT for beginners with Seeed and Microsoft - Raspberry Pi 4 Starter Kit&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>If you are interested in learning using virtual hardware, you can write IoT code locally as if you were using a Raspberry Pi, then simulate sensors and actuators using &lt;a href="https://github.com/CounterFit-IoT">CounterFit&lt;/a>, a free, open source tool for simulating hardware.&lt;/p>
&lt;h2 id="a-sneak-peek">A sneak peek&lt;/h2>
&lt;p>This curriculum is filled with a lot of art, created by our team. Take a look at this cool sketchnote created by &lt;a href="https://twitter.com/nitya">@nitya&lt;/a>.&lt;/p>
&lt;p>&lt;img src="sketchnote.png" alt="A sketch note visualizing lesson 1 of the curriculum">&lt;/p>
&lt;p>Without further ado, please meet &lt;a href="https://aka.ms/iot-beginners">IoT For Beginners: A Curriculum&lt;/a>!&lt;/p></description></item><item><title>Using TinyML to identify farts</title><link>https://jimbobbennett.dev/blogs/tiny-ml-farts/</link><pubDate>Mon, 22 Feb 2021 17:01:05 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/tiny-ml-farts/</guid><description>&lt;blockquote>
&lt;p>TLDR; Find a complete hands-on lab to build a TinyML audio classifier at &lt;a href="https://github.com/microsoft/iot-curriculum/tree/main/labs/tiny-ml/audio-classifier">github.com/microsoft/iot-curriculum/tree/main/labs/tiny-ml/audio-classifier&lt;/a>.&lt;/p>
&lt;/blockquote>
&lt;p>My 8-year-old daughter bought me &amp;ldquo;Farts - a spotters guide&amp;rdquo; - a book with some buttons down the side and when you press them, they make different fart sounds. This is the height of humor for an 8 year old, and still pretty funny as an adult. I thought it would be fun to see if I could distinguish between the different fart noises using machine learning - and not just any machine learning, but seeing as I love IoT, I wanted it to run on a microcontroller!&lt;/p>
&lt;p>&lt;img src="fart-book.jpg" alt="Farts, a spotters guide">&lt;/p>
&lt;h2 id="tinyml">TinyML&lt;/h2>
&lt;p>TinyML is a relatively new field, and is all about creating tiny machine learning models that can run on microcontrollers. These models are really tiny - in the order of kilobytes instead of the usual megabytes or gigabytes. They need to be this tiny to run on microcontrollers that typically have kilobytes of RAM. These models also draw little power, typically in the single-digit milliwatts or lower.&lt;/p>
&lt;p>What are the use cases for TinyML? Well there are loads, anywhere you want to run ML models offline with minimal power draw. You may even have some TinyML models running in your house right now. For example, smart voice controlled devices listen for a wake word, and this needs to be offline and draw minimal power - perfect for a TinyML model. Another use case is in healthcare with devices that can monitor your health that run for years on tiny batteries. It&amp;rsquo;s also being used in animal smart collars and trackers, &lt;a href="https://www.hackster.io/contests/ElephantEdge">using audio to monitor the health of elephants in the wild&lt;/a>. So yes - a fart detector has a real world application!&lt;/p>
&lt;p>To build a TinyML model you need to decide what type of model to build, gather training data, train the model, then deploy it to your device to handle new data. In this case, I wanted an audio classifier, so decided to use a &lt;a href="https://scikit-learn.org/stable/modules/svm.html">support vector machine classifier&lt;/a>.&lt;/p>
&lt;blockquote>
&lt;p>Despite this sounding all fancy and like I know what I&amp;rsquo;m talking about, I actually have no clue what this is - I just learned about them from a great tutorial which I followed to get inspiration for this post! The tutorial is &lt;a href="https://eloquentarduino.github.io/2020/08/better-word-classification-with-arduino-33-ble-sense-and-machine-learning/">Better word classification with Arduino Nano 33 BLE Sense and Machine Learning&lt;/a>.&lt;/p>
&lt;/blockquote>
&lt;h2 id="building-a-fart-detector">Building a fart detector&lt;/h2>
&lt;p>For my fart detector, I needed to build an audio classifier that could run on a microcontroller. Because I&amp;rsquo;m terrible at electronics and understanding I2C, SPI and all that other stuff, I decided to use an all-in-one Arduino board that has a microphone built in allowing me to use off-the-shelf Arduino libraries to gather audio data. The board of choice was the Arduino Nano 33 Sense BLE board, a small Arduino board with a whole raft of sensors including a microphone, temperature, pressure, humidity, light level and color, gesture and proximity. That&amp;rsquo;s a lot of sensors in such a tiny board!&lt;/p>
&lt;p>&lt;img src="nano-sense.jpg" alt="An arduino Nano sense 33 BLE IoT board">&lt;/p>
&lt;p>To code this board, I could use the free Arduino IDE, but I prefer to use &lt;a href="https://code.visualstudio.com/">Visual Studio Code&lt;/a>, along with the &lt;a href="https://platformio.org/">PlatformIO extension&lt;/a>. This allows the creation of standalone microcontroller projects with .ini files that define the board and libraries used. I can check a project into GitHub and someone can clone it and immediately start working with it without the need for instructions on what boards and libraries they need to set up.&lt;/p>
&lt;h3 id="getting-training-data">Getting training data&lt;/h3>
&lt;p>To train TinyML models you not only need the model to by tiny, but you also need small inputs - the more data that goes into training the model or inference (that is running the model), the larger it is. Audio data can be quite large - for example CD quality audio (remember CDs?) is 44.1KHz/16-bit which means it captures 2 bytes of data 44,100 times per second, or 176KB per second! That&amp;rsquo;s a lot of data - if we wanted to use all of it and train our model with 2 seconds worth of data it wouldn&amp;rsquo;t be TinyML any more.&lt;/p>
&lt;p>A great trick with audio data is realizing you don&amp;rsquo;t need all of it to classify particular sounds. Instead you can get an average value that represents many samples and use that as the data. In the case of the Arduino, the library that captures audio, &lt;a href="https://www.arduino.cc/en/Reference/PDM">PDM&lt;/a>, captures audio at 16KHz in 512 byte buffers, containing 256 2-byte samples. This means each buffer has 1/64th of a second of audio data in it. We can then calculate a root mean square (RMS) of all this data to get a single 4-byte floating point value. If we do this for every buffer, we end up with 64 4-byte floats per second, or 256 bytes per second. Much smaller than raw audio at the PDM sample rate of 16KHz giving 32,000 bytes per second!&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cpp" data-lang="cpp">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">#define BUFFER_SIZE 512U
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span>...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">// Check we have a full buffers worth
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#66d9ef">if&lt;/span> (PDM.available() &lt;span style="color:#f92672">==&lt;/span> BUFFER_SIZE)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// Read from the buffer
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> PDM.read(_buffer, BUFFER_SIZE);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// Calculate the root mean square value of the buffer
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">int16_t&lt;/span> rms;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> arm_rms_q15((q15_t &lt;span style="color:#f92672">*&lt;/span>)_buffer, BUFFER_SIZE&lt;span style="color:#f92672">/&lt;/span>&lt;span style="color:#66d9ef">sizeof&lt;/span>(&lt;span style="color:#66d9ef">int16_t&lt;/span>), (q15_t &lt;span style="color:#f92672">*&lt;/span>)&lt;span style="color:#f92672">&amp;amp;&lt;/span>rms);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The RMS value can be checked against a threshold to see if there is actual audio data or not, and if audio data is detected, the next 2 seconds worth can be grabbed. In this case it&amp;rsquo;s output to the serial port so it can be read from the PlatformIO serial monitor in VS Code.&lt;/p>
&lt;p>You can find the full code to capture audio samples in the &lt;a href="https://github.com/microsoft/iot-curriculum/tree/main/labs/tiny-ml/audio-classifier/code/audio-capture">Microsoft IoT Curriculum resource GitHub repo in the labs folder&lt;/a>.&lt;/p>
&lt;h3 id="train-the-model">Train the model&lt;/h3>
&lt;p>To train the model, we need a good range of audio data captured from the Arduino device - ideally 15-30 samples per audio we want to classify. A classifier distinguishes the input between multiple labels, so we need to gather data for multiple labels. For example, to classify the farts from my fart book I&amp;rsquo;d need to gather 15-30 samples for at least 2 different farts.&lt;/p>
&lt;p>The audio data sent to the serial monitor from the Arduino can be captured into .csv files, and these can be loaded by a Python script and used to train a model.&lt;/p>
&lt;p>The model in question is trained using &lt;a href="https://scikit-learn.org/">Scikit-Learn&lt;/a>, a Python Machine Learning library. The audio data is loaded into numpy arrays, then split into training and testing data, the model is trained using the training data, then tested with the testing data to give an idea on the accuracy.&lt;/p>
&lt;blockquote>
&lt;p>If you have a nice shiny Apple M1 mac (like I do), then installing Scikit-Learn is currently not as easy. Check out my &lt;a href="https://jimbobbennett.dev/blogs/installing-scikit-learn-on-an-apple-m1/">guide on how to install it&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cpp" data-lang="cpp">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Split the data into a training and testing set to test the accuracy of the model
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># If you are happy with the accuracy of the model, you can remove this split
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span>dataset_train, dataset_test, label_train, label_test &lt;span style="color:#f92672">=&lt;/span> train_test_split(dataset, dataset_labels.ravel(), test_size&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">0.2&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Build the support vector classification for our data and train the model
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span>svc &lt;span style="color:#f92672">=&lt;/span> SVC(kernel&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">&amp;#39;&lt;/span>poly&lt;span style="color:#960050;background-color:#1e0010">&amp;#39;&lt;/span>, degree&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span>, gamma&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">0.1&lt;/span>, C&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">100&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>svc.fit(dataset_train, label_train)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Test the accuracy of the model
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span>print(&lt;span style="color:#960050;background-color:#1e0010">&amp;#39;&lt;/span>Accuracy:&lt;span style="color:#960050;background-color:#1e0010">&amp;#39;&lt;/span>, svc.score(dataset_test, label_test))
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Once the model has been trained, it can be exported using the rather useful &lt;a href="https://pypi.org/project/micromlgen/">micromlgen Python library&lt;/a> which can convert ML models into raw C++ code to run on microcontrollers.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cpp" data-lang="cpp">&lt;span style="display:flex;">&lt;span>from micromlgen import port
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Convert the model to C code and write to the classifier.h file
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span>c_code &lt;span style="color:#f92672">=&lt;/span> port(svc, classmap&lt;span style="color:#f92672">=&lt;/span>label_map)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>with open(&lt;span style="color:#960050;background-color:#1e0010">&amp;#39;&lt;/span>classifier.h&lt;span style="color:#960050;background-color:#1e0010">&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;w&amp;#39;&lt;/span>) as f:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> f.write(c_code)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> f.close()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>You can find the training code in the &lt;a href="https://github.com/microsoft/iot-curriculum/tree/main/labs/tiny-ml/audio-classifier/code/model-trainer">Microsoft IoT Curriculum resource GitHub repo in the labs folder&lt;/a>.&lt;/p>
&lt;h2 id="classify-farts">Classify farts&lt;/h2>
&lt;p>The C++ code that comes out of the training can then be added to the microcontroller code. Instead of dumping the audio data to the serial port, it can be sent to the classifier code, and the label of the best match is returned.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cpp" data-lang="cpp">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">void&lt;/span> &lt;span style="color:#a6e22e">processSamples&lt;/span>()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// Write out the classification to the serial port
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> Serial.print(&lt;span style="color:#e6db74">&amp;#34;Label: &amp;#34;&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Serial.println(clf.predictLabel(_samples));
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="learn-more">Learn more&lt;/h2>
&lt;p>You can find a complete hands on lab implementing this in the &lt;a href="https://github.com/microsoft/iot-curriculum/tree/main/labs/tiny-ml/audio-classifier">Microsoft IoT Curriculum resource GitHub repo in the labs folder&lt;/a>.&lt;/p></description></item><item><title>Installing Scikit-Learn on a Apple Silicon</title><link>https://jimbobbennett.dev/blogs/installing-scikit-learn-on-an-apple-m1/</link><pubDate>Sun, 31 Jan 2021 17:01:05 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/installing-scikit-learn-on-an-apple-m1/</guid><description>&lt;p>At the end of last year I splashed out on a shiny new Apple MacBookAir with the M1 processor as I was fed up with an old Intel-based MacBookPro that was quite honestly crippled by corporate anti-virus software.&lt;/p>
&lt;p>Out the box this machine is amazing. It&amp;rsquo;s ridiculously fast, and lasts for ever on battery. Seriously - I charge it every 2 days and manage a full day of coding, writing, emails, Teams, the lot. Did I also mention it&amp;rsquo;s fast? I can have all the things running and it barely breaks a sweat, even with only 8GB of RAM.&lt;/p>
&lt;p>The downside is that not all software works on the new ARM-64 architecture. Apple have a translation layer called Rosetta 2 (Rosetta 1 was their translation from PowerPC to Intel), and this works great most of the time for every day apps, but it doesn&amp;rsquo;t always work for development tools and libraries, as the mix of translated and untranslated stuff just breaks down.&lt;/p>
&lt;p>One library I needed to use that isn&amp;rsquo;t supported is Scikit-Learn. Now I&amp;rsquo;m no Python expert, and I don&amp;rsquo;t really understand what Scikit-Learn does, I just know I need it to train some TinyML models to &lt;a href="https://eloquentarduino.github.io/2020/08/better-word-classification-with-arduino-33-ble-sense-and-machine-learning/">recognize wake words on an Arduino Nano 33 sense board&lt;/a>. If I try a normal pip install scikit-learn, I get a whole wall of errors, both using Python 3.9 for the M1, and Python 3.8 under Rosetta.&lt;/p>
&lt;p>So what to do?&lt;/p>
&lt;p>It turns out the solution is to use &lt;a href="https://github.com/conda-forge/miniforge">Miniforge&lt;/a>, a version of Conda that is comparable to Miniconda, but supports various CPU architectures. Whatever that means. As I said, I&amp;rsquo;m no Python expert, but this tool essentially allows me to create virtual environments and install packages compiling them for the M1 chip! Any packages it doesn&amp;rsquo;t support can then be installed from pip.&lt;/p>
&lt;p>So how do I install all this?&lt;/p>
&lt;p>Firstly - I need to install Miniforge. The install script is on the GitHub page, or you can download it by clicking &lt;a href="https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-MacOSX-arm64.sh">this link&lt;/a>. It wanted to activate it in every terminal, which I didn&amp;rsquo;t want so I turned that off by running:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>conda config --set auto_activate_base false
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Next I went to the folder containing my Python code, and created a virtual environment:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>conda create -n .venv python
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This is pretty much the same as creating a virtual environment with Python, just using a different tool. Like with Python, the virtual environment then needs to be activated:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>conda activate .venv
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Finally, I can install Scikit-Learn:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>conda install scikit-learn
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Done! For the particular thing I&amp;rsquo;m working on, I needed a package that isn&amp;rsquo;t available from Miniforge, so I just installed it with pip:&lt;/p>
&lt;p>pip install micromlgen
Done! I could then run my Python script as normal, and it all worked nicely. And fast - my M1 ran the script in question in 2 seconds, 5 times faster than the 10 seconds my Surface Book took.&lt;/p></description></item><item><title>Build a virtual IoT Lab with Raspberry Pis and Azure IoT Hub</title><link>https://jimbobbennett.dev/blogs/build-virtual-iot-lab/</link><pubDate>Fri, 11 Dec 2020 00:00:00 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/build-virtual-iot-lab/</guid><description>&lt;p>The rise of virtual education has led to sweeping changes in how students are taught. A lot of computer science lessons can be run with only small changes thanks to the cloud - &lt;a href="https://azure.microsoft.com/services/lab-services/pre-configured">Azure Lab Services&lt;/a> can provide virtual machines with developer tooling, or &lt;a href="https://github.com/features/codespaces">GitHub Codespaces&lt;/a> can replace the physical lab setups that Universities used to use.&lt;/p>
&lt;p>One area that has limitations is the Internet of Things. You can&amp;rsquo;t move small microcontrollers or small board computers to the cloud, posting devices is expensive and leads to support issues that often can only be resolved by posting the device back, and asking students to purchase devices is problematic as this can be expensive for a group of students who may already be paying many thousands of dollars for tuition, and in some cases not feasible due to shipping or customs issues.&lt;/p>
&lt;p>Although it is impossible to re-create an IoT lab fully in a virtual setting, it is possible to make devices like Raspberry Pi&amp;rsquo;s available over the internet, either from a University campus, or even from the Lecturers home (given enough upload bandwidth), and these can then be connected to microcontrollers to program these if needed. There are plenty of solutions to do this that involve opening SSH ports over the internet, but these are not the most secure as you have to have a public SSH port open.&lt;/p>
&lt;p>One novel way that increases security is using &lt;a href="https://docs.microsoft.com/azure/iot-hub/iot-hub-device-streams-overview?WT.mc_id=academic-7372-jabenn">Azure IoT Hub device streams&lt;/a>.&lt;/p>
&lt;h2 id="use-device-streams-to-proxy-an-ssh-connection">Use device streams to proxy an SSH connection&lt;/h2>
&lt;p>Device streams provide secure two-way TCP tunnels via standard HTTPS connections - allowing devices to bypass firewalls and other network considerations, and avoid having SSH ports open over the internet, but still have security via IoT Hub.&lt;/p>
&lt;p>You can then run server code on your local device to emulate SSH, and it can forward the connection to a device stream via IoT Hub, which streams to the client IoT device which is running client code to listen to the requests over the stream and redirect them to the local SSH port, and stream back the results, essentially using very thin proxies.&lt;/p>
&lt;p>&lt;img src="ssh-over-iot-hub-architecture.png" alt="IoT hub acting as an ssh proxy">&lt;/p>
&lt;p>Although the Pi is connected to an IoT Hub to stream the SSH commands, it can still connect to another IoT Hub for IoT development, and run services like Azure IoT Edge. From a users perspective, it&amp;rsquo;s the same as SSHing into the Pi - they connect an SSH session to the local proxy using a different port, and that logs them into the Pi. Behind the scenes the IoT Hub device streams make it work, but to the user, it&amp;rsquo;s as if they connected natively.&lt;/p>
&lt;p>The full process for how to set this up, as well as all the code you need to build and run the proxy is available as one of our &lt;a href="https://github.com/microsoft/iot-curriculum/blob/main/educator-guides/lab-guides/virtual-iot-lab/iot-hub-ssh-virtual-lab.md">Lab Guides as part of the Microsoft IoT Curriculum resources&lt;/a>. Check out the instructions and try it out.&lt;/p>
&lt;p>&lt;a href="https://github.com/microsoft/iot-curriculum/blob/main/educator-guides/lab-guides/virtual-iot-lab/iot-hub-ssh-virtual-lab.md">github.com/microsoft/iot-curriculum/blob/main/educator-guides/lab-guides/virtual-iot-lab/iot-hub-ssh-virtual-lab.md&lt;/a>&lt;/p></description></item><item><title>What is edge computing, why do it, why send IoT data to the cloud?</title><link>https://jimbobbennett.dev/blogs/what-is-edge-computing/</link><pubDate>Thu, 03 Dec 2020 00:00:00 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/what-is-edge-computing/</guid><description>&lt;p>I recently had a student reach out to me with some great questions around Edge computing and how it matches to IoT, and indeed why even use the cloud with IoT. They have to write a paper on the difference between edge computing and just using the cloud, and were researching these terms and trying to understand the whys and hows.&lt;/p>
&lt;p>There is currently a lot of confusion around this topic, especially when product pages are full of buzzwords, marketing speak and business decision maker language, not student friendly explanations, so I thought I&amp;rsquo;d take a moment to try to answer their questions with a blog post and hopefully help others navigate this minefield.&lt;/p>
&lt;p>This blog post is a mind dump in the style of I didn&amp;rsquo;t have time to give you a short answer, so I wrote a long blog post instead, so comments and criticism welcome.&lt;/p>
&lt;h2 id="temperature-detection">Temperature detection&lt;/h2>
&lt;p>I&amp;rsquo;m going to frame all this with the canonical IoT example of temperature detection. It&amp;rsquo;s one of the &amp;rsquo;easiest&amp;rsquo; IoT scenarios in that there are a huge range of devices and examples out there for this. You take an IoT device such as a micro controller (for example an Arduino board) or a single-board computer (for example a Raspberry Pi), attach a temperature sensor, and gather the data.&lt;/p>
&lt;h2 id="what-is-cloud-computing">What is cloud computing?&lt;/h2>
&lt;p>Lets start with the cloud. The cloud is someone elses computer - you pay per use for either computing resources or software resources managed by someone else. it allows you to not worry about purchasing hardware, managing cooling, electricity and networking, managing software, security, patching and the other day to day operations, and instead outsources these to experts. The cost comes down - you only pay for what you need when you need it, and speed of delivery goes up as the services are pretty much instant on.&lt;/p>
&lt;p>In the IoT space for example, a few clicks brings you a service you can securely send IoT data to, and a well defined way to get the data back out for analysis, all for a modest monthly fee. Running the same setup manually would be highly expensive and a lot of work.&lt;/p>
&lt;h3 id="why-send-this-data-to-the-cloud">Why send this data to the cloud?&lt;/h3>
&lt;p>A great question - why use the cloud when you can just read the data yourself, either by showing it on a screen or even by connecting to a Raspberry Pi and reading the values?&lt;/p>
&lt;p>The answer lies in the rise of the smart thermostat. In the house I grew up in, the temperature sensor was a dumb device - it detected the temperature and if it was lower than a value on a thermostat, the heating turned on. The next generation was connected thermostats - sending the data to the cloud. This added a level of usability to these devices - yes you could walk to the thermostat and check the temperature of your house, but you could also get this on your phone. Combine this with the ability to also control the thermostat remotely you have a great advantage of using the cloud. You can check the temperature of your house from anywhere and control it from anywhere. On your way home unexpectedly on a cold day? You can check how cold your house is and turn the heating up if it&amp;rsquo;s set to a colder vacant setting. The cloud starts to take your data and control anywhere.&lt;/p>
&lt;p>Yes, if you don&amp;rsquo;t care and just want a wall thermometer then there&amp;rsquo;s no need, but as soon as you want access away from the temperature sensor, the cloud wins.&lt;/p>
&lt;p>The next generation of smart thermostats is around analyzing this data in the cloud. A disconnected device relies on manual control, a cloud connected device can use algorithms to make control decisions for you based on a wide variety of data. Your cloud connected thermostat can check your calendar, and if it sees you are on vacation it can turn your heating off. It can also check weather, and if the heating is off but a cold snap is coming it can turn it on to stop pipes freezing. All this comes via having the data and control in the cloud.&lt;/p>
&lt;p>This idea can be taken further with temperature monitoring of factories and machinery - sometimes subtle variations in temperature of a machine component can indicate an upcoming failure. By constantly monitoring the temperature, with data sent to AI models, you can be do predictive maintenance, replacing a part early before a costly failure.&lt;/p>
&lt;h3 id="the-downside-of-the-cloud">The downside of the cloud&lt;/h3>
&lt;p>The cloud isn&amp;rsquo;t perfect, and can have a couple of downsides - though these can be mitigated.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Reliance on the cloud&lt;/p>
&lt;p>Recently one of the big cloud providers had an outage, and social media was full of complaints from people who can&amp;rsquo;t vacuum their house as the cloud was down. If your device relies on the cloud, it also needs to work when the cloud is not there - I don&amp;rsquo;t want a WiFi outage or a data center fire to stop me from having heating, especially if I lived in a really cold location! There are also locations where internet connections are unavailable or expensive, such as oil rigs or deep underground, or even in space.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Data privacy&lt;/p>
&lt;p>The cloud is secure, and the big clouds have a lot of certifications and approvals for data security, but there might be times when you don&amp;rsquo;t want data in the cloud. For example, some countries insist on personal data remaining in-country (data sovereignty laws). If the cloud doesn&amp;rsquo;t have a data center in your country, you have to store it locally or on a local data center. Some data, such as medical data might need to stay on-site in a hospital.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Bandwidth and network speed&lt;/p>
&lt;p>Bandwidth isn&amp;rsquo;t free. If you want to run AI models to analyze video from security cameras, sending all that data to the cloud is going to need a lot of bandwidth. That&amp;rsquo;s expensive, and not always available. The internet is also not as fast as internal networks, so if you need the data or results of analysis quickly then it might be faster to have the analytics closer to the data capture.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Cost&lt;/p>
&lt;p>The cloud brings the cost down, but sometimes you don&amp;rsquo;t want or need to pay for the power of the cloud. It might be that a $99 NVIDIA Jetson Nano can run your AI models fast enough that you don&amp;rsquo;t want to rent a $100 a month GPU-powered VM in the cloud.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>This is where Edge computing comes in.&lt;/p>
&lt;h2 id="what-is-edge-computing">What is edge computing?&lt;/h2>
&lt;p>Edge computing is running parts of the cloud on the edge - that is on your own network in your building or data center. You can take advantage of the cloud to build and train workloads, then deploy them to an edge device to run closer to your data. This way you get the benefit of the scalable power of the cloud to train complex models, and the advantage of local compute to:&lt;/p>
&lt;ul>
&lt;li>Avoid dependency on the internet and the cloud - your models can run offline, so if the cloud or internet goes down, or if you are away from the internet such as at sea, they keep running.&lt;/li>
&lt;li>Keep your data private and local&lt;/li>
&lt;li>Not be limited by external bandwidth and internet speed, only be limited by your internal network bandwidth&lt;/li>
&lt;li>Control costs using existing hardware&lt;/li>
&lt;/ul>
&lt;p>Thinking about factory monitoring - you can do this so much better on the edge than in the cloud. You can gather the data you need and train complex AI models for predictive maintenance in the cloud. Once trained, you can download these models to an IoT Edge device built using cheap hardware. This device can be on your local network close to the machinery, and respond to temperature data - instantly alerting someone or even turning the machinery down or off it it detects a possible failure. If the internet or the cloud goes down - the device still works. If you send millions of data points to it for analysis, you are not limited by outgoing internet speeds.&lt;/p>
&lt;p>These models running on the edge are not static - you can constantly improve and retrain models in the cloud and deploy them to the edge as required.&lt;/p>
&lt;p>You can also use these edge devices as gateways - sending data up to the cloud as needed. This can be filtered data, such as removing duplicate values or data within an allowed range, or they can be used to route data from devices that can&amp;rsquo;t connect to the cloud services directly. They can even shield devices from being connected directly to the internet of these devices are not secure.&lt;/p>
&lt;p>To visualize how this works - I&amp;rsquo;m going to defer to an article from the Microsoft Documentation covering &lt;a href="https://docs.microsoft.com/azure/stream-analytics/stream-analytics-edge">running Stream Analytics on IoT Edge&lt;/a>. Stream Analytics is a tool for creating real-time queries against streaming data, outputting the results of the query to other systems. Stream Analytics jobs can be run in the cloud, or downloaded onto an IoT Edge device and run on the edge.&lt;/p>
&lt;p>&lt;img src="asaedge-highlevel-diagram.png" alt="High-level diagram of IoT Edge">&lt;/p>
&lt;p>This diagram shows IoT Edge devices running Azure Stream Analytics jobs via the IoT Edge runtime, running on-premise in a factory, with data coming in from a variety of devices. The results of the Stream Analytics job are then sent on to Azure IoT Hub for further analytics if needed.&lt;/p>
&lt;h2 id="more-resource">More resource&lt;/h2>
&lt;p>If you want to learn more about this topic - here&amp;rsquo;s some great resource:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://azure.microsoft.com/services/iot-edge/">Azure IoT Edge product page&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.microsoft.com/azure/iot-edge/">Azure IoT Edge documentation&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://youtu.be/LaAiyuzPRyY">Run cognitive services on IoT Edge&lt;/a> - a video where I am joined by &lt;a href="https://twitter.com/mpaloski">Marko Paloski&lt;/a> and we talk about running a pre-built AI service on the Edge using Azure IoT Edge&lt;/li>
&lt;li>&lt;a href="https://docs.microsoft.com/learn/paths/ai-edge-engineer/?WT.mc_id=academic-11509-jabenn">AI Edge engineer learning path on Microsoft Learn&lt;/a> - a learning path produced in partnership with the &lt;a href="https://www.conted.ox.ac.uk/courses/artificial-intelligence-cloud-and-edge-implementations">University of Oxford&lt;/a> covering AI on the edge&lt;/li>
&lt;li>&lt;a href="https://docs.microsoft.com/learn/paths/build-intelligent-edge-with-azure-iot-edge/">Build the intelligent edge learning path on Microsoft Learn&lt;/a> - a learning path covering how to use Azure IoT Edge to build IoT solutions that require having cloud intelligence deployed locally on IoT Edge devices&lt;/li>
&lt;li>&lt;a href="https://github.com/microsoft/iot-curriculum">Microsoft IoT Curriculum resource&lt;/a> - a GitHub repo of resources, curated links and labs for IoT classes, projects and learning&lt;/li>
&lt;li>&lt;a href="https://github.com/microsoft/iot-curriculum/tree/main/labs/ai-edge/vision/manufacturing-part-check">Assembly line QA lab&lt;/a> - a hands-on-lab covering how to use IoT edge to do AI-powered assembly line validation&lt;/li>
&lt;/ul></description></item><item><title>Control holiday lights with Python, Azure IoT and Power Apps</title><link>https://jimbobbennett.dev/blogs/control-holiday-lights-power-apps/</link><pubDate>Fri, 13 Nov 2020 00:00:00 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/control-holiday-lights-power-apps/</guid><description>&lt;p>As the nights draw in here in the northern hemisphere, there are a number of winter celebrations that happen - and one thing they all have in common is lights.&lt;/p>
&lt;p>In the past I&amp;rsquo;ve just purchased strings of lights from the nearest retailer, strung them up to a tree or around my house, and fought with remote controls or buttons to get the color I wanted.&lt;/p>
&lt;p>Well this year I decided to do something better and build IoT powered holiday lights, controlled by a Power App built with no code!&lt;/p>
&lt;p>&lt;img src="app-controlled-lights.gif" alt="Lights controlled by a power app">&lt;/p>
&lt;p>The hardware would be based around &lt;a href="https://www.amazon.com/gp/product/B07FVPN3PH">WS2812B programmable LED strips (also referred to as Neopixels)&lt;/a>, controlled by a &lt;a href="https://www.raspberrypi.org/products/raspberry-pi-zero-w">Raspberry Pi Zero W&lt;/a>. Software wise, the Pi would run some Python code to talk to &lt;a href="https://azure.microsoft.com/services/iot-central">Azure IoT Central&lt;/a> - an IoT software as a service platform that can send commands to the Pi to turn the lights on or off. A &lt;a href="https://powerapps.microsoft.com/">Power App&lt;/a> would then be used to control IoT Central via a mobile app - written with no code! All these cloud services can be used for free, which is even better!&lt;/p>
&lt;blockquote>
&lt;p>You can find a full hands-on guide to building this your self with detailed instructions and all the code in my &lt;a href="https://github.com/jimbobbennett/NeopixelHolidayLights">Neopixel Holiday Lights GitHub Repo&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;h2 id="hardware-needed">Hardware needed&lt;/h2>
&lt;p>To create this, you will need the following hardware:&lt;/p>
&lt;ul>
&lt;li>A Raspberry Pi that can connect to the internet such as a Pi Zero W or a Pi 3/4, with appropriate SD card and power supply&lt;/li>
&lt;li>A strip of WS212B programmable LEDs&lt;/li>
&lt;li>A 5v power supply - either a USB to terminal block lead or a 5v DC converter&lt;/li>
&lt;li>Jumper wires&lt;/li>
&lt;/ul>
&lt;p>To wire the hardware, connect the positive lead or pin on the LEDs to the positive terminal on the 5v power supply, Connect the negative lead or pin to both the negative terminal on the power supply, and a GND GPIO pin on the Raspberry Pi. Some LED strips have twin negative leads for this reason, otherwise you&amp;rsquo;ll need to solder or attach more leads as necessary. Finally attach the control pin to GPIO pin 18 on the Raspberry Pi. You can find details on the pin numbers in the &lt;a href="https://www.raspberrypi.org/documentation/usage/gpio/">Raspberry Pi GPIO documentation&lt;/a>.&lt;/p>
&lt;p>&lt;img src="wiring-1.png" alt="The wiring of the neo pixels">&lt;/p>
&lt;h2 id="azure-iot-central">Azure IoT Central&lt;/h2>
&lt;p>&lt;a href="https://azure.microsoft.com/services/iot-central">Azure IoT Central&lt;/a> is a software as a services platform that allows you to build the cloud infrastructure and security for your IoT apps with no code. It is based around device templates - a description of the data that a device can send to the cloud, and commands the cloud can send to the device to instruct it to do something.&lt;/p>
&lt;p>Start by heading to &lt;a href="https://apps.azureiotcentral.com/">apps.azureiotcentral.com&lt;/a> and creating a new app. Although IoT Central is a paid service, you can use it for free. There is a free tier, but apps created using this are deleted after 7 days, so go for one of the standard tiers. Both the standard tiers offer 2 devices for free, so you can control your Pi without paying anything.&lt;/p>
&lt;p>You will need an Azure Subscription to sign up, so if you don&amp;rsquo;t have one you can sign up for free. Students can sign up at &lt;a href="https://azure.microsoft.com/free/students/">azure.microsoft.com/free/students&lt;/a> to get $100 of credit for a year, renewing every year, otherwise sign up at &lt;a href="https://azure.microsoft.com/free/">azure.microsoft.com/free&lt;/a> to get $200 of credit that lasts 30 days.&lt;/p>
&lt;p>Once you have your app created, create a device template with 2 commands and a property. The commands will turn the lights on and off, and the property will allow the color to be persisted so restarting the Pi means the lights will re-light with the last color set.&lt;/p>
&lt;p>Name one of the commands &lt;code>On&lt;/code> and make it take a request parameter called &lt;code>Color&lt;/code>. Name the other command &lt;code>Off&lt;/code> with no request parameter. Create the property called &lt;code>Color&lt;/code> as a &lt;code>string&lt;/code>. Publish this template, then create a new device using it. Once you&amp;rsquo;ve created the device, grab the connection details.&lt;/p>
&lt;h2 id="program-the-pi">Program the Pi&lt;/h2>
&lt;p>Next step is to program the Pi to connect to IoT Central, receive the commands and turn on the lights. This can be done in Python. Make sure your Pi is using the latest Raspberry Pi OS, with all the latest updates and is connected to the internet. You can use either the Lite or Desktop version - for a project like this where the Pi is running headless I like to use the Lite version to allow me to use smaller SD cards and boot the Pis faster.&lt;/p>
&lt;blockquote>
&lt;p>To program the Pi, you can use your favorite Python tool. I personally recommend using &lt;a href="https://code.visualstudio.com/">Visual Studio Code&lt;/a>, a free, open source developer text editor that has extensions for a variety of languages, including the &lt;a href="https://devblogs.microsoft.com/python/announcing-pylance-fast-feature-rich-language-support-for-python-in-visual-studio-code/">PyLance extension for Python&lt;/a>. If you are using the full desktop version of Raspberry Pi OS, you can &lt;a href="https://jimbobbennett.dev/blogs/run-visual-studio-code-on-a-raspberry-pi">install VS Code locally&lt;/a>, otherwise use the &lt;a href="https://code.visualstudio.com/docs/remote/ssh">Remote SSH extension&lt;/a> to code remotely on a Pi 3 or 4, or the &lt;a href="https://marketplace.visualstudio.com/items?itemName=Kelvin.vscode-sshfs">SSH File system extension&lt;/a> to code remotely on a Pi Zero.&lt;/p>
&lt;/blockquote>
&lt;p>First you need to install some Pip packages. These need to be installed using &lt;code>sudo&lt;/code> - to control the Neopixels you need to run the code as a super user. Install the following:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>rpi_ws281x
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>adafruit-circuitpython-neopixel
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>azure-iot-device
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>python-dotenv
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The first 2 packages provide control for the LEDs, the &lt;code>azure-iot-device&lt;/code> package has the Python code for devices to connect to IoT Central, and &lt;code>python-dotenv&lt;/code> is used to load secrets from .env files to avoid things like API keys being uploaded to source code control.&lt;/p>
&lt;p>Once these are installed, create a file called &lt;code>.env&lt;/code> on the Pi in whatever folder you want to create the code in to store the connection details for the IoT Central device, and add the following:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-ini" data-lang="ini">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">ID_SCOPE&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;lt;ID scope&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">DEVICE_ID&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;lt;device id&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">PRIMARY_KEY&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;lt;primary key&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Replace &lt;code>&amp;lt;ID scope&amp;gt;&lt;/code> with the value of the ID Scope from the IoT Central device connection dialog. Replace &lt;code>&amp;lt;device id&amp;gt;&lt;/code> with the device ID, and the &lt;code>&amp;lt;primary key&amp;gt;&lt;/code> with the primary key.&lt;/p>
&lt;p>Next create a file called &lt;code>app.py&lt;/code> and add the following code. You can also find this code in &lt;a href="https://github.com/jimbobbennett/NeopixelHolidayLights/blob/main/code/iot-controlled/app.py">the GitHub repo tha accompanies this post&lt;/a>.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> asyncio
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> board
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> neopixel
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> os
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> azure.iot.device.aio &lt;span style="color:#f92672">import&lt;/span> IoTHubDeviceClient, ProvisioningDeviceClient
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> azure.iot.device &lt;span style="color:#f92672">import&lt;/span> MethodResponse
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> dotenv &lt;span style="color:#f92672">import&lt;/span> load_dotenv
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Define the NeoPixel strip setting:&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># The pin the control wire is connected to (18 in this code)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># The length of the strip (150 LEDs in this code)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># The brightness (0.2 on a scale of 0-1)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># If the colors are written as soon as the values are updated, or if they need to be&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># updated all at once as soon as the values are set&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>pixels &lt;span style="color:#f92672">=&lt;/span> neopixel&lt;span style="color:#f92672">.&lt;/span>NeoPixel(board&lt;span style="color:#f92672">.&lt;/span>D18, &lt;span style="color:#ae81ff">150&lt;/span>, brightness&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">0.2&lt;/span>, auto_write&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">False&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Load the IoT Central connection details from a .env file&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>load_dotenv()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>id_scope &lt;span style="color:#f92672">=&lt;/span> os&lt;span style="color:#f92672">.&lt;/span>getenv(&lt;span style="color:#e6db74">&amp;#39;ID_SCOPE&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>device_id &lt;span style="color:#f92672">=&lt;/span> os&lt;span style="color:#f92672">.&lt;/span>getenv(&lt;span style="color:#e6db74">&amp;#39;DEVICE_ID&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>primary_key &lt;span style="color:#f92672">=&lt;/span> os&lt;span style="color:#f92672">.&lt;/span>getenv(&lt;span style="color:#e6db74">&amp;#39;PRIMARY_KEY&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Declare the device client so it can be used from all the function&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>device_client &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">None&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Provisions the device with the Azure device provisioning service or returns&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># the connection details if the device is already provisioned&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">async&lt;/span> &lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">register_device&lt;/span>():
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> provisioning_device_client &lt;span style="color:#f92672">=&lt;/span> ProvisioningDeviceClient&lt;span style="color:#f92672">.&lt;/span>create_from_symmetric_key(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> provisioning_host&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;global.azure-devices-provisioning.net&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> registration_id&lt;span style="color:#f92672">=&lt;/span>device_id,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> id_scope&lt;span style="color:#f92672">=&lt;/span>id_scope,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> symmetric_key&lt;span style="color:#f92672">=&lt;/span>primary_key,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> )
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#66d9ef">await&lt;/span> provisioning_device_client&lt;span style="color:#f92672">.&lt;/span>register()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Sets the color of the Neopixels based on a color string coming in.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># This color string is a 6 character code, 2 characters for red, 2 for green&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># and 2 for blue. These 2 characters are a HEX value from 00 to FF.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># For example FF0000 is full red, no green or blue. FFFFFF is white, 000000 is off.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Once the color is set, write it back to the IoT Central property via a device twin&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">async&lt;/span> &lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">set_color&lt;/span>(color):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># split in the color string into the red, green and blue components, and convert these&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># to valid hex strings&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> r &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#39;0x&amp;#39;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> color[&lt;span style="color:#ae81ff">0&lt;/span>:&lt;span style="color:#ae81ff">2&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> g &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#39;0x&amp;#39;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> color[&lt;span style="color:#ae81ff">2&lt;/span>:&lt;span style="color:#ae81ff">4&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> b &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#39;0x&amp;#39;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> color[&lt;span style="color:#ae81ff">4&lt;/span>:&lt;span style="color:#ae81ff">6&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Convert hext to numerical values&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> r_value &lt;span style="color:#f92672">=&lt;/span> int(r, &lt;span style="color:#ae81ff">0&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> g_value &lt;span style="color:#f92672">=&lt;/span> int(g, &lt;span style="color:#ae81ff">0&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> b_value &lt;span style="color:#f92672">=&lt;/span> int(b, &lt;span style="color:#ae81ff">0&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> print(&lt;span style="color:#e6db74">&amp;#39;Updating color: r =&amp;#39;&lt;/span>, r_value, &lt;span style="color:#e6db74">&amp;#39;, g =&amp;#39;&lt;/span>, g_value, &lt;span style="color:#e6db74">&amp;#39;, b =&amp;#39;&lt;/span>, b_value)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Set all the pixels to the new color&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> pixels&lt;span style="color:#f92672">.&lt;/span>fill((r_value, g_value, b_value))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Show the color on all the pixels&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> pixels&lt;span style="color:#f92672">.&lt;/span>show()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Write the color back as a property&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Properties are written to the device twin, so patch the reported properties&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># with the color&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> patch &lt;span style="color:#f92672">=&lt;/span> {&lt;span style="color:#e6db74">&amp;#39;Color&amp;#39;&lt;/span>:color}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> print(&lt;span style="color:#e6db74">&amp;#34;Sending patch:&amp;#34;&lt;/span>, patch)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">await&lt;/span> device_client&lt;span style="color:#f92672">.&lt;/span>patch_twin_reported_properties(patch)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># IoT Central command handler&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># IoT Central commands are implemented as IoT Hub direct methods&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">async&lt;/span> &lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">command_handler&lt;/span>(method_request):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> print(&lt;span style="color:#e6db74">&amp;#34;Message received:&amp;#34;&lt;/span>, method_request&lt;span style="color:#f92672">.&lt;/span>name)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> print(&lt;span style="color:#e6db74">&amp;#34;Message payload:&amp;#34;&lt;/span>, method_request&lt;span style="color:#f92672">.&lt;/span>payload)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Determine how to respond to the command based on the IoT Hub direct method method name&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># which is the same as the IoT Central command name&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> method_request&lt;span style="color:#f92672">.&lt;/span>name &lt;span style="color:#f92672">==&lt;/span> &lt;span style="color:#e6db74">&amp;#34;On&amp;#34;&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># For an On request, set the color based on the payload&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">await&lt;/span> set_color(method_request&lt;span style="color:#f92672">.&lt;/span>payload)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> print(&lt;span style="color:#e6db74">&amp;#34;executed on&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">elif&lt;/span> method_request&lt;span style="color:#f92672">.&lt;/span>name &lt;span style="color:#f92672">==&lt;/span> &lt;span style="color:#e6db74">&amp;#34;Off&amp;#34;&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># For an Off request, set the color to 000000, which turns the pixels off&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">await&lt;/span> set_color(&lt;span style="color:#e6db74">&amp;#34;000000&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> print(&lt;span style="color:#e6db74">&amp;#34;executed off&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">else&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> print(&lt;span style="color:#e6db74">&amp;#34;Received unknown method: &amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> method_request&lt;span style="color:#f92672">.&lt;/span>name)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Method calls have to return a response so IoT Central knows it was handled correctly,&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># So send a 200 response to show we handled this&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> payload &lt;span style="color:#f92672">=&lt;/span> {&lt;span style="color:#e6db74">&amp;#34;result&amp;#34;&lt;/span>: &lt;span style="color:#66d9ef">True&lt;/span>}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> status &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">200&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Send the response&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> method_response &lt;span style="color:#f92672">=&lt;/span> MethodResponse&lt;span style="color:#f92672">.&lt;/span>create_from_method_request(method_request, status, payload)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">await&lt;/span> device_client&lt;span style="color:#f92672">.&lt;/span>send_method_response(method_response)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">async&lt;/span> &lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">property_handler&lt;/span>(patch):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> print(&lt;span style="color:#e6db74">&amp;#34;Patch received:&amp;#34;&lt;/span>, patch)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#e6db74">&amp;#39;Color&amp;#39;&lt;/span> &lt;span style="color:#f92672">in&lt;/span> patch:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">await&lt;/span> set_color(patch[&lt;span style="color:#e6db74">&amp;#39;Color&amp;#39;&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># The main async function that runs the app&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">async&lt;/span> &lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">main&lt;/span>():
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">global&lt;/span> device_client
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Regsiter the Pi as an IoT device in IoT Central&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> registration_result &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">await&lt;/span> register_device()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Build the IoT Hub connection string from the registration details&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># IoT Central sits on top of IoT Hub, and the Python SDK only supports IoT Hub,&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># So to talk to IoT central the IoT Hub connection string needs to be built from details&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># from registering the device with the provisioning service&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> conn_str&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;HostName=&amp;#39;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> registration_result&lt;span style="color:#f92672">.&lt;/span>registration_state&lt;span style="color:#f92672">.&lt;/span>assigned_hub &lt;span style="color:#f92672">+&lt;/span> \
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#39;;DeviceId=&amp;#39;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> device_id &lt;span style="color:#f92672">+&lt;/span> \
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#39;;SharedAccessKey=&amp;#39;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> primary_key
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># The client object is used to interact with your Azure IoT Central app via IoT Hub, so create this &lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># from the connection string&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> device_client &lt;span style="color:#f92672">=&lt;/span> IoTHubDeviceClient&lt;span style="color:#f92672">.&lt;/span>create_from_connection_string(conn_str)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Connect the client to IoT Hub&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> print(&lt;span style="color:#e6db74">&amp;#39;Connecting&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">await&lt;/span> device_client&lt;span style="color:#f92672">.&lt;/span>connect()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> print(&lt;span style="color:#e6db74">&amp;#39;Connected&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># IoT Central stores properties in the device twin, so read this to see if we have a color&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># stored from the last run for the lights. This way when the device starts up it can set the color&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># to the last setting&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> twin &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">await&lt;/span> device_client&lt;span style="color:#f92672">.&lt;/span>get_twin()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> print(&lt;span style="color:#e6db74">&amp;#39;Got twin: &amp;#39;&lt;/span>, twin)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Load the color from the reported properties of the twin if it exists&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#e6db74">&amp;#39;reported&amp;#39;&lt;/span> &lt;span style="color:#f92672">in&lt;/span> twin &lt;span style="color:#f92672">and&lt;/span> &lt;span style="color:#e6db74">&amp;#39;Color&amp;#39;&lt;/span> &lt;span style="color:#f92672">in&lt;/span> twin[&lt;span style="color:#e6db74">&amp;#39;reported&amp;#39;&lt;/span>]:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">await&lt;/span> set_color(twin[&lt;span style="color:#e6db74">&amp;#39;reported&amp;#39;&lt;/span>][&lt;span style="color:#e6db74">&amp;#39;Color&amp;#39;&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Set the method request handler on the client to handle IoT Central commands&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> device_client&lt;span style="color:#f92672">.&lt;/span>on_method_request_received &lt;span style="color:#f92672">=&lt;/span> command_handler
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Handle updates to the color property from IoT Central&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> device_client&lt;span style="color:#f92672">.&lt;/span>on_twin_desired_properties_patch_received &lt;span style="color:#f92672">=&lt;/span> property_handler
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Define a message loop that keeps the app alive whilst listening for commands&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">async&lt;/span> &lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">main_loop&lt;/span>():
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">while&lt;/span> &lt;span style="color:#66d9ef">True&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">await&lt;/span> asyncio&lt;span style="color:#f92672">.&lt;/span>sleep(&lt;span style="color:#ae81ff">1&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Wait for user to indicate they are done listening for method calls&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">await&lt;/span> main_loop()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Finally, disconnect&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">await&lt;/span> device_client&lt;span style="color:#f92672">.&lt;/span>disconnect()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Start the async app running&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">if&lt;/span> __name__ &lt;span style="color:#f92672">==&lt;/span> &lt;span style="color:#e6db74">&amp;#34;__main__&amp;#34;&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> asyncio&lt;span style="color:#f92672">.&lt;/span>run(main())
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Read the code and the comments to see what it does.&lt;/p>
&lt;p>This code will connect to the Azure device provisioning service to authenticate the device using the settings from the &lt;code>.env&lt;/code> file, then connect. It will load the properties to see if a color has already been set, and if so set the Neopixels to that color. It will then listen for commands to change the color of the Neopixels or turn them off.&lt;/p>
&lt;p>Run the code as sudo with the following command:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>sudo python3 app.py
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The app will start up and connect. You can then run the commands in IoT Central to control the lights.&lt;/p>
&lt;p>The color for the On command should be given as a string value representing a Hex string. It will be 6 characters long, with 2 characters each representing the R, G and B values with values from 0-255 (&lt;code>00&lt;/code> - &lt;code>FF&lt;/code>). For example, red is &lt;code>FF0000&lt;/code>, green is &lt;code>00FF00&lt;/code>, blue is &lt;code>0000FF&lt;/code>, yellow is &lt;code>FFFF00&lt;/code>, white is &lt;code>FFFFFF&lt;/code>.&lt;/p>
&lt;h2 id="set-up-a-power-app">Set up a Power App&lt;/h2>
&lt;p>Power Apps allow you to build apps with low or no code, by creating flows that connect logic and services, and connecting these to a UI designed on a canvas.&lt;/p>
&lt;p>You will need a Power Apps account to create one, and if you don&amp;rsquo;t have one you can sign up for a &lt;a href="https://powerapps.microsoft.com/communityplan/">community plan&lt;/a>. This will give you a free environment for learning and building your own apps.&lt;/p>
&lt;p>Start by creating a flow in the Power App. This should use the &lt;strong>Create from Template&lt;/strong> option selecting &lt;strong>Power Apps button&lt;/strong>. Name this flow &lt;code>Turn lights on&lt;/code> and add an &lt;em>Azure IoT Central V3&lt;/em> connector (&lt;strong>NOT&lt;/strong> the V2 connector). Select your IoT Central app, add the device id, set the device template, select the capability, then select the &lt;em>On&lt;/em> command. A new box will appear for the color to pass to this command, so select this box and select &lt;strong>Ask in Power Apps&lt;/strong> from the box that appears. Then save the flow.&lt;/p>
&lt;p>&lt;img src="on-flow-complete.png" alt="The complete on flow">&lt;/p>
&lt;p>Create another flow for the &lt;em>Off&lt;/em> command called &lt;code>Turn lights off&lt;/code>.&lt;/p>
&lt;p>Once you have the flows, create an app, Drag a text input and two buttons to the canvas and align then in a column.&lt;/p>
&lt;p>Name the text input &lt;code>ColorInput&lt;/code>, remove the default value and change the hint to color.&lt;/p>
&lt;p>Name one button &lt;code>On&lt;/code> and select the &lt;strong>Action&lt;/strong> tab on the ribbon, then select &lt;strong>Power Automate&lt;/strong>. From the popup, select the &lt;em>Turn lights on&lt;/em> flow. It will take a few seconds to add the flow. When it does a half complete function will appear in the function bar. Pass the &lt;code>Text&lt;/code> property of the &lt;code>ColorInput&lt;/code> control into:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="display:flex;">&lt;span>PowerAppsbutton.Run(ColorInput.Text)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Name the other button &lt;code>Off&lt;/code> and add the &lt;em>Turn lights off&lt;/em> flow to it. The function for this doesn&amp;rsquo;t need any parameters, so just close the brackets.&lt;/p>
&lt;p>&lt;img src="power-app-canvas.png" alt="The complete power apps canvas">&lt;/p>
&lt;p>Make sure the app is running on the Pi, then save and test the Power App using the &lt;strong>Preview this app&lt;/strong> button on the toolbar.&lt;/p>
&lt;h2 id="done">Done!&lt;/h2>
&lt;p>Your app is now complete! Mount the lights somewhere and control them from the Power App. You can you can run it on your phone. Install the &lt;strong>Power Apps&lt;/strong> app from the &lt;a href="https://apps.apple.com/us/app/power-apps/id1047318566">Apple App Store&lt;/a> or &lt;a href="https://play.google.com/store/apps/details?id=com.microsoft.msapps">Google Play Store&lt;/a>, log in, select your app and use it to control your lights.&lt;/p>
&lt;h2 id="learn-more">Learn more&lt;/h2>
&lt;p>You can learn more about Azure IoT Central and the Microsoft Power Platform via Microsoft Learn, a hands-on, self-guided learning platform from Microsoft.&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://docs.microsoft.com/learn/paths/develop-iot-solutions-with-azure-iot-central">Develop IoT Central applications with IoT Central&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.microsoft.com/learn/paths/power-plat-fundamentals/">Microsoft Power Platform Fundamentals&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Run Visual Studio Code on a Raspberry Pi</title><link>https://jimbobbennett.dev/blogs/run-visual-studio-code-on-a-raspberry-pi/</link><pubDate>Sun, 25 Oct 2020 00:00:00 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/run-visual-studio-code-on-a-raspberry-pi/</guid><description>&lt;p>It&amp;rsquo;s finally here! An official supported version of VS Code that runs on a Raspberry Pi!&lt;/p>
&lt;blockquote class="twitter-tweet">&lt;p lang="en" dir="ltr">ICYMI: VS Code now officially supports &lt;a href="https://twitter.com/Raspberry_Pi?ref_src=twsrc%5Etfw">@Raspberry_Pi&lt;/a> too! 🍰&lt;br>&lt;br>➡️ Download the Linux ARM and ARM64 builds here: &lt;a href="https://t.co/aMc3pDFkDu">https://t.co/aMc3pDFkDu&lt;/a> &lt;a href="https://t.co/gsATu20K4X">pic.twitter.com/gsATu20K4X&lt;/a>&lt;/p>&amp;mdash; Visual Studio Code (@code) &lt;a href="https://twitter.com/code/status/1315371339012739072?ref_src=twsrc%5Etfw">October 11, 2020&lt;/a>&lt;/blockquote>
&lt;script async src="https://platform.twitter.com/widgets.js" charset="utf-8">&lt;/script>
&lt;p>This to me is great news. &lt;a href="https://raspberrypi.org/">The Raspberry Pi&lt;/a> is a low-priced, small form factor computer that can run a full version of Linux. It&amp;rsquo;s popular with hobbyists and kids - it was originally designed to be a cheap computer for kids to learn to code on. It has the same standard USB and HDMI ports that a PC or Mac would have, as well as GPIO (General Purpose Input Output) pins that can be used to work with a wide array of external electronic components, devices, sensors, machinery and robotics.&lt;/p>
&lt;p>What this VS Code release means is kids who are using a Pi can now use the same IDE that their grown ups use at work - Mum codes C# in VS Code at work and daughter codes Python in VS Code on a $35 computer at home connected to the family TV.&lt;/p>
&lt;p>Lets look at how to get it set up.&lt;/p>
&lt;h2 id="installing-vs-code-on-a-raspberry-pi">Installing VS Code on a Raspberry Pi&lt;/h2>
&lt;p>&lt;strong>STOP THE PRESS&lt;/strong>&lt;/p>
&lt;p>VS Code is now in the Raspberry Pi apt repositories. You can install it by launching a terminal and running the following command:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>sudo apt update
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sudo apt install code -y
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="using-vs-code">Using VS Code&lt;/h2>
&lt;p>Once the installer has finished, you will see Visual Studio Code as an option in the programming folder in the Pi menu. Select it to launch VS Code.&lt;/p>
&lt;p>&lt;img src="vscode-pi-menu.png" alt="VS Code in the Pi menu">&lt;/p>
&lt;p>You can now install your favourite extensions and program away! Be aware that not all extensions will work fully!&lt;/p>
&lt;p>&lt;img src="code-on-pi.png" alt="VS Code running on the Pi">&lt;/p></description></item><item><title>Building smart garden ornaments with a Raspberry Pi and micro:bits</title><link>https://jimbobbennett.dev/blogs/smart-garden-ornaments/</link><pubDate>Sat, 11 Jul 2020 00:00:00 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/smart-garden-ornaments/</guid><description>&lt;p>Ever wanted to track things happening in your garden, neighborhood or school using smart garden ornaments? Now you can using BBC micro:bits and a cloud-based IoT service.&lt;/p>
&lt;blockquote>
&lt;p>TL;DR: check out this project on GitHub for a weeks worth of fun to do with families, friends or in the classroom using a Raspberry Pi, microbits and an IoT service.&lt;/p>
&lt;p>&lt;a href="https://github.com/jimbobbennett/smart-garden-ornaments">github.com/jimbobbennett/smart-garden-ornaments&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>At Microsoft, we are celebrating July as our IoT month - after all who wouldn&amp;rsquo;t want to make use of the pun JulyOT! As part of this month, I created a fun project for schools, families and makers.&lt;/p>
&lt;p>This is a fun week long project for those who want to take their first steps into the world of the Internet of Things (IoT) using devices that are popular with kids, and tools that make programming accessible to young developers. You&amp;rsquo;ll use a Raspberry Pi along with some &lt;a href="https://microbit.org/">BBC micro:bits&lt;/a> and any garden ornaments you have to hand to build a smart neighborhood, gathering data such as temperature and noise levels and displaying it in the cloud using &lt;a href="https://azure.microsoft.com/services/iot-central">Azure IoT Central&lt;/a>.&lt;/p>
&lt;p>&lt;img src="project-dashboard.png" alt="The IoT Central project dashboard">&lt;/p>
&lt;p>This is great for families, groups of friends, or even in the classroom - gathering data around your home, neighborhood or school.&lt;/p>
&lt;p>Check out the project on GitHub! It&amp;rsquo;s broken down into 5 days of activities, from setting up the cloud service, to gathering data from micro:bits, to creating a mesh network to extend the range, to adding more sensors.&lt;/p>
&lt;p>&lt;a href="https://github.com/jimbobbennett/smart-garden-ornaments">github.com/jimbobbennett/smart-garden-ornaments&lt;/a>&lt;/p>
&lt;p>I&amp;rsquo;d love you to contribute to this project! Please send in your stories of what you have set up, any additional ideas for ways to extend the project, or any other sensors you&amp;rsquo;ve set up!&lt;/p>
&lt;p>Happy making!&lt;/p></description></item><item><title>Raspberry Pi cloud-connected Hat Cam</title><link>https://jimbobbennett.dev/blogs/raspberry-pi-hat-cam/</link><pubDate>Thu, 09 Jul 2020 17:45:27 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/raspberry-pi-hat-cam/</guid><description>&lt;p>&lt;strong>Build a cloud-connected hat/clothing camera powered by a Raspberry Pi and Azure!&lt;/strong>&lt;/p>
&lt;p>&lt;img src="https://github.com/jimbobbennett/pi-hat-cam/raw/main/images/make-jim-in-hat-cam.png" alt="Jim wearing a hat cam">&lt;/p>
&lt;blockquote>
&lt;p>This project builds a wearable, cloud connected camera. This is useful in situations where you want a record of what the camera sees stored in the cloud as quickly as possible. Make sure you use this in compliance will all applicable laws and privacy considerations.&lt;/p>
&lt;p>This is video only, no audio. If you want to add audio, then I&amp;rsquo;d love a PR to add, or wait till I get a chance to add it.&lt;/p>
&lt;/blockquote>
&lt;p>This project requires a Raspberry Pi connected to a Raspberry Pi Camera and WiFi. It continuously records short videos from the camera (by default 10 seconds in length), and uploads these to Azure blob storage. The ideal setup it a Pi Zero W due to it&amp;rsquo;s small size and low power requirements, tethered to a mobile phone or hotspot for internet access.&lt;/p>
&lt;blockquote>
&lt;p>This uses a cloud service to store the videos, and therefor may incur a cost. If you have a free trial account, you can get $200 for the first 30 days which should more than cover the cost. Check out the &lt;a href="https://azure.microsoft.com/pricing/details/storage/blobs/?WT.mc_id=pihatcam-blog-jabenn">Blob storage pricing guide&lt;/a> for more information on the cost of the service used.&lt;/p>
&lt;/blockquote>
&lt;p>This method allow resiliency - if WiFi connection is lost the upload will keep retrying. If the device is damaged then everything already uploaded will be secure. Files are stored on the SD card and only deleted after successfully being uploaded, so if there is no internet connection, files can be grabbed off the SD card.&lt;/p>
&lt;p>This also allows audit trails - each short video is named with the current timestamp, and Blob storage stores the time the file was uploaded.&lt;/p>
&lt;p>This project also includes a utility to download all the blobs and concatenate them into a single video file.&lt;/p>
&lt;h2 id="whats-required">What&amp;rsquo;s required&lt;/h2>
&lt;p>To make this, you will need:&lt;/p>
&lt;ul>
&lt;li>A Raspberry Pi Zero W (must be the W with WiFi access)&lt;/li>
&lt;li>A Raspberry Pi camera module and appropriate ribbon cable that is as long as possible. The V2 camera is the best as it is small with good quality. The HQ camera can be used but is bigger which makes it harder to mount on clothing.&lt;/li>
&lt;li>An SD Card&lt;/li>
&lt;li>A USB power pack and appropriate cable to power the Pi&lt;/li>
&lt;li>A mobile phone to tether to&lt;/li>
&lt;li>A hat or other piece of clothing&lt;/li>
&lt;li>Sewing materials, duct tape, bits of cloth to help affix the camera and Pi to your clothes&lt;/li>
&lt;/ul>
&lt;h2 id="set-up-the-application">Set up the application&lt;/h2>
&lt;p>Before you can run the application, you need an Azure subscription and a storage account.&lt;/p>
&lt;h3 id="set-up-your-azure-subscription">Set up your Azure Subscription&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>If you are a student aged 18 and up and have an email address from an academic institution, you can sign up for the free Azure for Students offer at &lt;a href="https://azure.microsoft.com/free/students/?WT.mc_id=pihatcam-blog-jabenn">azure.microsoft.com/free/students&lt;/a> without a credit card. At the time of writing this gives you $100 of credit to use over 12 months, as well as free tiers of a number of services for that 12 months. At the end of the 12 months, if you are still a student you can renew and get another $100 in credit and 12 months of free services.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>If you are not a student, you can sign up at &lt;a href="https://azure.microsoft.com/free/?WT.mc_id=pihatcam-blog-jabenn">azure.microsoft.com/free&lt;/a>. You will need a credit card for verification purposes only, you will not be billed unless you decide to upgrade your account to a paid offering. At the time of writing the free account will give you US$200 of free credit to spend on what you like in the first 30 days, 12 months of free services, plus a load of services that have tiers that are always free.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="set-up-the-storage-account">Set up the storage account&lt;/h3>
&lt;p>An Azure storage account is a general purpose account to store data as files, queues, tables or blobs. In this app, each short video is stored as a blob in the storage account.&lt;/p>
&lt;p>To create a storage account:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Head to &lt;a href="https://aka.ms/AA8xjmk">ms.portal.azure.com/#create/Microsoft.StorageAccount-ARM&lt;/a> to go straight to the create a new storage resource blade&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Sign in with your Azure account if necessary&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Select your Azure subscription&lt;/p>
&lt;/li>
&lt;li>
&lt;p>For the &lt;em>Resource group&lt;/em>, select &lt;strong>Create new&lt;/strong>. Name the resource group &lt;code>hatcam&lt;/code> then select &lt;strong>OK&lt;/strong>&lt;/p>
&lt;p>&lt;img src="https://github.com/jimbobbennett/pi-hat-cam/raw/main/images/portal-storage-new-resource-group.png" alt="Creating a new resource group">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Name the storage account. This name has to be globally unique across all storage accounts in Azure - this is because this name becomes part of the URL that can be used to access it. Pick a name that makes sense to you with something unique like your name, the date, etc.&lt;/p>
&lt;blockquote>
&lt;p>This name can only contain lowercase numbers and letters&lt;/p>
&lt;/blockquote>
&lt;/li>
&lt;li>
&lt;p>For the location, select the one closest to where you will be using the camera.&lt;/p>
&lt;blockquote>
&lt;p>If you want to see the locations of the regions, check out the map in the &lt;a href="https://azure.microsoft.com/global-infrastructure/regions/?WT.mc_id=pihatcam-blog-jabenn">Azure global infrastructure guide&lt;/a>.&lt;/p>
&lt;/blockquote>
&lt;/li>
&lt;li>
&lt;p>Leave the rest of the values as the defaults&lt;/p>
&lt;p>&lt;img src="https://github.com/jimbobbennett/pi-hat-cam/raw/main/images/portal-storage-all-details.png" alt="The create storage form filled in">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Select &lt;strong>Review + create&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The storage account settings will be validated. Once done, select &lt;strong>Create&lt;/strong>.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>The deployment will begin. You will be notified when it&amp;rsquo;s complete.&lt;/p>
&lt;h3 id="get-the-connection-string">Get the connection string&lt;/h3>
&lt;p>To connect to the storage account, you will need a connection string. To get this:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Open the storage account in the Azure portal. You can do this by selecting &lt;strong>Go to resource&lt;/strong> from the notification that pops up with the storage account is deployed.&lt;/p>
&lt;p>&lt;img src="https://github.com/jimbobbennett/pi-hat-cam/raw/main/images/portal-storage-deployed-notification.png" alt="The deployment notification">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>From the side bar, select &lt;strong>Settings -&amp;gt; Access keys&lt;/strong>&lt;/p>
&lt;p>&lt;img src="https://github.com/jimbobbennett/pi-hat-cam/raw/main/images/portal-storage-access-keys-menu.png" alt="The access keys menu">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Select the &lt;strong>Copy to clipboard&lt;/strong> button next to the &lt;em>Connection string&lt;/em> under either &lt;em>Key 1&lt;/em> or &lt;em>Key 2&lt;/em>. It doesn&amp;rsquo;t matter which one.&lt;/p>
&lt;p>&lt;img src="https://github.com/jimbobbennett/pi-hat-cam/raw/main/images/portal-storage-access-keys.png" alt="The connection string">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Store this connection string somewhere. You&amp;rsquo;ll need it to configure your Pi code.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h2 id="deploy-the-code">Deploy the code&lt;/h2>
&lt;p>Once you have the storage account, it&amp;rsquo;s time to deploy the code.&lt;/p>
&lt;p>You can find the code in GitHub at &lt;a href="https://github.com/jimbobbennett/pi-hat-cam">github.com/jimbobbennett/pi-hat-cam&lt;/a>.&lt;/p>
&lt;p>The code is fully documented and commented, so check out the &lt;a href="https://github.com/jimbobbennett/pi-hat-cam/blob/main/pi-app/app.py">&lt;code>app.py&lt;/code>&lt;/a> file to see how it all works.&lt;/p>
&lt;h3 id="configure-the-pi">Configure the Pi&lt;/h3>
&lt;p>You will need to be running the latest Raspberry Pi OS on your Pi Zero W. To make the camera faster to launch, you should install Raspberry Pi OS Lite.&lt;/p>
&lt;p>To do this, use the &lt;a href="https://www.raspberrypi.org/blog/raspberry-pi-imager-imaging-utility/">Raspberry Pi imager&lt;/a>. When you choose the OS, select &lt;strong>Raspberry Pi OS (other)&lt;/strong>, then select &lt;strong>Raspberry Pi OS Lite (32 bit)&lt;/strong>.&lt;/p>
&lt;p>Once your SD card is ready, configure the Pi for headless access by following the steps in this &lt;a href="https://github.com/microsoft/rpi-resources/tree/master/headless-setup#setting-up-ssh-and-wifi">headless setup guide&lt;/a>. Work through the steps up to the &lt;em>Remote desktop&lt;/em> section - you don&amp;rsquo;t need to follow this section as it contains instructions when using the full Raspberry Pi OS, not the Lite version you are using here.&lt;/p>
&lt;h3 id="deploy-the-python-code">Deploy the Python code&lt;/h3>
&lt;p>The Python code you need is in this repo in the &lt;code>pi-app&lt;/code> folder.&lt;/p>
&lt;ol>
&lt;li>
&lt;p>SSH into your Pi&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Install git, Pip and Python virtual environments using the following command:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>sudo apt install git
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sudo apt install python3-pip
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sudo apt install python3-venv
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>Clone the repo:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>git clone git@github.com:jimbobbennett/pi-hat-cam.git
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>Navigate to the folder containing the code&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>cd pi-hat-cam/pi-app
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>Create a &lt;a href="https://docs.python.org/3/tutorial/venv.html#:~:text=%20Virtual%20Environments%20and%20Packages%20%C2%B6%20%201,upgrade%2C%20and%20remove%20packages%20using%20a...%20More%20">Python Virtual Environment&lt;/a>:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>python3 -m venv .venv
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>Activate the virtual environment:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>source ./.venv/bin/activate
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>Install the Pip packages&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>pip install -r requirements.txt
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;/ol>
&lt;h3 id="configure-the-app">Configure the app&lt;/h3>
&lt;p>Once the code is deployed, you&amp;rsquo;ll need to configure the app to connect to your Azure storage account.&lt;/p>
&lt;p>The code uses the &lt;code>dotenv&lt;/code> package to read environment variables from a &lt;code>.env&lt;/code> file. You will need to create this file and add the Azure storage connection string that you copied earlier to it.&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Create the file and open it for editing in &lt;code>nano&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>nano .env
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>Add the following entry:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>BLOB_CONNECTION_STRING&lt;span style="color:#f92672">=&lt;/span>&amp;lt;connection_string&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Replace &lt;code>&amp;lt;connection_string&amp;gt;&lt;/code> with the connection string you copied earlier.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Close the file by pressing &lt;em>ctrl+X&lt;/em>. You will be prompted to save the file, so select &lt;code>yes&lt;/code> and press enter to select the &lt;code>.env&lt;/code> filename.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;blockquote>
&lt;p>There are other optional parameters you can add to this file to configure things like the video resolution or quality. Check out the &lt;code>app.py&lt;/code> code for more details.&lt;/p>
&lt;/blockquote>
&lt;h3 id="test-the-app">Test the app&lt;/h3>
&lt;p>Before you use this in the wild, you should test the app.&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Connect the camera to the Pi&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Run the Pi code with this command:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>python app.py
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>The app will start up and begin recording, uploading videos to blob storage once they are recorded. You should see something like this in the output:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">(&lt;/span>.venv&lt;span style="color:#f92672">)&lt;/span> pi@hat-cam:~/pi-hat-cam $ python app.py
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Checking container videos
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Setting camera resolution to &lt;span style="color:#ae81ff">1280&lt;/span> , &lt;span style="color:#ae81ff">720&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Starting queue worker
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Recording ./videos/2020-07-08 07:42:51.h264
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Queuing ./videos/2020-07-08 07:42:51.h264
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Recording ./videos/2020-07-08 07:43:01.h264
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Uploading ./videos/2020-07-08 07:42:51.h264 to 2020-07-08 07:42:51.h264
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Deleting ./videos/2020-07-08 07:42:51.h264
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>Stop the app using &lt;em>ctrl+c&lt;/em>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Head to the storage account in the Azure portal.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Select &lt;strong>Storage Explorer&lt;/strong> from the side menu&lt;/p>
&lt;p>&lt;img src="https://github.com/jimbobbennett/pi-hat-cam/raw/main/images/portal-storage-storage-explorer.png" alt="The storage explorer menu">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>You should see the blob files that were uploaded listed here&lt;/p>
&lt;p>&lt;img src="https://github.com/jimbobbennett/pi-hat-cam/raw/main/images/portal-storage-storage-explorer-files.png" alt="The files listed in the storage explorer">&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>You can download these files by selecting one and selecting &lt;strong>Download&lt;/strong>. The downloaded file can be opened in an app like &lt;a href="https://www.videolan.org/vlc/index.html">VLC&lt;/a>.&lt;/p>
&lt;h3 id="configure-the-app-to-run-on-startup">Configure the app to run on startup&lt;/h3>
&lt;p>Once the app is deployed, it can be run manually from the command line. It&amp;rsquo;s better, however, if it is started when the Pi is booted - that way it is running automatically not long after the Pi is connected to power.&lt;/p>
&lt;p>You can do this by adding an entry to the crontab. Cron is a tool that runs code at certain times, and can be configured to run the Pi code when the Pi is rebooted.&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Run the following code to configure the CronTab:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>sudo crontab -l &amp;gt; cron.tmp
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>echo &lt;span style="color:#e6db74">&amp;#34;@reboot sleep 30 &amp;amp;&amp;amp; cd /home/pi/pi-hat-cam/pi-app &amp;amp;&amp;amp; /home/pi/pi-hat-cam/pi-app/.venv/bin/python /home/pi/pi-hat-cam/pi-app/app.py&amp;#34;&lt;/span> &amp;gt;&amp;gt; cron.tmp
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sudo crontab cron.tmp
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>rm cron.tmp
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;/ol>
&lt;p>This code writes a new entry that is run on reboot. First it sleeps for 30 seconds to ensure the Pi is fully running and connected to the internet, then it launches the &lt;code>app.py&lt;/code> file using the Python binary in the virtual environment.&lt;/p>
&lt;p>Test this out by rebooting the Pi. You should see video files appear in the Storage Explorer in the Azure portal. Power the Pi off when done.&lt;/p>
&lt;h2 id="download-the-video">Download the video&lt;/h2>
&lt;p>By creating short videos it helps ensure the videos are uploaded, but this is not the best for watching later. It would be easier if there was a way to reassemble the video. The &lt;code>video_downloader.py&lt;/code> file in the &lt;code>downloader&lt;/code> folder has code to do this.&lt;/p>
&lt;p>This file needs a &lt;code>.env&lt;/code> file set up the same as the main app, with the &lt;code>BLOB_CONNECTION_STRING&lt;/code> value set. There are other values you can configure from the default, and this are listed in the code.&lt;/p>
&lt;p>Ideally you should run this code on a device that is not the Pi, so that you can view the video. You will need Python installed.&lt;/p>
&lt;ol>
&lt;li>
&lt;p>From the folder the &lt;code>video_downloader.py&lt;/code> is in, create a &lt;a href="https://docs.python.org/3/tutorial/venv.html#:~:text=%20Virtual%20Environments%20and%20Packages%20%C2%B6%20%201,upgrade%2C%20and%20remove%20packages%20using%20a...%20More%20">Python Virtual Environment&lt;/a>:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>python3 -m venv .venv
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>On Windows, use:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cmd" data-lang="cmd">&lt;span style="display:flex;">&lt;span>python -m venv .venv
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>Activate the virtual environment:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>source ./.venv/bin/activate
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>Install the Pip packages&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>pip install -r requirements.txt
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>Create a file called &lt;code>.env&lt;/code> in your favorite text editor, such as &lt;a href="https://code.visualstudio.com?WT.mc_id=pihatcam-blog-jabenn">Visual Studio Code&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Add the following entry:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>BLOB_CONNECTION_STRING&lt;span style="color:#f92672">=&lt;/span>&amp;lt;connection_string&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Replace &lt;code>&amp;lt;connection_string&amp;gt;&lt;/code> with the connection string you copied earlier.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Run the code:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>python video_downloader&lt;span style="color:#f92672">.&lt;/span>py
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;/ol>
&lt;p>This will download all the blobs, concatenating them into a single file called &lt;code>downloaded_video.h264&lt;/code>. You can then view ths file in an app like &lt;a href="https://www.videolan.org/vlc/index.html">VLC&lt;/a>.&lt;/p>
&lt;blockquote>
&lt;p>The blobs are not deleted when you download them. You will need to manually delete them from the storage resource once you are finished with them.&lt;/p>
&lt;/blockquote>
&lt;h2 id="create-the-wearable">Create the wearable&lt;/h2>
&lt;p>There&amp;rsquo;s so many different pieces of clothing you could attach this to. In this guide I&amp;rsquo;m going to focus on a cap.&lt;/p>
&lt;p>You will need:&lt;/p>
&lt;ul>
&lt;li>A cap that you don&amp;rsquo;t mind making holes in&lt;/li>
&lt;li>Scissors&lt;/li>
&lt;li>Gaffer tape, or offcuts of fabric and needle and thread depending on how good you are at sewing (I&amp;rsquo;m not very good)&lt;/li>
&lt;li>Double sided mounting tape&lt;/li>
&lt;li>A USB power pack and USB cable that can reach from the pack in a pocket or strapped to a belt to the hat&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://github.com/jimbobbennett/pi-hat-cam/raw/main/images/make-all-parts.png" alt="All the parts - cap, gaffer tape, scissors, pi, camera">&lt;/p>
&lt;h3 id="mount-the-camera">Mount the camera&lt;/h3>
&lt;ol>
&lt;li>
&lt;p>Make a small hole in the front of the cap - big enough for the camera lens to fit through&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Place the camera inside the hat and push the lens through the hole. It might be easier to detach the camera from the board to pass it through the hole.&lt;/p>
&lt;p>&lt;img src="https://github.com/jimbobbennett/pi-hat-cam/raw/main/images/make-camera-through-hole.png" alt="The camera poking through a hole">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Fix the camera in place on the front of the hat with double-sided mounting tape. You can use fabric glue, but be careful not to get any on the lens. This also reduces you ability to easily re-use the camera in a different make.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Fix the camera circuit board in place inside the cap using gaffer tape&lt;/p>
&lt;p>&lt;img src="https://github.com/jimbobbennett/pi-hat-cam/raw/main/images/camera-mounted-in-hat.png" alt="The camera module in the hat">&lt;img src="https://github.com/jimbobbennett/pi-hat-cam/raw/main/images/camera-taped-in-hat.png" alt="The camera module taped in teh hat">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Fix the camera ribbon cable to the inside of the cap, right through to the hole at the back. Use gaffer tape or sew it in place.&lt;/p>
&lt;p>&lt;img src="https://github.com/jimbobbennett/pi-hat-cam/raw/main/images/cable-taped-in-hat.png" alt="Ribbon cable taped into the hat">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Mount the Raspberry Pi Zero W to the back of the cap, attaching the camera ribbon cable. Use double sided mounting tape, gaffer tape or sew it in place, whatever works. The USB sockets should point downwards.&lt;/p>
&lt;p>&lt;img src="https://github.com/jimbobbennett/pi-hat-cam/raw/main/images/make-pi-fixed-to-hat.png" alt="The pi mounted to a hat">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Test out the connections - power the Pi over USB and make sure videos are being uploaded. Also test out the fit and camera position, adjust it as necessary using tape or fabric.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>&lt;img src="https://github.com/jimbobbennett/pi-hat-cam/raw/main/images/make-jim-in-hat-cam.png" alt="Jim in the hat cam">&lt;/p>
&lt;h2 id="use-the-camera">Use the camera&lt;/h2>
&lt;p>To use the camera, first it needs to be tethered to your phone or a WiFi hotspot to upload the videos. To tether:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Connect to the Pi over SSH&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Start your WiFi hotspot, or enable tethering on your phone&lt;/p>
&lt;/li>
&lt;li>
&lt;p>From your Pi, launch the configuration tool:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>sudo raspi-config
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>Select &lt;strong>2 Network options&lt;/strong>&lt;/p>
&lt;p>&lt;img src="https://github.com/jimbobbennett/pi-hat-cam/raw/main/images/pi-config-main-menu.png" alt="The pi config main menu">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Select &lt;strong>N2 Wireless LAN&lt;/strong>&lt;/p>
&lt;p>&lt;img src="https://github.com/jimbobbennett/pi-hat-cam/raw/main/images/pi-config-network-menu.png" alt="The network menu">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Enter the SSID and Password of your hotspot&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Select &lt;strong>Finish&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>When asked to reboot, select &lt;strong>Yes&lt;/strong>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>When the Pi reboots, it will connect to your hotspot or phone.&lt;/p>
&lt;p>Power off the camera until you are ready to use it.&lt;/p>
&lt;p>Once you are ready to use it, connect the power and it will start recording as soon as it has booted up.&lt;/p>
&lt;p>Here&amp;rsquo;s the camera in action browsing this repo:&lt;/p>
&lt;p>&lt;img src="https://github.com/jimbobbennett/pi-hat-cam/raw/main/images/cam-video.gif" alt="A video of this repo being browsed on a computer">&lt;/p></description></item><item><title>Recognizing words on a microcontroller using TinyML</title><link>https://jimbobbennett.dev/blogs/recognizing-words-on-a-microcontroller-using-tinyml/</link><pubDate>Tue, 21 Apr 2020 18:00:00 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/recognizing-words-on-a-microcontroller-using-tinyml/</guid><description>&lt;p>AI has traditionally been the realm of expensive computers, with models trained and run on GPUs and other expensive hardware. More recently this has started to change with a move towards TinyML - small machine learning models that are trained on the expensive hardware, but run on smaller, cheaper devices including the low power micro-controllers that run IoT and maker devices.&lt;/p>
&lt;p>Adafruit have recently released a device to run TinyML models on called the &lt;a href="https://www.adafruit.com/product/4400">EdgeBadge&lt;/a>.&lt;/p>
&lt;p>&lt;img src="https://cdn-shop.adafruit.com/970x728/4400-15.jpg" alt="The Adafruit Edgebadge">&lt;/p>
&lt;p>This device is based off their PyBadge device - a board with a screen, game style controllers, NeoPixel LEDs and connectors so you can wear it on a lanyard. The difference with the EdgeBadge is it has a built in microphone so you can use it for audio recognition. The product page has links to a demo you can run that recognizes two words, yes or no, and displays an image on screen when the words are detected.&lt;/p>
&lt;p>You can find the demo on &lt;a href="https://learn.adafruit.com/tensorflow-lite-for-edgebadge-kit-quickstart">Adafruit Learn&lt;/a>.&lt;/p>
&lt;p>I thought it would be fun to repurpose this example and learn how to retrain the board to recognize &amp;lsquo;Stop&amp;rsquo; and &amp;lsquo;Go&amp;rsquo; instead of yes and no.&lt;/p>
&lt;h2 id="train-the-model">Train the model&lt;/h2>
&lt;p>The yes/no detection model is a TensorFlow model, created using an example from the TensorFlow GitHub repository. The model is trained using a huge file of recordings of people saying a number of different words. Once the model has been trained, it is then shrunk down to run on tiny devices such as micro-controllers, and weighs in at only a few kilobytes.&lt;/p>
&lt;p>You can find the original TensorFlow example in the &lt;a href="https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/audio_recognition.md">TensorFlow GitHub repo&lt;/a>.&lt;/p>
&lt;p>I trained my new model using the &lt;a href="https://azure.microsoft.com/services/machine-learning/#product-overview/?WT.mc_id=aiapril-blog-jabenn">Azure Machine Learning Studio&lt;/a>, a service that allows you to build and train models using cloud compute, then either host them in the cloud or download them for use offline.&lt;/p>
&lt;h3 id="create-an-azure-account">Create an Azure account&lt;/h3>
&lt;p>To use Azure services you will need an Azure subscription. If you don&amp;rsquo;t have a subscription you can sign up for free.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>If you are a student aged 18 and up and have an email address from an academic institution, you can sign up for the free Azure for Students offer at &lt;a href="https://azure.microsoft.com/free/students/?WT.mc_id=aiapril-blog-jabenn">azure.microsoft.com/free/students&lt;/a> without a credit card. At the time of writing this gives you $100 of credit to use over 12 months, as well as free tiers of a number of services for that 2 months. At the end of the 12 months, if you are still a student you can renew and get another $100 in credit and 12 months of free services.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>If you are not a student, you can sign up at &lt;a href="https://azure.microsoft.com/free/?WT.mc_id=aiapril-blog-jabenn">azure.microsoft.com/free&lt;/a>. You will need a credit card for verification purposes only, you will not be billed unless you decide to upgrade your account to a paid offering. At the time of writing the free account will give you US$200 of free credit to spend on what you like in the first 30 days, 12 months of free services, plus a load of services that have tiers that are always free.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="create-a-machine-learning-resource">Create a Machine Learning resource&lt;/h3>
&lt;p>Before you can use the Azure Machine Learning (ML) Studio, you need to spin up a Machine Learning resource. This is created in your Azure subscription but then can be shared with other developers so that you can all share the same ML Studio workspace.&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Open the &lt;a href="https://portal.azure.com/?WT.mc_id=aiapril-blog-jabenn">Azure portal&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Select &lt;strong>Create a resource&lt;/strong> then search for &lt;code>Machine Learning&lt;/code>. Select &lt;strong>Machine Learning&lt;/strong> then select &lt;strong>Create&lt;/strong>.&lt;/p>
&lt;p>&lt;img src="https://raw.githubusercontent.com/jimbobbennett/EdgeBadge-WordRecogniser/master/images/CreateMLResource.png" alt="The Machine Learning resource">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Give the workspace a name and select your Azure subscription.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Create a new resource group for this service.&lt;/p>
&lt;blockquote>
&lt;p>Resource groups are logic groupings of services, so it is good practice to put all the resources for one project in a single resource group so that you can manage them together. When you create a Machine Learning resource it will create a few different services, so having them in the same resource group means you can delete them all together by deleting the resource group.&lt;/p>
&lt;/blockquote>
&lt;/li>
&lt;li>
&lt;p>Select the location nearest to you. For the workspace edition, select &lt;strong>Basic&lt;/strong>. This price tier of the core service is free to use, you only pay for the compute used to train or run models.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Select &lt;strong>Review + Create&lt;/strong>, then select &lt;strong>Create&lt;/strong>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>The resource will be created.&lt;/p>
&lt;h3 id="set-up-ml-studio">Set up ML Studio&lt;/h3>
&lt;p>Now that the Machine Learning resource has been created, you can use it from ML Studio.&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Open ML Studio at &lt;a href="https://ml.azure.com/?WT.mc_id=aiapril-blog-jabenn">ml.azure.com&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Log in with your Azure account, then select your directory, subscription and the workspace you just created&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Select &lt;strong>Get started&lt;/strong>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>ML Studio will log in to your workspace. From here you can run Machine Learning workloads using Jupyter notebooks, AutoML to create models for you based off data sets, or a drag and drop designer.&lt;/p>
&lt;h3 id="set-up-compute">Set up compute&lt;/h3>
&lt;p>The TensorFlow example uses a Jupyter notebook to train the model. For this, I used a slightly tweaked version of the notebook, tweaked to fix some versioning issues and use the power of ML Studio.&lt;/p>
&lt;p>To run a notebook, you need compute - a machine allocated to run the training. This compute is paid for based on the time it&amp;rsquo;s running and the power of the machine, the more powerful, the more you pay per minute.&lt;/p>
&lt;blockquote>
&lt;p>You can see the pricing per hour on the &lt;a href="https://azure.microsoft.com/pricing/details/machine-learning/?WT.mc_id=aiapril-blog-jabenn">Machine Learning pricing page&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;ol>
&lt;li>
&lt;p>Select &lt;strong>Compute&lt;/strong> from the left-hand menu&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Select &lt;strong>+ New&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Give the compute a name&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Drop down the &lt;em>Virtual Machine Size&lt;/em> box, and select &lt;strong>GPU&lt;/strong> to list the GPU-based compute options. Select the &lt;strong>Standard_NC12&lt;/strong> machine - this has 2 GPUs and is enough to train this model in an hour and a half or so. At the time of writing the cost is US$1.80 per hour when running in the US.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Select &lt;strong>Create&lt;/strong>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>The compute will be created a spun up.&lt;/p>
&lt;h3 id="upload-the-notebook">Upload the notebook&lt;/h3>
&lt;p>You can find the notebook in the Releases in this GitHub repository. Use this link to download the notebook:&lt;/p>
&lt;p>&lt;a href="https://github.com/jimbobbennett/EdgeBadge-WordRecogniser/releases/download/v1.0/word-recognizer-training.ipynb">word-recognizer-training.ipynb&lt;/a>.&lt;/p>
&lt;p>Once you&amp;rsquo;ve downloaded the notebook, you need to upload it to ML Studio.&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Select &lt;strong>Notebooks&lt;/strong> from the left-hand menu&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Select &lt;strong>Upload files&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Find the notebook you&amp;rsquo;ve just downloaded, and select it&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>The notebook will be uploaded and available to run. You will see it in a file tree on the left hand side of the &lt;strong>Notebooks&lt;/strong> blade.&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Select the notebook and it will open up in read only mode&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Select the compute you created in the menu at the top&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Select &lt;strong>Edit -&amp;gt; Edit in Jupyter&lt;/strong> top open the notebook in Jupyter notebooks. You will need to sign in to your Azure account again.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>The notebook has a number of sections, each documented so read the notebook to see what each section does. A basic overview is:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Create some environment variables to define the words to train for and the number of training iterations.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Install a specific version of TensorFlow GPU to ensure the training uses the GPU, and uses a version that the example training script was written for&lt;/p>
&lt;blockquote>
&lt;p>The training script will only work against TensorFlow 1.5.x, don&amp;rsquo;t update the notebook to a later version otherwise the training will fail&lt;/p>
&lt;/blockquote>
&lt;/li>
&lt;li>
&lt;p>Clone the TensorFlow repository to get access to the training script&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Run the training, then freeze the created TensorFlow graph to save down the weights&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Convert the model to TensorFlow light to make it smaller, then save it out as binary data in a C code file so that it can be used from code.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>From the Jupyter notebooks:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>The first cell defines the words the model should be trained for.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># A comma-delimited list of the words you want to train for.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># All other words will be used to train an &amp;#34;unknown&amp;#34; category.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>os&lt;span style="color:#f92672">.&lt;/span>environ[&lt;span style="color:#e6db74">&amp;#34;WANTED_WORDS&amp;#34;&lt;/span>] &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;stop,go&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The data set supports the following words:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Yes&lt;/td>
&lt;td>No&lt;/td>
&lt;td>Up&lt;/td>
&lt;td>Down&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Left&lt;/td>
&lt;td>Right&lt;/td>
&lt;td>On&lt;/td>
&lt;td>Off&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Stop&lt;/td>
&lt;td>Go&lt;/td>
&lt;td>Zero&lt;/td>
&lt;td>One&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Two&lt;/td>
&lt;td>Three&lt;/td>
&lt;td>Four&lt;/td>
&lt;td>Five&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Six&lt;/td>
&lt;td>Seven&lt;/td>
&lt;td>Eight&lt;/td>
&lt;td>Nine&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>The notebook is set to train for &amp;lsquo;Stop&amp;rsquo; and &amp;lsquo;Go&amp;rsquo;, but if you want to change the words it is trained for, change the array.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Select &lt;strong>Run&lt;/strong> from the top menu for each cell to run them one at a time, or select &lt;strong>Cell -&amp;gt; Run All&lt;/strong> to run all the cells. The training step will take 1.5-2 hours to run.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Once the steps have all finished, head back to ML Studio, select &lt;strong>Compute&lt;/strong> from the left-hand menu, check the box next to your compute and select &lt;strong>Stop&lt;/strong> to stop the compute.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Select &lt;strong>Notebooks&lt;/strong> from the left-hand menu. Expand the &lt;em>Content&lt;/em> node above the notebook in the file explorer, and select the &lt;code>tiny_conv.cc&lt;/code> file. This is the C code for the resulting model.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;blockquote>
&lt;p>Don&amp;rsquo;t forget to stop the compute once the model is trained! You pay for the time that the compute is running, not the time that the notebooks are running, so to avoid unnecessary costs, remember to stop the compute as soon as you are finished, then restart it if you want to train the model again.&lt;/p>
&lt;/blockquote>
&lt;h2 id="compile-the-code-for-the-edgebadge">Compile the code for the EdgeBadge&lt;/h2>
&lt;p>Now that the model is created, it can be compiled into the sample app for the EdgeBadge.&lt;/p>
&lt;h3 id="set-up-the-development-environment">Set up the development environment&lt;/h3>
&lt;p>It takes a bit of setup to be able to program Adafruit devices using C++. The Arduino IDE is the main tool for programming them, but I personally like to use Visual Studio Code as an IDE, and the Arduino extension to allow Visual Studio Code to control Arduino to program the boards.&lt;/p>
&lt;h4 id="install-the-tools">Install the tools&lt;/h4>
&lt;ol>
&lt;li>
&lt;p>Install &lt;a href="https://code.visualstudio.com/Download/?WT.mc_id=aiapril-blog-jabenn">Visual Studio Code&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Install the &lt;a href="https://www.arduino.cc/en/Main/Software">Arduino IDE&lt;/a> - &lt;strong>NOTE&lt;/strong> On Windows DO NOT install using the Windows store, instead use the &lt;em>Windows Installer, for Windows XP and up&lt;/em>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Inside Visual Studio Code, select the &lt;strong>Extensions&lt;/strong> tab from the left hand side, and search for an install the &lt;em>Arduino&lt;/em> extension. Make sure to install the one from Microsoft as there is more than one extension called &lt;em>Arduino&lt;/em>.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h4 id="configure-the-arduino-ide-and-visual-studio-code-for-adafruit-development">Configure the Arduino IDE and Visual Studio Code for Adafruit development&lt;/h4>
&lt;p>To talk to Adafruit boards, the Arduino IDE needs to be configured to know how to send the compiled code.&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Follow the instructions on the Adafruit site to configure the Arduino IDE for Adafruit boards: &lt;a href="https://learn.adafruit.com/adafruit-pybadge/using-with-arduino-ide">learn.adafruit.com/adafruit-pybadge/using-with-arduino-ide&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>From Visual Studio Code launch the command palette, then select &lt;em>Arduino: Library manager&lt;/em>. From here you can install some additional libraries that are needed to compile the code.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Search for and install the following libraries:&lt;/p>
&lt;ol>
&lt;li>Adafruit EPD&lt;/li>
&lt;li>Adafruit TinyUSB Library&lt;/li>
&lt;li>Adafruit WavePlayer Library&lt;/li>
&lt;li>Adafruit SPIFlash&lt;/li>
&lt;li>Adafruit ImageReader Library&lt;/li>
&lt;li>Adafruit ST7735_and_ST7789 Library&lt;/li>
&lt;li>Adafruit Unified_Sensor&lt;/li>
&lt;li>Adafruit LIS3DH&lt;/li>
&lt;li>Adafruit TouchScreen&lt;/li>
&lt;li>Adafruit NeoPixel&lt;/li>
&lt;li>Adafruit GFX Library&lt;/li>
&lt;li>Adafruit Arcada Library&lt;/li>
&lt;li>Adafruit Zero_PDM Library&lt;/li>
&lt;li>Adafruit ZeroTimer Library&lt;/li>
&lt;li>Adafruit TensorFlow Lite&lt;/li>
&lt;li>Arduino TensorFlowLite&lt;/li>
&lt;li>SdFat - Adafruit Fork (make sure to install the Adafruit fork, not the original SdFat)&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ol>
&lt;h4 id="configure-the-board">Configure the board&lt;/h4>
&lt;ol>
&lt;li>
&lt;p>Connect your EdgeBadge to your computer via USB and make sure the device is switched on&lt;/p>
&lt;/li>
&lt;li>
&lt;p>From the command palette, select &lt;em>Arduino: Board Configuration&lt;/em>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Select the following settings:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Setting&lt;/th>
&lt;th>Value&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Selected board&lt;/td>
&lt;td>Adafruit pyBadge M4 Express (SAMD51)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Cache&lt;/td>
&lt;td>Enabled&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>CPU Speed&lt;/td>
&lt;td>180 MHz (overclock)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Optimize&lt;/td>
&lt;td>Fastest (-Ofast)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Max QSPI&lt;/td>
&lt;td>50 MHz (standard)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>USB Stack&lt;/td>
&lt;td>TinyUSB&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Debug&lt;/td>
&lt;td>Off&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;/li>
&lt;li>
&lt;p>From the command palette, select &lt;em>Arduino: Select serial port&lt;/em> and select the port the EdgeBadge is plugged into. On macOS it will be named something like &lt;code>/dev/cu.usbmodem&amp;lt;xxx&amp;gt;&lt;/code> where &lt;code>&amp;lt;xxx&amp;gt;&lt;/code> is a number. On Windows it will be called &lt;code>COM&amp;lt;x&amp;gt;&lt;/code> where &lt;code>&amp;lt;x&amp;gt;&lt;/code> is a number.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h3 id="compile-the-code">Compile the code&lt;/h3>
&lt;p>The code for the edge badge is in the &lt;code>word_recognizer&lt;/code> folder in &lt;a href="https://github.com/jimbobbennett/EdgeBadge-WordRecogniser">this GitHub repo&lt;/a>. Clone the repo and open the &lt;code>word_recognizer&lt;/code> folder in Visual Studio Code.&lt;/p>
&lt;p>The code contains images and a model that can recognize two words, &amp;lsquo;Stop&amp;rsquo; and &amp;lsquo;Go&amp;rsquo;.&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Double tap the &lt;strong>Reset&lt;/strong> button on the back of the EdgeBadge to put it into the boot loader ready to program&lt;/p>
&lt;p>&lt;img src="https://raw.githubusercontent.com/jimbobbennett/EdgeBadge-WordRecogniser/master/images/BootLoader.png" alt="EdgeBadge in bootloader mode">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>From the command palette, select &lt;em>Arduino: Upload&lt;/em>. The code will be compiled and uploaded to the board.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Once the device reboots, say the words &amp;lsquo;Stop&amp;rsquo; and &amp;lsquo;Go&amp;rsquo;, and the board will show an image for the word you have said.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>Select the image below to see a video of this in action.&lt;/p>
&lt;p>&lt;a href="https://www.youtube.com/watch?v=Z0XiTjXCOdk">&lt;img src="https://img.youtube.com/vi/Z0XiTjXCOdk/0.jpg" alt="The badge responding to stop">&lt;/a>&lt;/p>
&lt;h3 id="use-your-own-model">Use your own model&lt;/h3>
&lt;p>If you want to use your own model trained using Azure ML Studio, you will need to update the code to use this model, and provide image files.&lt;/p>
&lt;h4 id="upload-image-files">Upload image files&lt;/h4>
&lt;ol>
&lt;li>
&lt;p>Create bitmaps for each word that you are detecting, named in the format &lt;code>&amp;lt;word&amp;gt;.bmp&lt;/code>. For example, if you trained the model for &amp;lsquo;Yes&amp;rsquo; and &amp;lsquo;No&amp;rsquo; you will need &lt;code>Yes.bmp&lt;/code> and &lt;code>No.bmp&lt;/code>. These files must be 24-bit bitmaps at a size of 160x128. The best tools to use to create these is good old-fashioned MS Paint on Windows or ImageMagik on macOS.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Reset the EdgeBadge. It will mount on your computer with a disk called &lt;strong>CIRCUITPY&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Copy the bitmaps into this drive&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h4 id="update-the-code">Update the code&lt;/h4>
&lt;ol>
&lt;li>
&lt;p>Open &lt;code>micro_features_micro_model_settings.cpp&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Update &lt;code>kCategoryLabels&lt;/code> to include the words the model was trained on. Keep &lt;code>&amp;quot;silence&amp;quot;&lt;/code> and &lt;code>&amp;quot;unknown&amp;quot;&lt;/code> at the start of the array, and put the words after in the order they were specified in the notebook. Ensure the casing of the words matches the names of the bitmaps created earlier.&lt;/p>
&lt;blockquote>
&lt;p>The words &lt;strong>HAVE&lt;/strong> to be in the same order as the notebook or the wrong word will be detected&lt;/p>
&lt;/blockquote>
&lt;/li>
&lt;li>
&lt;p>Open `micro_features_micro_model_settings.h&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Update &lt;code>kCategoryCount&lt;/code> to be 2 higher than the number of words you trained the model for, so that it is the same as the size of the &lt;code>kCategoryLabels&lt;/code> array. For example if you trained it for &amp;lsquo;Yes&amp;rsquo; and &amp;lsquo;No&amp;rsquo;, set &lt;code>kCategoryCount&lt;/code> to &lt;code>4&lt;/code>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Open &lt;code>micro_features_tiny_conv_micro_features_model_data.cpp&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Replace the contents of the &lt;code>g_tiny_conv_micro_features_model_data&lt;/code> array with the values from &lt;code>__content_tiny_conv_tflite&lt;/code> in the &lt;code>tiny_conv.cc&lt;/code> file downloaded from the Azure ML Studio notebook&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Replace the value of &lt;code>g_tiny_conv_micro_features_model_data_len&lt;/code> with the value of &lt;code>__content_tiny_conv_tflite_len&lt;/code> from the &lt;code>tiny_conv.cc&lt;/code> file downloaded from the Azure ML Studio notebook&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Use the steps above to compile and deploy this new code to the device, then test it out.&lt;/p>
&lt;/li>
&lt;/ol></description></item><item><title>Let your family know you are in meetings with an IoT Busy light</title><link>https://jimbobbennett.dev/blogs/let-your-family-know-you-are-in-meetings-with-an-iot-busy-light/</link><pubDate>Thu, 19 Mar 2020 00:53:47 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/let-your-family-know-you-are-in-meetings-with-an-iot-busy-light/</guid><description>&lt;p>Like a lot of folks at the moment, I&amp;rsquo;m working for home and my child is off school.&lt;/p>
&lt;blockquote>
&lt;p>For those reading this in the future and wondering why, I am currently living in the time of the COVID-19 pandemic and worldwide toilet paper shortages.&lt;/p>
&lt;/blockquote>
&lt;p>One of the upsides of working from home, especially when my 7 year old is off school is that I am available most of the time for the occasional quick cuddle, to laugh at something silly she&amp;rsquo;d just done or help her with something. One of the downsides is that at any time she could walk in to my office whilst I&amp;rsquo;m on a call.&lt;/p>
&lt;p>&lt;img src="https://github.com/jimbobbennett/BusyLight/raw/master/images/kid-crashing-interview.jpg" alt="Image from BBC news of a child walking in to an office during an on-air interview">&lt;/p>
&lt;p>What I need is a on-air style light, to let her know when I&amp;rsquo;m in meetings and when I&amp;rsquo;m not. Luckily I&amp;rsquo;m an IoT nut so I not only have the skills to build such a thing, but I have all the parts just lying around begging me to use them! So I built one!&lt;/p>
&lt;p>&lt;img src="https://github.com/jimbobbennett/BusyLight/raw/master/images/BusyLight.gif" alt="The busy light changing from green to red to off at the press of a button">&lt;/p>
&lt;h2 id="what-i-needed-it-to-do">What I needed it to do&lt;/h2>
&lt;p>This light needs to live outside my office so my family can see it before they come in, but I don&amp;rsquo;t want to have to get up and walk out the door to turn it on or off. I want to have it controlled automatically by my calendar, so it shows red when I have a meeting and green when I&amp;rsquo;m free.&lt;/p>
&lt;p>This leads to the problem of connectivity - how can my calendar control my light remotely. For that the answer was obvious - a mixture of &lt;a href="https://azure.microsoft.com/services/iot-central/?WT.mc_id=busylight-blog-jabenn">Azure IoT Central&lt;/a>, the glorious IoT SaaS platform from Microsoft, and &lt;a href="https://azure.microsoft.com/services/logic-apps/?WT.mc_id=busylight-blog-jabenn">Azure Logic Apps&lt;/a>, a no-code tool for building apps. Both have such a low barrier to entry I knew I&amp;rsquo;d be able to get something up and running quickly.&lt;/p>
&lt;h2 id="hardware">Hardware&lt;/h2>
&lt;blockquote>
&lt;p>All the Amazon links below are affiliate links. Any money I make from these links will be donated to support families affected by COVID-19. If you don&amp;rsquo;t want to use these links then search for the items directly on Amazon or buy from your local maker store or direct from the manufacturers.&lt;/p>
&lt;/blockquote>
&lt;p>Every good maker project starts with hardware. I needed a device I could program, some lights and something to put it in. After digging around in my supply of bits I put together the following:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;a href="https://amzn.to/2TMqckO">Pimoroni Mood Light&lt;/a> - this is a nice little kit that contains a Raspberry Pi Zero W, a Pimoroni unicorn pHAT with 55 programmable LEDs in a rectangle, some laser cut plastic to make a case that looks like a light, and various cables and headers.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://amzn.to/38L5VAk">16GB SD Card&lt;/a> - the mood light doesn&amp;rsquo;t come with an SD Card, so you&amp;rsquo;ll need one to run the code from.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>The Pimoroni mood light is a great all-in-one package for a light, but any Raspberry Pi would work as long as it has internet connectivity. If you want to get the Pi parts separately and make your own enclosure, then you will need:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;a href="https://amzn.to/3cRtfj7">Raspberry Pi Zero W&lt;/a> - the W part is important as it needs internet connectivity&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://amzn.to/2wV1uWh">Headers for the Pi&lt;/a> - the kit linked above includes them, but if you buy a board on it&amp;rsquo;s own you will need the headers&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://amzn.to/2U02HUl">Pimoroni Unicorn pHAT&lt;/a> - this is a grid of 55 programmable LEDs that you can control from the Pi&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>One of the downsides to a make like this is it involves the bane of my existence - a soldering iron&amp;hellip;&lt;/p>
&lt;p>The Pi Zero doesn&amp;rsquo;t come with headers pre-soldered unless you are lucky enough to track down one that does. The Unicorn pHAT also needs to be soldered. If you don&amp;rsquo;t have a soldering iron, nows the time to buy one and learn. Be warned, the headers are small and fiddly, so you may also need a magnifier to help you.&lt;/p>
&lt;p>If you are new to soldering, some great videos to help you are from EEVblog:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://youtu.be/J5Sb21qbpEQ">Soldering tutorial Part 1 - tools&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://youtu.be/fYz5nIHH0iY">Soldering tutorial Part 2&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://youtu.be/b9FC9fAlfQE">Soldering tutorial Part 3&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>You can also use a different Pi such as the new &lt;a href="https://amzn.to/2xziEt7">Raspberry Pi 4&lt;/a>, and these have the headers already on the board. There are also many different light options you could use, so work with whatever you have, but you&amp;rsquo;ll have to work out the code to use them yourself.&lt;/p>
&lt;h2 id="configure-iot-central">Configure IoT Central&lt;/h2>
&lt;p>My favorite IoT cloud service is &lt;a href="https://azure.microsoft.com/services/iot-central/?WT.mc_id=busylight-blog-jabenn">Azure IoT Central&lt;/a>. This is a software as a service (SaaS) platform that allows devices to send data to and be controlled from the cloud. I can use this to send commands to the device to change the color of the light. I can also use to cache the current color so that if the device resets, it can retain it&amp;rsquo;s previous color setting.&lt;/p>
&lt;h3 id="set-up-the-iot-central-app">Set up the IoT Central app&lt;/h3>
&lt;ol>
&lt;li>
&lt;p>Head to &lt;a href="https://aka.ms/BusyLightTemplate">aka.ms/BusyLightTemplate&lt;/a>. This link is to a pre-configured application template that you can use to create the IoT Central application&lt;/p>
&lt;/li>
&lt;li>
&lt;p>You may be prompted to sign in, so sign in with your Microsoft account. If you don&amp;rsquo;t have one you can create one during this step. A Microsoft account can be created with an email address from any provider, it doesn&amp;rsquo;t just have to be hotmail or outlook.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Give the application a name and a URL. The URL will need to be globally unique across all IoT central apps so add something personal or leave the auto-generated name.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Select a pricing plan. You can have a free plan for 7 days without an Azure account, or a standard plan using an Azure account. Every account has 2 devices for free, so as long as you are only using 1 or 2 devices then you will never have to pay.&lt;/p>
&lt;p>You will need an Azure subscription for a later step, and you can sign up for free:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>If you are a student aged 18 and up and have an email address from an academic institution, you can sign up for the free Azure for Students offer at &lt;a href="https://azure.microsoft.com/free/students/?WT.mc_id=busylight-blog-jabenn">azure.microsoft.com/free/students&lt;/a> without a credit card. At the time of writing this gives you $100 of credit to use over 12 months, as well as free tiers of a number of services for that 2 months. At the end of the 12 months, if you are still a student you can renew and get another $100 in credit and 12 months of free services.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>If you are not a student, you can sign up at &lt;a href="https://azure.microsoft.com/free/?WT.mc_id=busylight-blog-jabenn">azure.microsoft.com/free&lt;/a>. You will need a credit card for verification purposes only, you will not be billed unless you decide to upgrade your account to a paid offering. At the time of writing the free account will give you US$200 of free credit to spend on what you like in the first 30 days, 12 months of free services, plus a load of services that have tiers that are always free.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>If you go with a standard plan, select your &lt;em>Directory&lt;/em>, &lt;em>Azure subscription&lt;/em> and the &lt;em>Location&lt;/em> nearest to you.&lt;/p>
&lt;p>If you go with the free plan, enter your contact information.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Select &lt;strong>Create&lt;/strong>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>The IoT Central app will be provisioned and the dashboard will be loaded.&lt;/p>
&lt;h3 id="create-a-device">Create a device&lt;/h3>
&lt;p>The app that is created contains everything you need to get going - except a configured device. From this app you can configure one or more devices and control these.&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Select &lt;strong>Devices&lt;/strong> from the left-hand menu&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Select &lt;em>Busy Light&lt;/em> from the &lt;strong>Devices&lt;/strong> list&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Select &lt;strong>+ New&lt;/strong> from the top menu&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Give the device a name and an Id, then select &lt;strong>Create&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Select the newly created device, then select &lt;strong>Connect&lt;/strong> from the top menu. This will show some connection values.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Take a note of the &lt;em>ID scope&lt;/em>, &lt;em>Device ID&lt;/em> and &lt;em>Primary key&lt;/em>&lt;/p>
&lt;p>&lt;img src="https://github.com/jimbobbennett/BusyLight/raw/master/images/ConnectionDialog.png" alt="The connection dialog">&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>Repeat this for as many devices as you want to control.&lt;/p>
&lt;h2 id="program-the-pi">Program the Pi&lt;/h2>
&lt;p>The device will be running some Python code that can control the Unicorn pHAT as well as talk to IoT Central.&lt;/p>
&lt;h3 id="set-up-the-pi">Set up the Pi&lt;/h3>
&lt;p>The Pi needs to be running Raspbian Lite&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Configure Rasbian Lite on the SD card by following instructions here: &lt;a href="https://www.raspberrypi.org/documentation/installation/installing-images/">raspberrypi.org/documentation/installation/installing-images&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Once the image has been burned, open it in your file explorer or Finder. It will be mounted as a drive called &lt;code>BOOT&lt;/code>. You may need to eject the re-insert the SD card to make it visible after burning.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Create an empty file in the root of the drive called &lt;code>ssh&lt;/code> with no extension. This file should be empty, the presence of a file called &lt;code>ssh&lt;/code> is enough to enable SSH on the Pi.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Create a new file in the root of the drive called &lt;code>wpa_supplicant.conf&lt;/code>. This file contains the WiFi connection details. Add the following to this file:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>ctrl_interface&lt;span style="color:#f92672">=&lt;/span>DIR&lt;span style="color:#f92672">=&lt;/span>/var/run/wpa_supplicant GROUP&lt;span style="color:#f92672">=&lt;/span>netdev
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>update_config&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>country&lt;span style="color:#f92672">=&lt;/span>US
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>network&lt;span style="color:#f92672">={&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ssid&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;YOURSSID&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> psk&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;YOURPASSWORD&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> scan_ssid&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Replace &lt;code>YOURSSID&lt;/code> and &lt;code>YOURPASSWORD&lt;/code> with the SSID and password of your WiFi.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Eject the SD card and insert it into your Raspberry Pi.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Power up the Pi. It should only take a few seconds to boot, and whilst this is happening you will see the LED by the power socket flash.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Test the connection by SSHing into your Pi. From your computer connect to &lt;code>pi@raspberrypi.local&lt;/code>.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>ssh pi@raspberrypi.local
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>If the host cannot be found then if you know the IP address (for example by using your routers management software) then you can log in to &lt;code>pi@192.168.0.1&lt;/code>, replacing &lt;code>192.168.0.1&lt;/code> with the IP address of your Pi. You can also use the &lt;a href="https://learn.adafruit.com/the-adafruit-raspberry-pi-finder/finding-and-connecting">Adafruit Pi Finder utility&lt;/a> to locate it&amp;rsquo;s IP address.&lt;/p>
&lt;p>The default password is &lt;code>raspberry&lt;/code>.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h3 id="install-the-light-controller-software">Install the light controller software&lt;/h3>
&lt;p>The light controller software is in my &lt;a href="https://github.com/jimbobbennett/BusyLight/tree/master/app">GitHub repo&lt;/a> in the &lt;a href="https://github.com/jimbobbennett/BusyLight/tree/master/app/app.py">&lt;code>app.py&lt;/code>&lt;/a> file. This contains code to talk to IoT Central to receive commands to change the light color, then set this color on the Unicorn pHAT. For this script to connect to IoT central some environment variables need to be configured in a file.&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Run the install script using this command:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>bash -c &lt;span style="color:#e6db74">&amp;#34;&lt;/span>&lt;span style="color:#66d9ef">$(&lt;/span>curl -s -L https://github.com/jimbobbennett/BusyLight/releases/download/v0.1/install.sh&lt;span style="color:#66d9ef">)&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This will update the Pi, install libraries for the Unicorn pHAT, the Python code for this app, and configure the CronTab to run this app when the device reboots. You may need to select &amp;lsquo;y&amp;rsquo; one or more times when prompted.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>When prompted enter the values for the &lt;em>ID scope&lt;/em>, &lt;em>Device ID&lt;/em> and &lt;em>Primary Key&lt;/em> copied from the IoT Central device connection dialog&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The app will be installed in the &lt;code>BusyLight&lt;/code> folder in the home directory&lt;/p>
&lt;/li>
&lt;li>
&lt;p>After installation, the device will reboot and you will be disconnected from the SSH session. When the Pi reboots the app will be running.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;blockquote>
&lt;p>If you are using a different light than the Unicorn pHAT you will need to install the relevant libraries yourself and update the code. The code is in the &lt;code>~/BusyLight/app.py&lt;/code> file.&lt;/p>
&lt;p>You will need to remove all references to the &lt;code>unicornhat&lt;/code> module and the calls to set it up. Then update the &lt;code>set_color&lt;/code> function to use your preferred lights. This function is passed the color as an RGB HEX string, the first 2 characters are the hex value to set for the red channel, second two are the hex value for the green channel and last two the hex values for the blue channel.&lt;/p>
&lt;/blockquote>
&lt;h3 id="test-the-light">Test the light&lt;/h3>
&lt;p>The light is now ready to be controlled from IoT Central.&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Head to your IoT Central app in your browser&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Select &lt;strong>Devices&lt;/strong> from the left-hand menu, then select your device&lt;/p>
&lt;/li>
&lt;li>
&lt;p>You will see a dashboard with 2 cells - one showing the current color, then other labelled &lt;strong>Update Colour&lt;/strong>. Select the &lt;strong>Update Colour&lt;/strong> cell.&lt;/p>
&lt;p>&lt;img src="https://github.com/jimbobbennett/BusyLight/raw/master/images/Dashboard.png" alt="The device dashboard">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Enter a value for the &lt;strong>Colour&lt;/strong> using a 6-character HEX string for RGB values. For example, for red enter &lt;code>FF000&lt;/code>, green is &lt;code>00FF00&lt;/code>, blue is &lt;code>0000FF&lt;/code>, white is &lt;code>FFFFFF&lt;/code> and off is &lt;code>000000&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Select &lt;strong>Run&lt;/strong>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>The light should change to match the color specific. Try with a few different colours.&lt;/p>
&lt;p>If you return to the dashboard, you will see the value of the &lt;strong>Colour&lt;/strong> cell updated to show the value sent to the light. This value is read by the app every time it restarts to ensure that the light keeps its color between restarts.&lt;/p>
&lt;h2 id="connect-my-calendar-to-control-the-device">Connect my calendar to control the device&lt;/h2>
&lt;p>Finally my light needs to be controlled. I want it to turn red automatically when a meeting starts, then turn green when it ends. This can be done using Azure Logic Apps.&lt;/p>
&lt;p>Azure logic apps are not free, but are &lt;em>VERY&lt;/em> cheap for small numbers of runs. For example at the time of writing, a single run on a logic app is $0.000025 per action, so to poll for meetings every 10 minutes each day might cost $0.50 a month.&lt;/p>
&lt;blockquote>
&lt;p>In this I cover using Logic Apps to connect to my Office 365 calendar, but you can use these to control IoT Central triggered by a number of different things such as:&lt;/p>
&lt;ul>
&lt;li>A web request - this can then be called by a device such as a Flic button&lt;/li>
&lt;li>A timer to turn the light on and off based of a normal work day&lt;/li>
&lt;li>Azure dev ops - turn the light red when a work item is assigned&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;h3 id="create-the-logic-app">Create the logic app&lt;/h3>
&lt;ol>
&lt;li>
&lt;p>Open the Azure Portal at &lt;a href="https://portal.azure.com/?WT.mc_id=busylight-blog-jabenn">portal.azure.com&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Log in if you need to using your Microsoft account. If you don&amp;rsquo;t have an Azure account follow the &lt;a href="https://github.com/jimbobbennett/BusyLight/tree/master#set-up-the-iot-central-app">instructions above&lt;/a> to create one.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Select &lt;strong>+ Create a resource&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Search for &lt;code>Logic App&lt;/code>, select it then select &lt;strong>Create&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Select your Azure subscription&lt;/p>
&lt;/li>
&lt;li>
&lt;p>For the &lt;em>Resource group&lt;/em> select &lt;strong>Create new&lt;/strong> and name the new resource group &lt;strong>BusyLight&lt;/strong>&lt;/p>
&lt;blockquote>
&lt;p>Resource groups are logical groupings of Azure services, allowing you to manage all the services for a particular application or project together.&lt;/p>
&lt;/blockquote>
&lt;/li>
&lt;li>
&lt;p>Name the logic app &lt;code>CalendarControl&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Select the &lt;em>location&lt;/em> closest to you&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Select &lt;strong>Review + create&lt;/strong>, then &lt;strong>Create&lt;/strong>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>The logic app will be created, and when it is ready select &lt;strong>Go to resource&lt;/strong>&lt;/p>
&lt;h3 id="program-the-logic-app">Program the logic app&lt;/h3>
&lt;p>Logic apps are no-code apps where you can connect triggers to actions, and these can connect to external services such as Office365 and IoT Central. I want mine connected to my Office365 calendar to poll for upcoming events, and if it finds any schedule calls to IoT Central to execute the &lt;strong>Update Colour&lt;/strong> command.&lt;/p>
&lt;h4 id="create-a-trigger">Create a trigger&lt;/h4>
&lt;ol>
&lt;li>
&lt;p>When you first open the Logic App it will take you to the designer. From the &lt;em>Templates&lt;/em> section, select &lt;strong>Blank logic app&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Search the connectors and triggers for &lt;code>office 365 outlook&lt;/code> and select the &lt;strong>Office 365 Outlook&lt;/strong> connector&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Select the &lt;strong>When an upcoming event is starting soon&lt;/strong> trigger&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The designer will show the new trigger. Select &lt;strong>Sign In&lt;/strong> and sign in with your Office 365 account.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Select your calendar in the &lt;em>Calendar Id&lt;/em> drop down&lt;/p>
&lt;blockquote>
&lt;p>If you have multiple calendars to check, you will need to create multiple Logic Apps.&lt;/p>
&lt;/blockquote>
&lt;/li>
&lt;li>
&lt;p>Leave the look ahead time at 15 minutes&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Set an appropriate interval to poll for new items. Depending on how far in advance meetings can added to your calendar you can choose a suitable interval, as you pay for each poll. I use 10 minutes as I don&amp;rsquo;t get meetings appearing in my calendar with less notice than that.&lt;/p>
&lt;blockquote>
&lt;p>This value needs to be less than the look ahead time otherwise events might be missed&lt;/p>
&lt;/blockquote>
&lt;/li>
&lt;/ol>
&lt;h4 id="wait-till-the-event-starts">Wait till the event starts&lt;/h4>
&lt;p>The trigger is fired when it sees an upcoming event, so the app needs to delay till the event actually starts before changing the light to red. Logic app triggers and actions can pass data between them, so the Office 365 connector can pass the start and end times to the next action in the app.&lt;/p>
&lt;p>There is a small snag however - date and time formats are hard! The date format passed from the Office connector is not quite right for the one expected by the delay actions, so needs to be adjusted.&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Select &lt;strong>+ New step&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Search for &lt;code>Schedule&lt;/code> and select &lt;strong>Schedule&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Select the &lt;strong>Delay until&lt;/strong> action&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Select the &lt;em>Timestamp&lt;/em> value and a box should pop up allowing you to build an expression&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Select the &lt;strong>Expression&lt;/strong> tab, then select &lt;strong>Concat&lt;/strong>&lt;/p>
&lt;p>&lt;img src="https://github.com/jimbobbennett/BusyLight/raw/master/images/BuildExpression1.png" alt="Adding concat to the expression">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Select the &lt;strong>Dynamic content&lt;/strong> tab and select &lt;strong>Start time&lt;/strong>. If you can&amp;rsquo;t see this, select &lt;strong>See more&lt;/strong> from the top of the list.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Select the expression, and add &lt;code>, 'Z'&lt;/code> before the last bracket. The select &lt;strong>OK&lt;/strong>.&lt;/p>
&lt;p>&lt;img src="https://github.com/jimbobbennett/BusyLight/raw/master/images/BuildExpression2.png" alt="Adding Z to the expression">&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h4 id="execute-the-iot-central-command-to-change-the-light-color">Execute the IoT Central command to change the light color&lt;/h4>
&lt;p>The delay will hold till the meeting is about to start, so the next step is to connect to IoT Central to execute the command. To do this, you will need the IoT Central application Id and device Id.&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Open your IoT Central app&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Select &lt;strong>Administration&lt;/strong> from the left-hand menu&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Select &lt;strong>Your application&lt;/strong> from the &lt;em>Administration&lt;/em> menu&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Take a note of the &lt;em>Application ID&lt;/em>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Select &lt;strong>Devices&lt;/strong> from the left-hand menu&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Take a note of the &lt;em>Device Id&lt;/em> of your device&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>Once you have this Id, you can create the connector&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Head back to your logic app&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Select &lt;strong>+ New step&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Search for &lt;code>Azure IoT Central&lt;/code>, then select &lt;strong>Azure IoT Central&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Select the &lt;strong>Run a command&lt;/strong> action&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Once the action appears, select &lt;strong>Sign in&lt;/strong> and log in with your Azure account if required&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Drop down the &lt;em>Application&lt;/em> box and select &lt;strong>Enter custom value&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Enter in the Application ID you noted down earlier&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Drop down the &lt;em>Device Template&lt;/em> and select &lt;code>Busy Light (1.0.0)&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Enter your device id in the &lt;em>Device&lt;/em> box&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Drop down the &lt;em>Command&lt;/em> and select &lt;code>Update Colour&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Drop down &lt;em>Add a new parameter&lt;/em> and check the box next to &lt;strong>Colour&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Set the value of &lt;em>Colour&lt;/em> to be the colour you want when you are in a meeting, using a 6 character RGB hex string. For example, for red enter &lt;code>FF0000&lt;/code>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h4 id="handle-the-event-ending">Handle the event ending&lt;/h4>
&lt;p>Repeat the two steps above to add another Delay Until and Run a Command action to the app. The second delay should use the &lt;em>End time&lt;/em> instead of the &lt;em>Start time&lt;/em>, and for the colour use the colour you want when you are not in a meeting, such as &lt;code>00FF00&lt;/code> for green.&lt;/p>
&lt;h4 id="save-the-logic-app">Save the logic app&lt;/h4>
&lt;ol>
&lt;li>Select &lt;strong>Save&lt;/strong> from the Logic App designer menu to save the Logic App and enable it&lt;/li>
&lt;/ol>
&lt;h4 id="test-the-logic-app">Test the logic app&lt;/h4>
&lt;p>Add an upcoming event to your calendar - far enough away that the poll will be run once. Your light will turn red when the event starts and green when it finishes.&lt;/p>
&lt;h2 id="next-steps">Next steps&lt;/h2>
&lt;p>I also added a &lt;a href="https://amzn.to/3aRYlpe">Flic button&lt;/a> to control the light, in case of impromptu meetings or if a meeting ends early (Yay!). To do this I set up three Logic Apps with HTTP triggers and actions calls the IoT Central command passing different colors - red, green and off (000000). I then connected these to the Flic button, so one click for red, two for green and hold to turn the light off.&lt;/p>
&lt;h2 id="learn-more">Learn more&lt;/h2>
&lt;p>If you want to learn more about Azure IoT and AI services, the best place to start is Microsoft Learn - our free on-line, self guided hands on learning experience.&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://docs.microsoft.com/learn/browse/?term=IOT&amp;amp;WT.mc_id=busylight-blog-jabenn">IoT Learning Paths on Microsoft Learn&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.microsoft.com/learn/browse/?term=logic%20apps&amp;amp;WT.mc_id=busylight-blog-jabenn">Logic app learning paths on Microsoft Learn&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Setting an Azure IoT Hub connection string in code on an MXChip</title><link>https://jimbobbennett.dev/blogs/setting-an-mxchip-connection-string-in-code/</link><pubDate>Wed, 12 Feb 2020 02:02:48 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/setting-an-mxchip-connection-string-in-code/</guid><description>&lt;p>I was recently asked if there was a way to set the Azure IoT Hub connection string for an MXChip board in code. Normally you&amp;rsquo;d push this to the EEPROM using the tooling in VS code, or from a terminal using SSH as described &lt;a href="https://microsoft.github.io/azure-iot-developer-kit/docs/use-configuration-mode/">here&lt;/a>. In this situation, this was for students and was needed for two reasons:&lt;/p>
&lt;ul>
&lt;li>The students would be sharing lab PCs and MXChip boards so would need to constantly log in and out of the Azure extensions in VS Code and re-configure boards - something they would probably forget to do every now and again causing a support headache.&lt;/li>
&lt;li>The lecturer would need to be able to take their code and run it on their own board to test, so would need their connection string. To save time configuring boards and looking up connection strings, it would be better to have it in code. Again, it could easily be forgotten!&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>&lt;strong>NOTE&lt;/strong> - this is potentially a &lt;strong>very bad thing&lt;/strong> as you can end up essentially putting secrets in code. &lt;strong>DO NOT&lt;/strong> do this for public code, code then ends up on GitHub or anything like this, this only makes sense for private code submitted internally for something like a students assessment using a hub on a free tier so cannot cause any cost if it gets flooded.&lt;/p>
&lt;/blockquote>
&lt;p>Out of the box there are no APIs available to do this. However, there is a way!&lt;/p>
&lt;p>When connecting to Azure IoT Hub over MQTT, you call &lt;em>&lt;code>DevKitMQTTClient_Init&lt;/code>&lt;/em> and this loads the connection string from EEPROM and uses it for the connection. As it turn out, as well as being able to read from EEPROM in code, you can also &lt;a href="https://microsoft.github.io/azure-iot-developer-kit/docs/apis/eeprom-interface/#write">write to the EEPROM&lt;/a>, meaning you can set the value before it is read.&lt;/p>
&lt;p>Using this, it wasn&amp;rsquo;t too hard to write the code to set this value:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-c" data-lang="c">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># include &amp;#34;EEPROMInterface.h&amp;#34;
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># include &amp;#34;SerialLog.h&amp;#34;
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">void&lt;/span> &lt;span style="color:#a6e22e">setup&lt;/span>() {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> (WiFi.&lt;span style="color:#a6e22e">begin&lt;/span>() &lt;span style="color:#f92672">==&lt;/span> WL_CONNECTED)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// Write the connection string to EEPROM as an array of uint8_t
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> EEPROMInterface eeprom;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">char&lt;/span> connString[] &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;&amp;lt;my connection string&amp;gt;&amp;#34;&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">int&lt;/span> ret &lt;span style="color:#f92672">=&lt;/span> eeprom.&lt;span style="color:#a6e22e">write&lt;/span>((&lt;span style="color:#66d9ef">uint8_t&lt;/span>&lt;span style="color:#f92672">*&lt;/span>)connString,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">strlen&lt;/span>(connString),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> AZ_IOT_HUB_ZONE_IDX);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// Check the write worked - 0 means it was written
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#75715e">// Less than 0 is an error
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">if&lt;/span> (ret &lt;span style="color:#f92672">&amp;lt;&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">LogError&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;Unable to get the connection string from EEPROM.&amp;#34;&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// Connect as normal, this will read the new value
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#75715e">// for the connection string
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">DevKitMQTTClient_Init&lt;/span>();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Replace &lt;code>&amp;lt;my connection string&amp;gt;&lt;/code> in the above code with your connection string. It will then be written to the EEPROM before the call to &lt;code>DevKitMQTTClient_Init&lt;/code>.&lt;/p>
&lt;p>If you read the &lt;a href="https://microsoft.github.io/azure-iot-developer-kit/docs/apis/eeprom-interface/#write">EEPROM write documentation&lt;/a>, you will see &lt;em>zones&lt;/em> listed. These are defined areas in the EEPROM and you can use these to write the WiFi SSID and Password as well as the connection string. This is useful if you want to build a solution that downloads new WiFi details.&lt;/p></description></item><item><title>Storing IoT Data in a database</title><link>https://jimbobbennett.dev/blogs/storing-iot-data-in-a-database/</link><pubDate>Thu, 05 Dec 2019 23:17:04 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/storing-iot-data-in-a-database/</guid><description>&lt;p>One question that comes up a lot when getting started with IoT is &amp;lsquo;How do I store all this data?&amp;rsquo;. This is an important question - IoT creates a &lt;em>LOT&lt;/em> of data, some of which can be analyzed on the fly, but there are a large number of cases where you want to run analytics later, or have access to historical raw data to run new analytics later.&lt;/p>
&lt;p>IoT typically involves ingesting a large number of messages through a single hub, and these hubs are typically dumb - in that they provide a single point to ingest the messages but don&amp;rsquo;t do anything with them. That&amp;rsquo;s the responsibility of the developers building out the IoT solution.&lt;/p>
&lt;p>One area that is powerful with Azure IoT is &lt;a href="https://azure.microsoft.com/services/stream-analytics/?WT.mc_id=streamanalytics-blog-jabenn">Azure Stream Analytics&lt;/a>. This is a service that can be connected to any event stream, such as an IoT Hub, and take the live stream of data and do something with it, such as filter, manipulate and output to other systems. You can even wire up ML based anomaly detection to be alerted when unexpected values are received.&lt;/p>
&lt;p>In this post we will see how to use Stream Analytics to stream IoT data into a database. This assumes you already have an IoT hub receiving data.&lt;/p>
&lt;h1 id="create-a-database">Create a database&lt;/h1>
&lt;p>The first thing you need is a database to put the data into. Stream analytics works with both &lt;a href="https://azure.microsoft.com/services/cosmos-db/?WT.mc_id=streamanalytics-blog-jabenn">Azure Cosmos DB&lt;/a> and &lt;a href="https://azure.microsoft.com/services/sql-database/?WT.mc_id=streamanalytics-blog-jabenn">Azure SQL Database&lt;/a>, as well as many other storage solutions, so it&amp;rsquo;s up to you which one you want to use. In this post I&amp;rsquo;ll use Cosmos DB, but the concepts apply to all data stores.&lt;/p>
&lt;ul>
&lt;li>Launch the &lt;a href="https://portal.azure.com/?WT.mc_id=streamanalytics-blog-jabenn">Azure Portal&lt;/a>&lt;/li>
&lt;li>Select &lt;strong>+ Create a resource&lt;/strong> from the menu on the left or the dashboard&lt;/li>
&lt;li>Search for &lt;em>Azure Cosmos DB&lt;/em>, select it and select &lt;strong>Create&lt;/strong>&lt;/li>
&lt;li>Select your subscription, select or create a new resource group and name your account.&lt;/li>
&lt;li>Set the API to &lt;em>Core (SQL).&lt;/em> Stream Analytics only supports the SQL API.&lt;/li>
&lt;li>Set the location closest to you, then select &lt;strong>Review + create&lt;/strong>, then select &lt;strong>Create&lt;/strong>&lt;/li>
&lt;li>This will take a few minutes to create, so once done load it in the portal&lt;/li>
&lt;li>Create a new collection to store the data. From the Cosmos DB resource, head to the &lt;strong>Data Explorer&lt;/strong> tab&lt;/li>
&lt;li>Select &lt;strong>New Container&lt;/strong>&lt;/li>
&lt;li>Give the database a name&lt;/li>
&lt;li>Set the throughput. You can find a discussion around throughput in &lt;a href="https://docs.microsoft.com/azure/cosmos-db/set-throughput/?WT.mc_id=streamanalytics-blog-jabenn">the documentation&lt;/a>. For a simple test setup, set this to be 400 (the minimum).&lt;/li>
&lt;li>Give the container a name&lt;/li>
&lt;li>Set a partition key. You can read more on partition keys in &lt;a href="https://docs.microsoft.com/azure/cosmos-db/partitioning-overview/?WT.mc_id=streamanalytics-blog-jabenn">the documentation&lt;/a>&lt;/li>
&lt;li>Select &lt;strong>OK&lt;/strong>&lt;/li>
&lt;/ul>
&lt;h1 id="create-a-stream-analytics-resource">Create a Stream Analytics resource&lt;/h1>
&lt;p>Once you have the database, you need to create a Stream Analytics resource.&lt;/p>
&lt;ul>
&lt;li>Launch the &lt;a href="https://portal.azure.com/?WT.mc_id=streamanalytics-blog-jabenn">Azure Portal&lt;/a>&lt;/li>
&lt;li>Select &lt;strong>+ Create a resource&lt;/strong> from the menu on the left or the dashboard&lt;/li>
&lt;li>Search for &lt;em>Stream Analytics job&lt;/em>, select it and select &lt;strong>Create&lt;/strong>&lt;/li>
&lt;/ul>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/storing-iot-data-in-a-database/2019-12-05_14-28-07.png">
&lt;/figure>
&lt;ul>
&lt;li>Give the job a name, select your subscription, select or create a new resource group and set the location closest to you.&lt;/li>
&lt;li>Stream Analytics jobs can be hosted in the cloud, or run on the edge via an IoT Edge Gateway device. For now, select &lt;em>Cloud&lt;/em>, but you can learn more about running on the edge in &lt;a href="https://docs.microsoft.com/azure/stream-analytics/stream-analytics-edge/?WT.mc_id=streamanalytics-blog-jabenn">the documentation&lt;/a>.&lt;/li>
&lt;li>Set the number of Streaming units you need - the more data coming in, the larger the number of streaming units you need. You can read more about streaming units in &lt;a href="https://docs.microsoft.com/azure/stream-analytics/stream-analytics-streaming-unit-consumption/?WT.mc_id=streamanalytics-blog-jabenn">the documentation&lt;/a>, and learn about pricing on our &lt;a href="https://azure.microsoft.com/pricing/details/stream-analytics/?WT.mc_id=streamanalytics-blog-jabenn">pricing page&lt;/a>. For now leave this as the default of 3.&lt;/li>
&lt;/ul>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/storing-iot-data-in-a-database/2019-12-05_14-37-25-1.png">
&lt;/figure>
&lt;ul>
&lt;li>Select &lt;strong>Create&lt;/strong>.&lt;/li>
&lt;/ul>
&lt;h1 id="connect-the-dots">Connect the dots&lt;/h1>
&lt;p>Stream analytics allows you to define inputs, outputs and queries. Queries query inputs and can push data into outputs, so you can query all items from an IoT Hub and select them into a Cosmos DB database. These queries run on the stream as data is received, and output as each item is processed - these are not like traditional SQL queries that run synchronously against a static set of data.&lt;/p>
&lt;h2 id="adding-the-iot-hub-as-an-input">Adding the IoT Hub as an input&lt;/h2>
&lt;ul>
&lt;li>Select the stream analytics job in the Azure portal&lt;/li>
&lt;li>Head to the &lt;strong>Inputs&lt;/strong> tab&lt;/li>
&lt;li>Select &lt;strong>+ Add stream input&lt;/strong>, then select &lt;em>IoT Hub&lt;/em>&lt;/li>
&lt;/ul>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/storing-iot-data-in-a-database/2019-12-05_14-47-41.png">
&lt;/figure>
&lt;ul>
&lt;li>Give the input an alias - this is the name you will use in your queries&lt;/li>
&lt;li>Ensure &lt;em>Select IoT Hub from your subscription&lt;/em> is selected, and select your IoT Hub. Leave the rest of the values as the defaults.&lt;/li>
&lt;li>Select &lt;strong>Save&lt;/strong>&lt;/li>
&lt;/ul>
&lt;h2 id="adding-cosmos-db-as-an-output">Adding Cosmos DB as an output&lt;/h2>
&lt;ul>
&lt;li>Head to the &lt;strong>Outputs&lt;/strong> tab&lt;/li>
&lt;li>Select &lt;strong>+ Add&lt;/strong>, then select &lt;em>Cosmos DB&lt;/em>&lt;/li>
&lt;/ul>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/storing-iot-data-in-a-database/2019-12-05_14-52-46.png">
&lt;/figure>
&lt;ul>
&lt;li>Give the output an alias - this is the name you will use in your queries&lt;/li>
&lt;li>Ensure &lt;em>Select Cosmos DB from your subscriptions&lt;/em> is selected, and select your Cosmos DB account, database and container.&lt;/li>
&lt;li>Set the &lt;strong>Document id&lt;/strong> field to be the unique key field for the records you will be inserting. If you are inserting directly from IoT Hub without any translation then use what ever unique id is set on each message.&lt;/li>
&lt;li>Select &lt;strong>Save&lt;/strong>&lt;/li>
&lt;/ul>
&lt;h2 id="building-the-query">Building the query&lt;/h2>
&lt;ul>
&lt;li>Head to the &lt;strong>Query&lt;/strong> tab&lt;/li>
&lt;li>Change the query to be:&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sql" data-lang="sql">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">SELECT&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">*&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">INTO&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> [cosmos&lt;span style="color:#f92672">-&lt;/span>db]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">FROM&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> [iot&lt;span style="color:#f92672">-&lt;/span>hub]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>Set &lt;code>[cosmos-db]&lt;/code> to be the alias you used for your Cosmos DB database. This needs to be inside square brackets, so if you used &lt;code>myCosmosDB&lt;/code> as the alias, you would use &lt;code>[myCosmosDB]&lt;/code>.&lt;/li>
&lt;li>Set &lt;code>[iot-hub]&lt;/code> to be the alias of the IoT hub, again inside square brackets&lt;/li>
&lt;li>Select &lt;strong>Save query&lt;/strong>&lt;/li>
&lt;/ul>
&lt;h2 id="start-the-query">Start the query&lt;/h2>
&lt;ul>
&lt;li>Head the the &lt;strong>Overview&lt;/strong> tab&lt;/li>
&lt;li>Select &lt;strong>Start&lt;/strong>&lt;/li>
&lt;li>The query will start listening to data coming in the input, and send it to the output&lt;/li>
&lt;/ul>
&lt;p>Once data comes in, you will be able to see it appear in Cosmos DB.&lt;/p>
&lt;h1 id="learn-more">Learn more&lt;/h1>
&lt;ul>
&lt;li>Create a free &lt;a href="https://azure.microsoft.com/free/?WT.mc_id=streamanalytics-blog-jabenn">Azure account&lt;/a>&lt;/li>
&lt;li>Check out the &lt;a href="https://docs.microsoft.com/azure/stream-analytics/stream-analytics-introduction/?WT.mc_id=streamanalytics-blog-jabenn">Stream Analytics documentation&lt;/a>.&lt;/li>
&lt;li>Browse the [Stream Analytics modules on Microsoft Learn](&lt;a href="https://docs.microsoft.com/learn/browse/?term=stream">https://docs.microsoft.com/learn/browse/?term=stream&lt;/a> analytics&amp;amp;WT.mc_id=streamanalytics-blog-jabenn) and grow your skills via hands on learning.&lt;/li>
&lt;/ul></description></item><item><title>Connecting your Domain.com domain name to your web app during an MLH hackathon</title><link>https://jimbobbennett.dev/blogs/connecting-your-domain-com-domain-name-to-azure-app-services/</link><pubDate>Wed, 27 Nov 2019 01:55:32 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/connecting-your-domain-com-domain-name-to-azure-app-services/</guid><description>&lt;p>You&amp;rsquo;re at an &lt;a href="https://mlh.io">MLH Hackathon&lt;/a> and you decide you want to win the Domain.com prize for the best domain name registered at the event. You&amp;rsquo;ve decided on the ultimate name, and now you want to use it for your hack&amp;hellip;&lt;/p>
&lt;p>But what do you do next? How can you take your amazing code and have it appear across the internet using your new domain name? Well this post is here to help!&lt;/p>
&lt;h1 id="deploy-your-code-to-the-cloud">Deploy your code to the cloud&lt;/h1>
&lt;p>The first thing to do is deploy your code to the cloud, ready to have the domain name assigned. To do this, you will need to deploy it to an Azure App Service.&lt;/p>
&lt;p>If you don&amp;rsquo;t already have an Azure account, sign up for a free account now!&lt;/p>
&lt;ul>
&lt;li>Students can sign up at &lt;a href="https://aka.ms/freestudentazure">aka.ms/FreeStudentAzure&lt;/a> and get US$100 to use for 12 months, along with free tiers of a load of services for 12 months along with other services free for life, and after that 12 months is up, as long as you are still a student you can renew each year and get another US$100/12 months of free stuff. No credit card required.&lt;/li>
&lt;li>If you are not a student, you can sign up at &lt;a href="https://aka.ms/freeaz">aka.ms/FreeAz&lt;/a> and get US$200 to use in the first 30 days, as well as 12 months of free services along with other services free for life.&lt;/li>
&lt;/ul>
&lt;p>Next deploy your code to Azure App Service. App Service is a fully managed platform to run your web apps, be they Flask, Node, PHP, ASP .NET, whatever. You supply the code and App Service will host it for you. There are loads of ways to deploy to App Service, so I won&amp;rsquo;t cover them all here. You can read about deployments on the &lt;a href="https://docs.microsoft.com/azure/app-service/deploy-local-git/?WT.mc_id=domaincom-blog-jabenn">App Service docs&lt;/a>. My personal favorite is the &lt;a href="https://marketplace.visualstudio.com/items?itemName=ms-azuretools.vscode-azureappservice&amp;amp;WT.mc_id=domaincom-blog-jabenn">Azure App Service extension for VSCode&lt;/a>, and the instructions for using it are in their &lt;a href="https://github.com/Microsoft/vscode-azureappservice/blob/master/README.md">GitHub ReadMe&lt;/a>.&lt;/p>
&lt;p>One thing to note - you cannot assign a custom domain to a Free Tier app service, you will need to use a higher tier, such as the B1 tier. At the time of writing in the US this is about US$13 a month, so don&amp;rsquo;t forget to delete this resource after the hackathon if you don&amp;rsquo;t want to keep being billed! It&amp;rsquo;s also free for the first 30 days, so you won&amp;rsquo;t need to pay anything during the weekend.&lt;/p>
&lt;p>If you&amp;rsquo;ve already configured your App Service using the free tier, don&amp;rsquo;t worry - you can scale it up from the Azure Portal. All the instructions are in the &lt;a href="https://docs.microsoft.com/azure/app-service/app-service-web-tutorial-custom-domain?WT.mc_id=domaincom-blog-jabenn#prepare-the-app">App Service docs&lt;/a>.&lt;/p>
&lt;h1 id="configure-your-domain-to-point-to-your-app">Configure your domain to point to your app&lt;/h1>
&lt;p>Once your app is deployed you need to point your new domain at it. This is a two step process - you need to tell Domain.com that you want to point your domain to your App Service, and then tell your App Service to handle requests at that domain.&lt;/p>
&lt;h2 id="configuring-domaincom">Configuring Domain.com&lt;/h2>
&lt;p>The first thing to do is to get the IP address of your App Service. You can do this from the Azure Portal or the command line.&lt;/p>
&lt;h4 id="from-the-portal">From the portal:&lt;/h4>
&lt;ul>
&lt;li>Log into the &lt;a href="https://portal.azure.com/?WT.mc_id=domaincom-blog-jabenn">Azure Portal&lt;/a>, and find your App Service resource.&lt;/li>
&lt;li>Select the &lt;strong>Custom domains&lt;/strong> menu item. From here, copy the IP address.&lt;/li>
&lt;/ul>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/connecting-your-domain-com-domain-name-to-azure-app-services/2019-11-26_17-25-57-3.png">
&lt;/figure>
&lt;h4 id="from-the-command-line">From the command line:&lt;/h4>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>nslookup &amp;lt;your-app-service&amp;gt;.azurewebsites.net
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Substitute &lt;code>&amp;lt;your-app-service&amp;gt;&lt;/code> with the name of your App Service.&lt;/p>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/connecting-your-domain-com-domain-name-to-azure-app-services/2019-11-26_18-12-44.png">
&lt;/figure>
&lt;p>Next you need to configure domain.com to point to this IP address.&lt;/p>
&lt;ul>
&lt;li>Log in to Domain.com and select the &lt;strong>Domains&lt;/strong> tab. Then click the &lt;strong>Manage&lt;/strong> button for the domain you want to manage.&lt;/li>
&lt;/ul>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/connecting-your-domain-com-domain-name-to-azure-app-services/2019-11-26_17-18-46-1.png">
&lt;/figure>
&lt;ul>
&lt;li>Select the &lt;strong>DNS and Nameservers&lt;/strong> option from the menu on the left&lt;/li>
&lt;/ul>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/connecting-your-domain-com-domain-name-to-azure-app-services/2019-11-26_17-22-18.png">
&lt;/figure>
&lt;ul>
&lt;li>Under the &lt;strong>DNS Records&lt;/strong> section there will be a number of records. One will have a &lt;strong>Record&lt;/strong> of &lt;em>A&lt;/em>, a &lt;strong>Name&lt;/strong> of &lt;em>@&lt;/em> and the &lt;strong>Content&lt;/strong> set to an IP address. Click the three downwards ellipses at the end of the row and select &lt;strong>Edit&lt;/strong>.&lt;/li>
&lt;/ul>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/connecting-your-domain-com-domain-name-to-azure-app-services/2019-11-26_17-29-08.png">
&lt;/figure>
&lt;ul>
&lt;li>Set the &lt;strong>IP address&lt;/strong> to be the IP address you copied from the Azure portal, then select &lt;strong>Update DNS&lt;/strong>.&lt;/li>
&lt;/ul>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/connecting-your-domain-com-domain-name-to-azure-app-services/2019-11-26_17-31-44-1.png">
&lt;/figure>
&lt;ul>
&lt;li>Look for a &lt;strong>TXT&lt;/strong> record with a name of &lt;em>@&lt;/em>. Edit this record and update the &lt;strong>Content&lt;/strong> to be the URL of your App Service which will be &lt;code>&amp;lt;your-app-name&amp;gt;.azurewebsites.net&lt;/code>.&lt;/li>
&lt;/ul>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/connecting-your-domain-com-domain-name-to-azure-app-services/2019-11-26_17-35-02.png">
&lt;/figure>
&lt;h2 id="configuring-app-service">Configuring App Service&lt;/h2>
&lt;p>Once Domain.com has been configured, you need to tell your App Service to use it. This can be done from the Azure Portal, or the cli.&lt;/p>
&lt;h4 id="from-the-azure-portal">From the Azure Portal&lt;/h4>
&lt;ul>
&lt;li>Select the &lt;strong>Custom domains&lt;/strong> tab&lt;/li>
&lt;li>Select &lt;strong>+ Add custom domain&lt;/strong>&lt;/li>
&lt;/ul>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/connecting-your-domain-com-domain-name-to-azure-app-services/2019-11-26_17-37-44.png">
&lt;/figure>
&lt;ul>
&lt;li>In the blade that pops up, enter your domain name that you registered with Domain.com. Then select &lt;strong>Validate&lt;/strong>. This will validate that the records are set up correctly and the hostname is available. If everything is valid you will see two green ticks at the bottom.&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>In theory the DNS record updates can take up to 48 hours to propagate, but in my experience it happens in a few minutes. If the validation fails then wait a minute and try again.&lt;/p>
&lt;/blockquote>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/connecting-your-domain-com-domain-name-to-azure-app-services/2019-11-26_17-40-39.png">
&lt;/figure>
&lt;ul>
&lt;li>Once everything has been validated, select &lt;strong>Add custom domain&lt;/strong>.&lt;/li>
&lt;/ul>
&lt;h4 id="from-the-azure-cli">From the Azure CLI&lt;/h4>
&lt;ul>
&lt;li>Make sure you have the Azure CLI installed. If not, follow the &lt;a href="https://docs.microsoft.com/cli/azure/install-azure-cli/?WT.mc_id=domaincom-blog-jabenn">installation instructions&lt;/a>. Otherwise use the online cloud shell at &lt;a href="https://shell.azure.com/?WT.mc_id=domaincom-blog-jabenn">shell.azure.com&lt;/a>.&lt;/li>
&lt;li>Enter the following command:&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>az webapp config hostname add --webapp-name &amp;lt;your-app-servce&amp;gt; --resource-group &amp;lt;your-resource-group&amp;gt; --hostname &amp;lt;domain-name&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Substitute &lt;code>&amp;lt;your-app-servce&amp;gt;&lt;/code> with your app service name, &lt;code>&amp;lt;your-resource-group&amp;gt;&lt;/code> with the name of the resource group your app service lives in, and &lt;code>&amp;lt;domain-name&amp;gt;&lt;/code> with the domain name from Domain.com.&lt;/p>
&lt;p>If you see any errors, wait a few minutes are try again as the DNS records may not have propagated.&lt;/p>
&lt;h1 id="done">Done!&lt;/h1>
&lt;p>That&amp;rsquo;s it - everything should now work. Head to &lt;code>http://&amp;lt;your-new-domain&amp;gt;.&amp;lt;tech/online/site&amp;gt;&lt;/code> and you should see the app you deployed to App Service.&lt;/p>
&lt;p>You may see a 404 or 403 error to start with - this is because DNS records are cached for a while to save lookups, and your browser is using an old record. To fix this you can either try a new browser or browser window (this sometimes works), or flush your DNS cache.&lt;/p>
&lt;ul>
&lt;li>On Windows launch a command prompt and run:&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>ipconfig /flushdns
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>On macOS launch the Terminal and run:&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>sudo killall -HUP mDNSResponder;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Enter your password when asked.&lt;/p>
&lt;ul>
&lt;li>On Linux this depends on which distro you are using, so it would be easier to search for the relevant instructions using &lt;a href="https://www.bing.com/">Bing&lt;/a>.&lt;/li>
&lt;/ul>
&lt;p>Good luck with your hackathon, and I hope you win!&lt;/p></description></item><item><title>Getting an internship at Microsoft</title><link>https://jimbobbennett.dev/blogs/getting-an-internship-at-microsoft/</link><pubDate>Thu, 17 Oct 2019 19:39:16 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/getting-an-internship-at-microsoft/</guid><description>&lt;blockquote>
&lt;p>Come as you are, do what you love&lt;/p>
&lt;/blockquote>
&lt;p>I&amp;rsquo;ve been asked a few times for thoughts and tips around getting an internship at Microsoft. So in the spirit of &amp;ldquo;I didn&amp;rsquo;t have time to reply to you so I wrote this blog post&amp;rdquo;, I thought I&amp;rsquo;d provide a stack of resources useful to folks wanting to know more about the process.&lt;/p>
&lt;h1 id="application">Application&lt;/h1>
&lt;p>Interested in an internship here at Microsoft? The first port of call is the &lt;a href="https://careers.microsoft.com/students/us/en/usuniversityinternship/?WT.mc_id=internships-blog-jabenn">University internship Careers site&lt;/a>. This is the US site, and we have similar sites globally so if you are looking outside the US then head to &lt;a href="https://careers.microsoft.com">careers.microsoft.com&lt;/a> and search for international internship opportunities.&lt;/p>
&lt;p>This site has a wealth of information around the program, as well as a link to apply. Get those applications in now!&lt;/p>
&lt;h1 id="the-interview-process">The interview process&lt;/h1>
&lt;p>This is a question I often get asked - what is the interview process? It varies depending on the type of role, and I&amp;rsquo;m not a recruiter so I can&amp;rsquo;t talk officially on the topic, but there are some great posts from former interns that might help shed some light on it.&lt;/p>
&lt;blockquote>
&lt;p>Note that these are third party posts and have not been checked for accuracy or correctness. The content may be out of date.&lt;/p>
&lt;/blockquote>
&lt;p>&lt;a href="https://www.fastcompany.com/40420936/diary-of-an-ex-microsoft-intern">Diary of an Ex-Microsoft Intern on Fast Company&lt;/a> by &lt;a href="https://www.linkedin.com/in/lawrencewill/">Will Lawrence&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://medium.com/@ditikhazanchi/the-road-to-redmond-getting-an-internship-at-microsoft-12432e30b73f">How I got an internship at Microsoft — interview process and learnings&lt;/a> by &lt;a href="https://medium.com/@ditikhazanchi">Aditi Khazanchi&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://github.com/CourtneyThurston/microsoft-internships/blob/master/README.md">microsoft-internships open document on GitHub&lt;/a> by &lt;a href="https://github.com/CourtneyThurston">Courtney Thurston&lt;/a>&lt;/p>
&lt;p>&lt;a href="http://ronaksakhuja.me/how-i-made-into-microsoft-the-off-campus-way/">How I made into Microsoft: The Off-campus way&lt;/a> by &lt;a href="https://twitter.com/ronaksakhuja">Ronak Sakhuja&lt;/a> focusing on the India intern recruitment process.&lt;/p>
&lt;p>The main thing is to come as you are and do what you love - out mantra for recruiting. Let your passions shine through, talk about the projects you are most proud of, the work you do outside the classroom, hacks you attend. Be aware of Microsoft and its culture. And most importantly, be yourself.&lt;/p>
&lt;h1 id="life-as-an-intern">Life as an intern&lt;/h1>
&lt;p>You&amp;rsquo;ve made it through the interview and have an internship. So what&amp;rsquo;s it like here?&lt;/p>
&lt;p>&lt;a href="https://medium.com/@jlshiohira23/sneak-peak-into-the-life-of-a-microsoft-intern-929e2e9768c5">Sneak Peak into the Life of a Microsoft Intern&lt;/a> by &lt;a href="https://twitter.com/jshiohaha">Jacob Shiohira&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://www.microsoft.com/en-us/garage/blog/2017/09/12-weeks-microsoft-garage/?WT.mc_id=internships-blog-jabenn">12 Weeks at the Microsoft Garage&lt;/a> by Dominic Whyte&lt;/p>
&lt;h1 id="its-all-happening-here">It&amp;rsquo;s all happening here&lt;/h1>
&lt;p>Yes - it&amp;rsquo;s true, it is all happening here. Don&amp;rsquo;t believe me, then see what the last set of interns did in their spare time:&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/ZGeWNR8CWnA" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;h1 id="let-me-know-your-experiences">Let me know your experiences&lt;/h1>
&lt;p>I&amp;rsquo;d love to know your experiences - please add a comment with any links to posts you have written about your time as a Microsoft intern, or your thoughts or experiences.&lt;/p></description></item><item><title>Visualizing locations and paths on a map with Azure Maps</title><link>https://jimbobbennett.dev/blogs/visualising-locations-and-paths-on-a-map/</link><pubDate>Mon, 23 Sep 2019 21:06:50 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/visualising-locations-and-paths-on-a-map/</guid><description>&lt;p>Azure Maps is a great way to add geospatial capabilities to your apps, from showing a map on a web page, to checking geofences, to routing and traffic data. You can read more about Azure Maps in the &lt;a href="https://docs.microsoft.com/azure/azure-maps/?WT.mc_id=azuremaps-blog-jabenn">official documentation&lt;/a>.&lt;/p>
&lt;p>This post covers:&lt;/p>
&lt;ul>
&lt;li>Showing an Azure Maps control on a web page&lt;/li>
&lt;li>Adding pins to the map to show locations&lt;/li>
&lt;li>Adding a path to the map&lt;/li>
&lt;/ul>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/visualising-locations-and-paths-on-a-map/2019-09-20_16-46-39.png">
&lt;/figure>
&lt;h2 id="getting-started">Getting started&lt;/h2>
&lt;ul>
&lt;li>Start by signing up for Azure if you don&amp;rsquo;t have an account:If you are a student, sign up at &lt;a href="https://azure.microsoft.com/free/students/?WT.mc_id=azuremaps-blog-jabenn">azure.microsoft.com/free/students&lt;/a> to get US$100 of free credit and free services for a year.Otherwise sign up at &lt;a href="https://azure.microsoft.com/free/?WT.mc_id=azuremaps-blog-jabenn">azure.microsoft.com/free&lt;/a> to get US$200 of credit for 30 days and a year of free services.&lt;/li>
&lt;li>Sign into Azure and create an Azure Maps resource by following &lt;a href="https://ms.portal.azure.com/?WT.mc_id=azuremaps-blog-jabenn%2F#create/Microsoft.Maps">this link&lt;/a>.&lt;/li>
&lt;/ul>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/visualising-locations-and-paths-on-a-map/2019-09-06_16-51-33-2.png">
&lt;/figure>
&lt;p>Once you have your Maps resource created, head to the &lt;strong>Shared Key Authentication&lt;/strong> section of the _&lt;em>Settings -&amp;gt; Authentication&lt;/em> _ tab in the map blade in the Azure portal and take a copy of your &lt;strong>Primary Key&lt;/strong>.&lt;/p>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/visualising-locations-and-paths-on-a-map/2019-09-09_16-13-17-1.png">
&lt;/figure>
&lt;h2 id="showing-the-azure-maps-control-in-a-web-page">Showing the Azure Maps control in a web page&lt;/h2>
&lt;p>Create a web site using your favorite tooling - I personally have been using &lt;a href="https://flask.palletsprojects.com/">Flask&lt;/a> as I&amp;rsquo;m getting into Python. Create an HTML page. To the &lt;code>&amp;lt;head&amp;gt;&lt;/code> section add the following to add support for the Azure Maps control:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-html" data-lang="html">&lt;span style="display:flex;">&lt;span>&amp;lt;&lt;span style="color:#f92672">link&lt;/span> &lt;span style="color:#a6e22e">rel&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;stylesheet&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">href&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;https://atlas.microsoft.com/sdk/javascript/mapcontrol/2/atlas.min.css&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">type&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;text/css&amp;#34;&lt;/span>&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&amp;lt;&lt;span style="color:#f92672">script&lt;/span> &lt;span style="color:#a6e22e">src&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;https://atlas.microsoft.com/sdk/javascript/mapcontrol/2/atlas.min.js&amp;#34;&lt;/span>&amp;gt;&amp;lt;/&lt;span style="color:#f92672">script&lt;/span>&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>In the &lt;code>&amp;lt;body&amp;gt;&lt;/code>, add a &lt;code>div&lt;/code> with an id of &lt;code>myMap&lt;/code>.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-html" data-lang="html">&lt;span style="display:flex;">&lt;span>&amp;lt;&lt;span style="color:#f92672">div&lt;/span> &lt;span style="color:#a6e22e">id&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;myMap&amp;#34;&lt;/span>&amp;gt;&amp;lt;/&lt;span style="color:#f92672">div&lt;/span>&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Follow this with a &lt;code>script&lt;/code> tag that creates the Azure Maps control and assigns it to this div:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-html" data-lang="html">&lt;span style="display:flex;">&lt;span>&amp;lt;&lt;span style="color:#f92672">script&lt;/span> &lt;span style="color:#a6e22e">type&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;text/javascript&amp;#34;&lt;/span>&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">map&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> &lt;span style="color:#a6e22e">atlas&lt;/span>.&lt;span style="color:#a6e22e">Map&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;myMap&amp;#39;&lt;/span>, {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">language&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;en-US&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">authOptions&lt;/span>&lt;span style="color:#f92672">:&lt;/span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">authType&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;subscriptionKey&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">subscriptionKey&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;{subscription-key}&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> });
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&amp;lt;/&lt;span style="color:#f92672">script&lt;/span>&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>You will need to replace &lt;code>{subscription-key}&lt;/code> with your primary key that you captured from from the Azure Maps resource blade.&lt;/p>
&lt;p>If you view this page you will see the map control over the top part of the page. To size it, you can style the map to be the size of the whole page by adding a style to the &lt;code>head&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-html" data-lang="html">&lt;span style="display:flex;">&lt;span>&amp;lt;&lt;span style="color:#f92672">style&lt;/span>&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">html&lt;/span>&lt;span style="color:#f92672">,&lt;/span> &lt;span style="color:#f92672">body&lt;/span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">margin&lt;/span>: &lt;span style="color:#ae81ff">0&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> #myMap {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">height&lt;/span>: &lt;span style="color:#ae81ff">100&lt;/span>&lt;span style="color:#66d9ef">vh&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">width&lt;/span>: &lt;span style="color:#ae81ff">100&lt;/span>&lt;span style="color:#66d9ef">vw&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&amp;lt;/&lt;span style="color:#f92672">style&lt;/span>&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This will give a nice, full size map showing the whole world.&lt;/p>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/visualising-locations-and-paths-on-a-map/2019-09-23_12-33-40.png">
&lt;/figure>
&lt;p>You can read more about getting started with the Map control in the &lt;a href="https://docs.microsoft.com/azure/azure-maps/how-to-use-map-control/?WT.mc_id=azuremaps-blog-jabenn">Getting started docs&lt;/a>.&lt;/p>
&lt;h2 id="zooming-into-a-certain-area">Zooming into a certain area&lt;/h2>
&lt;p>You can set the area that the map shows by setting the camera using a set of bounds and some padding - essentially giving the coordinates that must be included in the visible map and how much space you want around them. The map control works out the actual position and zoom to ensure the bounds and padding are visible, with extra map showing to ensure it fits on the page.&lt;/p>
&lt;p>First your page will need to wait till the map control is ready before it can call any methods. You can do this using the &lt;code>ready&lt;/code> event:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-js" data-lang="js">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">map&lt;/span>.&lt;span style="color:#a6e22e">events&lt;/span>.&lt;span style="color:#a6e22e">add&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;ready&amp;#39;&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span> () {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// add code to be run when the map is ready here
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Inside this handler, you can set the camera using the &lt;code>setCamera&lt;/code> method:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-js" data-lang="js">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">map&lt;/span>.&lt;span style="color:#a6e22e">setCamera&lt;/span>({
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">bounds&lt;/span>&lt;span style="color:#f92672">:&lt;/span> [{&lt;span style="color:#a6e22e">min_long&lt;/span>}, {&lt;span style="color:#a6e22e">min_lat&lt;/span>}, {&lt;span style="color:#a6e22e">max_long&lt;/span>}, {&lt;span style="color:#a6e22e">max_lat&lt;/span>}],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">padding&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#ae81ff">50&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>});
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Set &lt;code>min_long&lt;/code> and &lt;code>min_lat&lt;/code> to be one corner of the bounding box that you want to ensure is visible using longitude and latitude coordinates. &lt;code>max_long&lt;/code> and &lt;code>max_lat&lt;/code> are the opposite corner. Set &lt;code>padding&lt;/code> to the minimum number of pixels to have around the edge of the bounds.&lt;/p>
&lt;p>For example, this code shows the area around Seattle:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-js" data-lang="js">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">map&lt;/span>.&lt;span style="color:#a6e22e">events&lt;/span>.&lt;span style="color:#a6e22e">add&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;ready&amp;#39;&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span> () {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">map&lt;/span>.&lt;span style="color:#a6e22e">setCamera&lt;/span>({
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">bounds&lt;/span>&lt;span style="color:#f92672">:&lt;/span> [&lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">123&lt;/span>, &lt;span style="color:#ae81ff">47&lt;/span>, &lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">122&lt;/span>, &lt;span style="color:#ae81ff">48&lt;/span>],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">padding&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#ae81ff">50&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> });
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/visualising-locations-and-paths-on-a-map/2019-09-23_12-48-30.png">
&lt;/figure>
&lt;p>You can read more about this method in the &lt;a href="https://docs.microsoft.com/javascript/api/azure-maps-control/atlas.map?WT.mc_id=azuremaps-blog-jabenn&amp;amp;view=azure-maps-typescript-latest#setcamera-cameraoptions---cameraboundsoptions---animationoptions-">Map class docs&lt;/a>.&lt;/p>
&lt;h2 id="adding-pins-for-a-location">Adding pins for a location&lt;/h2>
&lt;p>Maps can have added layers such as pins and paths, with each layer showing coordinate data. This data is put into a &lt;code>DataSource&lt;/code>, which gets added to the map, then a layer is applied to this data source.&lt;/p>
&lt;p>To show pins on a map, the coordinates for the pins are added as a map feature to the data source, and a &lt;code>SymbolLayer&lt;/code> is added referencing this data source. The map will show a pin for each point in the data source.&lt;/p>
&lt;p>First, create the data source in the maps &lt;code>ready&lt;/code> event handler:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-js" data-lang="js">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">dataSource&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> &lt;span style="color:#a6e22e">atlas&lt;/span>.&lt;span style="color:#a6e22e">source&lt;/span>.&lt;span style="color:#a6e22e">DataSource&lt;/span>();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">map&lt;/span>.&lt;span style="color:#a6e22e">sources&lt;/span>.&lt;span style="color:#a6e22e">add&lt;/span>(&lt;span style="color:#a6e22e">dataSource&lt;/span>);
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Then create a data feature to wrap a point and add it to the data source. Features can include single points, polygons or lines, in this case it is a single point.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-js" data-lang="js">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">dataSource&lt;/span>.&lt;span style="color:#a6e22e">add&lt;/span>(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">new&lt;/span> &lt;span style="color:#a6e22e">atlas&lt;/span>.&lt;span style="color:#a6e22e">data&lt;/span>.&lt;span style="color:#a6e22e">Feature&lt;/span>(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">new&lt;/span> &lt;span style="color:#a6e22e">atlas&lt;/span>.&lt;span style="color:#a6e22e">data&lt;/span>.&lt;span style="color:#a6e22e">Point&lt;/span>([{&lt;span style="color:#a6e22e">longitude&lt;/span>}, {&lt;span style="color:#a6e22e">latitude&lt;/span>}])));
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>In this code, &lt;code>{longitude}&lt;/code> needs to be set to the longitude of the point, and &lt;code>{latitude}&lt;/code> set to the latitude. Finally a symbol layer is added to show the pins, and this symbol layer wraps the data source:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-js" data-lang="js">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">map&lt;/span>.&lt;span style="color:#a6e22e">layers&lt;/span>.&lt;span style="color:#a6e22e">add&lt;/span>(&lt;span style="color:#66d9ef">new&lt;/span> &lt;span style="color:#a6e22e">atlas&lt;/span>.&lt;span style="color:#a6e22e">layer&lt;/span>.&lt;span style="color:#a6e22e">SymbolLayer&lt;/span>(&lt;span style="color:#a6e22e">dataSource&lt;/span>, &lt;span style="color:#66d9ef">null&lt;/span>));
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/visualising-locations-and-paths-on-a-map/2019-09-23_13-39-19.png">
&lt;/figure>
&lt;p>There&amp;rsquo;s loads more you can do with these symbol layers, including customizing the symbols using images. You can read more and try some of these out in the &lt;a href="https://docs.microsoft.com/azure/azure-maps/map-add-pin/?WT.mc_id=azuremaps-blog-jabenn">Azure Maps Symbol Layer docs&lt;/a>.&lt;/p>
&lt;h2 id="showing-a-path-on-the-map">Showing a path on the map&lt;/h2>
&lt;p>As well as points, maps can also show a line layer. This is a series of points in a connected line, connected in the order the points are declared. This can be used to show a journey for example, tracking the route taken over time. You start with a data source, but this time with a flag set to show it contains line information:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-js" data-lang="js">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">line_datasource&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> &lt;span style="color:#a6e22e">atlas&lt;/span>.&lt;span style="color:#a6e22e">source&lt;/span>.&lt;span style="color:#a6e22e">DataSource&lt;/span>(&lt;span style="color:#66d9ef">null&lt;/span>, {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">lineMetrics&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#66d9ef">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>});
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">map&lt;/span>.&lt;span style="color:#a6e22e">sources&lt;/span>.&lt;span style="color:#a6e22e">add&lt;/span>(&lt;span style="color:#a6e22e">line_datasource&lt;/span>);
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Next, a &lt;code>LineString&lt;/code> feature is added to the data source:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-js" data-lang="js">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">line_datasource&lt;/span>.&lt;span style="color:#a6e22e">add&lt;/span>(&lt;span style="color:#66d9ef">new&lt;/span> &lt;span style="color:#a6e22e">atlas&lt;/span>.&lt;span style="color:#a6e22e">data&lt;/span>.&lt;span style="color:#a6e22e">Feature&lt;/span>(&lt;span style="color:#66d9ef">new&lt;/span> &lt;span style="color:#a6e22e">atlas&lt;/span>.&lt;span style="color:#a6e22e">data&lt;/span>.&lt;span style="color:#a6e22e">LineString&lt;/span>([
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> [{&lt;span style="color:#a6e22e">point1_longitude&lt;/span>}, {&lt;span style="color:#a6e22e">point1_latitude&lt;/span>}],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> [{&lt;span style="color:#a6e22e">point2_longitude&lt;/span>}, {&lt;span style="color:#a6e22e">point2_latitude&lt;/span>}],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>])));
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Each point is added to the array passed into the &lt;code>LineString&lt;/code>, in the order that you want the points to be connected. Finally a line layer is added to the map:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-js" data-lang="js">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">map&lt;/span>.&lt;span style="color:#a6e22e">layers&lt;/span>.&lt;span style="color:#a6e22e">add&lt;/span>(&lt;span style="color:#66d9ef">new&lt;/span> &lt;span style="color:#a6e22e">atlas&lt;/span>.&lt;span style="color:#a6e22e">layer&lt;/span>.&lt;span style="color:#a6e22e">LineLayer&lt;/span>(&lt;span style="color:#a6e22e">line_datasource&lt;/span>, &lt;span style="color:#66d9ef">null&lt;/span>));
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/visualising-locations-and-paths-on-a-map/2019-09-23_13-57-47.png">
&lt;/figure>
&lt;p>You can add multiple data sources to the map, and use them for multiple layers. For example you can have a data source for a line, and another for a point at the end of the line.&lt;/p>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/visualising-locations-and-paths-on-a-map/2019-09-23_13-58-54.png">
&lt;/figure>
&lt;p>You can customize the line, such as the stroke size or color, including having color gradients to indicate the start and end of the line, by passing options when creating the layer. For example, to have a blue to red gradient, with red showing the end of the line (the last coordinate in the array passed to the data source), use the following:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-js" data-lang="js">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">map&lt;/span>.&lt;span style="color:#a6e22e">layers&lt;/span>.&lt;span style="color:#a6e22e">add&lt;/span>(&lt;span style="color:#66d9ef">new&lt;/span> &lt;span style="color:#a6e22e">atlas&lt;/span>.&lt;span style="color:#a6e22e">layer&lt;/span>.&lt;span style="color:#a6e22e">LineLayer&lt;/span>(&lt;span style="color:#a6e22e">line_datasource&lt;/span>, &lt;span style="color:#66d9ef">null&lt;/span>, {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">strokeWidth&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#ae81ff">6&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">strokeGradient&lt;/span>&lt;span style="color:#f92672">:&lt;/span> [
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#39;interpolate&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> [&lt;span style="color:#e6db74">&amp;#39;linear&amp;#39;&lt;/span>],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> [&lt;span style="color:#e6db74">&amp;#39;line-progress&amp;#39;&lt;/span>],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;blue&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;red&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}));
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/visualising-locations-and-paths-on-a-map/2019-09-23_14-02-22.png">
&lt;/figure>
&lt;h2 id="summary">Summary&lt;/h2>
&lt;p>In this post we learned how to add an Azure Maps control to a web page, position the camera, add pins and add lines. Head to the &lt;a href="https://docs.microsoft.com/azure/azure-maps/?WT.mc_id=azuremaps-blog-jabenn">official documentation&lt;/a> to learn more about the capabilities of Azure Maps.&lt;/p></description></item><item><title>Are you where you should be? Checking Geofences using Azure Maps</title><link>https://jimbobbennett.dev/blogs/are-you-where-you-should-be-checking-geofences-using-azure-maps/</link><pubDate>Tue, 10 Sep 2019 00:08:58 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/are-you-where-you-should-be-checking-geofences-using-azure-maps/</guid><description>&lt;p>&lt;strong>A Geofence is a virtual boundary defined using an area on a map. Azure Maps has tools for checking if a coordinate is inside that Geofence. This post looks at how to do these checks.&lt;/strong>&lt;/p>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/are-you-where-you-should-be-checking-geofences-using-azure-maps/stephen-monroe-yg8Cz-i5U30-unsplash.jpg">
&lt;/figure>
&lt;p>There are many use cases for tracking where an item is, and if it moves into or out of a defined location. One great example is legal compliance - for example has an asset crossed an international or state boundary, is a vehicle on roads that require road tax to be paid (for example &lt;a href="https://www.nzta.govt.nz/vehicles/licensing-rego/road-user-charges/">New Zealand&amp;rsquo;s RUC&lt;/a>) or is a ship near a port.&lt;/p>
&lt;p>One use case I&amp;rsquo;ve been thinking about recently is wildlife tracking. I&amp;rsquo;m building a sample app that can be used to track animal sightings including a GPS device that could be attached to an animal to provide 24/7 tracking (I&amp;rsquo;m not really going to put it on a real animal, this is just for demo purposes, so will be using a plushie bear). As well as knowing where an animal is, it would also be good to have an alert if the animal enters certain areas, for example if a bear goes near a center of population. This post shows how to create and check geofences using Azure Maps.&lt;/p>
&lt;h2 id="getting-started">Getting started&lt;/h2>
&lt;ul>
&lt;li>Start by signing up for Azure if you don&amp;rsquo;t have an account:If you are a student, sign up at &lt;a href="https://azure.microsoft.com/free/students/?WT.mc_id=azuremaps-blog-jabenn">azure.microsoft.com/free/students&lt;/a> to get US$100 of free credit and free services for a year.Otherwise sign up at &lt;a href="https://azure.microsoft.com/free/?WT.mc_id=azuremaps-blog-jabenn">azure.microsoft.com/free&lt;/a> to get US$200 of credit for 30 days and a year of free services.&lt;/li>
&lt;li>Sign into Azure and create an Azure Maps resource by following &lt;a href="https://ms.portal.azure.com/?WT.mc_id=azuremaps-blog-jabenn%2F#create/Microsoft.Maps">this link&lt;/a>.&lt;/li>
&lt;/ul>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/are-you-where-you-should-be-checking-geofences-using-azure-maps/2019-09-06_16-51-33.png">
&lt;/figure>
&lt;h2 id="defining-a-geofence">Defining a Geofence&lt;/h2>
&lt;p>Once you have an Azure Maps resource you need to define a geofence. These are defined using GeoJSON - a JSON document designed for geographic information. TO create a simple geofence for the Seattle/Redmond area, you would define it like this:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-json" data-lang="json">&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;type&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;Feature&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;properties&amp;#34;&lt;/span>: {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;geometryId&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;1&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> },
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;geometry&amp;#34;&lt;/span>: {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;type&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;Polygon&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;coordinates&amp;#34;&lt;/span>: [
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> [
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> [
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ae81ff">-122.41864&lt;/span>, &lt;span style="color:#ae81ff">47.54548&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> [
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ae81ff">-122.41864&lt;/span>, &lt;span style="color:#ae81ff">47.70502&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> [
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ae81ff">-122.00867&lt;/span>, &lt;span style="color:#ae81ff">47.70502&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> [
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ae81ff">-122.00867&lt;/span>, &lt;span style="color:#ae81ff">47.54548&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> [
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ae81ff">-122.41864&lt;/span>, &lt;span style="color:#ae81ff">47.54548&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This defines a geometric feature, that is a polygon using the coordinates given, with the last coordinate being the same as the first to close the shape - in this case a rectangle.&lt;/p>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/are-you-where-you-should-be-checking-geofences-using-azure-maps/response.png">
&lt;/figure>
&lt;p>You can do a lot with GeoJson, and you can read more in the &lt;a href="https://docs.microsoft.com/azure/azure-maps/geofence-geojson/?WT.mc_id=azuremaps-blog-jabenn">GeoJSON docs&lt;/a>.&lt;/p>
&lt;p>To set the geofence, you need to send this JSON to a call to the Azure Maps REST API. There aren&amp;rsquo;t any SDKs available for this service yet, but hopefully should be some soon.&lt;/p>
&lt;p>Uploading a geofence needs a couple of calls - you make one call to upload which returns an endpoint that stores the data, then you call that endpoint to get back an Id you use to access the geofence from later calls.&lt;/p>
&lt;p>The first REST call is:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>https://atlas.microsoft.com/mapData/upload?
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> subscription-key&lt;span style="color:#f92672">={&lt;/span>subscription-key&lt;span style="color:#f92672">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;amp;api-version&lt;span style="color:#f92672">=&lt;/span>1.0
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;amp;dataFormat&lt;span style="color:#f92672">=&lt;/span>geojson
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>You will need to replace &lt;code>{subscription-key}&lt;/code> with your primary or secondary key from the &lt;em>Shared Key Authentication&lt;/em> section of the &lt;em>Settings -&amp;gt; Authentication&lt;/em> tab in the map blade in the Azure portal.&lt;/p>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/are-you-where-you-should-be-checking-geofences-using-azure-maps/2019-09-09_16-13-17.png">
&lt;/figure>
&lt;p>The body of the request will need to be set to &lt;code>application/json&lt;/code> and contain the GeoJSON for your geofence.&lt;/p>
&lt;p>When you call this end point you should get back a status of &lt;strong>202 - Accepted&lt;/strong>. In the headers will be a &lt;code>Location&lt;/code> containing an end point to call to get the Id of the geofence.&lt;/p>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/are-you-where-you-should-be-checking-geofences-using-azure-maps/2019-09-09_16-23-18.png">
&lt;/figure>
&lt;p>To get the Id, call the &lt;code>Location&lt;/code> endpoint, adding your subscription key as an additional parameter:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>https://atlas.microsoft.com/mapData/&lt;span style="color:#f92672">{&lt;/span>location&lt;span style="color:#f92672">}&lt;/span>/status?api-version&lt;span style="color:#f92672">=&lt;/span>1.0
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;amp;subscription-key&lt;span style="color:#f92672">={&lt;/span>subscription-key&lt;span style="color:#f92672">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This will return a status of &lt;strong>201 - Created&lt;/strong>, with a body containing a JSON document with a single field - &lt;code>&amp;quot;udId&amp;quot;&lt;/code>, the unique Id of the geofence.&lt;/p>
&lt;h2 id="testing-if-a-coordinate-is-in-the-geofence">Testing if a coordinate is in the geofence&lt;/h2>
&lt;p>The purpose of a geofence is to know when something goes in or out of it. This is done by making a call to another REST API, giving it the udId of the geofence, and the latitude and longitude of the coordinate you want to check.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>https://atlas.microsoft.com/spatial/geofence/json
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ?subscription-key&lt;span style="color:#f92672">={&lt;/span>subscription-key&lt;span style="color:#f92672">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;amp;api-version&lt;span style="color:#f92672">=&lt;/span>1.0
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;amp;udId&lt;span style="color:#f92672">={&lt;/span>udId&lt;span style="color:#f92672">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;amp;lat&lt;span style="color:#f92672">={&lt;/span>latitude&lt;span style="color:#f92672">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;amp;lon&lt;span style="color:#f92672">=&lt;/span>-&lt;span style="color:#f92672">{&lt;/span>longitude&lt;span style="color:#f92672">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;amp;deviceId&lt;span style="color:#f92672">={&lt;/span>device-id&lt;span style="color:#f92672">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>In the above call replace &lt;code>{subscription-key}&lt;/code> with your Azure Maps shared access key, &lt;code>{udId}&lt;/code> with the udId from the second REST call, &lt;code>{latitude}&lt;/code> and &lt;code>{longitude}&lt;/code> with the latitude and longitude of the coordinate you want to check. The final parameter you need to set is &lt;code>{device-id}&lt;/code>, and this needs to be set to an Id for the device that the coordinates come from. This device id doesn&amp;rsquo;t seem to be used for anything, so can be set to whatever you want, but it must be set otherwise you get an error.&lt;/p>
&lt;p>The result of this call is a JSON document containing details about the location of the coordinates relative to the geofence.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-json" data-lang="json">&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;geometries&amp;#34;&lt;/span>: [
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;deviceId&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;device&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;udId&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;xxxxxxxxx&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;geometryId&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;1&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;distance&amp;#34;&lt;/span>: &lt;span style="color:#ae81ff">-999.0&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;nearestLat&amp;#34;&lt;/span>: &lt;span style="color:#ae81ff">47.54548&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;nearestLon&amp;#34;&lt;/span>: &lt;span style="color:#ae81ff">-122.2&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;expiredGeofenceGeometryId&amp;#34;&lt;/span>: [],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;invalidPeriodGeofenceGeometryId&amp;#34;&lt;/span>: []
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This JSON document returns the device and udId values passed in, useful if you want to pass this on to some form of notification system. It also gives a distance and the nearest latitude and longitude.&lt;/p>
&lt;p>One thing to be aware of is GPS is not always exact - although calculations can be exact, coordinates are not always totally accurate. GPS sensors are at best accurate to a few meters, so a device could be inside the geofence but detected outside. The &lt;code>distance&lt;/code> value takes this into consideration:&lt;/p>
&lt;ul>
&lt;li>Positive distance values are outside the geofence, negative are inside.&lt;/li>
&lt;li>If the location is within a short distance (default of 50m and referred to as a &lt;em>search buffer)&lt;/em> of the edge of the geofence, the &lt;code>distance&lt;/code> will be the distance to the geofence in meters.&lt;/li>
&lt;li>If the device is further away from the edge, the value will be &lt;code>999&lt;/code> if outside, &lt;code>-999&lt;/code> inside.&lt;/li>
&lt;li>The search buffer can be configured in the REST call by setting the &lt;code>searchBuffer&lt;/code> parameter to a value in meters from &lt;code>0&lt;/code> to &lt;code>500&lt;/code>. If this is not set, the default of 50m is used.&lt;/li>
&lt;/ul>
&lt;p>When triggering alerts based off being close to the edge of a geofence you should take other information into consideration - for example if the GSP sensor is on a road going device, is the nearest road inside the geofence?&lt;/p>
&lt;p>The &lt;code>nearestLat&lt;/code> and &lt;code>nearestLon&lt;/code> values give the point on the geofence that is nearest to the device - useful for example if you are tracking animals in an enclosed space, this might be where there is hole in the fence!&lt;/p>
&lt;h1 id="learn-more">Learn more&lt;/h1>
&lt;p>If you want to learn more, check out these links:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://docs.microsoft.com/azure/azure-maps/?WT.mc_id=azuremaps-blog-jabenn">Azure maps docs&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.microsoft.com/rest/api/maps/?WT.mc_id=azuremaps-blog-jabenn">Azure Maps REST API docs&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Streaming Serial data using an MXChip</title><link>https://jimbobbennett.dev/blogs/streaming-serial-data-using-an-mxchip/</link><pubDate>Wed, 04 Sep 2019 21:47:05 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/streaming-serial-data-using-an-mxchip/</guid><description>&lt;p>&lt;strong>The MXChip board has 2 serial ports - one using the USB which is great for debugging, and one you can use to stream data from third party modules. This article shows you how!&lt;/strong>&lt;/p>
&lt;blockquote>
&lt;p>TL;DR - connect the TXD on the module to 1 on the MXChip, RXD to 2, then create a new Serial using &lt;code>UARTClass Serial1(UART_1);&lt;/code> You can then call this in the same way as the Arduino &lt;code>Serial&lt;/code> class.&lt;/p>
&lt;/blockquote>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/streaming-serial-data-using-an-mxchip/devkit-board-vector@2x-2-1.png">
&lt;/figure>
&lt;p>I&amp;rsquo;ve spent a lot of time working with the &lt;a href="https://microsoft.github.io/azure-iot-developer-kit/v1/">Azure IoT Dev Kit&lt;/a>, also known as the MXChip. This is a great prototyping board that works seamlessly with Azure IoT Hub and comes with a stack of sensors built in. But what happens if you want to attach another device to it?&lt;/p>
&lt;p>I&amp;rsquo;ve recently started creating a demo app based around a wildlife tracker - both spotting with a phone and an actual GSP collar. Not serious, not planning on putting it on an actual animal, just for a nice end to end demo of a scenario. Honestly - this is the bear that I&amp;rsquo;ll be tracking.&lt;/p>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/streaming-serial-data-using-an-mxchip/IMG_4484.JPG">
&lt;/figure>
&lt;h3 id="hardware">Hardware&lt;/h3>
&lt;p>The hardware I&amp;rsquo;m using for this is a cheap &lt;a href="https://amzn.to/2ZP03lb">GPS module&lt;/a> (note - mine didn&amp;rsquo;t come with mounting pins or an antenna). It sends serial data over UART at 9600 baud, and this data uses &lt;a href="https://en.wikipedia.org/wiki/NMEA_0183">NMEA sentences&lt;/a> - ASCII codes that contain GPS information including position, speed, satellite information and other data.&lt;/p>
&lt;p>I plugged my GPS sensor into my &lt;a href="https://amzn.to/2Lsagif">Kitronic Inventors Kit&lt;/a>, a breakout board for the BBC micro:bit that uses the same finger connector as the MXChip, found out which pins do serial data and connected some wires.&lt;/p>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/streaming-serial-data-using-an-mxchip/PinMappings.png">
&lt;/figure>
&lt;p>TXD on the GPS connects to Pin 1 on the Kitronic Inventors kit - the RXD pin (transmission on the module connects to receive on the MXChip and vice versa), RXD connects to Pin 2, the TXD pin. Power and ground comes from the chip as well, but can also come over USB if needed.&lt;/p>
&lt;p>If you want to connect to the MXChip directly using crocodile clips, TXD connects to the large connector labelled &lt;strong>1,&lt;/strong> RXD connects to the one labelled &lt;strong>2&lt;/strong>, GND connects to the connected labelled &lt;strong>GND&lt;/strong>, and VCC connects to the connector labelled &lt;strong>3V&lt;/strong>.&lt;/p>
&lt;blockquote>
&lt;p>I had to solder pins to my GPS module to get a good connection as breakout pins didn&amp;rsquo;t work very well and kept on losing data.&lt;/p>
&lt;/blockquote>
&lt;h3 id="software">Software&lt;/h3>
&lt;p>Next then tried to find the docs on accessing serial data. This is where I hit a brick wall - nothing! The Arduino docs recommend using a library that is shipped with it called SoftwareSerial, but this is not available in the MXChip libraries. The only thing that does work is using the built in &lt;code>Serial&lt;/code> API to send data over the USB port.&lt;/p>
&lt;p>I dug further, and the specs confirmed that there are 2 serial ports on the MXChip, so how can I access one? Eventually I found this post by &lt;a href="https://twitter.com/robmiles/">Rob Miles&lt;/a>:&lt;/p>
&lt;p>&lt;a href="https://www.robmiles.com/journal/2018/11/18/using-the-second-serial-port-on-the-azure-iot-devkit">https://www.robmiles.com/journal/2018/11/18/using-the-second-serial-port-on-the-azure-iot-devkit&lt;/a>&lt;/p>
&lt;p>You can create a new instance of &lt;code>UARTClass&lt;/code>, the class that handles serial communication and connect it to &lt;code>UART_1&lt;/code>, the second serial port. Once this is created, you can call it using the same API as the standard &lt;code>Serial&lt;/code> instance:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-c" data-lang="c">&lt;span style="display:flex;">&lt;span>UARTClass &lt;span style="color:#a6e22e">Serial1&lt;/span>(UART_1);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Serial1.&lt;span style="color:#a6e22e">begin&lt;/span>(&lt;span style="color:#ae81ff">9600&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">while&lt;/span> (Serial1.&lt;span style="color:#a6e22e">available&lt;/span>() &lt;span style="color:#f92672">&amp;gt;&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">int&lt;/span> byte &lt;span style="color:#f92672">=&lt;/span> Serial1.&lt;span style="color:#a6e22e">read&lt;/span>();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Once done I was able to read serial data from the GPS sensor. I then sent it to &lt;a href="https://github.com/mikalhart/TinyGPSPlus">TinyGPS++&lt;/a> which I was able to install from the Android Library manager in VSCode. This decoded the data into latitude and longitude that I can then send to IoT Hub!&lt;/p></description></item><item><title>Save your users from typing with AI 🤖</title><link>https://jimbobbennett.dev/blogs/save-your-users-from-typing-with-ai/</link><pubDate>Sun, 21 Jul 2019 21:52:08 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/save-your-users-from-typing-with-ai/</guid><description>&lt;p>I&amp;rsquo;ve been playing a lot with the &lt;a href="https://customvision.ai/?WT.mc_id=textrecogniser-blog-jabenn">Azure Custom Vision Service&lt;/a> - a great service to build image classification and object detection models with just a few images. To make it easier to test my models, I wanted to build a mobile app that connects to a custom vision project and uses that to classify or detect objects in images captured using the camera.&lt;/p>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/save-your-users-from-typing-with-ai/IMG_1383-1.PNG">
&lt;/figure>
&lt;p>The app is pretty simple, it&amp;rsquo;s a &lt;a href="https://dotnet.microsoft.com/apps/xamarin/?WT.mc_id=textrecogniser-blog-jabenn">Xamarin&lt;/a> app that uses a camera plugin and the Custom Vision SDKs. There is a problem with it&amp;hellip; Configuration.&lt;/p>
&lt;p>To use a model you need four pieces of information:&lt;/p>
&lt;ul>
&lt;li>Prediction Key - a unique API key for you to use to classify or detect objects&lt;/li>
&lt;li>Endpoint - these services can be run in different Azure regions, so you need the endpoint to show which region it is in&lt;/li>
&lt;li>Project Id - you can have multiple projects, and each one is identified by a GUID&lt;/li>
&lt;li>Publish name - each model has multiple iterations, and you publish the ones you want to be made available with a name&lt;/li>
&lt;/ul>
&lt;p>To use my model, I need to configure my app with all for of these pieces of information. I didn&amp;rsquo;t want to hard code them - I don&amp;rsquo;t want to have to rebuild my app every time I change project or iteration. Ideally I should be able to set these at runtime and store them between sessions.&lt;/p>
&lt;p>I started off with a simple settings screen to type these 4 values in. I made a &lt;strong>&lt;strong>LOT&lt;/strong>&lt;/strong> of mistakes doing this as the values are long and complex. I needed to make my app more usable and find a way to avoid errors&amp;hellip;&lt;/p>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/save-your-users-from-typing-with-ai/IMG_91CBC50D535B-1-1.jpeg">
&lt;/figure>
&lt;p>The solution was to use OCR - optical character recognition, using AI to convert text in an image to a string value.&lt;/p>
&lt;p>Microsoft has a text recognition service available as part of the &lt;a href="https://azure.microsoft.com/services/cognitive-services/?WT.mc_id=textrecogniser-blog-jabenn">Azure Cognitive Services&lt;/a>. This service takes an image, then detects text in it and returns that text.&lt;/p>
&lt;h2 id="getting-started">Getting started&lt;/h2>
&lt;p>To get started you need either an Azure account. You can sign up for free &lt;a href="https://azure.microsoft.com/free/ai/?WT.mc_id=textrecogniser-blog-jabenn">here&lt;/a> if you don&amp;rsquo;t already have an account.&lt;/p>
&lt;blockquote>
&lt;p>You can access a free 7 day guest account without signup from &lt;a href="https://azure.microsoft.com/services/cognitive-services/computer-vision/?WT.mc_id=textrecogniser-blog-jabenn">here&lt;/a>.&lt;/p>
&lt;/blockquote>
&lt;p>Once you are signed up, head to the &lt;a href="https://ms.portal.azure.com/#create/Microsoft.CognitiveServicesComputerVision/?WT.mc_id=textrecogniser-blog-jabenn">Azure Portal&lt;/a> to create a computer vision resource.&lt;/p>
&lt;p>When you create this resource, you select what pricing tier you want - and there is a nice free tier allowing up to 20 requests per minute which is perfect for my app. Once created, you will need to grab the &lt;em>Endpoint&lt;/em> from the &lt;em>Overview&lt;/em> tab in the portal, and one of the keys from the &lt;em>Keys&lt;/em> tab.&lt;/p>
&lt;h2 id="using-the-service-from-code">Using the service from code&lt;/h2>
&lt;p>There are a whole stack of SDKs available for Azure, covering the most popular languages and technologies, as well as a REST API for languages that SDKs are not available for. My app is a Xamarin app, so I used the .NET SDKs available on &lt;a href="https://www.nuget.org/packages/Microsoft.Azure.CognitiveServices.Vision.ComputerVision/?WT.mc_id=textrecogniser-blog-jabenn">NuGet&lt;/a>.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>Install-Package Microsoft.Azure.CognitiveServices.Vision.ComputerVision -Version 5.0.0
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Once the package was added, I just needed to take a picture and send it for processing. Taking pictures with a Xamarin app is not that complicated thanks to the &lt;a href="https://github.com/jamesmontemagno/MediaPlugin">Media Plugin&lt;/a>, and I used this to take an image and give me a stream.&lt;/p>
&lt;p>Once I had the image, I sent it to the &lt;a href="https://docs.microsoft.com/azure/cognitive-services/computer-vision/concept-recognizing-text#read-api?WT.mc_id=textrecogniser-blog-jabenn">Read API&lt;/a>. This API takes an image and returns a token immediately whilst processing the image offline. You then call another API to check the status, and once the status comes back as processed you can grab the text.&lt;/p>
&lt;h3 id="create-the-computer-vision-client">Create the computer vision client&lt;/h3>
&lt;p>Before you can process an image, you need an instance of the &lt;code>ComputerVisionClient&lt;/code>.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> creds = &lt;span style="color:#66d9ef">new&lt;/span> ApiKeyServiceClientCredentials(&amp;lt;Your Key&amp;gt;);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> computerVision = &lt;span style="color:#66d9ef">new&lt;/span> ComputerVisionClient(creds)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Endpoint = &amp;lt;Your Endpoint&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>};
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>In the code above, &lt;code>&amp;lt;Your Key&amp;gt;&lt;/code> would be replaced with your API key for the computer vision service, and &lt;code>&amp;lt;Your Endpoint&amp;gt;&lt;/code> would be replaced with the services endpoint.&lt;/p>
&lt;h3 id="start-the-read-request">Start the read request&lt;/h3>
&lt;p>To start using the Read API, you send the image to call to one of the &lt;code>BatchRead&lt;/code> functions. There are several of these, depending on if you want to process a file or a stream. In my case I&amp;rsquo;m using a stream.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> results = &lt;span style="color:#66d9ef">await&lt;/span> computerVision.BatchReadFileInStreamAsync(photo.GetStream());
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> loc = results.OperationLocation;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> operationId = loc.Substring(loc.Length - &lt;span style="color:#ae81ff">36&lt;/span>);
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The call to &lt;code>BatchReadFileInStreamAsync&lt;/code> returns an intermediate result, and this has an &lt;code>OperationLocation&lt;/code> - a token for the read operation. This is a long URL with the token on the end, so we need to extract the last 36 characters to get the token.&lt;/p>
&lt;p>The result is an intermediate result, you will need to wait for the processing to finish&lt;/p>
&lt;h3 id="wait-for-the-request-to-finish">Wait for the request to finish&lt;/h3>
&lt;p>The request will take some time to run, as in a few milliseconds as opposed to minutes. The result of the batch call contains the status, and if this status is not complete then it can be retrieved continuously until it is complete, waiting between retries.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">while&lt;/span> (result.Status == TextOperationStatusCodes.Running ||
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> result.Status == TextOperationStatusCodes.NotStarted)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">await&lt;/span> Task.Delay(&lt;span style="color:#ae81ff">100&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> result = &lt;span style="color:#66d9ef">await&lt;/span> computerVision.GetReadOperationResultAsync(operationId);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This code loops whilst the status is &lt;code>NotStarted&lt;/code> or &lt;code>Running&lt;/code>, pausing for 100ms then requesting the new status. Ideally you would also limit the retries and check for a &lt;code>Failed&lt;/code> status.&lt;/p>
&lt;h3 id="get-the-text">Get the text&lt;/h3>
&lt;p>Once the status is &lt;code>Succeeded&lt;/code>, the results will be available. The results come back as a list of &lt;code>TextRecognitionResult&lt;/code>, each one referring to an area of text in the image. Each &lt;code>TextRecognitionResult&lt;/code> contains one or more lines of text in the &lt;code>Lines&lt;/code> property, and each line of text is accompanied by extra details such as the bounding box of the text. The lines are from top to bottom, so the topmost line of text would be the first entry in the &lt;code>Lines&lt;/code> property, the next line down the next entry and so on.For my purposes, the settings page on the custom vision service has the data I need in a vertical list with the title of the field above the value, such as for the &lt;strong>Project Id&lt;/strong> shown below.&lt;/p>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/save-your-users-from-typing-with-ai/ProjectId.png">
&lt;/figure>
&lt;p>In this case if I photographed these values and detected the text I would have one line containing the text &lt;code>&amp;quot;Project Id&amp;quot;&lt;/code> with the next line being the GUID for the project Id.&lt;/p>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/save-your-users-from-typing-with-ai/ProjectIdImmediate.png">
&lt;/figure>
&lt;p>I can now extract this value and use it in my app.&lt;/p>
&lt;h3 id="done">Done&lt;/h3>
&lt;p>Using the text recognition service from the Azure Cognitive Services means you will never have to ask your users to type in complicated data ever again!&lt;/p>
&lt;hr/>
&lt;p>You can find the code for my app on GitHub here: &lt;a href="https://github.com/jimbobbennett/ObjectDetector">github.com/jimbobbennett/ObjectDetector&lt;/a>. All the code that uses the cognitive services is in the &lt;code>SettingsViewModel&lt;/code>.&lt;/p></description></item><item><title>Building a live caption tool - part 1</title><link>https://jimbobbennett.dev/blogs/building-a-live-caption-tool/</link><pubDate>Tue, 02 Jul 2019 11:39:24 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/building-a-live-caption-tool/</guid><description>&lt;p>I&amp;rsquo;ve started a &lt;a href="https://twitch.tv/jimbobbennett">Twitch stream where I&amp;rsquo;m learning Python&lt;/a> every Wednesday at 12pm UK time. One way I&amp;rsquo;d like to make my stream more accessible is by having live captions whilst I&amp;rsquo;m speaking.&lt;/p>
&lt;p>What I need is a tool that will stream captions to something I can add to my OBS scenes, but also be customizable. A lot of off the shelf speech to text models are great, but I need something I can tune to my voice and accent, as well as any special words I am using such as technical tools and terms.&lt;/p>
&lt;p>The &lt;a href="https://azure.microsoft.com/services/cognitive-services/directory/speech/?WT.mc_id=livecaption-blog-jabenn">Azure Cognitive Services&lt;/a> have such a tool - as well as using a standard speech to text model, you can customize the model for your voice, accent, background noise and special words.&lt;/p>
&lt;p>In this part, I&amp;rsquo;ll show how to get started building a live captioner in Python. In the next part, I&amp;rsquo;ll show how to customize the output.&lt;/p>
&lt;h2 id="create-the-speech-resource">Create the speech resource&lt;/h2>
&lt;p>To get started, you first need to create a Speech resource in Azure. You can do it from the Azure Portal by following &lt;a href="https://portal.azure.com/?WT.mc_id=twitchcaptions-blog-jabenn#create/Microsoft.CognitiveServicesSpeechServices">this link&lt;/a>. There is a free tier which I&amp;rsquo;m using - after all we all love free stuff!&lt;/p>
&lt;blockquote>
&lt;p>If you don&amp;rsquo;t have an Azure account you can create a free account at &lt;a href="?WT.mc_id=twitchcaptions-blog-jabenn">azure.microsoft.com/free&lt;/a> and get $200 of free credit for the first 30 days and a host of services free for a year. Students and academic faculty can sign up at &lt;a href="https://azure.microsoft.com/free/students/?WT.mc_id=livecaption-blog-jabenn">azure.microsoft.com/free/students&lt;/a> and get $100 that lasts a year as well as 12 months of free services, and this can be renewed every year that you are a student.&lt;/p>
&lt;/blockquote>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/building-a-live-caption-tool/2019-07-02_11-21-40.png">
&lt;/figure>
&lt;p>When the resource is created, note down the first part of the endpoint from the &lt;strong>Overview&lt;/strong> tab. The endpoint will be something like &lt;code>https://uksouth.api.cognitive.microsoft.com/sts/v1.0/issuetoken&lt;/code>, and the bit you want is the part before &lt;code>api.microsoft.com&lt;/code>, so in my case &lt;code>uksouth&lt;/code>. This will be the name of the region you created your resource in. You all also need to grab a key from the &lt;strong>Keys&lt;/strong> tab.&lt;/p>
&lt;p>Once you have your Speech resource the next step is to use it to create captions.&lt;/p>
&lt;h2 id="create-a-captioner">Create a captioner&lt;/h2>
&lt;p>Seeing as my stream is all about learning Python, I thought it would be fun to build the captioner in Python. All the Microsoft Cognitive Services have &lt;a href="https://azure.microsoft.com/resources/samples/cognitive-services-python-sdk-samples/?WT.mc_id=livecaption-blog-jabenn">Python APIs&lt;/a> which makes them easy to use.&lt;/p>
&lt;p>I launched VS Code (which has excellent Python support thanks to the &lt;a href="https://code.visualstudio.com/docs/languages/python/?WT.mc_id=livecaption-blog-jabenn">Python extension&lt;/a>), and created a new Python project. The Speech SDK is available via &lt;code>pip&lt;/code>, so I installed via the Terminal it using:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>pip install azure-cognitiveservices-speech
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>To recognize speech you need to create a &lt;code>speechRecognizer&lt;/code>, telling it the details of your resource via a &lt;code>speechConfig&lt;/code>.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> azure.cognitiveservices.speech &lt;span style="color:#66d9ef">as&lt;/span> speechsdk
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>speech_config &lt;span style="color:#f92672">=&lt;/span> speechsdk&lt;span style="color:#f92672">.&lt;/span>SpeechConfig(subscription&lt;span style="color:#f92672">=&lt;/span>speech_key, region&lt;span style="color:#f92672">=&lt;/span>service_region)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>speech_recognizer &lt;span style="color:#f92672">=&lt;/span> speechsdk&lt;span style="color:#f92672">.&lt;/span>SpeechRecognizer(speech_config&lt;span style="color:#f92672">=&lt;/span>speech_config)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>In the code above, replace &lt;code>speech_key&lt;/code> with the key from the Speech resource, and replace &lt;code>service_region&lt;/code> with the region name.&lt;/p>
&lt;blockquote>
&lt;p>This will create a speech recognizer using the default microphone. If you want to change the microphone you will need to know the device id and use this to create an &lt;code>AudioConfig&lt;/code> object which is used to create the recognizer. You can read more about this in &lt;a href="https://docs.microsoft.com/azure/cognitive-services/speech-service/how-to-select-audio-input-devices/?WT.mc_id=twitchcaptions-blog-jabenn">the docs&lt;/a>.&lt;/p>
&lt;/blockquote>
&lt;p>The speech recognizer can be run as a one off and listen for a single block of speech until a break is found, or it can run continuously providing a constant stream of text via events. To detect continuously, an event needs to be wired up to collect the text.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">recognizing&lt;/span>(args):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Do something&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>speech_recognizer&lt;span style="color:#f92672">.&lt;/span>recognizing&lt;span style="color:#f92672">.&lt;/span>connect(recognizing)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>speech_recognizer&lt;span style="color:#f92672">.&lt;/span>start_continuous_recognition()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>In the above code, the &lt;code>recognizing&lt;/code> event is fired every time some text is recognized. This event is fired multiple times for the same set of words, building up the text over time as the model refines the output. After a break it will reset and send new text.&lt;/p>
&lt;p>The &lt;code>args&lt;/code> parameter is a &lt;code>SpeechRecognitionEventArgs&lt;/code> instance with a property called &lt;code>result&lt;/code> that contains the result of the recognition. This result has a property called &lt;code>text&lt;/code> with the recognized text.&lt;/p>
&lt;p>For example, if you run this and say &amp;ldquo;Hello and welcome to the speech captioner&amp;rdquo;, this event will be called probably 7 times:&lt;/p>
&lt;pre tabindex="0">&lt;code>hello
hello and
hello and welcome
hello and welcome to
hello and welcome to the
hello and welcome to the speech
hello and welcome to the speech captioner
&lt;/code>&lt;/pre>&lt;p>If you then pause and say &amp;ldquo;This works&amp;rdquo; it will be called 2 more times, with just the new words.&lt;/p>
&lt;pre tabindex="0">&lt;code>this
this works
&lt;/code>&lt;/pre>&lt;p>The text is refined as the words are analyzed, so the text can change over time. For example if you say &amp;ldquo;This is a live caption test&amp;rdquo;, you may get back:&lt;/p>
&lt;pre tabindex="0">&lt;code>this
this is
this is alive
this is a live caption
this is a live caption text
&lt;/code>&lt;/pre>&lt;p>Notice in the third result there is the word &amp;ldquo;alive&amp;rdquo;, which gets split into &amp;ldquo;a live&amp;rdquo; as more context is understood by the model.&lt;/p>
&lt;p>The model doesn&amp;rsquo;t understand sentences, and in reality humans rarely speak in coherent sentences with a structure that is easy for the model to break up, hence why you won&amp;rsquo;t see full stops or capital letters.&lt;/p>
&lt;p>The &lt;code>start_continuous_recognition&lt;/code> call will run the recognition in the background, so the app will need a way to keep running, such as a looping sleep or an app loop using a GUI framework like Tkinter.&lt;/p>
&lt;p>I&amp;rsquo;ve created a GUI app using Tkinter using this code. My app will put a semi-opaque window at the bottom of the screen that has a live stream of the captions in a label. The label is updated with the text from the &lt;code>recognizing&lt;/code> event, so will be updated as I speak, then cleared down after each block of text ends and a new one begins.&lt;/p>
&lt;p>You can find it on &lt;a href="https://github.com/jimbobbennett/TwitchCaptioner">GitHub&lt;/a>, to use it add your key and region to the &lt;em>config.py&lt;/em> file, install the &lt;code>pip&lt;/code> packages from the &lt;em>requirements.txt&lt;/em> file and run &lt;em>captioner.py&lt;/em> through Python.&lt;/p>
&lt;p>In the next part, I&amp;rsquo;ll show how to customize the model to my voice and terms I use.&lt;/p></description></item><item><title>Adding Try .NET to VSCode launch.json</title><link>https://jimbobbennett.dev/blogs/adding-try-net-to-vscode-launch-json/</link><pubDate>Tue, 11 Jun 2019 10:31:32 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/adding-try-net-to-vscode-launch-json/</guid><description>&lt;p>I&amp;rsquo;ve been playing a lot with &lt;a href="https://github.com/dotnet/try?WT.mc_id=trydotnet-blog-jabenn">Try .NET&lt;/a>. I even blogged about it recently - [&lt;a href="https://jimbobbennett.dev/blogs/trying-out-try-net/">jimbobbennett.io/trying-out-try-net&lt;/a>](/blogs/trying-out-try-net/).&lt;/p>
&lt;p>One thing that was beginning to annoy me slightly was having to constantly launch the terminal and type &lt;code>dotnet try&lt;/code> to test out what I was working in. My life would be infinitely improved (not really), if I could run it via &lt;strong>F5&lt;/strong> or the debug menu/tab instead of the terminal.&lt;/p>
&lt;p>Turns out its pretty easy to do - just add a new entry to your &lt;code>launch.json&lt;/code> file either directly from the file in the &lt;code>.vscode&lt;/code> folder, or adding a configuration using the debug menu.&lt;/p>
&lt;p>Add this to it:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-json" data-lang="json">&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;name&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;Try .NET&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;type&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;coreclr&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;request&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;launch&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;program&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;dotnet&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;args&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;try&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>That&amp;rsquo;s all you need. Now you can run &lt;code>dotnet try&lt;/code> just by pressing &lt;strong>F5&lt;/strong>.&lt;/p></description></item><item><title>Trying out Try .NET</title><link>https://jimbobbennett.dev/blogs/trying-out-try-net/</link><pubDate>Tue, 04 Jun 2019 10:27:34 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/trying-out-try-net/</guid><description>&lt;p>&lt;a href="https://github.com/dotnet/try?WT.mc_id=trydotnet-blog-jabenn">Try .NET&lt;/a> is a new thing to come from the .NET teams that allows you to, well, try .NET. In a browser. You can think of it as a way to create interactive .NET documentation using .NET Core.&lt;/p>
&lt;h2 id="what-is-try-net">What is Try .NET&lt;/h2>
&lt;p>The experience or writing code in a browser itself isn&amp;rsquo;t new, developers have been able to try out C# coding snippets &lt;a href="https://dotnet.microsoft.com/learn/dotnet/in-browser-tutorial/1/?WT.mc_id=trydotnet-blog-jabenn">in the browser&lt;/a> for a while but this is different. Try .NET is different, as it allows you to:&lt;/p>
&lt;ul>
&lt;li>Mix code and markdown which then gets run as a web page where you can read the markdown and edit and run the code in place&lt;/li>
&lt;li>Create projects with code, NuGet package dependencies, whatever is needed, then only surface the bits you want people to focus on&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>Note - Try .NET only supports C# at the moment, but F# is the most requested enhancement, obviously.&lt;/p>
&lt;/blockquote>
&lt;h3 id="mix-code-and-markdown">Mix code and markdown&lt;/h3>
&lt;p>Imagine you wanted to create a tutorial project to show how to do something in C#. In the past, you would write the instructions and provide code snippets for the reader to run by creating a project, then adding the code to a &lt;code>.cs&lt;/code> file in that project, then running it from the command line.&lt;/p>
&lt;p>With Try .NET, you can create a markdown file that links to a piece of code in an existing project. The reader can then run that code from inside the browser. They can also edit the code with full intellisense, get compiler errors if something isn&amp;rsquo;t write and generally play with the code.&lt;/p>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/trying-out-try-net/TryDotNetRunMarkdownAndCode.png">
&lt;/figure>
&lt;h3 id="only-surface-what-you-need">Only surface what you need&lt;/h3>
&lt;p>When running code, you normally need some boiler plate stuff - a &lt;code>main&lt;/code> method, some &lt;code>using&lt;/code> directives, that sort of thing. If you want to run more advanced code that relies on external packages or setup code you need a way to bring those packages in or run the setup code. This can be complex, and fill up the code window with code that really isn&amp;rsquo;t relevant to what you want to teach.&lt;/p>
&lt;p>Try .NET fixes this by having a C# project behind the scenes that you can set up how you want. You then write all the code you need, then surface just the bit you want to show in the markdown using &lt;code>#region&lt;/code> directives - yup, finally a good reason for them.&lt;/p>
&lt;h2 id="creating-your-first-try-net-project">Creating your first Try .NET project&lt;/h2>
&lt;p>Try .NET is a global .NET tool, and you can install it from a terminal or command line using:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>dotnet tool install --global dotnet-try
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>It supports .NET Core 2.1, but for all the best stuff it&amp;rsquo;s worth &lt;a href="https://dotnet.microsoft.com/download/dotnet-core/3.0/?WT.mc_id=trydotnet-blog-jabenn">installing 3.0&lt;/a>.&lt;/p>
&lt;p>You can spin up a demo project using:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>dotnet try demo
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>but I thought it would be fun to walk through creating a project from scratch and go through how it all runs.&lt;/p>
&lt;h3 id="create-a-dotnet-project">Create a dotnet project&lt;/h3>
&lt;p>Start with a simple dotnet console app:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>dotnet new console -o TryDotNetDemo
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>In my case I&amp;rsquo;ve called my app &lt;code>TryDotNetDemo&lt;/code>. Open this project in &lt;a href="https://code.visualstudio.com/?WT.mc_id=trydotnet-blog-jabenn">Visual Studio Code&lt;/a>, then add a new file to the project called &lt;code>README.MD&lt;/code>. This is a standard read me markdown file, the same as you would use in GitHub.&lt;/p>
&lt;p>Add some markdown to this file to display a simple header and intro:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-markdown" data-lang="markdown">&lt;span style="display:flex;">&lt;span># A try .NET demo
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>This is a demo of Try .NET.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Run the code below to see some code being run.
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>From the Visual Studio Code terminal run the following:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>dotnet try
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Your code will be compiled, and launched in a browser where you will see your markdown rendered.&lt;/p>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/trying-out-try-net/TryDotNetFirstRun-1.png">
&lt;/figure>
&lt;h3 id="add-some-code">Add some code&lt;/h3>
&lt;p>Now we have some markdown, lets add some code. A simple &lt;em>Hello World&lt;/em> will do for now.&lt;/p>
&lt;p>Open the &lt;code>Program.cs&lt;/code> file. The default &lt;code>main&lt;/code> method will have a single line to write &lt;code>Hello World&lt;/code> to the console.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">using&lt;/span> System;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">namespace&lt;/span> TryDotNetDemo
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">Program&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">static&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> Main(&lt;span style="color:#66d9ef">string&lt;/span>[] args)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Console.WriteLine(&lt;span style="color:#e6db74">&amp;#34;Hello World!&amp;#34;&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>We want the &lt;code>Console.WriteLine&lt;/code> call in the markdown, but not the rest of the code, so what do we do?&lt;/p>
&lt;p>Well we add a region! Wrap the line in a named region block, using a name that makes sense.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># region&lt;/span> HelloWorld
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Console.WriteLine(&lt;span style="color:#e6db74">&amp;#34;Hello World!&amp;#34;&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># endregion&lt;/span> HelloWorld
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Next, add an empty code block to your markdown:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-markdown" data-lang="markdown">&lt;span style="display:flex;">&lt;span>```cs --region HelloWorld --source-file .\Program.cs --project .\TryDotNetDemo.csproj
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre tabindex="0">&lt;code>
Lets break this markdown block down:
```markdown
``` cs
&lt;/code>&lt;/pre>&lt;pre tabindex="0">&lt;code>
These are the open and closing sections of the code block, shown by three back ticks. The closing set of three back ticks needs to be on a new line. The `cs` part tells the markdown renderer that the code in this block is C# code.
```markdown
--region HelloWorld
&lt;/code>&lt;/pre>&lt;p>This tells Try .NET to look for a region called &lt;code>HelloWorld&lt;/code> and put all the code inside this region into the rendered markdown.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-markdown" data-lang="markdown">&lt;span style="display:flex;">&lt;span>--source-file .\Program.cs
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This tells Try .NET to look for this region in the &lt;code>Program.cs&lt;/code> code file.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-markdown" data-lang="markdown">&lt;span style="display:flex;">&lt;span>--project .\TryDotNetDemo.csproj
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This final option tells Try .NET that the code comes from the &lt;code>TryDotNetDemo.csproj&lt;/code> file, so this project needs to be compiled and run.&lt;/p>
&lt;p>Kill the running session in the Visual Studio Code terminal if it is still running, and relaunch it.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>dotnet try
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>You will now see your code in the browser, and you can run it using the purple run button.&lt;/p>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/trying-out-try-net/TryDotNetFirstRunWithCode.png">
&lt;/figure>
&lt;p>This is cool - but what&amp;rsquo;s even cooler is you can edit this code. Have a play - you get full intellisense and &lt;em>ctrl+space&lt;/em> autocomplete, and if your code doesn&amp;rsquo;t compile you get proper compiler errors - with line numbers based off the code in the browser, not in the &lt;code>.cs&lt;/code> file.&lt;/p>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/trying-out-try-net/TryDotNetRunMarkdownAndCodeAndError.png">
&lt;/figure>
&lt;h3 id="whats-happening">What&amp;rsquo;s happening&lt;/h3>
&lt;p>When your code runs, it will compile the console app with any code changes you&amp;rsquo;ve made included. If it fails to compile, you see the errors, otherwise the console app runs as normal - the &lt;code>main&lt;/code> method is run and any output to the console is shown below your code.&lt;/p>
&lt;h2 id="creating-a-more-advanced-project">Creating a more advanced project&lt;/h2>
&lt;p>This first example runs one bit of code, but what if you wanted to have multiple methods that can be edited, for example in a multi part or multi page tutorial? How would that work as the &lt;code>main&lt;/code> method is run every time?&lt;/p>
&lt;p>The answer comes in the form of command line parameters. When Try .NET runs your console app, it passes the region name, source file and project file as command line parameters to the app. To see this in action you can dump the parameters to the console and relaunch the code.-&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>Console.WriteLine(&lt;span style="color:#66d9ef">string&lt;/span>.Join(&lt;span style="color:#e6db74">&amp;#39; &amp;#39;&lt;/span>, args));
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/trying-out-try-net/TryNetCommandLIneParams.png">
&lt;/figure>
&lt;p>You will see 6 parameters:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>--region HelloWorld --source-file .&lt;span style="color:#ae81ff">\P&lt;/span>rogram.cs --project .&lt;span style="color:#ae81ff">\T&lt;/span>ryDotNetDemo.csproj
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>These are the additional parameters added to the &lt;code>cs&lt;/code> code block in the markdown.&lt;/p>
&lt;p>You can use these to direct your code. A good pattern is to switch on the region in your &lt;code>main&lt;/code> method, then call a different method.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">static&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> Main(&lt;span style="color:#66d9ef">string&lt;/span>[] args)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">switch&lt;/span> (args[&lt;span style="color:#ae81ff">1&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">case&lt;/span> &lt;span style="color:#e6db74">&amp;#34;HelloWorld&amp;#34;&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> HelloWorld();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">break&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">case&lt;/span> &lt;span style="color:#e6db74">&amp;#34;Addition&amp;#34;&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Addition();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">break&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">static&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> HelloWorld()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">#region&lt;/span> HelloWorld
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Console.WriteLine(&lt;span style="color:#e6db74">&amp;#34;Hello World!&amp;#34;&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">#endregion&lt;/span> HelloWorld
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">static&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> Addition()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">#region&lt;/span> Addition
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">int&lt;/span> a = &lt;span style="color:#ae81ff">1&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">int&lt;/span> b = &lt;span style="color:#ae81ff">2&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">int&lt;/span> c = a + b;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Console.WriteLine(&lt;span style="color:#e6db74">$&amp;#34;{a} + {b} = {c}&amp;#34;&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">#endregion&lt;/span> Addition
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>You can then surface both methods in the markdown:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-markdown" data-lang="markdown">&lt;span style="display:flex;">&lt;span># A try .NET demo
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>This is a demo of Try .NET.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Run the code below to see some code being run.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>```cs --region HelloWorld --source-file .\Program.cs --project .\TryDotNetDemo.csproj
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The code below shows addition:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;/code>&lt;/pre>&lt;/div>&lt;pre tabindex="0">&lt;code>
When the `HelloWorld` region is run, the console app is called and `&amp;#34;HelloWorld&amp;#34;` is passed as the second argument to the app (the first argument is the `--region` parameter). The `switch` statement in the `main` method picks this up and runs the `HelloWorld` method only. Similarly the `Addition` region passes `&amp;#34;Addition&amp;#34;` to the app, and only the `Addition` method is run.
This allows you to break your app down into many methods that can be called in isolation inside your markdown.
## What about adding packages?
This is totally supported! Just add the package to your C# project as normal and use it in your code.
```cs
static void Json()
{
#region Json
var x = new { name = &amp;#34;Try .NET&amp;#34;, status = &amp;#34;Awesome&amp;#34; };
var json = JsonConvert.SerializeObject(x);
Console.WriteLine(json);
#endregion Json
}
&lt;/code>&lt;/pre>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-markdown" data-lang="markdown">&lt;span style="display:flex;">&lt;span>The code below shows some JSON handling with Newtonsoft JSON:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>```cs --region Json --source-file .\Program.cs --project .\TryDotNetDemo.csproj
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre tabindex="0">&lt;code>
When you run this code in the browser it will use `Newtonsoft.Json.JsonConvert` to serialize an anonymous object to a string. You even get full intellisense for this package in the editor.
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/trying-out-try-net/JsonHandling.png">
&lt;/figure>
---
All the code for this is available on GitHub here - [github.com/jimbobbennett/TryDotNetDemo](https://github.com/jimbobbennett/TryDotNetDemo).
You can also read more on the [.NET blog](https://devblogs.microsoft.com/dotnet/creating-interactive-net-documentation/?WT.mc_id=trydotnet-blog-jabenn).
&lt;/code>&lt;/pre></description></item><item><title>Connecting Pycom boards to Azure IoT Hub</title><link>https://jimbobbennett.dev/blogs/connecting-pycom-boards-to-azure-iot-hub/</link><pubDate>Wed, 10 Apr 2019 12:38:16 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/connecting-pycom-boards-to-azure-iot-hub/</guid><description>&lt;p>I&amp;rsquo;m supporting an IoT hackathon over the weekend of April 27th/28th 2019. It will be a cool event, where you can win six months free business support from &lt;a href="https://twitter.com/setsquared">SETsquared&lt;/a> – the world’s leading university business incubator. If you are interested, sign up here:&lt;/p>
&lt;p>&lt;a href="https://www.eventbrite.com/e/the-big-iothack-tickets-58111865153">eventbrite.com/e/the-big-iothack-tickets-58111865153&lt;/a>&lt;/p>
&lt;p>As a part of this hackathon, &lt;a href="https://pycom.io">PyCom&lt;/a> are providing a load of devices. These are tiny IoT development boards that run MicroPython, and can connect over WiFi, BLE, &lt;a href="https://lora-alliance.org">LoRa&lt;/a> or &lt;a href="https://www.sigfox.com/">SigFox&lt;/a>. PyCom have a service called PyBytes that can take data from the devices, and this can be integrated into &lt;a href="https://azure.microsoft.com/services/iot-hub/?WT.mc_id=pycom-blog-jabenn">Azure IoT Hub&lt;/a>. To prepare for this event, I grabbed a board and started to play.&lt;/p>
&lt;blockquote>
&lt;p>You will need an Azure subscription to work thorough this. If you don&amp;rsquo;t have one, you can sign up for free at &lt;a href="https://azure.microsoft.com/free/?WT.mc_id=pycom-blog-jabenn">azure.microsoft.com/free&lt;/a>. This will give you $200 of credit, access to free services for 12 months, and other services free forever. You will need a credit card, but this is only for validation - you will &lt;strong>NOT&lt;/strong> be billed unless to choose to upgrade your subscription.&lt;/p>
&lt;/blockquote>
&lt;h2 id="getting-started">Getting started&lt;/h2>
&lt;h3 id="unpack-the-board">Unpack the board&lt;/h3>
&lt;p>We were given a big box of kit to try out before the hackathon. It had a range of boards and shields inside.&lt;/p>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/connecting-pycom-boards-to-azure-iot-hub/IMG_0290.jpg">
&lt;/figure>
&lt;p>I grabbed a WiPy and a Pysense board.&lt;/p>
&lt;p>The &lt;a href="https://pycom.io/product/wipy-3-0/">WiPy&lt;/a> is a WiFi and BLE enabled board running an ESP32 micro controller. It doesn&amp;rsquo;t have any sensors or USB connectivity, it needs to be added to an expansion board.&lt;/p>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/connecting-pycom-boards-to-azure-iot-hub/IMG_0286.jpg">
&lt;/figure>
&lt;p>The &lt;a href="https://pycom.io/product/pysense/">PySense&lt;/a> is an expansion board that the WiPy plugs into. It has a load of sensors as well as a USB port you can use to program the micro controller.&lt;/p>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/connecting-pycom-boards-to-azure-iot-hub/IMG_0287.jpg">
&lt;/figure>
&lt;h3 id="plug-it-in">Plug it in&lt;/h3>
&lt;p>The boards fit together, with the WiPy plugging into the socket on the Pysense. It took a bit of research to determine which way round to plug it in. Next I connected a WiFi antenna. Once it was all plugged together I connected the USB port to my Mac and an LED started flashing! Everyone loves blinking LEDs.&lt;/p>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/connecting-pycom-boards-to-azure-iot-hub/IMG_0293.jpg">
&lt;/figure>
&lt;p>I then did the usual dance to upgrade the firmware by following the &lt;a href="https://docs.pycom.io/gettingstarted/installation/firmwaretool.html">PyCom docs&lt;/a>. As a heads up, if you are using a Mac, unplug everything from the USB ports first otherwise you&amp;rsquo;ll get errors as it tried to push the firmware to the wrong device!&lt;/p>
&lt;h3 id="configure-the-software">Configure the software&lt;/h3>
&lt;p>Like a lot of developers, I love &lt;a href="https://code.visualstudio.com/?WT.mc_id=pycom-blog-jabenn">Visual Studio Code&lt;/a>! PyCom provides an &lt;a href="https://marketplace.visualstudio.com/itemdetails?itemName=pycom.Pymakr&amp;amp;WT.mc_id=pycom-blog-jabenn">extension for Code&lt;/a> that can talk to their boards.&lt;/p>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/connecting-pycom-boards-to-azure-iot-hub/2019-04-10_10-39-54.png">
&lt;/figure>
&lt;h3 id="write-some-code">Write some code!&lt;/h3>
&lt;p>These boards run &lt;a href="https://www.micropython.org">MicroPython&lt;/a>, an implementation of Python designed to run on micro controllers. MicroPython projects have the following structure:&lt;/p>
&lt;pre tabindex="0">&lt;code>Project folder
|-lib
| |- some_library.py
|- boot.py
|- main.py
&lt;/code>&lt;/pre>&lt;p>Inside the project folder, there is an optional &lt;code>lib&lt;/code> folder and two &lt;code>.py&lt;/code> files. &lt;code>boot.py&lt;/code> is optional and contains any code that you want run when the board boots up, such as connecting to WiFi. You can think of this as the same as the &lt;code>setup&lt;/code> function in an Arduino C project. &lt;code>main.py&lt;/code> is not optional, and contains the main code that will run on the device, analogous to the &lt;code>loop&lt;/code> function in Arduino. It isn&amp;rsquo;t a loop as such, it won&amp;rsquo;t be called continuously, instead you will need to add your own processing loop. The &lt;code>lib&lt;/code> folder is where you can put other &lt;code>.py&lt;/code> files. This is the only directory that MicroPython will look in, you can&amp;rsquo;t put files in other directories or sub-directories of &lt;code>lib&lt;/code>.&lt;/p>
&lt;p>I created a new folder, and added &lt;code>main.py&lt;/code> file. The code for this file is:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> pycom
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> time
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>pycom&lt;span style="color:#f92672">.&lt;/span>heartbeat(&lt;span style="color:#66d9ef">False&lt;/span>) &lt;span style="color:#75715e"># Turn off the heartbeat&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">while&lt;/span> &lt;span style="color:#66d9ef">True&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> pycom&lt;span style="color:#f92672">.&lt;/span>rgbled(&lt;span style="color:#ae81ff">0xFF0000&lt;/span>) &lt;span style="color:#75715e"># Red&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> time&lt;span style="color:#f92672">.&lt;/span>sleep(&lt;span style="color:#ae81ff">1&lt;/span>) &lt;span style="color:#75715e"># Sleep for 1 second&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> pycom&lt;span style="color:#f92672">.&lt;/span>rgbled(&lt;span style="color:#ae81ff">0x00FF00&lt;/span>) &lt;span style="color:#75715e"># Green&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> time&lt;span style="color:#f92672">.&lt;/span>sleep(&lt;span style="color:#ae81ff">1&lt;/span>) &lt;span style="color:#75715e"># Sleep for 1 second&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> pycom&lt;span style="color:#f92672">.&lt;/span>rgbled(&lt;span style="color:#ae81ff">0x0000FF&lt;/span>) &lt;span style="color:#75715e"># Blue&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> time&lt;span style="color:#f92672">.&lt;/span>sleep(&lt;span style="color:#ae81ff">1&lt;/span>) &lt;span style="color:#75715e"># Sleep for 1 second&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This code imports the &lt;code>pycom&lt;/code> module containing code to interact with the board, and a &lt;a href="https://docs.python.org/3/library/time.html">&lt;code>time&lt;/code> module&lt;/a> to provide access to code to sleep.&lt;/p>
&lt;p>The code starts by turning off the heartbeat - this is a regular pulse of the on-board LED that shows you the board is powered on.&lt;/p>
&lt;p>Next it runs a loop - using a &lt;code>while True:&lt;/code> loop to always run the code. The suite inside this loop sets the LED to red, sleeps for a second, then green, sleep, then blue, sleep.&lt;/p>
&lt;blockquote>
&lt;p>Python is different to a lot of other languages in that &lt;code>sleep&lt;/code> takes a time in seconds, not milliseconds.&lt;/p>
&lt;/blockquote>
&lt;p>To deploy the code, launch the command palette and select &lt;em>Pymakr-&amp;gt;Run current file&lt;/em>. This will compile the code and run it to the device. Once done, the LED will start to flash red, then green, then blue.&lt;/p>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/connecting-pycom-boards-to-azure-iot-hub/2019-04-10_11-06-04.png">
&lt;/figure>
&lt;p>This only runs the code on the device, it doesn&amp;rsquo;t store it permanently, so once the device is rebooted, the code is wiped. To upload the code so that it is maintained between reboots, use &lt;em>Pymakr -&amp;gt; Upload project&lt;/em>.&lt;/p>
&lt;h2 id="send-data-to-the-cloud-using-pybytes">Send data to the cloud using PyBytes&lt;/h2>
&lt;p>Getting an LED flashing is cool, but what is cooler is getting data and sending it to the cloud. PyCom has a service called &lt;a href="https://pybytes.pycom.io/">PyBytes&lt;/a> that takes in data from PyCom devices.&lt;/p>
&lt;h3 id="connect-to-pybytes">Connect to PyBytes&lt;/h3>
&lt;p>PyBytes makes it easy to configure your device. You add a new device from their Web dashboard, set up a unique name for it and the WiFi details for the WiFi you want the PyCom device to connect to. You then get an activation token that you can use when flashing the firmware to push these details to the device.&lt;/p>
&lt;p>Flash the firmware, and configure it for PyBytes, setting the activation token.&lt;/p>
&lt;p>Once the firmware is updated, the device will appear in the PyBytes dashboard.&lt;/p>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/connecting-pycom-boards-to-azure-iot-hub/2019-04-10_11-30-17.png">
&lt;/figure>
&lt;h3 id="set-up-the-dashboard-to-receive-some-data">Set up the dashboard to receive some data&lt;/h3>
&lt;p>PyBytes manages data as signals. A signal is data sent from the device, identified by a unique number. The PyBytes dashboard takes the signal data, enriches it with a name and unit and allows it to be displayed on a dashboard.&lt;/p>
&lt;p>From the &lt;strong>Data&lt;/strong> tab on the dashboard, I defined a new signal called &lt;strong>Temperature&lt;/strong> for ID &lt;code>0&lt;/code>, with the unit set to °C.&lt;/p>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/connecting-pycom-boards-to-azure-iot-hub/2019-04-10_11-34-34.png">
&lt;/figure>
&lt;h3 id="send-some-data">Send some data&lt;/h3>
&lt;p>Once the signal was created, I needed to send data to it from the PySense temperature sensor. There are libraries for accessing the PyBytes API, and the PySense board, and these need to be grabbed from the &lt;a href="https://github.com/pycom/pycom-libraries">PyCom GitHub repo&lt;/a> and dropped in the &lt;code>lib&lt;/code> folder. I grabbed the &lt;code>[pysense.py](https://github.com/pycom/pycom-libraries/blob/master/pybytes/pysense/lib/pysense.py)&lt;/code> and &lt;code>[pycoproc.py](https://github.com/pycom/pycom-libraries/blob/master/pybytes/pysense/lib/pycoproc.py)&lt;/code> libraries to talk to the PySense board, and the &lt;code>[SI7006A20.py](https://github.com/pycom/pycom-libraries/blob/master/pybytes/pysense/lib/SI7006A20.py)&lt;/code> library to access the temperature sensor.&lt;/p>
&lt;p>The code I used to send the data is:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> pycom
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> _thread
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> pysense &lt;span style="color:#f92672">import&lt;/span> Pysense
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> SI7006A20 &lt;span style="color:#f92672">import&lt;/span> SI7006A20
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> time &lt;span style="color:#f92672">import&lt;/span> sleep
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>pycom&lt;span style="color:#f92672">.&lt;/span>heartbeat(&lt;span style="color:#66d9ef">False&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>py &lt;span style="color:#f92672">=&lt;/span> Pysense() &lt;span style="color:#75715e"># Connect to the PySense board&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>si &lt;span style="color:#f92672">=&lt;/span> SI7006A20(py) &lt;span style="color:#75715e"># Connect to the temperature sensor&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">while&lt;/span> &lt;span style="color:#66d9ef">True&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> pycom&lt;span style="color:#f92672">.&lt;/span>rgbled(&lt;span style="color:#ae81ff">0x0000FF&lt;/span>) &lt;span style="color:#75715e"># Flash the LED blue&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> temp &lt;span style="color:#f92672">=&lt;/span> si&lt;span style="color:#f92672">.&lt;/span>temperature() &lt;span style="color:#75715e"># Get the temperature&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> pybytes&lt;span style="color:#f92672">.&lt;/span>send_signal(&lt;span style="color:#ae81ff">0&lt;/span>, temp) &lt;span style="color:#75715e"># Send the temperature using signal 0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> pycom&lt;span style="color:#f92672">.&lt;/span>rgbled(&lt;span style="color:#ae81ff">0x000000&lt;/span>) &lt;span style="color:#75715e"># Turn off the LED&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> sleep(&lt;span style="color:#ae81ff">5&lt;/span>) &lt;span style="color:#75715e"># Sleep for 5 seconds&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This uses the &lt;code>SI7006A20&lt;/code> temperature sensor to get the temperature, then sends a signal to PyBytes, using a signal id of &lt;code>0&lt;/code>. This data then appears on the PyBytes dashboard.&lt;/p>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/connecting-pycom-boards-to-azure-iot-hub/2019-04-10_12-04-12.png">
&lt;/figure>
&lt;h2 id="integrate-pybytes-with-iot-hub">Integrate PyBytes with IoT Hub&lt;/h2>
&lt;p>PyBytes supports integrations with &lt;a href="https://azure.microsoft.com/services/iot-hub/?WT.mc_id=pycom-blog-jabenn">Azure IoT Hub&lt;/a>, and it can push the data received from the device into IoT Hub.&lt;/p>
&lt;h3 id="create-an-iot-hub">Create an IoT Hub&lt;/h3>
&lt;p>I created a new IoT Hub instance to send the data to. I&amp;rsquo;ve got the &lt;a href="https://marketplace.visualstudio.com/itemdetails?itemName=vsciot-vscode.vscode-iot-workbench/?WT.mc_id=pycom-blog-jabenn">Azure IoT Device Workbench extension&lt;/a> installed in Visual Studio Code, and this provides capabilities to configure IoT services from inside Code.&lt;/p>
&lt;p>From the command palette, selecting &lt;em>Azure IoT Hub -&amp;gt; Create IoT Hub&lt;/em> allows you to create a new IoT Hub. Follow the instructions, and you get a new IoT Hub set up.&lt;/p>
&lt;h3 id="integrate-the-iot-hub-into-pybytes">Integrate the IoT Hub into PyBytes&lt;/h3>
&lt;p>When the IoT Hub is running, open it up in the &lt;a href="https://portal.azure.com/?WT.mc_id=pycom-blog-jabenn">Azure Portal.&lt;/a> Head to &lt;em>Settings -&amp;gt; Shared Access Policies&lt;/em>, select the &lt;em>registryReadWrite&lt;/em> policy and copy the &lt;em>Connection string - Primary key&lt;/em>. PyBytes needs read and write permissions on the registry to register devices for you - each device configured in PyBytes becomes a device in IoT Hub.&lt;/p>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/connecting-pycom-boards-to-azure-iot-hub/2019-04-10_12-31-07.png">
&lt;/figure>
&lt;p>From PyBytes, select &lt;em>Integrations -&amp;gt; New Integration&lt;/em>. Select &lt;em>Microsoft Azure&lt;/em>, then paste the connection string and select &lt;em>Login&lt;/em>. Give the integration a name, enter a topic for the messages and select the devices you want to include. Then select &lt;strong>Create&lt;/strong>. Once the integration is created, you can send a test message, then check for this in the IoT Hub.&lt;/p>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/connecting-pycom-boards-to-azure-iot-hub/2019-04-10_13-01-16.png">
&lt;/figure>
&lt;p>You will also be able to see the device in the devices list both in the IoT Hub list, and in the &lt;em>Azure IoT Hub Devices&lt;/em> section in the explorer. You can right-click on the device in the explorer and select &lt;em>Start monitoring D2C messages&amp;hellip;&lt;/em> to see a stream of the messages in the output window.&lt;/p>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/connecting-pycom-boards-to-azure-iot-hub/2019-04-10_13-02-35.png">
&lt;/figure>
&lt;p>The data is raw, unenriched data showing the signal id and value.&lt;/p>
&lt;h2 id="next-steps">Next steps&lt;/h2>
&lt;p>Now that the data is flowing into IoT Hub, you can do anything you want with it - enrich it using &lt;a href="https://azure.microsoft.com/services/stream-analytics/?WT.mc_id=pycom-blog-jabenn">stream analytics&lt;/a> or an &lt;a href="https://azure.microsoft.com/services/functions/?WT.mc_id=pycom-blog-jabenn">Azure function&lt;/a>, do &lt;a href="https://azure.microsoft.com/services/time-series-insights/?WT.mc_id=pycom-blog-jabenn">time series insights&lt;/a> on it, anything you want!&lt;/p>
&lt;hr>
&lt;p>All the code for this project is available on GitHub here: &lt;a href="https://github.com/jimbobbennett/PyCom-AzureIoTHub">github.com/jimbobbennett/PyCom-AzureIoTHub&lt;/a>&lt;/p></description></item><item><title>Python on a Raspberry Pi using VS Code</title><link>https://jimbobbennett.dev/blogs/python-on-a-raspberry-pi-using-vs-code/</link><pubDate>Tue, 02 Apr 2019 14:32:05 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/python-on-a-raspberry-pi-using-vs-code/</guid><description>&lt;p>I&amp;rsquo;ve recently been playing with a Raspberry Pi with the aim of learning Python. These are great little computers and have been an amazing success, selling 19 million as of March 2018, and kids everywhere are using them to learn to code with &lt;a href="https://scratch.mit.edu">Scratch&lt;/a> and Python.&lt;/p>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/python-on-a-raspberry-pi-using-vs-code/IMG_0252.jpg">
&lt;/figure>
&lt;p>The IDE for Python that is shipped by default is IDLE. This is a great IDE that comes as part of the standard Python install - it has an interactive shell and file editor, debugger and everything you need. It&amp;rsquo;s good enough, but not quite on par with the world class editor that is &lt;a href="https://code.visualstudio.com/?WT.mc_id=vscodepi-blog-jabenn">Visual Studio Code&lt;/a>.&lt;/p>
&lt;p>Currently there aren&amp;rsquo;t any official builds for VS Code for ARM processors, although there is a request for it on GitHub. Please head to this link and upvote it:&lt;/p>
&lt;p>&lt;a href="https://github.com/Microsoft/vscode/issues/6442">https://github.com/Microsoft/vscode/issues/6442&lt;/a>&lt;/p>
&lt;p>There is however a community build, courtesy of &lt;a href="https://github.com/headmelted">Jay Rodgers&lt;/a>. You can find the installation instructions on &lt;a href="https://code.headmelted.com">code.headmelted.com&lt;/a>, but I&amp;rsquo;ve found that these instructions don&amp;rsquo;t work due to an &lt;a href="https://github.com/headmelted/codebuilds/issues/71">issue with the GPG key&lt;/a>. There is a workaround!&lt;/p>
&lt;p>To get the GPG key installed, launch a terminal and enter the following commands.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>wget https://packagecloud.io/headmelted/codebuilds/gpgkey
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sudo apt-key add gpgkey
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Once done, you can run the installer script. Enter sudo mode using:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>sudo -s
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Then run the installer:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>. &amp;lt;&lt;span style="color:#f92672">(&lt;/span> wget -O - https://code.headmelted.com/installers/apt.sh &lt;span style="color:#f92672">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This will install a non-VS branded version of code. The lack of Visual Studio branding is intentional - the code is open source, but the logos are copyright Microsoft. This means that a community build can&amp;rsquo;t use these icons. You can launch this from the menu, &lt;em>Raspberry-&amp;gt;Programming-&amp;gt;Code - OSS (Headmelted)&lt;/em>.&lt;/p>
&lt;p>There is an &lt;a href="https://github.com/headmelted/codebuilds/issues/67">issue with v1.32&lt;/a>. It will launch, but not run properly. The fix is to rollback to an earlier version, v1.29. To do this, run this command:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>apt-get install code-oss&lt;span style="color:#f92672">=&lt;/span>1.29.0-1539702286
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This rolls back to an earlier version. This does mean if you run &lt;code>apt-get update&lt;/code> at a later date the latest version will be installed, breaking it again. To stop this happening, you can lock the version using:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>apt-mark hold code-oss
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Once a fix has been released, you can remove the version lock with:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>apt-mark unhold code-oss
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Once you launch code you will be able to install the extensions you need. In my case, I wanted the Python extension.&lt;/p>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/python-on-a-raspberry-pi-using-vs-code/2019-04-02_15-22-17.png">
&lt;/figure>
&lt;p>Quick restart later and I&amp;rsquo;m up and running with a full Python environment inside VS Code, with a full debugger and all the goodies I could ever want!&lt;/p></description></item><item><title>Jim made some dumb mistakes when recording a video. You won't believe how he fixed it with Azure Media Services!</title><link>https://jimbobbennett.dev/blogs/making-video-editing-easier-with-azure-media-services/</link><pubDate>Tue, 02 Apr 2019 09:38:50 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/making-video-editing-easier-with-azure-media-services/</guid><description>&lt;p>I was at a recent &lt;a href="https://www.meetup.com/Reading-NET-Meetup/">Reading .NET Meetup&lt;/a>, and wanted to record the event to make it available to members of the group who couldn&amp;rsquo;t attend the event in person. This is part of my aim to &lt;a href="https://github.com/jimbobbennett/MakingMeetupsMoreAccessible">make meetups more accessible&lt;/a>.&lt;/p>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/making-video-editing-easier-with-azure-media-services/IMG_0187.jpg">
&lt;/figure>
&lt;p>We have a cool box of recording git, courtesy of the &lt;a href="https://twitter.com/ch9">Channel9&lt;/a> team at Microsoft, including a Canon XC10 camera. This camera records using the Canon MXF format, a propriety format that doesn&amp;rsquo;t work with my video editing app of choice, &lt;a href="https://www.techsmith.com/video-editor.html">Camtasia&lt;/a>. I also made a basic video recording error, I recorded the video at 30fps, and the audio using a separate recorder at 60fps!&lt;/p>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/making-video-editing-easier-with-azure-media-services/IMG_0192.jpg">
&lt;/figure>
&lt;p>This needed to be fixed - I needed to align the frame rates, and convert the MXF files to MP4 to work with Camtasia. And this is where Azure Media services comes in.&lt;/p>
&lt;p>&lt;a href="https://azure.microsoft.com/services/media-services/?WT.mc_id=azuremedia-blog-jabenn">Azure Media Services&lt;/a> is a suite of services that can encode and stream media. You create a media services resource, then you can use it to encode video either via the portal, or via &lt;a href="https://docs.microsoft.com/azure/media-services/latest/?WT.mc_id=azuremedia-blog-jabenn">the SDK&lt;/a>.&lt;/p>
&lt;h3 id="getting-started">Getting started&lt;/h3>
&lt;p>The first thing to do is to launch the &lt;a href="https://portal.azure.com/?WT.mc_id=azuremedia-blog-jabenn">Azure Portal&lt;/a> and create a &lt;strong>Media Service&lt;/strong> resource.&lt;/p>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/making-video-editing-easier-with-azure-media-services/2019-03-29_11-13-38.png">
&lt;/figure>
&lt;p>Once created, upload an asset - a video file to encode. From the Media Service resource, go to the &lt;em>Assets&lt;/em> tab and select &lt;em>Upload&lt;/em>. Point it to your .MXF file and it will start uploading. You can upload more than one file at once if needed.&lt;/p>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/making-video-editing-easier-with-azure-media-services/2019-04-02_10-31-09.png">
&lt;/figure>
&lt;blockquote>
&lt;p>Video files are huge - my smallest one was 6GB, so it takes a loooooooong time to upload if like me you have crappy bandwidth. Don&amp;rsquo;t let your computer go to sleep as this interrupts the upload and you have to delete the asset and start again.&lt;/p>
&lt;/blockquote>
&lt;p>Once uploading starts, you will be able to see the video file in the &lt;em>Assets&lt;/em> tab. To encode it in the correct format, select the video file, then select &lt;em>encode&lt;/em>.&lt;/p>
&lt;p>From the &lt;strong>Encode an asset&lt;/strong> tab, select the preset you want to use. The default is &lt;em>Content Adaptive Multiple Bitrate MP4&lt;/em>, which provides adaptive streaming, changing the bitrate to match the streaming speed. This is great for content published on the net where viewers will be streaming it using different download speeds, but not so great for just re-encoding to bring into a video editing tool. Select an appropriate preset - I went for H264 Single Bitrate 1080p as I just want the highest bitrate and full size video. You can encode a video that is uploading - it will just queue the encoding job until the video is fully uploaded.&lt;/p>
&lt;p>Again, this will take a long time!&lt;/p>
&lt;p>Once the job is complete, head to the &lt;em>Assets&lt;/em> tab and select the encoded asset. Before you can download the video file you need to publish the asset using a progressive encoder. Click the &lt;strong>Publish&lt;/strong> button, set the encoder as &lt;em>Progressive&lt;/em> and click &lt;strong>Add&lt;/strong>.&lt;/p>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/making-video-editing-easier-with-azure-media-services/2019-04-02_13-24-13.png">
&lt;/figure>
&lt;p>The files for the asset wil be listed at the bottom, and one file will be a &lt;code>video/mp4&lt;/code> file. Select this file, and the details on it will expand out the side, including a download link. Use this link to download the encoded file.&lt;/p>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/making-video-editing-easier-with-azure-media-services/2019-04-02_10-36-48.png">
&lt;/figure>
&lt;p>Done! You can now import this file into tools like Camtasia.&lt;/p></description></item><item><title>Screen sharing a Raspberry Pi from a Mac</title><link>https://jimbobbennett.dev/blogs/screen-sharing-a-raspberry-pi-from-a-mac/</link><pubDate>Sun, 31 Mar 2019 22:34:10 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/screen-sharing-a-raspberry-pi-from-a-mac/</guid><description>&lt;p>I&amp;rsquo;ve been playing with a Raspberry Pi for a while, and I&amp;rsquo;m getting fed up with changing the input to my monitor and using a second keyboard/mouse (yeah, yeah, 1st World Problem I know). I decided to set up a remote screen share so I can share the screen. This means I can use the same monitor/keyboard/mouse that I use for my Mac, but it also means I can un-cable myself and use my Pi from anywhere in the house, and even grab screenshots - useful for some upcoming blog posts I&amp;rsquo;m planning.&lt;/p>
&lt;p>As it turns out, it&amp;rsquo;s really simple to get this set up.&lt;/p>
&lt;h2 id="configure-the-pi">Configure the Pi&lt;/h2>
&lt;p>Start by enabling VNC on the Pi. To do this, click the Raspberry Menu and select &lt;em>Raspberry Pi Configuration&lt;/em>. From the configuration tool, select the &lt;em>Interfaces&lt;/em> tab, then check the &lt;em>Enabled&lt;/em> option next to &lt;em>VNC&lt;/em>. Click &lt;strong>OK&lt;/strong>, then restart the Pi when prompted.&lt;/p>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/screen-sharing-a-raspberry-pi-from-a-mac/2019-03-31_23-12-31.png">
&lt;/figure>
&lt;p>Once the Pi reboots, you need to configure VNC. Click the VNC icon in the menu bar.&lt;/p>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/screen-sharing-a-raspberry-pi-from-a-mac/2019-03-31_23-15-58.png">
&lt;/figure>
&lt;p>This will launch the &lt;em>VNC Server&lt;/em> tool. Click the hamburger and select &lt;em>Options&lt;/em>.&lt;/p>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/screen-sharing-a-raspberry-pi-from-a-mac/2019-03-31_23-19-22.png">
&lt;/figure>
&lt;p>In the &lt;em>Security&lt;/em> tab, set the &lt;em>Encryption&lt;/em> to &lt;code>Prefer off&lt;/code> and the &lt;em>Authentication&lt;/em> to &lt;code>VNC Password&lt;/code>.&lt;/p>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/screen-sharing-a-raspberry-pi-from-a-mac/2019-03-31_23-21-21.png">
&lt;/figure>
&lt;p>In the &lt;em>Users &amp;amp; Permissions&lt;/em> tab, select the &lt;em>Standard user (user)&lt;/em>, and click the &lt;strong>Password&amp;hellip;&lt;/strong> button. Set the password then click &lt;strong>OK&lt;/strong>, then click &lt;strong>OK.&lt;/strong>&lt;/p>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/screen-sharing-a-raspberry-pi-from-a-mac/2019-03-31_23-22-52-1.png">
&lt;/figure>
&lt;p>Finally you need the IP address of the Raspberry Pi. Launch a terminal, and type &lt;code>ifconfig&lt;/code>. Find the &lt;code>inet&lt;/code> address from &lt;code>wlan0&lt;/code> and note this down.&lt;/p>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/screen-sharing-a-raspberry-pi-from-a-mac/2019-03-31_23-25-59.png">
&lt;/figure>
&lt;h2 id="connecting-from-the-mac">Connecting from the Mac&lt;/h2>
&lt;p>To connect from the Mac, open Finder, then select &lt;em>Go -&amp;gt; Connect to server&amp;hellip;&lt;/em>. Enter the address as &lt;code>vnc://&amp;lt;ip address of the Pi&amp;gt;&lt;/code>, for example &lt;code>vnc://192.168.2.10&lt;/code>. Click &lt;strong>Connect&lt;/strong>.&lt;/p>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/screen-sharing-a-raspberry-pi-from-a-mac/2019-03-31_23-28-04.png">
&lt;/figure>
&lt;p>You will be prompted for a password. Enter the password you set up for your VNC standard user and check the box to remember this password. Click &lt;strong>Sign In&lt;/strong>.&lt;/p>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/screen-sharing-a-raspberry-pi-from-a-mac/2019-03-31_23-30-00.png">
&lt;/figure>
&lt;p>Screen sharing will launch, showing your Raspberry PI desktop!&lt;/p>
&lt;figure>&lt;img src="https://jimbobbennett.dev/blogs/screen-sharing-a-raspberry-pi-from-a-mac/2019-03-31_23-33-15.png">
&lt;/figure></description></item><item><title>Xamarin ❤ F#</title><link>https://jimbobbennett.dev/blogs/xamarin-f/</link><pubDate>Sat, 16 Feb 2019 20:35:51 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/xamarin-f/</guid><description>&lt;p>&lt;a href="aka.ms/XamDocs">Xamarin&lt;/a> and &lt;a href="aka.ms/XamFormsDocs">Xamarin.Forms&lt;/a> need no introduction. I&amp;rsquo;m sure by now you are well aware of these technologies and have seen many examples of building cross-platform mobile apps using C#. If not, I can highly recommend my book &lt;a href="xam.jbb.io">Xamarin in Action&lt;/a> which if you follow &lt;a href="xam.jbb.io">this link&lt;/a> and use code &amp;lsquo;xamarininaction&amp;rsquo; you can get 40% off the cover price.&lt;/p>
&lt;p>What you many not realize however, is you don&amp;rsquo;t have to just use C#. Yes, C# is a fantastic object-oriented language, but what if you like functional programming?&lt;/p>
&lt;p>The answer is &lt;a href="https://aka.ms/learnfs">F#&lt;/a>. F# is a functional-first programming language that is fully compatible with the .NET stack. What does &amp;lsquo;functional-first&amp;rsquo; mean? Well it means it is a functional programming language that also supports object-orientation, classes and inheritance and whatnot. Essentially it encourages function programming whilst still supporting enough to interact with the OO world of the .NET framework.&lt;/p>
&lt;p>For Xamarin developers, this is pretty awesome. Out the box F# is supported. This means you can build your apps in the same way as you would with C#, just using F#. You can write all your internal logic in a functional style, then take advantage of the OO features to interact with the APIs - derive a class from &lt;code>UIApplicationDelegate&lt;/code> to configure your iOS app, derive a class from &lt;code>Activity&lt;/code> for your Android app.&lt;/p>
&lt;p>As is, this is pretty good combining the best of both worlds. This is far from perfect though for functional programmers - if you are going to use a functional programming language then you want to take advantage of everything the language has to offer, and not flip-flop from FP to OO style.&lt;/p>
&lt;p>This dilemma has lead to a new framework being created, &lt;a href="https://fsprojects.github.io/Fabulous/guide.html">Fabulous&lt;/a>. This framework sits on top of Xamarin.Forms and provides an MVU style architecture, putting a FP layer over the OO of UI code.&lt;/p>
&lt;p>MVU stands for Model-View-Update and consists of 4 main parts:&lt;/p>
&lt;p>&lt;strong>Model&lt;/strong> - this is an immutable model containing all the state of your application. This model cannot change, and this is enforced by using an &lt;a href="https://docs.microsoft.com/dotnet/fsharp/language-reference/records/?WT.mc_id=fsharp-blog-jabenn">F# record type&lt;/a> which is immutable by default. This allows you to stop worrying about the state of you application, as it is always in this model - in a single, well defined place.&lt;/p>
&lt;p>&lt;strong>Message&lt;/strong> - these define a start transformation request, and are triggered by either UI events like a button tap, or background events like a network call finishing or a push notification. These have a defined type, and can optionally have data taking advantage of the &lt;a href="https://docs.microsoft.com/dotnet/fsharp/language-reference/discriminated-unions/?WT.mc_id=fsharp-blog-jabenn">F# discriminated union type&lt;/a>.&lt;/p>
&lt;p>&lt;strong>Update&lt;/strong> - this is a function that takes a model and a message and returns a new model. This is the only place that the state of the system can change, and is called synchronously removing any worries about race conditions.&lt;/p>
&lt;p>&lt;strong>View&lt;/strong> - this is a function that takes the model and returns a virtual UI based off the model. This virtual UI is lightweight, and can be thought of as analogous to HTML as text, a raw representation that is rendered on screen creating heavyweight UI components. The framework takes the virtual UI returned by this function and compares it to the actual UI. If any differences are found, the real UI is updated to match. This is called a differential update.&lt;/p>
&lt;p>This design pattern brings the full power of functional programming to the OO based world of UI development, allowing you to craft great mobile apps using Xamarin, but sticking to the amazing power, flexibility and development pace of F#. And because it is built on Xamarin.Forms you get to maximize the amount of cross-platform code you write, but still can access all the native features you need, including being able to access the native controls being rendered, call any native API and even use native libraries from Java or Objective-C.&lt;/p>
&lt;p>I recently spoke about this pattern at NDC London, and you can find my code, slides and some great links on &lt;a href="https://github.com/jimbobbennett/BuildingCrossPlatformMobileAppsWithFabulous">my GitHub&lt;/a>. The video of my talk will be up there soon.&lt;/p>
&lt;p>Go check it out, I promise you once you start using Fabulous you won&amp;rsquo;t be disappointed.&lt;/p></description></item><item><title>Prototyping your first cloud-connected IoT project using an MXChip board and Azure IoT hub.</title><link>https://jimbobbennett.dev/blogs/internet-connected-fan/</link><pubDate>Wed, 06 Feb 2019 03:59:43 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/internet-connected-fan/</guid><description>&lt;p>We all have cloud-connected devices. These are devices that do something taking advantage of sensors and hardware, then sync information via the cloud, such as sending sensor data or downloading configuration. For example, you might have a internet controlled thermostat in your home, that controls your heating and air conditioning, reports the temperature to the cloud so you can view it on your mobile device, and allows you to configure the temperature from your mobile device.&lt;/p>
&lt;p>I decided to prototype my own cloud-connected IoT device by building an internet powered fan - a fan that comes on/goes off at a temperature threshold, reports the current temperature to the cloud, and allows you to control the on/off threshold also via the cloud. All this controlled by a mobile app.&lt;/p>
&lt;p>You can find this project in GitHub here: &lt;a href="https://github.com/jimbobbennett/InternetConnectedFan">https://github.com/jimbobbennett/InternetConnectedFan&lt;/a>&lt;/p>
&lt;p>This project contains all the code needed to build an internet connected fan using the &lt;a href="https://microsoft.github.io/azure-iot-developer-kit/v1/">MXChip Azure IoT Dev Kit&lt;/a> and &lt;a href="https://azure.microsoft.com/services/iot-hub/?WT.mc_id=iotfan-github-jabenn">Azure IoT Hub&lt;/a>.&lt;/p>
&lt;p>This project detects the current temperature using the MSChips on-board temperature sensor, and if it is above a threshold, it will turn the fan on. It will also send telemetry data with the current temperature to an Azure IoT hub, which in turn triggers an Azure Function to save the temperature into a CosmosDB instance.&lt;/p>
&lt;p>This project has a Xamarin mobile app that will poll another Azure Function to get the temperature and show it on screen. It also shows the threshold for turning on the fan, and this threshold can be configured from the app. Setting the value will call another Azure Function that updates the &lt;a href="https://docs.microsoft.com/azure/iot-hub/iot-hub-devguide-device-twins/?WT.mc_id=iotfan-github-jabenn">device twin&lt;/a> for the device - a JSON document that is kept in sync between the device and the IoT hub. When the value on the hub is updated, it syncs to the device and the temperature threshold is updated, starting the fan if necessary.&lt;/p>
&lt;h2 id="hardware">Hardware&lt;/h2>
&lt;figure>&lt;img src="https://github.com/jimbobbennett/InternetConnectedFan/raw/master/Images/PhotoOfFinalHardware.jpg">
&lt;/figure>
&lt;p>The hardware for this project is based around the MXChip which you can buy from &lt;a href="https://amzn.to/2Bguvem">here&lt;/a> for around £40. This is an Arduino-compatible prototyping board that comes with a range of sensors, LEDs, buttons, a screen and other capabilities, as well as connectivity to Azure IoT Hub built in.&lt;/p>
&lt;p>This then needs to be attached to a relay and a fan. For the fan, I used a simple battery powered fan that works with 2 AA batteries that is available &lt;a href="https://amzn.to/2CYVQlm">here&lt;/a>. I removed the batteries and connected wires instead, removing the on/off switch and running the cables through the hole. The fan runs on 3V so I was able to use power from the MXChip instead of batteries, as this board can supply 3V.&lt;/p>
&lt;p>The relay I used was one that came with an Intel Edison kit, but any 3V relay will do. To make wiring easier, I used the &lt;a href="https://amzn.to/2BgtRxs">Inventors Kit for the BBC Micro:bit&lt;/a> - the MXChip has the same connector as the &lt;a href="https://microbit.org/">Micro:bit&lt;/a>, and this kit converts the connector to a set of GPIO pins with a built in breadboard for easy prototyping.&lt;/p>
&lt;p>Power to the relay poles was wired to the 3V/0V pins on the board, with PIN0 wired to the relay control. The input to the contacts was wired to 3V from the board, with the output connected to the +ve input on the fan. Finally the -ve input on the fan was wired to the 0V connection on the board.&lt;/p>
&lt;figure>&lt;img src="https://github.com/jimbobbennett/InternetConnectedFan/raw/master/Images/Wiring.png">
&lt;/figure>
&lt;h2 id="software">Software&lt;/h2>
&lt;p>The software for this is in 3 parts - firmware for the device, some Azure Functions to work with device data and configure the device, and client code in the form of a mobile app.&lt;/p>
&lt;h3 id="pre-requisites">Pre-requisites&lt;/h3>
&lt;p>To build and deploy the firmware and Azure Function app you will need:&lt;/p>
&lt;ul>
&lt;li>A valid Azure account. Sign up for free &lt;a href="https://azure.com/free/?WT.mc_id=iotfan-github-jabenn">here&lt;/a> if you don&amp;rsquo;t already have an account.&lt;/li>
&lt;li>&lt;a href="https://code.visualstudio.com/?WT.mc_id=iotfan-github-jabenn">VSCode&lt;/a>&lt;/li>
&lt;li>The VSCode &lt;a href="https://github.com/Microsoft/vscode-iot-workbench">IoT Workbench extension&lt;/a>. This can be installed from inside VSCode.&lt;/li>
&lt;/ul>
&lt;p>To build and deploy the mobile app, you will need:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://visualstudio.microsoft.com/?WT.mc_id=iotfan-github-jabenn">Visual Studio&lt;/a>. This can be either Visual Studio 2017/2019 on Windows with the Xamarin workload installed, or Visual Studio for Mac.&lt;/li>
&lt;li>To deploy on iOS you will need an &lt;a href="https://developer.apple.com/">Apple Developer Account&lt;/a>.&lt;/li>
&lt;li>To deploy to an Android device, you will need an Android device configured for &lt;a href="https://docs.microsoft.com/xamarin/android/deploy-test/debugging/debug-on-device?WT.mc_id=iotfan-github-jabenn">developer mode&lt;/a>.&lt;/li>
&lt;/ul>
&lt;h3 id="setting-up-the-development-environment">Setting up the development environment&lt;/h3>
&lt;p>Start by opening the &lt;code>project.code-workspace&lt;/code> file in VSCode.&lt;/p>
&lt;p>Once you have the hardware assembled, you will need to configure the MXChip with a WiFi connection, create an Azure IoT hub and register the device. To do this, follow the instructions in the &lt;a href="https://microsoft.github.io/azure-iot-developer-kit/docs/get-started/">Getting Started Guide&lt;/a> up to the &lt;strong>Test the project&lt;/strong>section.&lt;/p>
&lt;p>At this point, you will have an IoT hub configured, the device will be registered and and be configured with a connection string, and the code will be deployed to the device.&lt;/p>
&lt;h3 id="firmware">Firmware&lt;/h3>
&lt;p>The device code is in the &lt;code>Device&lt;/code> folder in the project, and contains a single file called &lt;code>FanController.ino&lt;/code>. This is an Arduino sketch file - a &lt;strong>C&lt;/strong> file with the code for the firmware.&lt;/p>
&lt;p>Arduino code has 2 functions called automatically - &lt;code>setup&lt;/code> and &lt;code>loop&lt;/code>.The &lt;code>setup&lt;/code> function is called once when the device starts up, and is a good place to initialize the device, connect to WiFi etc. After that, the &lt;code>loop&lt;/code> function is called repeatedly to do whatever your code needs.&lt;/p>
&lt;p>The &lt;code>setup&lt;/code> function for this project initializes the WiFi, connects to the IoT hub over MQTT including setting up a callback for updates to the device twin, then initializes one of the pins, &lt;strong>PIN0&lt;/strong>, to send data. This pin is used to control the relay.&lt;/p>
&lt;p>The &lt;code>loop&lt;/code> function polls the sensor for the current temperature, writing it to the screen and sending it as a message to the IoT hub over MQTT.&lt;/p>
&lt;ul>
&lt;li>If the temperature is above the threshold, a signal is sent to &lt;strong>PIN0&lt;/strong> to turn on the relay and send power to the fan, starting it up. The on-board LED is also turned to red.&lt;/li>
&lt;li>If the temperature is below the threshold, the signal is stopped, turning the relay off and stopping power to the fan. The LED is set to blue. At the end of the function, it sleeps for 5 seconds to give a delay between polls of the sensor.&lt;/li>
&lt;/ul>
&lt;p>The device twin callback function, &lt;code>DeviceTwinCallback&lt;/code>, is called whenever an update to the device twin is received by the board. This callback parses the JSON that is sent, extracting the threshold value.&lt;/p>
&lt;p>When you worked through the setup, you would have deployed the code to the device, so this should be running already. If you want to re-deploy, use the &lt;em>Azure IoT Device Workbench: Upload Device Code&lt;/em> option from the Command Palette.&lt;/p>
&lt;p>When this app is running, you will be able to see telemetry on the messages received by navigating to your IoT hub in the &lt;a href="https://portal.azure.com/?WT.mc_id=iotfan-github-jabenn">Azure Portal&lt;/a>.&lt;/p>
&lt;figure>&lt;img src="https://github.com/jimbobbennett/InternetConnectedFan/raw/master/Images/Telemetry.png">
&lt;/figure>
&lt;h3 id="azure-function-app">Azure Function App&lt;/h3>
&lt;p>The Azure Function app lives in the &lt;code>Functions&lt;/code> folder, and has 3 functions:&lt;/p>
&lt;ul>
&lt;li>An event hub trigger that is called whenever a message is received by the IoT hub from the device. This saves the temperature to a CosmosDB instance.&lt;/li>
&lt;li>A function to retrieve the temperature from CosmosDB&lt;/li>
&lt;li>A function to update the temperature threshold using a device twin&lt;/li>
&lt;/ul>
&lt;p>This function app is written in C#, using Azunre Functions V2.&lt;/p>
&lt;p>For the sake of simplicity, this app assumes you only have one device and the device id is &lt;code>fan-controller&lt;/code>.&lt;/p>
&lt;p>Before you can wire up the function app, you will need to create a CosmosDB instance using your preferred method (for example the &lt;a href="https://portal.azure.com/?WT.mc_id=iotfan-github-jabenn">Azure Portal&lt;/a>). Ideally this should be in the same resource group as the IoT hub for easier resource management, such as deleting all the resources when you are done. Once this has been created, create a database called &lt;code>Devices&lt;/code> containing a collection called &lt;code>Temperatures&lt;/code>. Take a copy of one of the connection strings from the &lt;em>Read-write Keys&lt;/em> tab of the &lt;em>Keys&lt;/em> section as you will need this later.&lt;/p>
&lt;p>To deploy the function app, use the Command Palette and select &lt;em>Azure IoT Device Workbench: Deploy to Azure&amp;hellip;&lt;/em>. Then select &lt;em>Function App&lt;/em>. This will walk you through the steps to create a new function app in the same resource group as your IoT Hub, and deploy the code to it. Open the function app in the &lt;a href="https://portal.azure.com/?WT.mc_id=iotfan-github-jabenn">portal&lt;/a>, and head to the &lt;em>Application Settings&lt;/em> tab. Add 2 new settings:&lt;/p>
&lt;ul>
&lt;li>&lt;code>CosmosDBConnection&lt;/code> - set this to the CosmosDB connection string you copied earlier&lt;/li>
&lt;li>&lt;code>ecs&lt;/code> - set this to be the &lt;em>Event-hub compatible endpoint&lt;/em> value from the &lt;em>Built-in endpoints&lt;/em> section of the IoT hub.&lt;/li>
&lt;/ul>
&lt;p>After these settings have been updated, you should be able to use the storage explorer for the CosmosDB instance and see the temperature being written for the device. It will only write one record, overwriting it each time to save storage space.&lt;/p>
&lt;p>You should now be able to retrieve the temperature and update the threshold using the REST endpoint, for example with a tool such as &lt;a href="https://www.getpostman.com/downloads/">Postman&lt;/a>. Make a &lt;code>GET&lt;/code> request to &lt;code>https://&amp;lt;your function app&amp;gt;/api/temperature/fan-controller&lt;/code> to get back a JSON document with the temperature for the &lt;code>fan-controller&lt;/code> device.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-json" data-lang="json">&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;partitionKey&amp;#34;&lt;/span> : &lt;span style="color:#e6db74">&amp;#34;temperature&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;id&amp;#34;&lt;/span> : &lt;span style="color:#e6db74">&amp;#34;fan-controller&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;temperature&amp;#34;&lt;/span> : &lt;span style="color:#ae81ff">24.6&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>To update the threshold, send a &lt;code>POST&lt;/code> to &lt;code>https://&amp;lt;your function app&amp;gt;/api/temp-threshold/fan-controller&lt;/code> with the following JSON body:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-json" data-lang="json">&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;threshold&amp;#34;&lt;/span> : &lt;span style="color:#960050;background-color:#1e0010">&amp;lt;the_threshold&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>setting &lt;code>&amp;lt;the_threshold&amp;gt;&lt;/code> to be a double value of the threshold you want. For example, to set the threshold to 20°C use:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-json" data-lang="json">&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;threshold&amp;#34;&lt;/span> : &lt;span style="color:#ae81ff">20.0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="mobile-app">Mobile app&lt;/h3>
&lt;p>To build the mobile app, open the &lt;code>FanController.sln&lt;/code> file in Visual Studio. Set the Android or iOS app to be the startup app depending on what device you want to run on.&lt;/p>
&lt;p>You will need to update the &lt;code>urlRoot&lt;/code> field in the &lt;code>FanController\MainViewModel.cs&lt;/code> file to be the function app URL root - so &lt;code>&amp;lt;your function app&amp;gt;.azurewebsites.net&lt;/code> without the &lt;code>https://&lt;/code> part.&lt;/p>
&lt;p>Launch the app and you will see the temperature. Use the slider to change the threshold and tap the &lt;em>Set&lt;/em> button to set this threshold. Once you tap &lt;em>Set&lt;/em> you should see the threshold on the device change and the fan come on or turn off if applicable.&lt;/p></description></item><item><title>Flying long haul with young children</title><link>https://jimbobbennett.dev/blogs/travelling-with-children/</link><pubDate>Tue, 22 Jan 2019 11:34:28 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/travelling-with-children/</guid><description>&lt;p>A discussion came up at work the other day on flying long-haul with very young children (toddler age), so I though it would be good to share the tips that I shared with the discussion. My daughter is 6 and has been on over 40 flights, including a lot of long haul as a toddler so I&amp;rsquo;ve managed to build up a selection of tips that have worked well for me.&lt;/p>
&lt;p>&lt;img src="martin-widenka-493681-unsplash-2.jpg" alt="Picture of a child looking out of an airplane window">&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Night flight. Long journeys are so much easier if they sleep lots. Try to plan how they will sleep seeing as they will be sitting up, so think about bringing cushions or pillows to make them comfortable. Remember - by default they don&amp;rsquo;t get their own seat so you will need to fit them on your lap.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Lots&lt;/strong> of spare clothes in hand luggage for both you and the child. Toilet accidents can happen, especially during turbulence if you can’t get them to a toilet. Also food spills happen, so you don’t want your little one in wet clothes for the entire flight if a juice box goes everywhere, nor do you want to sit there just in an airplane blanket because your trousers have 💩 on them. Pressure can affect bottles and juice boxes, so anything with liquid should be opened with care!&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Something to suck on the way up and down – if they are still young enough to breastfeed then that’s perfect for up and down as it provides comfort even if they aren’t getting any milk, and helps with the pressure on the ears.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Bring lots of their favorite snacks and even some packed lunch style meals as airplane meals might not be to their liking, even a kids meal.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Eating with a child on your lap is hard - when the food comes round ask if one of you can eat first, then once they have finished the rest of the plane, bring food for the other one so one east whilst the other holds the child.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Get them used to headphones before you travel if they aren’t already. Bring those headphones with you, along with travel adapters for the dual plugs that some planes have.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Lots of bags with toys or sensory play so there’s something new every now and again. Child gets bored – open another.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Parents of young kids can board early, so take advantage of this. Also when leaving the plane wait for everyone else to get off. It’s just easier, especially to ensure you have rounded up everything. You don’t want to lose the favorite toy that your child can’t sleep without just because you were rushing off the plane with everyone else jostling for space. You have plenty of time to get off so it’s better to wait and double/triple check the important stuff is there. You&amp;rsquo;ve been on a plane for hours, so an extra 10 minutes doesn&amp;rsquo;t matter, especially as a lot of airpots will fast-track parents through immigration!&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Take gifts such as pre-packaged chocolate for the crew because it’s a nice thing to do and can be a game for the child delivering presents to the cabin crew or ground staff. Happy cabin crew will be extra helpful when needed on the flight.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Have your hand luggage well organized so you know exactly where to go to get food/wipes/entertainment. Space is limited so you don’t want to have to fight through multiple bags to get something.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Spare batteries and power packs for any gadgets they have on the plane – if their iPad runs out 1 hour in it’ll be a long flight! Also make sure what you think you have downloaded is actually there on the device and works in airplane mode.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>In the run up to the flight make it exciting. My daughter has an &lt;a href="https://www.amazon.co.uk/Inside-Airport-Usborne-Board-Books/dp/1409551768/ref=sr_1_1?ie=UTF8&amp;amp;qid=1548156194&amp;amp;sr=8-1&amp;amp;keywords=usborne+airport">Usbourne flap book on airports and airplanes&lt;/a> and loves it. She used to take it on all her flights and find the right page for the thing we were doing (check in, boarding, take off etc.).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Be selfless with your partner. It will be trying for you both so if it does turn stressful laugh about it instead of fighting. Take turns to walk away and hang out in the galley if you need a break. Miserable parents make for a miserable flight so focus on happiness - maybe even pack a few hidden notes to each other saying things like &amp;ldquo;Sorry I&amp;rsquo;m grumpy as I have poo on me, I still love you&amp;rdquo; to hand to your partner at the appropriate time, or a hidden stash of their favorite chocolate to cheer them up.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Ignore anyone around you who complains without reason. Young children are allowed on a plane, so if the grumpy old man behind you complains about noise or demands up front that your child is silent and doesn’t cry all flight (has happened to us), then ignore them and don’t get stressed. Be nice, be apologetic if needed, but be fair to yourselves. You all have a right to travel.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Hope this is helpful to travelers! Enjoy your flight and let me know of any other top tips so I can update this list.&lt;/p></description></item><item><title>Fabulous Santa Tracker</title><link>https://jimbobbennett.dev/blogs/fabulous-santa-tracker/</link><pubDate>Mon, 24 Dec 2018 00:00:00 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/fabulous-santa-tracker/</guid><description>&lt;blockquote>
&lt;p>&lt;em>&amp;lsquo;Twas the night before Christmas,
and all through the house&amp;hellip;&lt;/em>&lt;/p>
&lt;/blockquote>
&lt;p>For millions of people worldwide, Christmas eve is a time of magic. Children are excited and unable to sleep because&amp;hellip;&lt;/p>
&lt;p>Santa is coming tonight!!!!&lt;/p>
&lt;div class="image-div" style="max-width:600px;">
&lt;p>&lt;img src="srikanta-h-u-51975-unsplash-1.jpg" alt="Santa">&lt;/p>
&lt;/div>
&lt;p>This is the one night of the year you want a stranger to come into your house whilst you sleep. He&amp;rsquo;ll magic his way in (cos who has a chimney these days, right?), and leave presents under your tree.&lt;/p>
&lt;blockquote>
&lt;p>&lt;em>He know if you are sleeping,
He knows if you&amp;rsquo;re awake&amp;hellip;&lt;/em>&lt;/p>
&lt;/blockquote>
&lt;p>But - and this is important, he only comes if you are asleep. So children, you need to be asleep early. But how early? How do you know when you need to be asleep by?&lt;/p>
&lt;p>For this - you need a Santa tracker mobile app. And not just any Santa tracker, a Fabulous one!&lt;/p>
&lt;div class="image-div" style="max-width:400px;">
&lt;p>&lt;img src="Simulator-Screen-Shot---iPhone-8---2018-12-05-at-11.31.25-1.png" alt="Screenshot of Santa tracker app">&lt;/p>
&lt;/div>
&lt;p>This app is pretty simple. It knows where Santa is at any given time on Christmas eve, and based on the current time displays the location of Santa on a map, along with a running count of how many presents he&amp;rsquo;s delivered so far to all the good girls and boys.&lt;/p>
&lt;p>The code is all on &lt;a href="https://github.com/jimbobbennett/FabulousSantaTracker">GitHub&lt;/a> if you want to check it out.&lt;/p>
&lt;h3 id="building-the-santa-tracker">Building the Santa tracker&lt;/h3>
&lt;p>To build this app I needed a source of data, and a mobile app.&lt;/p>
&lt;h5 id="where-did-the-data-come-from">Where did the data come from?&lt;/h5>
&lt;p>Every year for the past decade or so, NORAD has been &lt;a href="https://www.noradsanta.org">tracking Santa online&lt;/a> every Christmas eve. Unfortunately they don&amp;rsquo;t seem to have a public API that I could find to use. Luckily Google has &lt;a href="https://santatracker.google.com/village.html">got in on the action&lt;/a>, and provides &lt;a href="https://storage.googleapis.com/santa/route-v1/santa_en.json">an undocumented API&lt;/a> to download a JSON file containing Santas coordinates from last year. I simply downloaded that JSON document to use. The structure is pretty simple, and I&amp;rsquo;ve shown a snippet of it below showing only the bits I&amp;rsquo;m interested in.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-json" data-lang="json">&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;destinations&amp;#34;&lt;/span>: [
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;arrival&amp;#34;&lt;/span>: &lt;span style="color:#ae81ff">31536000000&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;presentsDelivered&amp;#34;&lt;/span>: &lt;span style="color:#ae81ff">0&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;city&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;Santa&amp;#39;s Village&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;region&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;North Pole&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;location&amp;#34;&lt;/span>: {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;lat&amp;#34;&lt;/span>: &lt;span style="color:#ae81ff">84.6&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;lng&amp;#34;&lt;/span>: &lt;span style="color:#ae81ff">168&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> },
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;arrival&amp;#34;&lt;/span>: &lt;span style="color:#ae81ff">1514110140000&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;presentsDelivered&amp;#34;&lt;/span>: &lt;span style="color:#ae81ff">46415&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;city&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;Provideniya&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;region&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;Russia&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;location&amp;#34;&lt;/span>: {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;lat&amp;#34;&lt;/span>: &lt;span style="color:#ae81ff">64.436249&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;lng&amp;#34;&lt;/span>: &lt;span style="color:#ae81ff">-173.233337&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#960050;background-color:#1e0010">...&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#960050;background-color:#1e0010">]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This gives a city and region name for each stop, total presents delivered, the latitude and longitude of the location and the arrival time. This arrival time is the number of milliseconds since the UNIX epoch - 1 Jan 1970.&lt;/p>
&lt;h5 id="creating-the-mobile-app">Creating the mobile app&lt;/h5>
&lt;p>For the mobile app, I wanted to use F#, and there is a great F# mobile framework called Fabulous!&lt;/p>
&lt;p>&lt;strong>Fabulous?&lt;/strong>&lt;/p>
&lt;p>If you haven&amp;rsquo;t heard of Fabulous yet, its an F#-based MVU framework (so like Elm) for building cross-platform mobile apps, built on top of the Xamarin.Forms platform. You can read all about it &lt;a href="https://fsprojects.github.io/Fabulous/guide.html">in the docs&lt;/a>. There&amp;rsquo;s even an &lt;a href="https://github.com/jimbobbennett/Awesome-Fabulous">awesome-fabulous list&lt;/a> containing cool projects that use it and some great resources.&lt;/p>
&lt;p>You can create a new Fabulous app using the &lt;code>dotnet&lt;/code> CLI. You install the template using:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>dotnet new -i Fabulous.Templates
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The create the app using:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>dotnet new fabulous-app -n FabulousSantaTracker
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This will create an F# solution with an Android app, an iOS app and a .NET standard library containing all the cross platform business logic and UI code.&lt;/p>
&lt;h5 id="reading-the-json">Reading the JSON&lt;/h5>
&lt;p>Processing the JSON file is easy. First I added the downloaded JSON file to the core project, setting the build action to &lt;code>EmbeddedResource&lt;/code>. Once I had this, I added a new F# source file and declared some new types to store the data.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>type Location = { Lat : &lt;span style="color:#66d9ef">float&lt;/span>; Lng : &lt;span style="color:#66d9ef">float&lt;/span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>type Destination =
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Arrival : &lt;span style="color:#66d9ef">float&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> PresentsDelivered : int64
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> City : &lt;span style="color:#66d9ef">string&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Region : &lt;span style="color:#66d9ef">string&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Location : Location
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>type Destinations = array&amp;lt;Destination&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>type SantaData = { Destinations : Destinations }
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>To read the JSON data I needed to read the embedded resource, then use Newtonsoft.JSON to deserialize it (the NuGet for this is included in the Fabulous template, so nothing extra to install).&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">let&lt;/span> GetResourceString fileName =
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">let&lt;/span> assembly = IntrospectionExtensions.GetTypeInfo(typedefof&amp;lt;Destination&amp;gt;).Assembly
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> use stream = assembly.GetManifestResourceStream(fileName)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> use reader = &lt;span style="color:#66d9ef">new&lt;/span> StreamReader (stream)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> reader.ReadToEnd()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">let&lt;/span> AllDestinations =
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">let&lt;/span> santaData = JsonConvert.DeserializeObject&amp;lt;SantaData&amp;gt;(GetResourceString &lt;span style="color:#e6db74">&amp;#34;FabulousSantaTracker.santa_en.json&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> santaData.Destinations
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The &lt;code>GetResourceString&lt;/code> function loads the assembly and extracts the resource string from it. The name of these resource strings needs to be namespace qualified. For example the file in my project is called &lt;code>santa_en.json&lt;/code>, and my namespace is &lt;code>FabulousSantaTracker&lt;/code>, so the full resource name is &lt;code>FabulousSantaTracker.santa_en.json&lt;/code>.&lt;/p>
&lt;p>The last bit I needed was to convert the arrival date from milliseconds after epoch. These arrival dates are for last year (2017), so I needed to update them to the current year.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">let&lt;/span> convertFromEpoch ms =
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">let&lt;/span> d = epoch.AddMilliseconds (ms)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> d.AddYears(DateTime.UtcNow.Year - d.Year)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Now I have my data, it&amp;rsquo;s time to display this on a map. Fabulous uses an MVU architecture, so I need to define a model, some messages, an update function to process these messages, and a view function.&lt;/p>
&lt;h6 id="defining-the-model">Defining the model&lt;/h6>
&lt;p>The model is simple - it just needs Santa&amp;rsquo;s current location by finding the latest destination in the list with an arrival time before now by working backwards through the list of destinations loaded from the JSON file. If Santa hasn&amp;rsquo;t arrived anywhere yet then the first destination is used - this is Santa&amp;rsquo;s workshop at the North Pole.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">let&lt;/span> currentDestination () =
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">let&lt;/span> current = TrackingData.AllDestinations |&amp;gt; Array.tryFindBack (fun i -&amp;gt; i.ArrivalDateTime &amp;lt; DateTime.UtcNow)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> match current with
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> | Some d -&amp;gt; d
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> | None -&amp;gt; TrackingData.AllDestinations |&amp;gt; Array.item &lt;span style="color:#ae81ff">0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>type Model =
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> CurrentDestination : Destination
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">let&lt;/span> &lt;span style="color:#66d9ef">init&lt;/span> () = { CurrentDestination = currentDestination() }, Cmd.none
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h6 id="updating-the-map-when-santa-moves">Updating the map when Santa moves&lt;/h6>
&lt;p>The easiest way to update the current destination when Santa moves is a simple timer - fire a timer every few seconds and update the current destination. This can be implemented by defining a message for a timer tick, and when this is handled in the &lt;code>update&lt;/code> function, update the models &lt;code>CurrentDestination&lt;/code> on every tick.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>type Msg =
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> | TimerTick
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">let&lt;/span> update msg model =
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> match msg with
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> | TimerTick -&amp;gt; { model with CurrentDestination = currentDestination() }, Cmd.none
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This message can then be fired using a subscription to a timer. These subscriptions are functions that take the Fabulous dispatcher and are called when setting up the program.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">let&lt;/span> timerTick dispatch =
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">let&lt;/span> timer = &lt;span style="color:#66d9ef">new&lt;/span> Timer(TimeSpan.FromSeconds(&lt;span style="color:#ae81ff">10.&lt;/span>).TotalMilliseconds)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> timer.Elapsed.Subscribe (fun _ -&amp;gt; dispatch TimerTick) |&amp;gt; ignore
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> timer.Enabled &amp;lt;- &lt;span style="color:#66d9ef">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> timer.Start()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">let&lt;/span> runner =
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> App.program
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> |&amp;gt; Program.withSubscription (fun _ -&amp;gt; Cmd.ofSub App.timerTick)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Once this subscription is called, the timer is started and every 10 seconds the &lt;code>TimerTick&lt;/code> message is dispatched. This causes the models &lt;code>CurrentDestination&lt;/code> to be re-evaluated and the view then gets updated.&lt;/p>
&lt;h6 id="drawing-the-view">Drawing the view&lt;/h6>
&lt;p>Drawing the view is pretty simple. Fabulous uses a virtual UI, so your &lt;code>view&lt;/code> function always returns a complete UI, and the internals of Fabulous compare the current with the result of the &lt;code>view&lt;/code> call and applies the deltas to the real UI.&lt;/p>
&lt;p>My view starts with a navigation page containing a content page with some emoji in the title:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">let&lt;/span> view (model: Model) dispatch =
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> View.NavigationPage(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> pages = [
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> View.ContentPage(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> title = &lt;span style="color:#e6db74">&amp;#34;🎅 Tracker&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>It then contains a grid with 3 rows. First row for the current location, second for the number of presents, third is a map.&lt;/p>
&lt;p>The label to show the location has the text set like this:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>View.Label(text = model.CurrentDestination.City,
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This is one of the ways MVU differs from MVVM (the canonical design pattern for Xamarin.Forms apps) - the value for the location isn&amp;rsquo;t bound to anything, it&amp;rsquo;s just set using the value from the model. Updates to this value can only come from the &lt;code>update&lt;/code> function, and after updating, the &lt;code>view&lt;/code> function is called and the label is created with the new text. The differential update in the Fabulous framework will see this value change and update the UI.&lt;/p>
&lt;p>To show the position on a map, we can use the &lt;code>Fabulous.Maps&lt;/code> NuGet package which contains a wrapper for the Xamarin.Forms Map element. These wrappers are the way that Fabulous can provide a virtual UI, so is needed for each component you want to use in your &lt;code>view&lt;/code> function. Once this NuGet is added, the map can be added to the view function.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>View.Map(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> hasZoomEnabled = &lt;span style="color:#66d9ef">true&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> hasScrollEnabled = &lt;span style="color:#66d9ef">true&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> requestedRegion = MapSpan.FromCenterAndRadius(model.CurrentDestination.Position, Distance.FromKilometers(&lt;span style="color:#ae81ff">1000.0&lt;/span>)),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> pins = [
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> View.Pin(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> model.CurrentDestination.Position,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> label = &lt;span style="color:#e6db74">&amp;#34;Santa&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> pinType = PinType.Place
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> )
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This code creates a map, sets the region to the position of the current destination (the position is an instance of the Xamarin.Forms &lt;code>Position&lt;/code> class using the latitude and longitude from the JSON file) and zooms out to show a radius of 1,000Km. It will also add a pin at the position so that the user can see the position more accurately.&lt;/p>
&lt;h6 id="using-a-custom-map-pin">Using a custom map pin&lt;/h6>
&lt;p>This code so far shows where Santa is, and updates the UI when he moves, but doesn&amp;rsquo;t look the best as the pin is, well just a map pin. It would be better to show Santa himself.&lt;/p>
&lt;p>To do this I added some images to the iOS and Android apps of Santa, drawn by using the Santa emoji. To show these as a custom pin means I need to dive down into some platform specific code. One of the upsides of Xamarin.Forms, the underlying technology for Fabulous, is that you have access to the native UI components, so can update them as if your app was a fully native swift/java app.&lt;/p>
&lt;div class="image-div" style="max-width:68px;">
&lt;p>&lt;img src="Santa.png" alt="Santa map pin image">&lt;/p>
&lt;/div>
&lt;p>Accessing this native code involves the use of custom renderers - custom code to help Fabulous renderer the native controls. Customizing the map means creating my own &lt;code>SantaMap&lt;/code> class that derives from the Forms &lt;code>Map&lt;/code> class.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>type SantaMap() =
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> inherit Xamarin.Forms.Maps.Map()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>You can see the full implementation of this on &lt;a href="https://github.com/jimbobbennett/FabulousSantaTracker/blob/master/FabulousSantaTracker/SantaMap.fs">GitHub&lt;/a>. There is a lot of code here, but is lifted from the original maps implementation so was minimal work. Hopefully in the future this will be easier!&lt;/p>
&lt;p>Once this was in place, I needed to create the custom renderers to draw different pins. The Android one is:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>type SantaMapRenderer(context : Context) =
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> inherit MapRenderer(context)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">override&lt;/span> &lt;span style="color:#66d9ef">this&lt;/span>.CreateMarker(pin : Pin) =
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> (&lt;span style="color:#66d9ef">new&lt;/span> MarkerOptions()).SetPosition(&lt;span style="color:#66d9ef">new&lt;/span> LatLng(pin.Position.Latitude, pin.Position.Longitude))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> .SetTitle(pin.Label)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> .SetIcon(BitmapDescriptorFactory.FromResource(Resources.Drawable.Santa))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>module Export_SantaMapRenderer =
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e"> [&amp;lt;assembly: ExportRenderer(typeof&amp;lt;SantaMap&amp;gt;, typeof&amp;lt;SantaMapRenderer&amp;gt;) &amp;gt;]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">do&lt;/span> ()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Pretty simple - it uses the existing renderer and overrides the code to create the pins to use my Santa image. These renderers need to be registered with the framework to be used, and this can be done using the &lt;code>ExportRenderer&lt;/code> attributes.&lt;/p>
&lt;h5 id="fin">Fin!&lt;/h5>
&lt;p>That&amp;rsquo;s all there is to this - a Santa tracker built using Fabulous. You can find all the code on GitHub here: &lt;a href="https://github.com/jimbobbennett/FabulousSantaTracker">https://github.com/jimbobbennett/FabulousSantaTracker&lt;/a>&lt;/p>
&lt;p>To build this app for iOS, just build it and run it and on Christmas eve watch for where Santa is. Android is a bit more effort as it needs a Google Maps key. You can find instructions on getting one in the &lt;a href="https://docs.microsoft.com/xamarin/android/platform/maps-and-location/maps/obtaining-a-google-maps-api-key?WT.mc_id=santa-blog-jabenn">Xamarin Docs&lt;/a>. Once you have your key, add it to the &lt;code>AndroidManifest.xml&lt;/code> file and track Santa!&lt;/p>
&lt;p>Merry Christmas!&lt;/p></description></item><item><title>Open anything in VS Code using a MacOS quick action</title><link>https://jimbobbennett.dev/blogs/open-anything-in-vs-code-using-a-macos-quick-action/</link><pubDate>Thu, 13 Dec 2018 14:29:25 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/open-anything-in-vs-code-using-a-macos-quick-action/</guid><description>&lt;p>I&amp;rsquo;ve been getting fed up with the long winded process to open things in VS Code - you know, typing in the terminal, opening VS Code and dragging folders in, that sort of long, manual process&amp;hellip; &lt;em>#FirstWorldProblems&lt;/em> 😜&lt;/p>
&lt;p>I thought it would be fun to automate the whole thing, using Automator!&lt;/p>
&lt;p>If you haven&amp;rsquo;t used Automator, it&amp;rsquo;s a great little tool. You can build simple workflows using capabilities from system apps and other apps, configure the data that comes in, then trigger these when things happen, such as calendar events, items changing in a folder or on demand.&lt;/p>
&lt;p>These workflows can be wired up to &amp;ldquo;Quick Actions&amp;rdquo;, these are actions that can be applied to text or images and are called from the context menus in Finder or in a text box. They can also be launched from a keyboard combination or the touch bar.&lt;/p>
&lt;h4 id="creating-a-quick-action-to-open-vs-code">Creating a Quick Action to open VS Code&lt;/h4>
&lt;p>The first step is to create a quick action to open VS Code.&lt;/p>
&lt;ul>
&lt;li>Launch Automator&lt;/li>
&lt;li>Create a new &lt;strong>Quick Action&lt;/strong>&lt;/li>
&lt;/ul>
&lt;div class="image-div" style="max-width:480px;">
&lt;p>&lt;img src="2018-12-13_14-01-47.png" alt="">&lt;/p>
&lt;/div>
&lt;ul>
&lt;li>Configure the workflow:
&lt;ul>
&lt;li>Set it to receive current &lt;em>&amp;ldquo;files and folders&amp;rdquo;&lt;/em> from &lt;em>Finder&lt;/em>.&lt;/li>
&lt;li>Set and image if you want one - I used the icons from &lt;a href="https://github.com/cnstntn-kndrtv/open-in-buttons-for-finder-toolbar">this GitHub repo&lt;/a>.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Add a new &lt;strong>Run Shell Script&lt;/strong> action to the workflow.
&lt;ul>
&lt;li>Set the &lt;em>Pass Input&lt;/em> to be &lt;em>&amp;ldquo;as arguments&amp;rdquo;&lt;/em>&lt;/li>
&lt;li>Set the shell script to be:&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>open -n -b &lt;span style="color:#e6db74">&amp;#34;com.microsoft.VSCode&amp;#34;&lt;/span> --args &lt;span style="color:#e6db74">&amp;#34;&lt;/span>$*&lt;span style="color:#e6db74">&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="image-div" style="max-width:600px;">
&lt;p>&lt;img src="workflow.png" alt="">&lt;/p>
&lt;/div>
&lt;ul>
&lt;li>Save the action using a name like &lt;code>Open In VS Code&lt;/code>.&lt;/li>
&lt;/ul>
&lt;p>This will register the quick action with Finder, and you will now be able to right-click on a file or folder in Finder and select &lt;em>Quick Actions-&amp;gt;Open In VS Code&lt;/em>&lt;/p>
&lt;div class="image-div" style="max-width:480px;">
&lt;p>&lt;img src="2018-12-13_14-11-29-1.png" alt="">&lt;/p>
&lt;/div>
&lt;h4 id="adding-a-keyboard-shortcut">Adding a keyboard shortcut&lt;/h4>
&lt;p>Keyboard shortcuts can be added to Quick Actions from &lt;em>System Preferences&lt;/em>.&lt;/p>
&lt;ul>
&lt;li>Launch System Preferences&lt;/li>
&lt;li>Open the Keyboard settings and select the &lt;em>Shortcuts&lt;/em> tab&lt;/li>
&lt;li>Select &lt;em>Services&lt;/em> from the list on the left&lt;/li>
&lt;li>Scroll down on the right to &lt;em>Files and Folders-&amp;gt;Open In VS Code&lt;/em>&lt;/li>
&lt;li>Click the &lt;strong>none&lt;/strong> keyboard shortcut and press the keys you want to use&lt;/li>
&lt;/ul>
&lt;div class="image-div" style="max-width:600px;">
&lt;p>&lt;img src="2018-12-13_14-13-23.png" alt="">&lt;/p>
&lt;/div>
&lt;h4 id="adding-to-the-touch-bar">Adding to the touch bar&lt;/h4>
&lt;p>If you are a fan of the touch bar (and I am, and I know it&amp;rsquo;a a controversial opinion), you can add quick actions there. Unfortunately not on an action-by-action basis, but you can add a button that shows the quick actions.&lt;/p>
&lt;ul>
&lt;li>From the Keyboard settings in System Preferences, select the &lt;em>Keyboard&lt;/em> tab.&lt;/li>
&lt;li>Click &lt;strong>Customize touch bar&amp;hellip;&lt;/strong>&lt;/li>
&lt;li>Drag the Quick Actions button down to the touch bar and position it where you want. For mine I replaced the default Siri button with the quick actions button as I&amp;rsquo;ve never used Siri on my Mac.&lt;/li>
&lt;li>Click &lt;strong>Done&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>You will now have a quick actions button on the touch bar, and when you tap it it will show you the Open in VS Code action. If you change the color of the quick action in Automator it will change the color of this button!&lt;/p>
&lt;h4 id="more-shortcuts">More shortcuts&amp;hellip;&lt;/h4>
&lt;p>Once I started with this, I added one to open a folder in terminal, and will probably add a load more for things like git commands.&lt;/p>
&lt;div class="image-div" style="max-width:600px;">
&lt;p>&lt;img src="IMG_9418--1-.jpg" alt="">&lt;/p>
&lt;/div></description></item><item><title>Controlling an IoT device from your phone</title><link>https://jimbobbennett.dev/blogs/controlling-an-iot-device-from-your-phone/</link><pubDate>Mon, 19 Nov 2018 17:26:51 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/controlling-an-iot-device-from-your-phone/</guid><description>&lt;p>I&amp;rsquo;ve just finished watching the &lt;a href="https://channel9.msdn.com/Shows/5-Things/Five-IoT-Devices-You-Should-Have-Bought-Yesterday/?WT.mc_id=mxchip-blog-jabenn">latest episode of Five Things&lt;/a>, where &lt;a href="https://twitter.com/noopkat">Suz Hinton&lt;/a> talks with &lt;a href="https://twitter.com/burkeholland">Burke&lt;/a> about &lt;a href="https://googoo.com">Goo Goo Clusters&lt;/a> and IoT devices.&lt;/p>
&lt;a href="https://googoo.com">
&lt;div class="image-div" style="max-width:400px;">
&lt;p>&lt;img src="goo-goo-cluster-logo.png" alt="Goo Goo clusters logo">&lt;/p>
&lt;/div>
&lt;/a>
&lt;p>One of the devices Suz showed was the &lt;a href="https://microsoft.github.io/azure-iot-developer-kit/">Azure IoT DevKit&lt;/a> - an arduino compatible board made by &lt;a href="http://mxchip.com/az3166">MXChip&lt;/a> that works beautifully with Azure, even down to having an Azure LED on board to show when it is connected. This is a great little board with a whole load of sensors and other gubbins built in.&lt;/p>
&lt;div class="image-div" style="max-width:400px;">
&lt;p>&lt;img src="IMG_3002-1.JPG" alt="My MXChip board">&lt;/p>
&lt;/div>
&lt;p>I have one of these boards thanks to Suz, so I thought it would be a good opportunity to get it out again and see how easy it would be to get my phone to control the board via Azure, with the eventual goal of doing some kind of holiday hack such as using it to control Christmas lights.&lt;/p>
&lt;h3 id="getting-started-with-the-iot-devkit">Getting started with the IoT DevKit&lt;/h3>
&lt;ul>
&lt;li>Buy one! Lots of links here - &lt;a href="http://mxchip.com/az3166">http://mxchip.com/az3166&lt;/a>. These boards are around $40 so not too expensive - maybe put one on your Christmas list.&lt;/li>
&lt;li>Follow the first part of the &lt;a href="https://github.com/Microsoft/vscode-iot-workbench/blob/master/docs/iot-devkit/devkit-get-started.md">Getting Started&lt;/a> guide to &lt;a href="https://github.com/Microsoft/vscode-iot-workbench/blob/master/docs/iot-devkit/devkit-get-started.md#prepare-your-hardware">prepare your hardware&lt;/a>, &lt;a href="https://github.com/Microsoft/vscode-iot-workbench/blob/master/docs/iot-devkit/devkit-get-started.md#configure-wi-fi">configure WiFi&lt;/a> and &lt;a href="https://github.com/Microsoft/vscode-iot-workbench/blob/master/docs/iot-devkit/devkit-get-started.md#install-development-environment">install the development environment&lt;/a>.&lt;/li>
&lt;li>Sign up for an Azure account. If you don&amp;rsquo;t already have an Azure account, you will need to sign up for one. There is a free tier that at the time of writing gives US$200 for the first 30 days, loads of services for free for 12 months, and a range of services free forever. You can sign up &lt;a href="https://aka.ms/FreeAz">for the free tier here&lt;/a>!&lt;/li>
&lt;/ul>
&lt;p>Once done your board will be ready to program.&lt;/p>
&lt;h3 id="controlling-the-board-from-the-cloud">Controlling the board from the cloud&lt;/h3>
&lt;p>My plan is to build an app where I can set a color and have the LED on the board match that color. The architecture I want is something like this:&lt;/p>
&lt;div class="image-div" style="max-width:600px;">
&lt;p>&lt;img src="Sketch.png" alt="Architecture of the app - a mobile device with RGB sliders talking to An Azure Functions back end via REST talking somehow to the IoT device">&lt;/p>
&lt;/div>
&lt;p>Part of this is easy - a mobile app talking to an Azure Functions back end over a REST API. The new bit for me is the big &lt;strong>?&lt;/strong>, the bit where the IoT device talks to the back end.&lt;/p>
&lt;h4 id="azure-iot">Azure IoT&lt;/h4>
&lt;p>Azure has some great services for managing IoT devices, all based around &lt;a href="https://docs.microsoft.com/azure/iot-hub/?WT.mc_id=mxchip-blog-jabenn">IoT Hub&lt;/a>. IoT Hub is a managed service that provides a central resource for two-way communication with IoT devices. You can register devices in the hub, configure them individually or en-masse, send and receive data using standard messaging protocols like &lt;a href="http://mqtt.org">MQTT&lt;/a>, or manage the devices including updating firmware.&lt;/p>
&lt;p>One feature that it also supports is &lt;a href="https://docs.microsoft.com/azure/iot-hub/iot-hub-devguide-device-twins/?WT.mc_id=mxchip-blog-jabenn">device twins&lt;/a>.&lt;/p>
&lt;div class="image-div" style="max-width:400px;">
&lt;p>&lt;img src="frank-mckenna-720261-unsplash.jpg" alt="Stock photo of some twins">&lt;/p>
&lt;/div>
&lt;p>Device twins are JSON documents that store information such as state or configuration. These exist on both the device and the Azure IoT hub and are kept in sync, so if you update a value on the device it syncs to the cloud and vice versa. This is perfect for my app - I can encode the RGB value for the LED into a device twin and update it from my Azure function. This update will then be pushed to the device where it can be parsed and the LED color changed to match.&lt;/p>
&lt;blockquote>
&lt;p>If you want to see this in action, then there is a great demo project available &lt;a href="https://github.com/Microsoft/vscode-iot-workbench/blob/master/docs/iot-devkit/devkit-state.md">here&lt;/a> that creates a web site that can turn the LED on/off and set the color. It doesn&amp;rsquo;t go into how it works, just shows you that it does so I thought it would be more fun to try to build it myself. The rest of this post covers how I did it instead of just following this walkthrough.&lt;/p>
&lt;/blockquote>
&lt;h4 id="creating-an-iot-hub">Creating an IoT hub&lt;/h4>
&lt;p>The first thing I needed to do was to create an IoT workbench project and set up the IoT hub and device. This can be done from inside VSCode using the &lt;a href="https://marketplace.visualstudio.com/items?itemName=vsciot-vscode.vscode-iot-workbench&amp;amp;WT.mc_id=mxchip-blog-jabenn">Azure IoT Workbench extension&lt;/a>. Launch VSCode, then plug in the IoT Dev Kit.&lt;/p>
&lt;p>To create a new IoT workbench project:&lt;/p>
&lt;ul>
&lt;li>Launch the command palette and select &lt;strong>IoT Workbench: New&lt;/strong>.&lt;/li>
&lt;li>Give it a folder to create the project in&lt;/li>
&lt;li>Give the project a name&lt;/li>
&lt;li>Select the IoT DevKit device.&lt;/li>
&lt;li>Create a project with an Azure IoT Hub&lt;/li>
&lt;li>Use the default sketch file name (sketch files are C code files that are run on the IoT device)&lt;/li>
&lt;/ul>
&lt;p>Once the project has been created, the IoT hub needs to be created and the device needs to be registered with the hub. Again, this can be done from inside VS Code.&lt;/p>
&lt;ul>
&lt;li>Launch the command palette and select &lt;strong>IoT Workbench: Cloud&lt;/strong>&lt;/li>
&lt;li>Select &lt;strong>Azure Provision&lt;/strong>&lt;/li>
&lt;li>Select a subscription, signing into Azure if necessary&lt;/li>
&lt;li>Create a new resource group or select an existing one&lt;/li>
&lt;li>Create a new IoT Hub in a location near you&lt;/li>
&lt;li>Select the &lt;em>F1&lt;/em> free tier. If you already have a free tier set up for another project then use an &lt;em>S&lt;/em> tier - the &lt;em>B&lt;/em> tiers don&amp;rsquo;t support device twins, and the &lt;em>F1&lt;/em> tier acts like an &lt;em>S&lt;/em> tier but with limits on messages.&lt;/li>
&lt;li>Give the IoT Hub a name - this will need to be globally unique across Azure.&lt;/li>
&lt;li>The IoT Hub will now be provisioned, and this will take a few minutes to complete.&lt;/li>
&lt;/ul>
&lt;p>Once the Hub has been provisioned, the device will need to be provisioned, and this step will start automatically once the Hub has been created.&lt;/p>
&lt;ul>
&lt;li>Create a new IoT device&lt;/li>
&lt;li>Give the device a name. Each device will need to have a unique name in the IoT hub.&lt;/li>
&lt;/ul>
&lt;p>Once done you will be able to navigate to your IoT Hub in the &lt;a href="https://portal.azure.com/?WT.mc_id=mxchip-blog-jabenn">Azure Portal&lt;/a> and see your device.&lt;/p>
&lt;div class="image-div" style="max-width:400px;">
&lt;p>&lt;img src="2018-11-16_14-41-56.png" alt="The IoT device shown in the IoT Hub in the Azure portal">&lt;/p>
&lt;/div>
&lt;p>Finally the IoT device needs to know the connection string so that it can connect to the IoT Hub.&lt;/p>
&lt;ul>
&lt;li>Put the IoT device into configuration mode by holding the &lt;strong>A&lt;/strong> button on the device, tapping the &lt;strong>Reset&lt;/strong> button, then releasing the &lt;strong>A&lt;/strong> button.&lt;/li>
&lt;/ul>
&lt;div class="image-div" style="max-width:400px;">
&lt;p>&lt;img src="IMG_9124.jpg" alt="The A and reset buttons on the IoT device">&lt;/p>
&lt;/div>
&lt;ul>
&lt;li>From the command palette select &lt;strong>IoT Workbench: Device&lt;/strong>&lt;/li>
&lt;li>Select &lt;strong>Config Device Settings&lt;/strong>&lt;/li>
&lt;li>Select &lt;strong>Config Device Connection String&lt;/strong>&lt;/li>
&lt;li>Select &lt;strong>Select IoT Hub Device Connection String&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>A notification will pop up once done. The IoT device can then be rebooted by disconnecting and re-connecting it, and when it&amp;rsquo;s booted it will be connected to the IoT Hub, as indicated by the blue Azure LED being lit.&lt;/p>
&lt;div class="image-div" style="max-width:400px;">
&lt;p>&lt;img src="IMG_5787.JPG" alt="The Azure LED lit up">&lt;/p>
&lt;/div>
&lt;h4 id="adding-code-to-handle-the-device-twin">Adding code to handle the device twin&lt;/h4>
&lt;p>The device is configured, so now it needs some code to detect updates to the device twin and update the LED color.&lt;/p>
&lt;p>The code for this is &lt;a href="https://github.com/jimbobbennett/IoTLedColorChanger/blob/master/DevKit/Device/device.ino">here&lt;/a>. Copy this code into the sketch file in the IoT project (the &lt;code>.ino&lt;/code> file). The interesting parts of this code are the &lt;code>setup&lt;/code> and &lt;code>loop&lt;/code> methods.&lt;/p>
&lt;h6 id="the-setup-method">The setup method&lt;/h6>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-c" data-lang="c">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">void&lt;/span> &lt;span style="color:#a6e22e">setup&lt;/span>()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">DevKitMQTTClient_Init&lt;/span>(true);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">DevKitMQTTClient_SetDeviceTwinCallback&lt;/span>(DeviceTwinCallback);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The &lt;a href="https://www.arduino.cc/en/Reference/Setup?setlang=en">&lt;code>setup&lt;/code> method&lt;/a> is a special method that is called every time the device starts up or is rest. This method is used to initialize things, such as the WiFi and connectivity to IoT Hub.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>The &lt;code>DevKitMQTTClient_Init&lt;/code> call initializes the MQTT client to connect to Azure IoT Hub.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The call to &lt;code>DevKitMQTTClient_SetDeviceTwinCallback&lt;/code> sets up a callback for any updates to the device twin on the IoT Hub. In the &lt;code>DeviceTwinCallback&lt;/code> function, the JSON payload is parsed looking for one of these values:&lt;/p>
&lt;ul>
&lt;li>&lt;code>&amp;quot;rgbLEDR&amp;quot;&lt;/code> - The red value for the LED from 0 to 255&lt;/li>
&lt;li>&lt;code>&amp;quot;rgbLEDG&amp;quot;&lt;/code> - The Green value for the LED from 0 to 255&lt;/li>
&lt;li>&lt;code>&amp;quot;rgbLEDB&amp;quot;&lt;/code> - The Blue value for the LED from 0 to 255&lt;/li>
&lt;/ul>
&lt;p>Once these values are found they are stored in global variables.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h6 id="the-loop-method">The loop method&lt;/h6>
&lt;p>The other method of interest is the &lt;a href="https://www.arduino.cc/en/Reference/Loop?setlang=en">&lt;code>loop&lt;/code> method&lt;/a>. This method is a special one that is called repeatedly by the OS on a loop. This method sets up the LED based on the on/off and RGB values stored in the global variables then applies these to the LED. It then sleeps for a bit and loops again.&lt;/p>
&lt;h6 id="deploying-the-code">Deploying the code&lt;/h6>
&lt;p>Once you&amp;rsquo;ve added the code, it needs to be deployed to the device:&lt;/p>
&lt;ul>
&lt;li>Select &lt;strong>IoT Workbench: Device&lt;/strong> from the command palette&lt;/li>
&lt;li>Select &lt;strong>Device Upload&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>The code will be compiled, uploaded to the device, and the device will reboot. After rebooting it will be ready to sync data using the device twin.&lt;/p>
&lt;blockquote>
&lt;p>Once the code has been deployed, the IoT device can be unplugged from your computer and connected to another power supply if needed. The connection to a computer is only needed for configuration and uploading code, when running it just needs power through the USB port, nothing else.&lt;/p>
&lt;/blockquote>
&lt;h4 id="testing-out-the-device-twin">Testing out the device twin&lt;/h4>
&lt;p>Once the device reboots, it will start listening to updates to the device twin. The device twin can be updated in code, but a simple way to get started is using the &lt;a href="https://portal.azure.com/?WT.mc_id=mxchip-blog-jabenn">Azure portal&lt;/a>.&lt;/p>
&lt;p>From inside the portal:&lt;/p>
&lt;ul>
&lt;li>Open up the newly created IoT hub&lt;/li>
&lt;li>Select &lt;em>Explorers-&amp;gt;IoT devices&lt;/em>&lt;/li>
&lt;li>Select the IoT device from the list&lt;/li>
&lt;li>Select &lt;strong>Device twin&lt;/strong> from the menu across the top&lt;/li>
&lt;/ul>
&lt;div class="image-div" style="max-width:400px;">
&lt;p>&lt;img src="2018-11-19_12-25-50.png" alt="The Device Twin menu item">&lt;/p>
&lt;/div>
&lt;p>This will show the device twin JSON document in an editor. This document can be updated, and once the update is saved it will be sent to the device. To turn the LED on on the IoT device, values for &lt;code>rgbLEDR&lt;/code>, &lt;code>rgbLEDG&lt;/code> and &lt;code>rgbLEDB&lt;/code> need to be added to the existing &lt;em>properties-&amp;gt;desired&lt;/em> node in the JSON document:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-json" data-lang="json">&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#960050;background-color:#1e0010">...&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;properties&amp;#34;&lt;/span>: {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;desired&amp;#34;&lt;/span>: {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;rgbLEDR&amp;#34;&lt;/span>: &lt;span style="color:#ae81ff">0&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;rgbLEDG&amp;#34;&lt;/span>: &lt;span style="color:#ae81ff">255&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;rgbLEDB&amp;#34;&lt;/span>: &lt;span style="color:#ae81ff">0&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#960050;background-color:#1e0010">...&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Once these values are added and the document saved, the LED will light up in bright green. Then changing these values will cause the LED to change color.&lt;/p>
&lt;div class="image-div" style="max-width:400px;">
&lt;p>&lt;img src="IMG_9194-1.jpg" alt="The LED lit up in green">
&lt;img src="IMG_9195-1.jpg" alt="The LED lit up in red">&lt;/p>
&lt;/div>
&lt;h4 id="updating-the-device-twins-from-an-azure-function">Updating the device twins from an Azure function&lt;/h4>
&lt;p>The device is working, so the next step is to create a back end that can be called from a mobile app to update the device twin. For this I&amp;rsquo;m going to use an Azure Function. This will be an HTTP trigger that listens for a POST with a body containing JSON with values for &lt;code>red&lt;/code>, &lt;code>green&lt;/code> and &lt;code>blue&lt;/code>. This JSON will be parsed and the values used to update the digital twin:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-json" data-lang="json">&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;red&amp;#34;&lt;/span> : &lt;span style="color:#ae81ff">0&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;green&amp;#34;&lt;/span> : &lt;span style="color:#ae81ff">0&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;blue&amp;#34;&lt;/span> : &lt;span style="color:#ae81ff">255&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>To help with Azure IoT projects, there is a &lt;a href="https://www.nuget.org/packages/Microsoft.Azure.Devices/">Microsoft.Azure.Devices&lt;/a> NuGet package. This contains a &lt;code>RegistryManager&lt;/code> class that can be used to manage devices, and this &lt;code>RegistryManager&lt;/code> is created using a connection string for the IoT Hub.&lt;/p>
&lt;p>Each IoT Hub can have multiple connection strings, all based around their different &lt;a href="https://docs.microsoft.com/azure/iot-hub/iot-hub-devguide-security#access-control-and-permissions/?WT.mc_id=mxchip-blog-jabenn">permissions&lt;/a>. To control a device twin you need these &lt;a href="https://docs.microsoft.com/azure/iot-hub/iot-hub-devguide-security#iot-hub-permissions/?WT.mc_id=mxchip-blog-jabenn">permissions&lt;/a>:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Registry Read&lt;/strong> - Allows reading from the IoT registry&lt;/li>
&lt;li>&lt;strong>Service Connect&lt;/strong> - Allows connections to the IoT Hub to manage devices and setting, this is designed for services to connect, as opposed to devices connecting.&lt;/li>
&lt;/ul>
&lt;p>From inside the portal:&lt;/p>
&lt;ul>
&lt;li>Open up the newly created IoT hub&lt;/li>
&lt;li>Select &lt;em>Settings-&amp;gt;Shared access policies&lt;/em>&lt;/li>
&lt;li>Click &lt;strong>+ Add&lt;/strong> to create a new shared access policy, call it &lt;em>Twin&lt;/em> and allow &lt;em>Registry Read&lt;/em> and &lt;em>Service Connect&lt;/em>&lt;/li>
&lt;li>Save this, and copy one of the connection strings using the &lt;strong>Copy&lt;/strong> button next to it&lt;/li>
&lt;/ul>
&lt;div class="image-div" style="max-width:300px;">
&lt;p>&lt;img src="2018-11-19_14-17-57.png" alt="Configuring a new shared access policy">&lt;/p>
&lt;/div>
&lt;p>Once the connection string has been created it can be used to create the &lt;code>RegistryManager&lt;/code>, ideally by setting this in the function app settings.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> connectionString = Environment.GetEnvironmentVariable(&lt;span style="color:#e6db74">&amp;#34;iotHubConnectionString&amp;#34;&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> registryManager = RegistryManager.CreateFromConnectionString(connectionString);
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The device twin can then be retrieved using the &lt;code>RegistryManager&lt;/code> and the name of the IoT device that was used when it was registered in the Hub (again ideally as a setting):&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> deviceName = Environment.GetEnvironmentVariable(&lt;span style="color:#e6db74">&amp;#34;iotHubDevice&amp;#34;&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> twin = &lt;span style="color:#66d9ef">await&lt;/span> registryManager.GetTwinAsync(deviceName);
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This twin can then be updated by passing a JSON string containing a patch to apply, and the values in the patch are applied to the twin. In this case, the &lt;code>rgbLEDR&lt;/code>, &lt;code>rgbLEDG&lt;/code> and &lt;code>rgbLEDB&lt;/code> values need to be added to the &lt;code>desired&lt;/code> node in the &lt;code>properties&lt;/code> node, and this can be done by creating an anonymous type with the right names and serializing it to JSON.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> patch = &lt;span style="color:#66d9ef">new&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> properties = &lt;span style="color:#66d9ef">new&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> desired = &lt;span style="color:#66d9ef">new&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> rgbLEDR = red,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> rgbLEDG = green,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> rgbLEDB = blue,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>};
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> jsonPatch = JsonConvert.SerializeObject(patch);
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This patch is then used to update the twin:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">await&lt;/span> registryManager.UpdateTwinAsync(twin.DeviceId, jsonPatch, twin.ETag);
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>That&amp;rsquo;s all that is needed to update the twin. The full code for this function is available &lt;a href="https://github.com/jimbobbennett/IoTLedColorChanger/blob/master/BackEnd/IotLedColorChanger.Functions/IoTFunctions.cs">here&lt;/a>. To test this out:&lt;/p>
&lt;ul>
&lt;li>Set the appropriate values for the connection string and device hub in the &lt;code>local.settings.json&lt;/code> file&lt;/li>
&lt;li>Run the function app using the local functions host&lt;/li>
&lt;li>Post a JSON document to the function using a tool such as &lt;a href="https://www.getpostman.com/apps">Postman&lt;/a>&lt;/li>
&lt;li>The LED will change color based on the JSON that was posted&lt;/li>
&lt;/ul>
&lt;p>Once the function is running, it can be deployed to Azure so that it can be called from a mobile app. Once deployed, the application settings will need to be set for the IoT Hub connection string and device name. This function can then be called by a tool like Postman to verify it is working.&lt;/p>
&lt;h4 id="building-the-mobile-app">Building the mobile app&lt;/h4>
&lt;p>The mobile app is pretty simple - three sliders and a button. Use the sliders to set RGB values, the button changes color as they slide, and when you tap the button it sends the RGB value to the back end. I built the app using &lt;a href="https://github.com/fsprojects/Fabulous">Fabulous&lt;/a>, a F# MVU architecture that sits on top of &lt;a href="https://visualstudio.microsoft.com/xamarin/?WT.mc_id=mxchip-blog-jabenn">Xamarin&lt;/a>. The code for this is pretty simple, with the values from the sliders being passed to an &lt;code>HTTP.AsyncRequest&lt;/code> from &lt;a href="http://fsharp.github.io/FSharp.Data/index.html">FSharp.Data&lt;/a>. This calls the Azure Functions back end to update the device twin.&lt;/p>
&lt;p>Here&amp;rsquo;s the app running in all it&amp;rsquo;s glory!&lt;/p>
&lt;div class="image-div" style="max-width:500px;">
&lt;p>&lt;img src="Running.gif" alt="">&lt;/p>
&lt;/div>
&lt;h4 id="summary">Summary&lt;/h4>
&lt;p>This post showed how to control the LED on an MXChip board using Azure device twins.&lt;/p>
&lt;p>All the code for this is on my &lt;a href="https://github.com/jimbobbennett/IoTLedColorChanger">GitHub&lt;/a>.&lt;/p>
&lt;p>Here&amp;rsquo;s some further reading:&lt;/p>
&lt;ul>
&lt;li>Learn more about the Azure IoT hub &lt;a href="https://azure.microsoft.com/services/iot-hub/?WT.mc_id=mxchip-blog-jabenn">here&lt;/a>&lt;/li>
&lt;li>&lt;a href="http://mxchip.com/az3166">Places to buy an MXChip board&lt;/a>&lt;/li>
&lt;li>Microsoft.Azure.Devices API docs: &lt;a href="https://docs.microsoft.com/dotnet/api/overview/azure/iot/client/?WT.mc_id=mxchip-blog-jabenn">docs.microsoft.com&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/fsprojects/Fabulous">Fabulous getting started guide&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://googoo.com">Goo Goo Clusters&lt;/a> - feel free to buy me some!&lt;/li>
&lt;/ul></description></item><item><title>Azure makers series</title><link>https://jimbobbennett.dev/blogs/azure-makers-series/</link><pubDate>Wed, 14 Nov 2018 17:09:50 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/azure-makers-series/</guid><description>&lt;p>I recently recorded a quick video to talk about an app I was building using the &lt;a href="https://azure.microsoft.com/free/?WT.mc_id=azurefree-blog-jabenn">Azure free account&lt;/a>. You can check it out here:&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/ejVtdb57Y5Y" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;br>
&lt;p>If you want to see the code, it&amp;rsquo;s in my GitHub repo here - &lt;a href="https://github.com/jimbobbennett/AzurePhotoSharer">https://github.com/jimbobbennett/AzurePhotoSharer&lt;/a>&lt;/p></description></item><item><title>Trust</title><link>https://jimbobbennett.dev/blogs/trust-2/</link><pubDate>Tue, 13 Nov 2018 18:11:34 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/trust-2/</guid><description>&lt;p>Thought I&amp;rsquo;d repost a blog post I wrote 4 1/2 years ago on Medium onto this blog - be interested in what readers think.&lt;/p>
&lt;h3 id="shouldnt-our-default-position-be-to-trust-first">Shouldn’t our default position be to trust first?&lt;/h3>
&lt;p>I was having a conversation with a friend of mine recently about his current work situation. His team leader has a default state of not trusting in the knowledge and abilities of the team. Systems are locked down so only the team leader can access them, decisions are made by said leader and bypass the knowledge, skills and abilities of the team. This was raised up the chain by one of his co workers only to be told to spend time earning that trust (despite already being there for a while). This has made for an unhappy team with one already leaving and a few more making plans in that direction.&lt;/p>
&lt;p>This is a very different model to how I like to run teams. I want to have a team working with me where I can trust in the skills of every member — instead of locking them out I open everything up to them. If they lack the right skills, instead of blocking them from doing a task I’d rather work with them to help them learn how to do it. Put them in a place where they can learn through self discovery, learn through failure with a guiding hand to help them succeed next time. I find this makes for a very cohesive team, everyone feels valued, they matter to the success of the team and they feel their skills growing. To quote Peopleware by Tom DeMarco and Timothy Lister “Once you have decided to go with a certain group, your best tactic is to trust them … People who feel untrusted have little inclination to bond together into a cooperative team”&lt;/p>
&lt;p>I feel very comfortable with my model. I always try my hardest to ensure that I interview thoroughly so that I know what my new hires can and can’t do. I also spend time with the team on a one to one basis to constantly get and give feedback on how they are doing as a team member and I am doing as their team lead. This constant cycle of information allows me to know when to sit back and leave them to it, or sit with them and help guide. And if I find someone on the team who cannot be trusted despite all efforts? Sorry — they’re out. Harsh, but fairer to the team as a whole. One bad apple should not ruin the success of the rest of the team.&lt;/p>
&lt;p>To me, trust in the workplace is earned in the interview and cemented by doing good work, not something that still has to be earned by someone who has already been through extensive interviews, worked for the company for a number of months and is delivering on target. This is the same as how we live our lives. We sit on a chair because we trust it won’t break on us (unless our initial assessment of the chair shows it’s already broken), we eat food and trust it won’t kill us (unless it already smells bad), we fall in love trusting that our partners will be faithful, only removing that trust if they show otherwise.&lt;/p>
&lt;p>Trust is good. My advice to my friend — go somewhere where you are trusted.&lt;/p></description></item><item><title>Debugging multiple Azure Functions apps at the same time</title><link>https://jimbobbennett.dev/blogs/debugging-multiple-azure-functions-apps-at-the-same-time/</link><pubDate>Tue, 13 Nov 2018 17:52:15 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/debugging-multiple-azure-functions-apps-at-the-same-time/</guid><description>&lt;p>&lt;strong>Dentists don&amp;rsquo;t want you to know these 5 tips that show how easy it is to run multiple Azure Functions apps locally and debug them all at the same time!&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Number 3 will shock you!&lt;/strong>&lt;/p>
&lt;div class="image-div" style="max-width:250px;">
&lt;p>&lt;img src="andre-guerra-676198-unsplash.jpg" alt="Stock photo of a surprised child - probably surprised at the pointless clickbait title at the top of this post">&lt;/p>
&lt;/div>
&lt;p>Enough ClickBait nonsense, on to the post.&lt;/p>
&lt;p>I recently built a &lt;a href="https://github.com/jimbobbennett/AzurePhotoSharer">demo app&lt;/a> that has two Azure Functions projects in it - one using the new V2 Functions runtime and written in C#, and one using the old V1 runtime so that it can access some .NET framework bits and written in F#.&lt;/p>
&lt;p>One of the really cool features that Azure Functions offers is the ability to &lt;a href="https://docs.microsoft.com/azure/azure-functions/functions-develop-local/?WT.mc_id=debugfunctionslocally-blog-jabenn">run your functions locally&lt;/a> with a full debugging experience, and this is supported in Visual Studio 2017 as well as VSCode.&lt;/p>
&lt;blockquote>
&lt;p>This post focuses on how to do this in VS2017. For VSCode, follow &lt;a href="https://code.visualstudio.com/tutorials/functions-extension/run-app/?WT.mc_id=debugfunctionslocally-blog-jabenn">these instructions&lt;/a>.&lt;/p>
&lt;/blockquote>
&lt;p>This post looks at:&lt;/p>
&lt;ul>
&lt;li>Debugging &lt;a href="#OneApp">one function app&lt;/a>&lt;/li>
&lt;li>How to run &lt;a href="#ManyApps">multiple function apps&lt;/a> at the same time&lt;/li>
&lt;li>How to &lt;a href="#DebugManyApps">debug multiple functions apps&lt;/a> at the same time using Visual Studio 2017&lt;/li>
&lt;/ul>
&lt;a id="OneApp">
&lt;h4 id="debugging-one-function-app">Debugging one Function app&lt;/h4>
&lt;/a>
&lt;p>This is easy to try out yourself, just create a new Azure Functions app in Visual Studio, add a breakpoint in the HTTP trigger then start debugging. The Azure Function app will launch in a local functions host, and your trigger will be available locally on &lt;code>http://localhost:7071/api/Function1&lt;/code> - so listening on port &lt;code>7071&lt;/code>. You can launch your favorite browser, navigate to this URL and your breakpoint will be hit, giving a full debugging experience with watch, edit and continue and all the normal bells and whistles.&lt;/p>
&lt;p>Create one of these:&lt;/p>
&lt;div class="image-div" style="max-width:600px;">
&lt;p>&lt;img src="2018-11-13_13-53-20.png" alt="Creating a new Azure Functions project from the Visual C#-&amp;gt;Cloud section of the File-&amp;gt;New dialog">&lt;/p>
&lt;/div>
&lt;p>Use these settings (V2, HTTP Trigger, Anonymous):&lt;/p>
&lt;div class="image-div" style="max-width:600px;">
&lt;p>&lt;img src="2018-11-13_13-54-12.png" alt="Configuring the Azure Function to use V2, an HTTP trigger with anonymous access rights">&lt;/p>
&lt;/div>
&lt;p>Stick a break point in the function:&lt;/p>
&lt;div class="image-div" style="max-width:600px;">
&lt;p>&lt;img src="2018-11-13_13-56-31.png" alt="Adding a breakpoint to line 22">&lt;/p>
&lt;/div>
&lt;p>Start debugging the function the same way as any normal app (you may need to grant firewall access). This will launch a console window with the functions host running - you&amp;rsquo;ll see some cool ASCII art then the functions output including the HTTP URLs for all HTTP triggers:&lt;/p>
&lt;div class="image-div" style="max-width:600px;">
&lt;p>&lt;img src="2018-11-13_14-00-39.png" alt="The functions app running in a console window">&lt;/p>
&lt;/div>
&lt;p>Now launch your favorite browser and navigate to the Function1 URL. The function will run and your breakpoint will be hit. This is a full debug session with edit and continue:&lt;/p>
&lt;div class="image-div" style="max-width:600px;">
&lt;p>&lt;img src="2018-11-13_14-02-14.png" alt="The breakpoint being hit">&lt;/p>
&lt;/div>
&lt;p>Click &lt;strong>Continue&lt;/strong> and see the output of the function in your browser:&lt;/p>
&lt;div class="image-div" style="max-width:600px;">
&lt;p>&lt;img src="2018-11-13_14-12-18.png" alt="The function output in your browser">&lt;/p>
&lt;/div>
&lt;blockquote>
&lt;p>There is also a storage emulator that you can run locally so you can read/write to blobs, tables and queues and even use triggers. Read more &lt;a href="https://docs.microsoft.com/azure/storage/common/storage-use-emulator/?WT.mc_id=debugfunctionslocally-blog-jabenn">here&lt;/a>.&lt;/p>
&lt;/blockquote>
&lt;a id="ManyApps">
&lt;h4 id="running-multiple-function-apps-at-the-same-time">Running multiple Function apps at the same time&lt;/h4>
&lt;/a>
&lt;p>Running one function app locally is cool, running multiple is even cooler!&lt;/p>
&lt;div class="image-div" style="max-width:600px;">
&lt;p>&lt;img src="2018-11-13_14-12-18-1.png" alt="Stock photo of a cool looking rubber duck - cos why not!">&lt;/p>
&lt;/div>
&lt;p>Add a new function app to your project, then run it without debugging using &lt;em>Debug-&amp;gt;Start without debugging&lt;/em>. This will spin up the local Azure Functions host and start listening on port &lt;code>7071&lt;/code>.&lt;/p>
&lt;p>Now the beady-eyed amongst you will notice this is the same port as the first functions app. By default the local functions host listens for HTTP requests on port &lt;code>7071&lt;/code>, so if you now launch the first functions app it will fail - with a really weird error:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>Cannot access a disposed object.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Object name: &lt;span style="color:#e6db74">&amp;#39;IServiceProvider&amp;#39;&lt;/span>.
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="image-div" style="max-width:400px;">
&lt;p>&lt;img src="2018-11-13_15-17-57.png" alt="The error shown when multiple local functions hosts run on the same port.">&lt;/p>
&lt;/div>
&lt;p>The fix for this is to tell the functions host to run on a different port, and this can be done by adding arguments to the command line that is run when the function app is debugged. Kill all the functions hosts, and open the properties for the second function app. Head to the &lt;strong>Debug&lt;/strong> tab, and set the &lt;em>Application arguments&lt;/em> to be:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>host start --pause-on-error --port &lt;span style="color:#ae81ff">5860&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This will start the functions host listening on &lt;code>port 5860&lt;/code>. You can use any port you wish for this of course.&lt;/p>
&lt;blockquote>
&lt;p>These settings are not saved in the project itself, just in your user settings so this won&amp;rsquo;t be in source control.&lt;/p>
&lt;/blockquote>
&lt;p>Now if you run the second function app it will be listening on a different port:&lt;/p>
&lt;div class="image-div" style="max-width:600px;">
&lt;p>&lt;img src="2018-11-13_15-25-31.png" alt="The Azure Functions local host running on port 5860">&lt;/p>
&lt;/div>
&lt;a id="DebugManyApps">
&lt;h4 id="debugging-multiple-function-apps-in-vs2017">Debugging multiple function apps in VS2017&lt;/h4>
&lt;/a>
&lt;p>Running multiple is good, but debugging them is even gooderer!&lt;/p>
&lt;div class="image-div" style="max-width:600px;">
&lt;p>&lt;img src="rawpixel-974535-unsplash.jpg" alt="Bad stock photo of people high-fiving">&lt;/p>
&lt;/div>
&lt;p>Although Visual Studio 2017 can&amp;rsquo;t launch multiple apps at the same time, you can launch one then attach to the others. To do this:&lt;/p>
&lt;ul>
&lt;li>Put break points in the HTTP triggers for both function apps&lt;/li>
&lt;li>Start the first function app without debugging&lt;/li>
&lt;li>Start the second function app through the debugger&lt;/li>
&lt;li>Attach the debugger to the first function app:
&lt;ul>
&lt;li>Select &lt;em>Debug-&amp;gt;Attach to process&amp;hellip;&lt;/em>&lt;/li>
&lt;li>Search for &lt;em>func&lt;/em>&lt;/li>
&lt;li>One &lt;code>func.exe&lt;/code> process will be greyed out - this is the one that is currently running through the debugger. Select the other one and click &lt;strong>Attach&lt;/strong>.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;div class="image-div" style="max-width:600px;">
&lt;p>&lt;img src="2018-11-13_15-39-25.png" alt="Finding the func process in the attach dialog">&lt;/p>
&lt;/div>
&lt;p>You should now be able to open &lt;code>http://localhost:7071/api/Function1&lt;/code> in your browser and hit the breakpoint in your first function app, and open &lt;code>http://localhost:5860/api/Function1&lt;/code> to hit the breakpoint in the second function app.&lt;/p>
&lt;blockquote>
&lt;p>You don&amp;rsquo;t get edit and continue in the function app you attached to, only in the one run through the original debugger. If you want edit and continue make sure the function app you want to use this for is run through the debugger, and attach to the others.&lt;/p>
&lt;/blockquote>
&lt;hr>
&lt;p>Want to learn more about Azure Functions? Well we have a learning path for that as part of &lt;a href="https://docs.microsoft.com/learn/?WT.mc_id=debugfunctionslocally-blog-jabenn">Microsoft Learn&lt;/a>. Check it out &lt;a href="https://docs.microsoft.com/learn/paths/create-serverless-applications/?WT.mc_id=debugfunctionslocally-blog-jabenn">here&lt;/a>.&lt;/p>
&lt;div class="image-div" style="max-width:150px;">
&lt;a href="https://docs.microsoft.com/learn/paths/create-serverless-applications/?WT.mc_id=debugfunctionslocally-blog-jabenn">
&lt;p>&lt;img src="create-serverless-applications.svg" alt="Create serverless applications learning path icon">&lt;/p>
&lt;/a>
&lt;/div></description></item><item><title>Updating your google-service.json from an AppCenter environment variable</title><link>https://jimbobbennett.dev/blogs/updating-your-google-service-json-from-an-appcenter-environment-variable/</link><pubDate>Tue, 25 Sep 2018 14:15:50 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/updating-your-google-service-json-from-an-appcenter-environment-variable/</guid><description>&lt;p>I&amp;rsquo;ve been working on an app that needs push notifications, but also needs to be open source. This led me to a problem - the &lt;code>google-services.json&lt;/code> file. This file is needed to sign up for Firebase messaging to implement push on Android, but it also contains my API keys, values I do &lt;strong>NOT&lt;/strong> want to be public.&lt;/p>
&lt;p>So - what to do?&lt;/p>
&lt;p>Well I&amp;rsquo;m building and distributing my app using &lt;a href="https://appcenter.ms/?WT.mc_id=appcenter-blog-jabenn">AppCenter&lt;/a> and the build configuration contains a couple of useful settings that I can take advantage of - &lt;a href="https://docs.microsoft.com/en-gb/appcenter/build/custom/scripts/?WT.mc_id=appcenter-blog-jabenn">build scripts&lt;/a> and &lt;a href="https://docs.microsoft.com/en-gb/appcenter/build/custom/variables/?WT.mc_id=appcenter-blog-jabenn">environment variables&lt;/a>.&lt;/p>
&lt;p>I can define the contents of my &lt;code>google-services.json&lt;/code> file inside an environment variable, add a dummy version to my GitHub repo, then overwrite the dummy one with the environment variable at build time. This means my secrets are safe, and the real value is protected using my AppCenter account. I can then also use the right version locally by excluding updates to this file from git as &lt;a href="https://jimbobbennett.dev/blogs/hiding-api-keys-from-git/">I&amp;rsquo;ve described before&lt;/a>.&lt;/p>
&lt;p>This works not only for an open source project, but if I wanted to have different settings for different builds (such as different push end points for QA or beta builds).&lt;/p>
&lt;h4 id="check-a-dummy-google-servicesjson-file-into-source-control">Check a dummy &lt;code>google-services.json&lt;/code> file into source control&lt;/h4>
&lt;p>Add the &lt;code>google-services.json&lt;/code> file to your project as normal. Blank out the file and add it to git. Revert the blanked out file and hide updates from git using:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>git update-index --assume-unchanged ./google-services.json
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Run this from the root of your Android app.&lt;/p>
&lt;h4 id="define-the-environment-variable">Define the environment variable&lt;/h4>
&lt;p>From the &lt;strong>Build configuration&lt;/strong> tab of your build in AppCenter, turn on &lt;strong>Environment variables&lt;/strong>. Add a new variable called &lt;code>GOOGLE_JSON&lt;/code> and paste in the contents of your &lt;code>google-services.json&lt;/code> file.&lt;/p>
&lt;div class="image-div" style="max-width:500px;">
&lt;p>&lt;img src="2018-09-25_14-59-02.png" alt="Adding the contents of the google services json file to an environment variable">&lt;/p>
&lt;/div>
&lt;h4 id="create-a-build-script-to-update-the-file">Create a build script to update the file&lt;/h4>
&lt;p>AppCenter can run build scripts before or after the build. These scripts have to have a &lt;a href="https://docs.microsoft.com/en-gb/appcenter/build/custom/scripts/?WT.mc_id=appcenter-blog-jabenn">specific name&lt;/a> to be picked up by the build configuration. To create a pre-build script, create a script file in the root of your repo called &lt;code>appcenter-pre-build.sh&lt;/code>. Add the following code to this script:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>GOOGLE_JSON_FILE&lt;span style="color:#f92672">=&lt;/span>$APPCENTER_SOURCE_DIRECTORY/&amp;lt;path&amp;gt;/google-services.json
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#f92672">[&lt;/span> -e &lt;span style="color:#e6db74">&amp;#34;&lt;/span>$GOOGLE_JSON_FILE&lt;span style="color:#e6db74">&amp;#34;&lt;/span> &lt;span style="color:#f92672">]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">then&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> echo &lt;span style="color:#e6db74">&amp;#34;Updating Google Json&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> echo &lt;span style="color:#e6db74">&amp;#34;&lt;/span>$GOOGLE_JSON&lt;span style="color:#e6db74">&amp;#34;&lt;/span> &amp;gt; $GOOGLE_JSON_FILE
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> sed -i -e &lt;span style="color:#e6db74">&amp;#39;s/\\&amp;#34;/&amp;#39;&lt;/span>&lt;span style="color:#ae81ff">\&amp;#34;&lt;/span>&lt;span style="color:#e6db74">&amp;#39;/g&amp;#39;&lt;/span> $GOOGLE_JSON_FILE
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> echo &lt;span style="color:#e6db74">&amp;#34;File content:&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cat $GOOGLE_JSON_FILE
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">fi&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Update &lt;path> to be the path to the &lt;code>google-services.json&lt;/code> file from the root of your repo. The &lt;code>$APPCENTER_SOURCE_DIRECTORY&lt;/code> environment variable points to where on the build VM App Center has put your code.&lt;/p>
&lt;p>This code will check for the file, and if it finds it copy the value of the environment variable into this file, followed by using a &lt;code>sed&lt;/code> command to strip out escape characters as environment variables get double quotes escaped to &lt;code>\&amp;quot;&lt;/code>.&lt;/p>
&lt;p>Once you add this file to your repo, it will appear under the &lt;strong>Build Scripts&lt;/strong> in the &lt;strong>Build Configuration&lt;/strong>.&lt;/p>
&lt;div class="image-div" style="max-width:500px;">
&lt;p>&lt;img src="2018-09-25_15-11-49.png" alt="Pre-build script turned on in the build configuration">&lt;/p>
&lt;/div>
&lt;p>If you &lt;strong>Save and build&lt;/strong> the project, you will see the &lt;code>google-services.json&lt;/code> file written to and dumped to the build log.&lt;/p>
&lt;div class="image-div" style="max-width:250px;">
&lt;p>&lt;img src="2018-09-25_15-13-43.png" alt="Log dump showing the file being written">&lt;/p>
&lt;/div>
&lt;hr/>
&lt;p>You can read more about the capabilities of &lt;a href="https://appcenter.ms/?WT.mc_id=appcenter-blog-jabenn">AppCenter&lt;/a> on &lt;a href="https://docs.microsoft.com/en-gb/appcenter/?WT.mc_id=appcenter-blog-jabenn">docs.com&lt;/a>.&lt;/p></description></item><item><title>Binding the Cognitive Services Android Speech SDK - Part 3 - Java 8 fun</title><link>https://jimbobbennett.dev/blogs/binding-the-cognitive-services-android-speech-sdk-part-3-java-8-fun/</link><pubDate>Mon, 10 Sep 2018 11:22:55 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/binding-the-cognitive-services-android-speech-sdk-part-3-java-8-fun/</guid><description>&lt;p>In the &lt;a href="https://jimbobbennett.dev/blogs/binding-the-cognitive-services-android-speech-sdk">first part&lt;/a> of this post, I showed how to get started binding the &lt;a href="https://docs.microsoft.com/azure/cognitive-services/speech-service/?WT.mc_id=speech-blog-jabenn">Microsoft Cognitive Services speech API&lt;/a>. In the &lt;a href="https://jimbobbennett.dev/blogs/binding-the-cognitive-services-android-speech-sdk-part-2-making-the-code-more-c-like">second part&lt;/a> I showed how to make the code look more C#-like. In this part, I&amp;rsquo;ll show how to use it and fix up a nasty issue with the Android compiler and using jars created with the latest versions of Java.&lt;/p>
&lt;h2 id="using-the-sdk">Using the SDK&lt;/h2>
&lt;p>To use the SDK, you will need an Android app. Create a new single-view Android app, and reference the SDK binding project. Then build the app and try to run it.&lt;/p>
&lt;p>Then marvel, as your app spectacularly fails to compile with a really weird error message.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>COMPILETODALVIK : Uncaught translation error : com.android.dx.cf.code.SimException: invalid opcode ba &lt;span style="color:#f92672">(&lt;/span>invokedynamic requires --min-sdk-version &amp;gt;&lt;span style="color:#f92672">=&lt;/span> 26&lt;span style="color:#f92672">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>WooHoo, invalid opcode ba. Ba indeed! What is this gibberish?&lt;/p>
&lt;p>Well the issue comes down to Java versions. Android in the past only supported Java code up to version 7. They are now adding support for later versions but Xamarin doesn&amp;rsquo;t have this yet, and this is only available on newer versions of Android (&amp;gt;= 26). To make your code work on earlier versions and with Xamarin you have to do a thing called desugaring (yes, really), and this alters the Java bytecode to convert Java 8 bytecode to a version that is supported by Java 7.&lt;/p>
&lt;p>At the moment there isn&amp;rsquo;t a nice IDE way to turn on desugaring, instead it has to be set inside the &lt;code>.csproj&lt;/code> file of the client application. Open up the &lt;code>.csproj&lt;/code> file for your newly created Android app inside &lt;a href="https://code.visualstudio.com/?WT.mc_id=speech-blog-jabenn">VSCode&lt;/a> (other editors are available, but hey - why would you), or by editing the file inside Visual Studio, and add the following to the default &lt;code>PropertyGroup&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-xml" data-lang="xml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;lt;AndroidEnableDesugar&amp;gt;&lt;/span>true&lt;span style="color:#f92672">&amp;lt;/AndroidEnableDesugar&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Your app should now build without errors!&lt;/p>
&lt;blockquote>
&lt;p>I have this working and compiling in the preview versions of Visual Studio on Windows at the time of writing cos that&amp;rsquo;s how I roll. If you are on stable and get weird errors then try with preview as I know support for this is being actively worked on.&lt;/p>
&lt;/blockquote>
&lt;blockquote>
&lt;p>If you do this on VS for Mac then you will get a crash at run-time. The workaround is documented here: &lt;a href="https://github.com/xamarin/xamarin-android/pull/1973">https://github.com/xamarin/xamarin-android/pull/1973&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;h2 id="buiding-an-app-using-the-sdk">Buiding an app using the SDK&lt;/h2>
&lt;p>To use the SDK you do need to sign up for the Speech service in Azure. Head to &lt;a href="https://portal.azure.com/?WT.mc_id=speech-blog-jabenn">portal.azure.com&lt;/a> and add a new Speech resource (at the time of writing this is in preview).&lt;/p>
&lt;div class="image-div" style="max-width:600px;">
&lt;p>&lt;img src="2018-09-09_20-43-15.png" alt="Searching for the speech resource in Azure">&lt;/p>
&lt;/div>
&lt;p>Once you have this, note down the endpoint from the &lt;strong>Overview&lt;/strong> page. It will be a URL, and you will need the bit before &lt;code>.api.cognitive.microsoft.com&lt;/code>. For example, if your endpoint is &lt;code>https://northeurope.api.cognitive.microsoft.com/sts/v1.0&lt;/code>, then you will need &lt;code>northeurope&lt;/code>. You will also need one of the two keys from the &lt;strong>Keys&lt;/strong> page.&lt;/p>
&lt;p>You can then create a &lt;code>SpeechFactory&lt;/code> using these values:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> factory = SpeechFactory.FromSubscription(&amp;lt;SpeechApiKey&amp;gt;, &amp;lt;endpoint&amp;gt;);
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Once you have a speech factory, you can create different recognizers - simple speech, a translator, or an intent recognizer using &lt;a href="https://www.luis.ai/?WT.mc_id=speech-blog-jabenn">LUIS&lt;/a>. To detect speech, handle the relevant events. You can see an example of using the &lt;code>TranslationRecognizer&lt;/code> to convert English to spoken German in an example project in my &lt;a href="https://github.com/jimbobbennett/SpeechSdkXamarinSample/blob/master/SpeechQuickStart/MainActivity.cs">GitHub repo&lt;/a>.&lt;/p>
&lt;blockquote class="twitter-tweet" data-lang="en">&lt;p lang="en" dir="ltr">Had a successful day. Created a &lt;a href="https://twitter.com/hashtag/Xamarin?src=hash&amp;amp;ref_src=twsrc%5Etfw">#Xamarin&lt;/a> binding for the &lt;a href="https://twitter.com/Azure?ref_src=twsrc%5Etfw">@Azure&lt;/a> &lt;a href="https://twitter.com/hashtag/CognitiveServices?src=hash&amp;amp;ref_src=twsrc%5Etfw">#CognitiveServices&lt;/a> Android speech SDK, and built a sample app that translates me voice into spoken German. &lt;a href="https://t.co/Bg4XDvhBjv">pic.twitter.com/Bg4XDvhBjv&lt;/a>&lt;/p>&amp;mdash; Jim Bennett ☁️ (@jimbobbennett) &lt;a href="https://twitter.com/jimbobbennett/status/1035559022743760896?ref_src=twsrc%5Etfw">August 31, 2018&lt;/a>&lt;/blockquote> &lt;script async src="https://platform.twitter.com/widgets.js" charset="utf-8">&lt;/script>
&lt;hr/>
&lt;p>In these three posts you have seen how to &lt;a href="https://jimbobbennett.dev/blogs/binding-the-cognitive-services-android-speech-sdk">create a binding library for the Speech SDK &lt;code>aar&lt;/code>&lt;/a>, make the code &lt;a href="https://jimbobbennett.dev/blogs/binding-the-cognitive-services-android-speech-sdk-part-2-making-the-code-more-c-like">more C#-like&lt;/a>, then finally use it from a client app, working around a Java bytecode issue. You can check out my implementation and a sample at on &lt;a href="https://github.com/jimbobbennett/SpeechSdkXamarinSample">GitHub&lt;/a>. As always, the best source of information with much more depth is the &lt;a href="https://docs.microsoft.com/xamarin/android/platform/binding-java-library/?WT.mc_id=speech-blog-jabenn">java binding dos on docs.microsoft.com&lt;/a>.&lt;/p>
&lt;p>Let me know what you build with this SDK - my DMs are always open on &lt;a href="https://twitter.com/jimbobbennett">Twitter&lt;/a>.&lt;/p></description></item><item><title>Binding the Cognitive Services Android Speech SDK - Part 2, making the code more C#-like</title><link>https://jimbobbennett.dev/blogs/binding-the-cognitive-services-android-speech-sdk-part-2-making-the-code-more-c-like/</link><pubDate>Mon, 10 Sep 2018 11:22:44 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/binding-the-cognitive-services-android-speech-sdk-part-2-making-the-code-more-c-like/</guid><description>&lt;p>In the &lt;a href="https://jimbobbennett.dev/blogs/binding-the-cognitive-services-android-speech-sdk">first part&lt;/a> of this post, I showed how to get started binding the &lt;a href="https://docs.microsoft.com/azure/cognitive-services/speech-service/?WT.mc_id=speech-blog-jabenn">Microsoft Cognitive Services speech API&lt;/a>. In this part I show how to make the code look more C#-like. In the &lt;a href="https://jimbobbennett.dev/blogs/binding-the-cognitive-services-android-speech-sdk-part-3-java-8-fun">third part&lt;/a> I&amp;rsquo;ll show how to use it and fix up a nasty issue with the Android compiler and using jars created with the latest versions of Java.&lt;/p>
&lt;h2 id="making-the-namespaces-more-c-like">Making the namespaces more C#-like&lt;/h2>
&lt;p>The namespaces that come from Java are different from traditional C# style namespaces. Java namespaces are reverse-URL format, so the default one created for this project is &lt;code>Com.Microsoft.Cognitiveservices.Speech.Internal&lt;/code>. A more-C# like one wouldn&amp;rsquo;t have the &lt;code>Com&lt;/code> at the start. The default namespace also capitalizes the first letter of each part, but obviously doesn&amp;rsquo;t know what other letters should be capitalized - in this case the &lt;code>S&lt;/code> in &lt;code>CognitiveServices&lt;/code>.&lt;/p>
&lt;p>The namespaces can be fixed by another &lt;code>attr&lt;/code> entry in the &lt;code>Metadata.xml&lt;/code> file - this time with the &lt;code>name&lt;/code> set to &lt;code>managedName&lt;/code> and the path set to the namespace. You will need one &lt;code>attr&lt;/code> node for every namespace inside the Java library - so for &lt;code>com.microsoft.cognitiveservices.speech&lt;/code> as well as the &lt;code>internal&lt;/code>, &lt;code>util&lt;/code>, &lt;code>intent&lt;/code> and &lt;code>translation&lt;/code> sub-namespaces. Change the namespaces to be more C# like, for example to &lt;code>Microsoft.Azure.CognitiveServices.Speech.*&lt;/code>.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-xml" data-lang="xml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;lt;attr&lt;/span> &lt;span style="color:#a6e22e">path=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;/api/package[@name=&amp;#39;com.microsoft.cognitiveservices.speech&amp;#39;]&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">name=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;managedName&amp;#34;&lt;/span>&lt;span style="color:#f92672">&amp;gt;&lt;/span>Microsoft.Azure.CognitiveServices.Speech&lt;span style="color:#f92672">&amp;lt;/attr&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;lt;attr&lt;/span> &lt;span style="color:#a6e22e">path=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;/api/package[@name=&amp;#39;com.microsoft.cognitiveservices.speech.internal&amp;#39;]&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">name=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;managedName&amp;#34;&lt;/span>&lt;span style="color:#f92672">&amp;gt;&lt;/span>Microsoft.Azure.CognitiveServices.Speech.Internal&lt;span style="color:#f92672">&amp;lt;/attr&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;lt;attr&lt;/span> &lt;span style="color:#a6e22e">path=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;/api/package[@name=&amp;#39;com.microsoft.cognitiveservices.speech.util&amp;#39;]&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">name=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;managedName&amp;#34;&lt;/span>&lt;span style="color:#f92672">&amp;gt;&lt;/span>Microsoft.Azure.CognitiveServices.Speech.Util&lt;span style="color:#f92672">&amp;lt;/attr&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;lt;attr&lt;/span> &lt;span style="color:#a6e22e">path=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;/api/package[@name=&amp;#39;com.microsoft.cognitiveservices.speech.intent&amp;#39;]&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">name=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;managedName&amp;#34;&lt;/span>&lt;span style="color:#f92672">&amp;gt;&lt;/span>Microsoft.Azure.CognitiveServices.Speech.Intent&lt;span style="color:#f92672">&amp;lt;/attr&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;lt;attr&lt;/span> &lt;span style="color:#a6e22e">path=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;/api/package[@name=&amp;#39;com.microsoft.cognitiveservices.speech.translation&amp;#39;]&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">name=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;managedName&amp;#34;&lt;/span>&lt;span style="color:#f92672">&amp;gt;&lt;/span>Microsoft.Azure.CognitiveServices.Speech.Translation&lt;span style="color:#f92672">&amp;lt;/attr&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Once these namespaces are changed, your code will no longer build as the &lt;code>StdMapWStringWStringMapIterator&lt;/code> class you added to the &lt;code>Additions&lt;/code> folder will be using the old namespace, so fix this one up manually. Your code should then now build.&lt;/p>
&lt;h2 id="handling-code-with-callbacks">Handling code with callbacks&lt;/h2>
&lt;p>The Speech SDK is actually implemented as cross-platform C++ code, with some platform-specific C++ code added to support each platform. This code is than wrapped using &lt;a href="http://www.swig.org">SWIG&lt;/a> to make it available as Java code for Android, C# code for Windows etc.&lt;/p>
&lt;p>This model has the problem that events are not implemented as standard Java listeners. If they were, then the binding library would automatically convert them to C# events. Seeing as they are not, you will need to convert them to events manually.&lt;/p>
&lt;blockquote>
&lt;p>This is a very specific example for this one library, so it is unlikely that other libraries will need exactly the same code - instead I thought I&amp;rsquo;d write about it as an example of the kind of thing you may have to do to make the code more C# like.&lt;/p>
&lt;/blockquote>
&lt;h3 id="how-events-are-implemented-in-this-sdk">How events are implemented in this SDK&lt;/h3>
&lt;p>In this SDK, events are implemented by passing an object that implements the &lt;code>IEventHandler&lt;/code> interface to the &lt;code>AddEventListener&lt;/code> method on a property of type &lt;code>EventHandlerImpl&lt;/code>. When the event is raised, the &lt;code>OnEvent&lt;/code> method on the &lt;code>IEventHandler&lt;/code> interface is called.&lt;/p>
&lt;p>For example, in the &lt;code>SpeechRecognizer&lt;/code> class there is a property called &lt;code>FinalResultReceived&lt;/code> of type &lt;code>EventHandlerImpl&lt;/code>, and you subscribe to this &amp;rsquo;event&amp;rsquo; by passing an instance of &lt;code>IEventHandler&lt;/code> to the &lt;code>AddEventListener&lt;/code> on this property.&lt;/p>
&lt;p>This pattern is not idiomatic C#, and is annoying to use as you will need to declare a class that implements the &lt;code>IEventHandler&lt;/code> interface just to handle the event.&lt;/p>
&lt;h3 id="making-this-code-more-c-like">Making this code more C#-like&lt;/h3>
&lt;p>To make this code more C# like, what you can do is:&lt;/p>
&lt;ul>
&lt;li>Create a generic implementation of &lt;code>IEventHandler&lt;/code> that raises an event&lt;/li>
&lt;li>Add a C# event to the class has a property of type &lt;code>EventHandlerImpl&lt;/code>&lt;/li>
&lt;li>Add an instance of the &lt;code>IEventHandler&lt;/code> implementation to this class, and add this as a listener to the &lt;code>EventHandlerImpl&lt;/code> property&lt;/li>
&lt;li>In the C# event, explicitly implement the &lt;code>add&lt;/code> and &lt;code>remove&lt;/code> methods. In these methods, add or remove the event from the event on the &lt;code>IEventHandler&lt;/code> implementation&lt;/li>
&lt;li>Hide the &lt;code>EventHandlerImpl&lt;/code> property from client code by marking it &lt;code>internal&lt;/code>&lt;/li>
&lt;/ul>
&lt;h3 id="creating-the-generic-event-handler">Creating the generic event handler&lt;/h3>
&lt;p>To create the event handler, add a new class to the &lt;code>Additions&lt;/code> folder called &lt;code>EventMapper&lt;/code>. The code for this is:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">EventMapper&lt;/span>&amp;lt;T, T1&amp;gt; : EventMapper, IEventHandler
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">where&lt;/span> T : &lt;span style="color:#66d9ef">class&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">where&lt;/span> T1 : &lt;span style="color:#66d9ef">class&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">readonly&lt;/span> &lt;span style="color:#66d9ef">object&lt;/span> sender;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">readonly&lt;/span> Func&amp;lt;T1, T&amp;gt; argExtractor;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> EventMapper(&lt;span style="color:#66d9ef">object&lt;/span> sender, Func&amp;lt;T1, T&amp;gt; argExtractor)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">this&lt;/span>.sender = sender;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">this&lt;/span>.argExtractor = argExtractor;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">event&lt;/span> EventHandler&amp;lt;EventArgs&amp;lt;T&amp;gt;&amp;gt; EventRaised;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> OnEvent(Java.Lang.Object p0, Java.Lang.Object p1)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> EventRaised?.Invoke(sender, &lt;span style="color:#66d9ef">new&lt;/span> EventArgs&amp;lt;T&amp;gt;(argExtractor(p1 &lt;span style="color:#66d9ef">as&lt;/span> T1)));
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This is an internal class, so is only available to the binding library.&lt;/p>
&lt;p>This class has two parts - an event and an &lt;code>argExtractor&lt;/code>.&lt;/p>
&lt;p>The event is a standard C# event using the &lt;code>EventHander&amp;lt;&amp;gt;&lt;/code> delegate type - so when called it passes the sender as an object and some event arguments that derive from &lt;code>EventArgs&lt;/code>. The &lt;code>EventArgs&amp;lt;T&amp;gt;&lt;/code> type is not one that exists in .NET Standard (which I am very surprised about as I&amp;rsquo;ve created this so many times, as have others). You will need to implement this yourself, so add a class called &lt;code>EventArgs&lt;/code> with the code below. This event args class is a simple wrapper for a value that needs to be passed to the event and saves you creating a load of custom event arg classes for each different value type that you want to pass.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">EventArgs&lt;/span>&amp;lt;T&amp;gt; : EventArgs
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> T Value { &lt;span style="color:#66d9ef">get&lt;/span>; }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> EventArgs(T &lt;span style="color:#66d9ef">value&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Value = &lt;span style="color:#66d9ef">value&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>When events are handled by the SDK, it passes it&amp;rsquo;s own event args implementation containing a value for those args. For example, the &lt;code>FinalRecognitionResult&lt;/code> event handler on the &lt;code>SpeechRecogniser&lt;/code> is passed an instance of &lt;code>SpeechRecognitionResultEventArgs&lt;/code>, containing a &lt;code>Result&lt;/code> property of type &lt;code>SpeechRecognitionResult&lt;/code>. These event args don&amp;rsquo;t derive from the standard .NET &lt;code>EventArgs&lt;/code> class, so you need a way to extract the relevant value and populate that into an &lt;code>EventArgs&lt;/code> class, and this is what the &lt;code>argExtractor&lt;/code> does - it takes the SDK args and pulls out the value needed. This is then wrapped in an &lt;code>EventArgs&amp;lt;T&amp;gt;&lt;/code> and passed to the event invocation.&lt;/p>
&lt;h3 id="handling-an-event">Handling an event&lt;/h3>
&lt;p>In the &lt;code>SpeechRecogniser&lt;/code> class there is a &lt;code>FinalRecognitionResult&lt;/code> handler that raises an event passing an instance of &lt;code>SpeechRecognitionResultEventArgs&lt;/code>, containing a &lt;code>Result&lt;/code> property of type &lt;code>SpeechRecognitionResult&lt;/code>. To map this to C#, you would add another part to the &lt;code>SpeechRecogniser&lt;/code> class:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">partial&lt;/span> &lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">SpeechRecognizer&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>You would then add a field for the event mapper:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>EventMapper&amp;lt;SpeechRecognitionResult, SpeechRecognitionResultEventArgs&amp;gt; finalResultMapper;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Then you add a C# event for the final result:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">event&lt;/span> EventHandler&amp;lt;EventArgs&amp;lt;SpeechRecognitionResult&amp;gt;&amp;gt; FinalResult
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">add&lt;/span> {}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">remove&lt;/span> {}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>In the &lt;code>add&lt;/code> method, if the &lt;code>EventMapper&lt;/code> hasn&amp;rsquo;t been created yet, you create it and pass it to the &lt;code>AddEventListener&lt;/code> of the bound handler. When it is created you will need to pass in the &lt;code>sender&lt;/code> which is passed to the events when invoked, and this is always &lt;code>this&lt;/code>. You also need to pass in a mapper function to extract the &lt;code>SpeechRecognitionResult&lt;/code> from the &lt;code>SpeechRecognitionResultEventArgs&lt;/code>, which can be a simple lambda function to return the &lt;code>Result&lt;/code> property. Then you subscribe the passed in &lt;code>value&lt;/code> to the event on the mapper.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">add&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> (finalResultMapper == &lt;span style="color:#66d9ef">null&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> finalResultMapper = &lt;span style="color:#66d9ef">new&lt;/span> EventMapper&amp;lt;SpeechRecognitionResult, SpeechRecognitionResultEventArgs&amp;gt;(sender, e =&amp;gt; e.Result);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> finalResultMapper.AddEventListener(handler);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> finalResultMapper.EventRaised += &lt;span style="color:#66d9ef">value&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>For the remove function, if the mapper has been created you can unsubscribe the value from the event:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">remove&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> (finalResultMapper != &lt;span style="color:#66d9ef">null&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> finalResultMapper.EventRaised -= &lt;span style="color:#66d9ef">value&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This is a lot of boilerplate code, so in my version I refactored this into some static methods. You can see these in my &lt;a href="https://github.com/jimbobbennett/SpeechSdkXamarinSample/blob/master/Microsoft.Azure.CognitiveServices.Speech.Client/Additions/EventMapper.cs">GitHub repo&lt;/a>.&lt;/p>
&lt;h3 id="hiding-the-original-event-handler">Hiding the original event handler&lt;/h3>
&lt;p>Now that you have C# style events, it is cleaner to hide the old event handler implementation to stop client code from calling instead of your nice, shiny, C# events. To do this, you can use an &lt;code>attr&lt;/code> in the &lt;code>Metadata.xml&lt;/code> file to change the visibility of the properties for the old event handlers to &lt;code>internal&lt;/code>. Seeing as these are the only places that &lt;code>IEventHandler&lt;/code> and &lt;code>EventHandlerImpl&lt;/code> are used, you can also mark these as internal. That way if you leave any &lt;code>EventHandlerImpl&lt;/code> properties as public, the compiler will give you an error - a great way to ensure you have mapped all the events.&lt;/p>
&lt;p>To mark these as internal, grab the paths from the source files in the &lt;code>obj&lt;/code> folder, and add an &lt;code>attr&lt;/code> node with the &lt;code>name&lt;/code> set to &lt;code>visibility&lt;/code>, and the content of the node set to &lt;code>internal&lt;/code>. The code below shows this for the &lt;code>FinalResultReceived&lt;/code> property on the &lt;code>SpeechRecognizer&lt;/code>, as well as the &lt;code>IEventHandler&lt;/code> and &lt;code>EventHandlerImpl&lt;/code> classes. Repeat this for all the event handler properties across all classes.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-xml" data-lang="xml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;lt;attr&lt;/span> &lt;span style="color:#a6e22e">path=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;/api/package[@name=&amp;#39;com.microsoft.cognitiveservices.speech&amp;#39;]/class[@name=&amp;#39;SpeechRecognizer&amp;#39;]/field[@name=&amp;#39;FinalResultReceived&amp;#39;]&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">name=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;visibility&amp;#34;&lt;/span>&lt;span style="color:#f92672">&amp;gt;&lt;/span>internal&lt;span style="color:#f92672">&amp;lt;/attr&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;lt;attr&lt;/span> &lt;span style="color:#a6e22e">path=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;/api/package[@name=&amp;#39;com.microsoft.cognitiveservices.speech.util&amp;#39;]/class[@name=&amp;#39;EventHandlerImpl&amp;#39;]&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">name=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;visibility&amp;#34;&lt;/span>&lt;span style="color:#f92672">&amp;gt;&lt;/span>internal&lt;span style="color:#f92672">&amp;lt;/attr&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;lt;attr&lt;/span> &lt;span style="color:#a6e22e">path=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;/api/package[@name=&amp;#39;com.microsoft.cognitiveservices.speech.util&amp;#39;]/class[@name=&amp;#39;IEventHandler&amp;#39;]&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">name=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;visibility&amp;#34;&lt;/span>&lt;span style="color:#f92672">&amp;gt;&lt;/span>internal&lt;span style="color:#f92672">&amp;lt;/attr&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;hr/>
&lt;p>In the &lt;a href="https://jimbobbennett.dev/blogs/binding-the-cognitive-services-android-speech-sdk-part-3-java-8-fun">final part&lt;/a>, I&amp;rsquo;ll show how you can call this code from a client app, as well as fixing up a nasty issue with the Android compiler and using jars created with the latest versions of Java. You can find the code for this &lt;a href="https://github.com/jimbobbennett/SpeechSdkXamarinSample">in my GitHub&lt;/a>, and you can read more on &lt;a href="https://docs.microsoft.com/xamarin/android/platform/binding-java-library/?WT.mc_id=speech-blog-jabenn">docs.microsoft.com&lt;/a>&lt;/p></description></item><item><title>Binding the Cognitive Services Android Speech SDK - Part 1, binding the library</title><link>https://jimbobbennett.dev/blogs/binding-the-cognitive-services-android-speech-sdk/</link><pubDate>Sun, 09 Sep 2018 14:55:00 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/binding-the-cognitive-services-android-speech-sdk/</guid><description>&lt;p>As part of the &lt;a href="https://docs.microsoft.com/azure/cognitive-services/speech-service/?WT.mc_id=speech-blog-jabenn">Microsoft Cognitive Services speech API&lt;/a>, there is a native Java Android SDK available as an &lt;code>.aar&lt;/code> file. I wanted to use this in a Xamarin app, so I created a binding project for it.&lt;/p>
&lt;p>The code for this is available &lt;a href="https://github.com/jimbobbennett/SpeechSdkXamarinSample">in my GitHub&lt;/a>.&lt;/p>
&lt;p>Binding an SDK is a four step process:&lt;/p>
&lt;ul>
&lt;li>Create the binding project with the relevant &lt;code>jar&lt;/code> or &lt;code>aar&lt;/code> file&lt;/li>
&lt;li>Make any necessary tweaks to the code or project to make it compile&lt;/li>
&lt;li>Make any required amendments to the code to make it into idiomatic C#&lt;/li>
&lt;li>Test it all out and fix up any issues&lt;/li>
&lt;/ul>
&lt;p>There are some great docs available on the basics for doing this at &lt;a href="https://docs.microsoft.com/xamarin/android/platform/binding-java-library/?WT.mc_id=speech-blog-jabenn">docs.microsoft.com&lt;/a>, but each library is different and can have it&amp;rsquo;s own unique challenges so I thought I&amp;rsquo;d write a few posts to highlight the steps I needed to take to bind the speech SDK.&lt;/p>
&lt;p>In this first part, I&amp;rsquo;ll show how to create a binding project, add the speech SDK &lt;code>aar&lt;/code> file, and make everything compile. In the &lt;a href="https://jimbobbennett.dev/blogs/binding-the-cognitive-services-android-speech-sdk-part-2-making-the-code-more-c-like">second part&lt;/a> I&amp;rsquo;ll show how to make the code more idiomatic C#, then in the &lt;a href="https://jimbobbennett.dev/blogs/binding-the-cognitive-services-android-speech-sdk-part-3-java-8-fun">third part&lt;/a> I&amp;rsquo;ll show how to use it and fix up a nasty issue with the Android compiler and using jars created with the latest versions of Java.&lt;/p>
&lt;h2 id="binding-the-sdk">Binding the SDK&lt;/h2>
&lt;p>The first step was to create a binding project and add the &lt;code>.aar&lt;/code> file. I followed the instructions in the &lt;a href="https://docs.microsoft.com/xamarin/android/platform/binding-java-library/?WT.mc_id=speech-blog-jabenn">Xamarin docs&lt;/a>, creating a new Android binding project and adding the &lt;code>client-sdk-0.6.0.aar&lt;/code> file to the &lt;code>Jars&lt;/code> folder.&lt;/p>
&lt;div class="image-div" style="max-width:400px;">
&lt;p>&lt;img src="2018-09-09_12-31-54.png" alt="A binding project with an aar file in the Jars folder">&lt;/p>
&lt;/div>
&lt;p>When you compile this project, the compile step will generate code to bind every Java class it finds. Each class in the generated code is a wrapper for a Java class - it doesn&amp;rsquo;t re-implement the Java code, it instead creates the same kind of thin wrapper that is used by the Xamarin Android SDK bindings. If you want to see this generated code, you can find it in the &lt;code>obj/${Congfiguration}/generated/src&lt;/code> folder.&lt;/p>
&lt;h2 id="making-it-work">Making it work&lt;/h2>
&lt;p>After doing this, I compiled the library and hit a couple of compiler errors that I needed to fix up:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>/.../Com.Microsoft.Cognitiveservices.Speech.Internal.StdMapWStringWString.cs&lt;span style="color:#f92672">(&lt;/span>72,72&lt;span style="color:#f92672">)&lt;/span>: Error CS0738: &lt;span style="color:#e6db74">&amp;#39;StdMapWStringWString&amp;#39;&lt;/span> does not implement interface member &lt;span style="color:#e6db74">&amp;#39;IIterable.Iterator()&amp;#39;&lt;/span>. &lt;span style="color:#e6db74">&amp;#39;StdMapWStringWString.Iterator()&amp;#39;&lt;/span> cannot implement &lt;span style="color:#e6db74">&amp;#39;IIterable.Iterator()&amp;#39;&lt;/span> because it does not have the matching &lt;span style="color:#66d9ef">return&lt;/span> type of &lt;span style="color:#e6db74">&amp;#39;IIterator&amp;#39;&lt;/span>. &lt;span style="color:#f92672">(&lt;/span>CS0738&lt;span style="color:#f92672">)&lt;/span> &lt;span style="color:#f92672">(&lt;/span>Speech&lt;span style="color:#f92672">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>/.../Com.Microsoft.Cognitiveservices.Speech.Internal.StdMapWStringWStringMapIterator.cs&lt;span style="color:#f92672">(&lt;/span>83,83&lt;span style="color:#f92672">)&lt;/span>: Error CS0738: &lt;span style="color:#e6db74">&amp;#39;StdMapWStringWStringMapIterator&amp;#39;&lt;/span> does not implement interface member &lt;span style="color:#e6db74">&amp;#39;IIterator.Next()&amp;#39;&lt;/span>. &lt;span style="color:#e6db74">&amp;#39;StdMapWStringWStringMapIterator.Next()&amp;#39;&lt;/span> cannot implement &lt;span style="color:#e6db74">&amp;#39;IIterator.Next()&amp;#39;&lt;/span> because it does not have the matching &lt;span style="color:#66d9ef">return&lt;/span> type of &lt;span style="color:#e6db74">&amp;#39;Object&amp;#39;&lt;/span>. &lt;span style="color:#f92672">(&lt;/span>CS0738&lt;span style="color:#f92672">)&lt;/span> &lt;span style="color:#f92672">(&lt;/span>Speech&lt;span style="color:#f92672">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The reason for this is that the Xamarin Java SDK doesn&amp;rsquo;t contain the generic versions of &lt;code>IIterator&lt;/code> and &lt;code>IIterable&lt;/code> which are used by this library, instead it will default to using the non-generic versions, and the implementation of the generic interfaces doesn&amp;rsquo;t match the signature of the non-generic version. So - how can it be fixed?&lt;/p>
&lt;h3 id="metadataxml-and-additions">Metadata.xml and Additions&lt;/h3>
&lt;p>Inside the binding project you can both alter the generated code and add new code.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;code>Transforms/Metadata.xml&lt;/code> - in this XML file you can alter the code that is generated. You can add entries to this file to remove some of the autogenerated code, either at class, method or property level. You can also change the generated code, for example changing the namespace - something especially useful to change from Java style namespaces to C# style.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>Additions&lt;/code> - In this folder you can add code that is compiled into the final dll. Each autogenerated class is declared as &lt;code>partial&lt;/code>, so not only can you add new classes and code, you can also add new parts to a generated class.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="fixing-the-stdmapwstringwstring-code">Fixing the &lt;code>StdMapWStringWString&lt;/code> code&lt;/h3>
&lt;p>The &lt;code>StdMapWStringWString&lt;/code> class implements a generic version of the &lt;code>IIterable&lt;/code> interface - &lt;code>IIterable&amp;lt;StdMapWStringWStringMapIterator&amp;gt;&lt;/code>. The Xamarin Java SDK doesn&amp;rsquo;t contain the generic base interface, so the bound library defaults to implementing &lt;code>IIterable&lt;/code>. The problem is this interface contains a method &lt;code>Iterator&lt;/code> that returns a different type in the generic version to the non-generic version. The generated code implements this method returning a &lt;code>StdMapWStringWStringMapIterator&lt;/code>, but the non-generic version expects a method returning &lt;code>IIterator&lt;/code>, so you get a compiler error.&lt;/p>
&lt;p>This is simple enough to fix - you just need to change the return type of the binding to be &lt;code>IIterator&lt;/code>, and this can be done in the &lt;code>Metadata.xml&lt;/code> file.&lt;/p>
&lt;p>The &lt;code>Metadata.xml&lt;/code> file is a file containing transforms that you want to make to the generated code - and can be adding new items, removing items or change the attributes of items such as the name or the return type.&lt;/p>
&lt;p>Open the generated code from the &lt;code>obj/${Congfiguration}/generated/src/&lt;/code> folder - the file will be called &lt;code>Microsoft.Azure.CognitiveServices.Speech.Internal.StdMapWStringWString.cs&lt;/code>. If you look at all the public items in this file (the class, public methods and public properties), you will see each one has a comment describing the &lt;code>Metadata.xml path&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">// Metadata.xml XPath class reference: path=&amp;#34;/api/package[@name=&amp;#39;com.microsoft.cognitiveservices.speech.internal&amp;#39;]/class[@name=&amp;#39;StdMapWStringWStringMapIterator&amp;#39;]&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">partial&lt;/span> &lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">StdMapWStringWStringMapIterator&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ...
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This path is used to identify each item to the &lt;code>Metadata.xml&lt;/code> file, so locate the &lt;code>Iterator()&lt;/code> method and note the &lt;code>path&lt;/code>.&lt;/p>
&lt;p>Open the &lt;code>Metadata.xml&lt;/code> file and add a new &lt;code>attr&lt;/code> node inside the &lt;code>metadata&lt;/code> node. Set the &lt;code>path&lt;/code> attribute of this node to match the path in the comment for the &lt;code>Iterator()&lt;/code> method. Then add an attribute called &lt;code>name&lt;/code> with the value &lt;code>managedReturn&lt;/code> to tell the transformations that this is a changed to the managed return type - so the type for the binding library only. This will treat the underlying return value as the original type which is what you want. The value for this attribute is set inside the node, and should be &lt;code>Java.Util.IIterator&lt;/code>.&lt;/p>
&lt;p>The full node is shown below:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-xml" data-lang="xml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;lt;metadata&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;lt;attr&lt;/span> &lt;span style="color:#a6e22e">path=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;/api/package[@name=&amp;#39;com.microsoft.cognitiveservices.speech.internal&amp;#39;]/class[@name=&amp;#39;StdMapWStringWString&amp;#39;]/method[@name=&amp;#39;iterator&amp;#39; and count(parameter)=0]&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">name=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;managedReturn&amp;#34;&lt;/span>&lt;span style="color:#f92672">&amp;gt;&lt;/span>Java.Util.IIterator&lt;span style="color:#f92672">&amp;lt;/attr&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;lt;/metadata&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Now if you compile the project, one error will be gone. If you re-open the generated file you will see the new return type.&lt;/p>
&lt;p>You can read more on the capabilities if this file in the &lt;a href="https://docs.microsoft.com/xamarin/android/platform/binding-java-library/customizing-bindings/java-bindings-metadata/?WT.mc_id=speech-blog-jabenn">docs&lt;/a>.&lt;/p>
&lt;h3 id="fixing-the-stdmapwstringwstringmapiterator-code">Fixing the &lt;code>StdMapWStringWStringMapIterator&lt;/code> code&lt;/h3>
&lt;p>The Xamarin Java SDK doesn&amp;rsquo;t contain the generic version of &lt;code>IIterator&lt;/code>, so the bound code uses the non-generic version. This interface has a &lt;code>Next()&lt;/code> method that returns the next item from the collection being iterated. In the non-generic version of this interface, &lt;code>Next()&lt;/code> returns a &lt;code>Java.Lang.Object&lt;/code>, whereas in the generic version it returns the generic arg, in this case a &lt;code>Java.Lang.String&lt;/code>. This means the generated code uses the non-generic interface, but the implementation uses the generic method, causing a compiler error.&lt;/p>
&lt;p>The fix for this is a little bit more work - you can&amp;rsquo;t just change the return type as it is used in a private method created by the binding. Instead, the fix for this is to remove the generic &lt;code>Next()&lt;/code> method and replace it with a non-generic version. Re-writing binding methods is not easy as there is a lot of code in the binding, so for cases like this the best way is to copy the generated code, adjusting it to suit. If you open the &lt;code>com.microsoft.cognitiveservices.speech.internal.StdMapWStringWStringMapIterator.cs&lt;/code> file from the &lt;code>obj&lt;/code> directory, and look at the &lt;code>Next()&lt;/code> method you will see the implementation consists of not just the &lt;code>Next()&lt;/code> method, but also an &lt;code>n_next()&lt;/code> method, a &lt;code>GetNextHandler()&lt;/code> method and a &lt;code>cb_next&lt;/code> &lt;code>Delegate&lt;/code> field. This is all the plumbing needed to create the binding method and call through to the underlying Java method.&lt;/p>
&lt;h4 id="adding-the-new-method">Adding the new method&lt;/h4>
&lt;p>Lets&amp;rsquo;s start by adding the new method as this will mostly be a copy of the existing code. Add a new class to the &lt;code>Additions&lt;/code> folder called &lt;code>StdMapWStringWStringMapIterator&lt;/code>, mark the class as &lt;code>partial&lt;/code> and change the namespace to match the generated file (these will be fixed up later to be more C#-like).&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">namespace&lt;/span> Com.Microsoft.Cognitiveservices.Speech.Internal
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">partial&lt;/span> &lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">StdMapWStringWStringMapIterator&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Copy the &lt;code>Next()&lt;/code>, &lt;code>GetNextHandler()&lt;/code>, &lt;code>n_next()&lt;/code> methods and the &lt;code>cb_next&lt;/code> field from the generated code and paste them into the new class part. Strip out any unnecessary namespaces and use &lt;code>var&lt;/code> everywhere - this will make it easier when you change the namespaces to be more C#-like in the next post.&lt;/p>
&lt;p>Change the return type of &lt;code>Next&lt;/code> to be &lt;code>Java.Lang.Object&lt;/code> instead of &lt;code>Java.Lang.String&lt;/code>. Leave the types in the &lt;code>Register&lt;/code> attribute and &lt;code>__id&lt;/code> fields as they are, as the underlying method that is called returns a &lt;code>Java.Lang.String&lt;/code>, and you only need to change the return type for the binding wrapper.&lt;/p>
&lt;p>In the &lt;code>n_next()&lt;/code> method, change the &lt;code>return&lt;/code> call to call &lt;code>ToString()&lt;/code> on the result of the call to &lt;code>Next()&lt;/code> to use the correct type. The final code will look like this:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">namespace&lt;/span> Com.Microsoft.Cognitiveservices.Speech.Internal
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">partial&lt;/span> &lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">StdMapWStringWStringMapIterator&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">static&lt;/span> Delegate cb_next;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># pragma&lt;/span> warning disable &lt;span style="color:#ae81ff">0169&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">static&lt;/span> Delegate GetNextHandler()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> (cb_next == &lt;span style="color:#66d9ef">null&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cb_next = JNINativeWrapper.CreateDelegate((Func&amp;lt;IntPtr, IntPtr, IntPtr&amp;gt;)n_Next);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> cb_next;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">static&lt;/span> IntPtr n_Next(IntPtr jnienv, IntPtr native__this)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">var&lt;/span> __this = Object.GetObject&amp;lt;StdMapWStringWStringMapIterator&amp;gt;(jnienv, native__this, JniHandleOwnership.DoNotTransfer);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> JNIEnv.NewString(__this.Next()?.ToString()); &lt;span style="color:#75715e">// ToString called on the object.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># pragma&lt;/span> warning restore &lt;span style="color:#ae81ff">0169&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e"> [Register(&amp;#34;next&amp;#34;, &amp;#34;()Ljava/lang/String;&amp;#34;, &amp;#34;GetNextHandler&amp;#34;)]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">virtual&lt;/span> &lt;span style="color:#66d9ef">unsafe&lt;/span> Java.Lang.Object Next() &lt;span style="color:#75715e">// Return type changed from string to object&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">const&lt;/span> &lt;span style="color:#66d9ef">string&lt;/span> __id = &lt;span style="color:#e6db74">&amp;#34;next.()Ljava/lang/String;&amp;#34;&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">try&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">var&lt;/span> __rm = _members.InstanceMethods.InvokeVirtualObjectMethod(__id, &lt;span style="color:#66d9ef">this&lt;/span>, &lt;span style="color:#66d9ef">null&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> JNIEnv.GetString(__rm.Handle, JniHandleOwnership.TransferLocalRef);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">finally&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="removing-the-next-method">Removing the &lt;code>Next&lt;/code> method&lt;/h4>
&lt;p>To remove a method from the autogenerated file, you add a &lt;code>remove-node&lt;/code> entry to the &lt;code>Metadata.xml&lt;/code> file with the path of the &lt;code>Next()&lt;/code> method node you want to remove. To remove the &lt;code>Next()&lt;/code> method, add this following to this file:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-xml" data-lang="xml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;lt;remove-node&lt;/span> &lt;span style="color:#a6e22e">path=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;/api/package[@name=&amp;#39;com.microsoft.cognitiveservices.speech.internal&amp;#39;]/class[@name=&amp;#39;StdMapWStringWStringMapIterator&amp;#39;]/method[@name=&amp;#39;next&amp;#39; and count(parameter)=0]&amp;#34;&lt;/span>&lt;span style="color:#f92672">/&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The syntax is &lt;code>&amp;lt;remove-node path=&amp;quot;...&amp;quot;/&amp;gt;&lt;/code> where the &lt;code>path&lt;/code> comes from the comment in the generated code. Once this line has been added, compile the code and check the generated file in the &lt;code>obj&lt;/code> directory. The compiler error about the missing &lt;code>Next()&lt;/code> method will have gone, and the &lt;code>Next()&lt;/code> method will be removed from the autogenerated file - when the library is built it will use the version in the file in the &lt;code>Additions&lt;/code> folder.&lt;/p>
&lt;p>You should now be able to compile this library successfully.&lt;/p>
&lt;hr/>
&lt;p>In the &lt;a href="https://jimbobbennett.dev/blogs/binding-the-cognitive-services-android-speech-sdk-part-2-making-the-code-more-c-like/">second part&lt;/a>, I&amp;rsquo;ll show how you can make the code more C#-like. You can find the code for this &lt;a href="https://github.com/jimbobbennett/SpeechSdkXamarinSample">in my GitHub&lt;/a>, and you can read more on &lt;a href="https://docs.microsoft.com/xamarin/android/platform/binding-java-library/?WT.mc_id=speech-blog-jabenn">docs.microsoft.com&lt;/a>&lt;/p></description></item><item><title>Running AI models on iOS, Android and Windows using Xamarin</title><link>https://jimbobbennett.dev/blogs/running-ai-models-on-ios-android-and-windows-using-xamarin/</link><pubDate>Fri, 20 Jul 2018 16:59:01 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/running-ai-models-on-ios-android-and-windows-using-xamarin/</guid><description>&lt;p>I created a &lt;a href="https://www.nuget.org/packages/Xam.Plugins.OnDeviceCustomVision/">NuGet package&lt;/a> a while ago to allow you to run models exported from the &lt;a href="https://customvision.ai">Azure Custom Vision&lt;/a> service on iOS and Android in Xamarin apps from your cross-platform code. You can read about this &lt;a href="https://jimbobbennett.dev/blogs/identifying-my-daughters-toys-using-ai-part-5-plugin-for-on-device-models/">here&lt;/a>.&lt;/p>
&lt;p>Since then, the Custom Vision service has added &lt;a href="https://jimbobbennett.dev/blogs/running-custom-vision-models-on-a-windows-device/">ONNX export&lt;/a>, meaning you can now run these models on-device on Windows as well. This meant it was time to update my plugin to support Windows.&lt;/p>
&lt;p>This was released in v2.0 of the plugin - I thought I&amp;rsquo;d be a good developer and bump the major version number as I&amp;rsquo;ve broken the API.&lt;/p>
&lt;h4 id="api-changes">API changes&lt;/h4>
&lt;p>The main change is that the &lt;code>IImageClassifier.Init&lt;/code> method has now gone. When I wrote this it was a bit of a fudge - it took a single model name and a model type. The model type was only needed on Android as some image adjustments needed to be made based on the model type used. It also meant that there was no way to use a different TensorFlow labels file, it had to be called &lt;code>labels.txt&lt;/code>. With Windows, the &lt;code>Init&lt;/code> call would need a list of labels, so it made sense to strip it down and have platform-specific calls to allow each platform to be passes just what is needed.&lt;/p>
&lt;h5 id="initialization-on-ios">Initialization on iOS&lt;/h5>
&lt;p>Models can be compiled before being used, or compiled on the device. To use a pre-compiled model, compile the downloaded model using:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>xcrun coremlcompiler compile &amp;lt;model_file_name&amp;gt;.mlmodel &amp;lt;model_name&amp;gt;.mlmodelc
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Add the model (compiled or uncompiled) to the &lt;code>Resources&lt;/code> folder in your iOS app. Then initialize the plugin using:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>iOSImageClassifier.Init(&lt;span style="color:#e6db74">&amp;#34;&amp;lt;model_name&amp;gt;&amp;#34;&lt;/span>);
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Passing in the name of the model without the &lt;code>mlmodel&lt;/code> or &lt;code>mlmodelc&lt;/code> extension. If the model is uncompiled, it will be compiled before use.&lt;/p>
&lt;h5 id="initialization-on-android">Initialization on Android&lt;/h5>
&lt;p>Add the &lt;code>model.pb&lt;/code> and &lt;code>labels.txt&lt;/code> files to the &lt;code>Assets&lt;/code> folder of your Android app. Then initalize the plugin using:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>AndroidImageClassifier.Current.Init(&lt;span style="color:#e6db74">&amp;#34;model.pb&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;labels.txt&amp;#34;&lt;/span>, ModelType.General);
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>These values are actually defaults, so you can leave these off and just use &lt;code>AndroidImageClassifier.Current.Init()&lt;/code> if you want.&lt;/p>
&lt;blockquote>
&lt;p>A note about model types. You needed the model type because the original TensorFlow export created models that needed image adjustments for some model types to work correctly. Since 7th May 2018 then models have a layer that adjusts for this automatically. The plugin will detect this and only make image adjustments if needed, so the model type is only relevant for models created before this date. It is ignored for models created after.&lt;/p>
&lt;/blockquote>
&lt;h5 id="initialization-on-windows">Initialization on Windows&lt;/h5>
&lt;p>Add the &lt;code>&amp;lt;model&amp;gt;.onnx&lt;/code> file to the &lt;code>Assets&lt;/code> folder of your Windows app. A &lt;code>&amp;lt;model&amp;gt;.cs&lt;/code> file will be created to process the model in the root of your UWP app. The wrapper will have a class called &lt;code>&amp;lt;model&amp;gt;ModelOutput&lt;/code> and in the constructor for this class will be some code to create a dictionary called loss:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">this&lt;/span>.loss = &lt;span style="color:#66d9ef">new&lt;/span> Dictionary&amp;lt;&lt;span style="color:#66d9ef">string&lt;/span>, &lt;span style="color:#66d9ef">float&lt;/span>&amp;gt;()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> { &lt;span style="color:#e6db74">&amp;#34;&amp;lt;label 1&amp;gt;&amp;#34;&lt;/span>, &lt;span style="color:#66d9ef">float&lt;/span>.NaN },
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> { &lt;span style="color:#e6db74">&amp;#34;&amp;lt;label 2&amp;gt;&amp;#34;&lt;/span>, &lt;span style="color:#66d9ef">float&lt;/span>.NaN },
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>};
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This defines the labels in the correct order for the model. These labels will need to be passed to the &lt;code>Init&lt;/code> method in the correct order.&lt;/p>
&lt;p>The &lt;code>Init&lt;/code> method on Windows is also an async method, so will need to be called from another async method, such as by overriding &lt;code>OnNavigatedTo&lt;/code> on a page and marking it as &lt;code>async&lt;/code>. Await the init method passing the model name and labels like this:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">await&lt;/span> WindowsImageClassifier.Init(&lt;span style="color:#e6db74">&amp;#34;Currency&amp;#34;&lt;/span>, &lt;span style="color:#66d9ef">new&lt;/span>[] { &lt;span style="color:#e6db74">&amp;#34;&amp;lt;label 1&amp;gt;&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;&amp;lt;label 2&amp;gt;&amp;#34;&lt;/span>, ... });
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;hr/>
&lt;p>I&amp;rsquo;m sure this can be improved, including adding code to detect the labels from the ONNX model, so feel free to raise a PR with any improvements. All the code is on &lt;a href="https://github.com/jimbobbennett/Xam.Plugins.OnDeviceCustomVision">GitHub here&lt;/a>.&lt;/p></description></item><item><title>Running custom vision models on a Windows device</title><link>https://jimbobbennett.dev/blogs/running-custom-vision-models-on-a-windows-device/</link><pubDate>Fri, 20 Jul 2018 16:29:53 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/running-custom-vision-models-on-a-windows-device/</guid><description>&lt;p>Recently I &lt;a href="https://jimbobbennett.dev/blogs/identifying-my-daughters-toys-using-ai-part-5-plugin-for-on-device-models/">wrote about creating AI models&lt;/a> using the &lt;a href="https://customvision.ai">Azure Custom Vision Service&lt;/a>. In these posts I looked at creating and training models, running them online, then finally exporting the models to run on iOS using CoreML and Android using TensorFlow.&lt;/p>
&lt;p>Recently Microsoft announced another way to export models - as &lt;a href="https://github.com/onnx/onnx">ONNX models&lt;/a> that can be run using &lt;a href="https://docs.microsoft.com/en-us/windows/uwp/machine-learning/?WT.mc_id=toyidentifier-blog-jabenn">Windows ML&lt;/a>. Like with CoreML and TensorFlow, these are models that can be run on-device, taking advantage of the power of the devices GPU instead of needing to be run in the cloud.&lt;/p>
&lt;div class="image-div" style="max-width:400px;">
&lt;p>&lt;img src="winml-graphic.png" alt="Windows ML logo">&lt;/p>
&lt;/div>
&lt;p>ONNX models can be exported in the same way as CoreML and TensorFlow - select you iteration, click the &lt;strong>Export&lt;/strong> button to generate the model, then the &lt;strong>Doanload&lt;/strong> button to download it.&lt;/p>
&lt;div class="image-div" style="max-width:500px;">
&lt;p>&lt;img src="2018-07-20_17-10-40.gif" alt="Exporting a ONNX model">&lt;/p>
&lt;/div>
&lt;p>To use this model you need a UWP app targeting Build 17110 or higher of the Windows SDK (as this version is the first one containing the Windows ML API). Create a new app, then drag your downloaded model into the &lt;code>Assets&lt;/code> folder. When you add the model, some wrapper classes will be created inside a file in the root directory of your app with a really weird name - they will all start with the Id of your model converted into a format that is C# friendly. The three classes that will be created are for inputs, outputs and running the model - and will end with &lt;code>ModelInput&lt;/code>, &lt;code>ModelOutput&lt;/code> and &lt;code>Model&lt;/code>.&lt;/p>
&lt;p>It would make sense to rename them, so rename the file to something sensible that reflects your model, then rename the classes as well to &lt;code>ModelInput&lt;/code>, &lt;code>ModelOutput&lt;/code> and &lt;code>Model&lt;/code>.&lt;/p>
&lt;ul>
&lt;li>&lt;code>ModelInput&lt;/code> is the input to the model and contains a single property called &lt;code>data&lt;/code> which is a &lt;code>VideoFrame&lt;/code>. You can populate this with a capture from the camera or a frame from a video feed.&lt;/li>
&lt;li>&lt;code>ModelOutput&lt;/code> is the outputs of the model as a dictionary of strings to floats. The dictionary is auto-populated with the tags from the model, and when the model is run this will be updated to set the percentages for each tag.&lt;/li>
&lt;li>&lt;code>Model&lt;/code> is the class that evaluates the model, binding the inputs and outputs and executing the model.&lt;/li>
&lt;/ul>
&lt;p>To create a model, use the static &lt;code>CreateModel&lt;/code> method on &lt;code>Model&lt;/code>, passing in the &lt;code>&amp;lt;model&amp;gt;.onnx&lt;/code> file as a &lt;code>StorageFile&lt;/code>, loaded like this:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> file = &lt;span style="color:#66d9ef">await&lt;/span> StorageFile.GetFileFromApplicationUriAsync(&lt;span style="color:#66d9ef">new&lt;/span> Uri(&lt;span style="color:#e6db74">$&amp;#34;ms-appx:///Assets/&amp;lt;model&amp;gt;.onnx&amp;#34;&lt;/span>));
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>To run the model, capture a &lt;code>VideoFrame&lt;/code>, set it on an instance of &lt;code>ModelInput&lt;/code>, then pass that to the &lt;code>EvaluateAsync&lt;/code> method on the model. This will return a &lt;code>ModelOutput&lt;/code> with the probabilities set.&lt;/p>
&lt;p>You can find a sample of this in the &lt;a href="https://github.com/Azure-Samples/Custom-Vision-ONNX-UWP">GitHub Azure Samples repo&lt;/a>. You can also learn more by checking out the &lt;a href="https://docs.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/custom-vision-onnx-windows-ml/?WT.mc_id=toyidentifier-blog-jabenn">docs&lt;/a>.&lt;/p></description></item><item><title>Setting iOS permission descriptions in Visual Studio 2017</title><link>https://jimbobbennett.dev/blogs/setting-ios-permission-descriptions-in-visual-studio-2017/</link><pubDate>Thu, 05 Jul 2018 14:39:40 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/setting-ios-permission-descriptions-in-visual-studio-2017/</guid><description>&lt;p>I spend most of my developer day using Visual Studio for Mac, but occasionally I flip back to Visual Studio 2017 on Windows. Last time I flipped back I tried to build an app that uses the camera and I got stuck on one simple thing - setting the camera usage description.&lt;/p>
&lt;p>If you double click on the &lt;code>info.plist&lt;/code> file in an iOS app project, it will open in the iOS manifest editor. This editor allows you to set or change a number of settings for your app, such as the bundle identifier, app name or scheme URLs that your app uses. But one thing this editor doesn&amp;rsquo;t support is setting the usage descriptions.&lt;/p>
&lt;p>After a quick chat to some other developers, I found out how to do it (thanks &lt;a href="https://twitter.com/pierceboggan">Pierce&lt;/a>).&lt;/p>
&lt;p>From Visual Studio, right-click on the &lt;code>info.plist&lt;/code> file, then select &lt;strong>Open With&amp;hellip;&lt;/strong>.&lt;/p>
&lt;p>From the &lt;strong>Open With&amp;hellip;&lt;/strong> dialog, select the &lt;strong>Generic PList Editor&lt;/strong>.&lt;/p>
&lt;div class="image-div" style="max-width:480px;">
&lt;p>&lt;img src="InfoEditorSelectionVs.png" alt="Select the Generic PList editor from the open with dialog">&lt;/p>
&lt;/div>
&lt;p>Once the file has been opened, click the &lt;strong>+&lt;/strong> on the bottom row to create a new property. Click the property name to get a drop down showing all the supported properties, then click the one you want.&lt;/p>
&lt;div class="image-div" style="max-width:480px;">
&lt;p>&lt;img src="InfoPListEditorSelectKey.png" alt="Selecting the property key">&lt;/p>
&lt;/div>
&lt;p>Finally add the description to the &lt;strong>Value&lt;/strong> column.&lt;/p>
&lt;div class="image-div" style="max-width:480px;">
&lt;p>&lt;img src="InfoPListSetValue.png" alt="Setting the property value">&lt;/p>
&lt;/div>
&lt;p>Read more about this in the &lt;a href="https://docs.microsoft.com/en-us/xamarin/ios/app-fundamentals/security-privacy?tabs=vswin#setting-privacy-keys&amp;amp;WT.mc_id=ios-blog-jabenn">docs&lt;/a>.&lt;/p>
&lt;blockquote>
&lt;p>At the time of writing, the docs are out of date, showing that there is no &lt;code>info.plist&lt;/code> editor support in VS on Windows. But worry not, I&amp;rsquo;ve already submitted a PR against the docs to fix this, so hopefully by the time you read this the docs will be up to date.&lt;/p>
&lt;/blockquote></description></item><item><title>What the @ - fixing weirdness in return JSON from Azure functions using F#</title><link>https://jimbobbennett.dev/blogs/what-the-fixing-weirdness-in-return-json-from-azure-functions-using-f/</link><pubDate>Tue, 19 Jun 2018 15:59:44 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/what-the-fixing-weirdness-in-return-json-from-azure-functions-using-f/</guid><description>&lt;p>I&amp;rsquo;ve been playing a lot with &lt;a href="https://docs.microsoft.com/en-us/dotnet/fsharp/?WT.mc_id=fsharp-blog-jabenn">F#&lt;/a> recently, both to build Xamarin apps using &lt;a href="https://github.com/fsprojects/Elmish.XamarinForms">Elmish.XamarinForms&lt;/a> and for some &lt;a href="https://docs.microsoft.com/en-us/azure/azure-functions/functions-reference-fsharp/?WT.mc_id=fsharp-blog-jabenn">Azure Functions&lt;/a>. Whilst building an HTTP trigger I came across some weirdness when serializing a record type to JSON.&lt;/p>
&lt;p>This is the relevant parts of my code:&lt;/p>
&lt;pre tabindex="0">&lt;code>type Output = { TotalBalance : float }
let Run(req: HttpRequestMessage, boundTable: IQueryable&amp;lt;Transaction&amp;gt;, log: TraceWriter) =
async {
// stuff
return req.CreateResponse(HttpStatusCode.OK, { TotalBalance = sum })
} |&amp;gt; Async.RunSynchronously
&lt;/code>&lt;/pre>&lt;p>Now it&amp;rsquo;s normal to assume the &lt;code>Output&lt;/code> type would be serialized to JSON correctly, leading to something like:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-json" data-lang="json">&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;balance&amp;#34;&lt;/span> : &lt;span style="color:#ae81ff">100&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Unfortunately not - what I actually get is:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-json" data-lang="json">&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;Balance@&amp;#34;&lt;/span> : &lt;span style="color:#ae81ff">100&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Note the weird &lt;strong>@&lt;/strong> symbol on the property name.&lt;/p>
&lt;p>So I went spelunking around Google and SO for a fix. The first suggestion was to add the &lt;code>[&amp;lt;CLIMutable&amp;gt;]&lt;/code> attribute to my &lt;code>Output&lt;/code> type, but this didn&amp;rsquo;t actually work, the &lt;strong>@&lt;/strong> symbol was still there.&lt;/p>
&lt;p>In the end I found the fix here: &lt;a href="https://stackoverflow.com/questions/43118406/return-an-f-record-type-as-json-in-azure-functions/48718297#48718297">https://stackoverflow.com/questions/43118406/return-an-f-record-type-as-json-in-azure-functions/48718297#48718297&lt;/a>. You can pass a different JSON formatter to the &lt;code>CreateResponse&lt;/code> call, and configure that to return the correct property names:&lt;/p>
&lt;pre tabindex="0">&lt;code>let jsonFormatter = Formatting.JsonMediaTypeFormatter()
jsonFormatter.SerializerSettings.ContractResolver &amp;lt;- CamelCasePropertyNamesContractResolver()
return req.CreateResponse(HttpStatusCode.OK, { TotalBalance = sum }, jsonFormatter)
&lt;/code>&lt;/pre>&lt;p>Done!&lt;/p></description></item><item><title>Describing a photo in a mobile app using Azure Computer Vision</title><link>https://jimbobbennett.dev/blogs/describing-a-photo-in-a-mobile-app-using-azure-computer-vision/</link><pubDate>Wed, 30 May 2018 16:05:41 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/describing-a-photo-in-a-mobile-app-using-azure-computer-vision/</guid><description>&lt;p>I recently gave an introduction to Xamarin talk at &lt;a href="http://www.imperial.ac.uk">Imperial College, London&lt;/a> and wanted to build a cool app to show off what you can do on mobile using the awesome Cognitive Services available on Azure. I only had about 30-40 minutes to not only introduce Xamarin, but build an app so I decided to throw together a simple app to take a photo and describe it using the &lt;a href="https://docs.microsoft.com/azure/cognitive-services/computer-vision/home/?WT.mc_id=imperial-blog-jabenn">Azure Computer Vision&lt;/a> service.&lt;/p>
&lt;p>It really is simple to set up and use this service. Head to the &lt;a href="https://azure.microsoft.com/services/cognitive-services/computer-vision/?WT.mc_id=imperial-blog-jabenn">Computer Vision cognitive services site&lt;/a>, click the big &lt;strong>Try the Computer Vision API&lt;/strong> button. Log in with an appropriate provider, and get an API key, noting the region the key is for.&lt;/p>
&lt;p>From inside your Xamarin app, install the pre-release &lt;a href="https://www.nuget.org/packages/Microsoft.Azure.CognitiveServices.Vision.ComputerVision/">Microsoft.Azure.CognitiveServices.Vision.ComputerVision&lt;/a> NuGet package into all the projects. Then install the &lt;a href="https://www.nuget.org/packages/Xam.Plugin.Media/">Xam.Plugin.Media&lt;/a> NuGet package and follow the instructions in the &lt;code>readme.txt&lt;/code> that is auto-opened to enable permissions and other gumpf.&lt;/p>
&lt;p>Add some code to take a photo using the media plugin:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> opts = &lt;span style="color:#66d9ef">new&lt;/span> Plugin.Media.Abstractions.StoreCameraMediaOptions();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> photo = &lt;span style="color:#66d9ef">await&lt;/span> Plugin.Media.CrossMedia.Current.TakePhotoAsync(opts);
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Next, set up the Computer Vision API by creating an &lt;code>ApiKeyServiceClientCredentials&lt;/code> with your API key, then constructing an instance of &lt;code>ComputerVisionAPI&lt;/code> using these credentials, not forgetting to set the region.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">var&lt;/span> creds = &lt;span style="color:#66d9ef">new&lt;/span> ApiKeyServiceClientCredentials(&lt;span style="color:#e6db74">&amp;#34;&amp;lt;your key here&amp;gt;&amp;#34;&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">var&lt;/span> visionApi = &lt;span style="color:#66d9ef">new&lt;/span> ComputerVisionAPI(creds)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> AzureRegion = AzureRegions.Westeurope
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> };
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Finally, get a stream containing the image and pass it to the computer vision API.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> desc = &lt;span style="color:#66d9ef">await&lt;/span> _visionApi.DescribeImageInStreamAsync(photo.GetStream());
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>You can then access a description for the image using the &lt;code>Captions&lt;/code> property on the &lt;code>ImageDescription&lt;/code> that is returned. You can also get a list of tags for the image using the &lt;code>Tags&lt;/code> property. The image below shows my app using this to caption an image.&lt;/p>
&lt;div class="image-div" style="max-width:320px;">
&lt;p>&lt;img src="IMG_7078.jpg" alt="The app running showing an image and its description">&lt;/p>
&lt;/div>
&lt;p>You can find the code for this on &lt;a href="https://github.com/jimbobbennett/PhotoDescriber">my GitHub&lt;/a>, and you can read more on the computer vision service in the &lt;a href="https://docs.microsoft.com/azure/cognitive-services/computer-vision/home/?WT.mc_id=imperial-blog-jabenn">docs&lt;/a>.&lt;/p></description></item><item><title>Xamarin in Action is now on the bookshelves!</title><link>https://jimbobbennett.dev/blogs/xamarin-in-action-is-now-on-the-bookshelves/</link><pubDate>Mon, 21 May 2018 09:03:04 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/xamarin-in-action-is-now-on-the-bookshelves/</guid><description>&lt;p>Finally, after 2 years since I first put pen to paper (well, put keystroke to &lt;a href="https://atom.io">Atom&lt;/a>), &lt;a href="http://xam.jbb.io">Xamarin in Action&lt;/a> is done and available from your favorite bookseller as a printed, paper book, with a forward from my good friend, the amazing &lt;a href="https://twitter.com/JamesMontemagno">James Montemagno&lt;/a>!&lt;/p>
&lt;div class="image-div" style="max-width: 600px;">
&lt;a href="http://xam.jbb.io">
&lt;p>&lt;img src="IMG_7012.jpg" alt="Xamarin in Action book cover">&lt;/p>
&lt;/a>
&lt;/div>
&lt;div class="image-div" style="max-width: 581;">
&lt;p>&lt;img src="2018-05-04_14-10-37.png" alt="&amp;ldquo;A guide to best practices for building production-quality mobile applications&amp;rdquo; from the foreword by James Montemagno, Microsoft">&lt;/p>
&lt;/div>
&lt;p>You can buy this book in one of two ways - an eBook in PDF, kindle, iBook format, or a printed book. If you buy the printed book, you get the eBook for free!
It&amp;rsquo;s available from all good booksellers, or &lt;a href="http://xam.jbb.io">direct from Manning&lt;/a> - and if you buy direct you can use code &amp;lsquo;xamarininaction&amp;rsquo; for a hefty discount!&lt;/p>
&lt;div class="image-div" style="max-width: 600px;">
&lt;a href="http://xam.jbb.io">
&lt;p>&lt;img src="IMG_7014.jpg" alt="Xamarin in Action book open">&lt;/p>
&lt;/a>
&lt;/div>
&lt;p>This book is designed to teach you how to build a production quality Xamarin app, from idea through implementation and testing, to the store and beyond. It doesn&amp;rsquo;t cover just a list of UI widgets with lists of properties and methods, instead it focuses on building real world, well written, testable apps using MVVM. It covers using traditional Xamarin for iOS and Android, looking at how to maximize the amount of cross-platform code in your app, how to build UIs using Android XML and iOS Storyboards, how to share and unit test your UI logic, and how to test your UI. It then shows how to use &lt;a href="https://appcenter.ms">AppCenter&lt;/a> to build, test and distribute your app, as well as monitor usage and crashes after publication.&lt;/p>
&lt;p>Here&amp;rsquo;s some things that people have said about this book:&lt;/p>
&lt;div class="image-div" style="max-width: 581;">
&lt;p>&lt;img src="2018-05-04_14-10-51.png" alt="Reviews of this book">&lt;/p>
&lt;/div>
&lt;p>Buy your copy today - head to &lt;a href="http://xam.jbb.io">the Manning website&lt;/a> and use code &amp;lsquo;xamarininaction&amp;rsquo; for a hefty discount!&lt;/p></description></item><item><title>Xamarin Essentials</title><link>https://jimbobbennett.dev/blogs/xamarin-essentials/</link><pubDate>Tue, 08 May 2018 15:48:04 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/xamarin-essentials/</guid><description>&lt;p>TL;DR - check out Xamarin Essentials in the &lt;a href="https://docs.microsoft.com/en-gb/xamarin/essentials/?WT.mc_id=pocketmoney-blog-jabenn">official documentation&lt;/a>.&lt;/p>
&lt;hr/>
&lt;p>Like a lot of developers, I love how Xamarin allows me to share business logic between iOS and Android apps, and share UI using Forms, but still have access to the native APIs. But one thing has been missing - a consistent, out of the box way of accessing native APIs from cross-platform code. The power of Xamarin is you have full API access allowing you to take advantage of the unique features of each platform, but sometimes you just want to do something in one line of code that applies to all platforms.&lt;/p>
&lt;p>Plugins have helped with this - so you can install a NuGet package such as the &lt;a href="https://www.nuget.org/packages/Plugin.Permissions/">permissions&lt;/a> or &lt;a href="https://www.nuget.org/packages/Xam.Plugin.Connectivity/">connectivity&lt;/a> plugins from James Montemagno and have a nice cross-platform API, but discoverability has always been a bit hard, you have to know there is a plugin and what the NuGet package is called.&lt;/p>
&lt;p>To make it easier, there is now &lt;a href="https://www.nuget.org/packages/Xamarin.Essentials/">Xamarin.Essentials&lt;/a>, a single package that you can install into any Xamarin app to get cross-platform access to a wide range of APIs such as accelerometer, compass, network connectivity, keeping the screen awake and more. You can see the full list of supported features on the &lt;a href="http://github.com/xamarin/Essentials">Xamarin Essentials GitHub page&lt;/a>. This package currently has 24 different API sets, with more planned. Essentials is for all Xamarin apps, both traditional and Forms apps.&lt;/p>
&lt;div class="image-div" style="max-width: 128px;">
&lt;p>&lt;img src="xamarin.essentials_128x128.png" alt="Xamarin Essentials logo">&lt;/p>
&lt;/div>
&lt;p>I&amp;rsquo;ve started building an app to track my daughters pocket money - I don&amp;rsquo;t use cash so it&amp;rsquo;s hard to regularly put cash into a piggy bank, instead I though I&amp;rsquo;d write an app I can use to regularly put an amount into a virtual account, and when she wants to spend it, use my card for the purchase (easier with Amazon for example) and deduct the cost from her virtual piggy bank. The first part of this app is logging in, and for that I&amp;rsquo;m going to use &lt;a href="https://jimbobbennett.dev/blogs/authenticating-your-xamarin-app-with-azure-and-facebook/">social auth and Azure&lt;/a>, but there is no point in showing a login screen if the user is not connected to the internet, so I thought I&amp;rsquo;d give Essentials a spin and use the connectivity part.&lt;/p>
&lt;p>Setting it up is easy, just install the NuGet package into all projects in your app (it must be all as it has the platform specifics in the iOS and Android packages). For Android you do need to initialize the library and set up some permissions stuff in all activities. I&amp;rsquo;m using Xamarin Forms, so only have one activity to do it in:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">protected&lt;/span> &lt;span style="color:#66d9ef">override&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> OnCreate(Bundle savedInstanceState)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Forms.Init(&lt;span style="color:#66d9ef">this&lt;/span>, savedInstanceState);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Xamarin.Essentials.Platform.Init(&lt;span style="color:#66d9ef">this&lt;/span>, savedInstanceState);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">override&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> OnRequestPermissionsResult(&lt;span style="color:#66d9ef">int&lt;/span> requestCode,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">string&lt;/span>[] permissions,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e"> [GeneratedEnum]&lt;/span> Permission[] grantResults)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Xamarin.Essentials.Platform.OnRequestPermissionsResult(requestCode, permissions, grantResults);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">base&lt;/span>.OnRequestPermissionsResult(requestCode, permissions, grantResults);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Done - Essentials is all set up. Checking connectivity is now really easy:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">using&lt;/span> Xamarin.Essentials;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">if&lt;/span> (Connectivity.NetworkAccess != NetworkAccess.Internet)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ... &lt;span style="color:#75715e">// no internet access &lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Checking network access is as simple as checking the value of the &lt;code>Connectivity.NetworkAccess&lt;/code> static property. If this is set to &lt;code>NetworkAccess.Internet&lt;/code> then there is internet access. There is also an enum member called &lt;code>ConstrainedInternet&lt;/code> when there is a connection but with a poor signal. Otherwise - no internet.&lt;/p>
&lt;blockquote>
&lt;p>These properties are all static, which might seem odd to developers who prefer interfaces for use in IoC containers. There is a discussion around this on the &lt;a href="https://github.com/xamarin/Essentials#where-are-the-interfaces">README.md on GitHub&lt;/a>.&lt;/p>
&lt;/blockquote>
&lt;p>I might also want to be notified when the users internet access has changed. For example if I hide the login button when they are not connected due to being in airplane mode, I&amp;rsquo;d want my app to know when they turned airplane mode off so it can show the login button again. I can do this using the &lt;code>Connectivity.ConnectivityChanged&lt;/code> event. This means the code for my login page can be:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">public&lt;/span> LoginPage()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Connectivity.ConnectivityChanged += e =&amp;gt; ShowOrHideLoginButton();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ShowOrHideLoginButton();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">void&lt;/span> ShowOrHideLoginButton()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> LoginButton.IsVisble = (Connectivity.NetworkAccess == NetworkAccess.Internet ||
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Connectivity.NetworkAccess == NetworkAccess.ConstrainedInternet);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>You can read more about Xamarin Essentials in the &lt;a href="https://docs.microsoft.com/en-gb/xamarin/essentials/?WT.mc_id=pocketmoney-blog-jabenn">official documentation&lt;/a>. Also check out the &lt;a href="https://github.com/xamarin/Essentials">GitHub page&lt;/a> - this library is fully open source like all Xamarin goodness, and you can raise issues or pull request there if you feel like contributing to this awesome project.&lt;/p></description></item><item><title>Building mobile apps in F# using Xamarin.Forms and Elmish</title><link>https://jimbobbennett.dev/blogs/building-mobile-apps-in-f-using-xamarin-forms-and-elmish/</link><pubDate>Sun, 06 May 2018 15:00:40 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/building-mobile-apps-in-f-using-xamarin-forms-and-elmish/</guid><description>&lt;h1 id="fsharp-and-xamarin">FSharp and Xamarin&lt;/h1>
&lt;p>Xamarin is well known for allowing you to build mobile apps in C#, but you can use F# as well. F# is fully supported by the compiler and toolchains in both Visual Studio 2017 and Visual Studio for Mac. It&amp;rsquo;s also pretty much supported by all the Xamarin tools including Xamarin.Forms (&lt;a href="https://github.com/xamarin/Xamarin.Forms/issues/2425">except for one bug&lt;/a> that should be fixed soon).&lt;/p>
&lt;p>This is great for F# fans like me, but one thing that has been missing for a while has been architecture recomendations. Mobile apps, like other UI heavy apps are very object oriented. Buttons are objects, labels are objects and they fit very nicely into the classic &amp;lsquo;OO&amp;rsquo; space. This has meant that traditionally UI apps are also built using objects - it&amp;rsquo;s objects all the way down and mutable state everywhere. This doesn&amp;rsquo;t match well with functional programming paradigms which try to move away from objects and mutability.&lt;/p>
&lt;p>To go functional when it comes to UI, one trend is towards Elm. This is an architecture that comes from Erlang and has become popular in the F# community via &lt;a href="https://github.com/elmish/elmish">Elmish for Fable&lt;/a> for web sites. This architecture abstracts the object nature of the UI away and replaced by a purely functional model. The app runs with a function to create a view, a function to initialise an immutable model, and an update function to handle messages from either the UI or other parts of the system. The update function takes the current model and a message, and returns a new instance of the model containing a copy of the original model updated based off the message recieved. Once a new model is generated the UI is updated.&lt;/p>
&lt;div class="image-div" style="max-width: 410px;">
&lt;p>&lt;img src="04-flow.png" alt="Overview diagram of Elm">&lt;/p>
&lt;/div>
&lt;p>This paradigm has been ported to F# by &lt;a href="https://twitter.com/dsyme">Don Syme&lt;/a> as &lt;a href="https://github.com/fsprojects/Elmish.XamarinForms">Elmish.XamarinForms&lt;/a>, an open source project also available on &lt;a href="https://www.nuget.org/packages/Elmish.XamarinForms">NuGet&lt;/a>. This project provides two possible implementations of Elmish for Xamarin.Forms - known as half-elmish and full-elmish. In this post I&amp;rsquo;ll look at the half-elmish implementation as this is more suited to Xamarin developers who want to move to F# (full-elmish is more suited to F# developers wanting to move to Xamarin).&lt;/p>
&lt;h3 id="half-elmish">Half-Elmish&lt;/h3>
&lt;p>Half-elmish mixes traditional Xamarin.Forms development with the elmish architecture. At it&amp;rsquo;s most basic, you define your UI using XAML, setting bindings on the UI elements as if you were using MVVM. You then implement an imutable model, an update method that handles messages that you define and returns an updated model, and a view method that configures the bindings for your UI including property bindings and commands. When a message is handled the bindings are re-evaluated and the UI updates using the normal Xamarin.Forms data binding.&lt;/p>
&lt;h4 id="getting-started">Getting started&lt;/h4>
&lt;p>Start by creating a new blank Xamarin.Forms F# app using either Visual Studio 2017 or Visual Studio for Mac called &lt;strong>HelloElmish&lt;/strong>. The latest versions of both will allow you to create apps with a .NET standard core project. Add the &lt;code>Elmish.XamarinForms&lt;/code> NuGet package to all the projects in your app.&lt;/p>
&lt;p>We&amp;rsquo;ll create a fairly boring app, one that tracks the number of clicks of a button. Not exciting, but enough to illustrate the basics to get you started. Open the &lt;code>MainPage.xaml&lt;/code> file, remove the contents of the &lt;code>ContentPage&lt;/code> and add the following:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-xml" data-lang="xml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;lt;StackLayout&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;lt;Label&lt;/span> &lt;span style="color:#a6e22e">Text=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;{Binding Path=[Count]}&amp;#34;&lt;/span>&lt;span style="color:#f92672">/&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;lt;Button&lt;/span> &lt;span style="color:#a6e22e">Text=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;Increment&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">Command=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;{Binding Path=[Increment]}&amp;#34;&lt;/span>&lt;span style="color:#f92672">/&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;lt;/StackLayout&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;blockquote>
&lt;p>Notice how the bindings are set using an array-indexer style syntax. This is part of the Elmish implementation of binding, so if you want to know more head to GitHub and dig through the source, but for now just accept that this is how we bind.&lt;/p>
&lt;/blockquote>
&lt;p>Next, lets implement the application logic. Open the &lt;code>App.xaml.cs&lt;/code> file. We need to declare a model to track the button click count, an &lt;code>enum&lt;/code> to define the messages our app supports, as well as three functions - &lt;code>init&lt;/code>, &lt;code>update&lt;/code> and &lt;code>view&lt;/code>.&lt;/p>
&lt;p>The model is fairly simple, so declare this before the &lt;code>App&lt;/code> class declaration:&lt;/p>
&lt;pre tabindex="0">&lt;code>type Model =
{
Count : int
}
&lt;/code>&lt;/pre>&lt;p>Next up, add an enum type for the messages that the update function will handle:&lt;/p>
&lt;pre tabindex="0">&lt;code>type Msg =
| Increment
&lt;/code>&lt;/pre>&lt;p>Now we need to implement the &lt;code>init&lt;/code> method. This is called when your app starts up to create the initial model, so add this function to the &lt;code>App&lt;/code> class:&lt;/p>
&lt;pre tabindex="0">&lt;code>let init () = { Count = 0 }
&lt;/code>&lt;/pre>&lt;p>This creates a new model with the count set to 0. Next is to add a function to handle a message to increment the counter. This takes a message and a model, so add this to the &lt;code>App&lt;/code> class:&lt;/p>
&lt;pre tabindex="0">&lt;code>let update msg model =
match msg with
| Increment -&amp;gt; { Count = model.Count + 1 }
&lt;/code>&lt;/pre>&lt;p>This function matches the message with the &lt;code>Increment&lt;/code> message, and if it matches returns a new model with the &lt;code>Count&lt;/code> set to the count of the previous model plus one. It may seem overkill to match when we only have one message type, but we&amp;rsquo;ll add another message type later. Notice how it is always a new model that is returned - the &lt;code>Model&lt;/code> type is immutable so we always have to create a new copy.&lt;/p>
&lt;p>After the &lt;code>update&lt;/code> function we need to add the &lt;code>view&lt;/code> function to the &lt;code>App&lt;/code> type. This is used to create bindings between the UI, the model and the messages. This function returns a tuple of a Xamarin.Forms page and a list of bindings:&lt;/p>
&lt;pre tabindex="0">&lt;code>let view () =
MainPage(),
[ &amp;#34;Count&amp;#34; |&amp;gt; Binding.oneWay (fun m -&amp;gt; m.Count.ToString())
&amp;#34;Increment&amp;#34; |&amp;gt; Binding.msg Increment
]
&lt;/code>&lt;/pre>&lt;p>You&amp;rsquo;ll need to open the following modules at the top of the file for this to compile:&lt;/p>
&lt;pre tabindex="0">&lt;code>open Elmish.XamarinForms
open Elmish.XamarinForms.StaticViews
&lt;/code>&lt;/pre>&lt;p>This view method defines two bindings. One is a one way binding for the &lt;code>&amp;quot;Count&amp;quot;&lt;/code> property that binds the value to a function that returns the &lt;code>Count&lt;/code> from the model converted to a string. The next is a binding from the &lt;code>&amp;quot;Increment&amp;quot;&lt;/code> command to the &lt;code>Increment&lt;/code> message.&lt;/p>
&lt;p>When the app is launched this &lt;code>view&lt;/code> function is run and the page is created. The values of the bindings are evaluated and set. The &lt;code>oneWay&lt;/code> binding sets the value on the Label based on the return value of the function, and the &lt;code>msg&lt;/code> binding binds the button command property to a command created for you by the elmish implementation. Executing this command calls the &lt;code>update&lt;/code> function passing in the &lt;code>Increment&lt;/code> message and the current model.&lt;/p>
&lt;p>When the button is clicked, this command is executed, calling the &lt;code>update&lt;/code> function. The new model that comes back from this function call is then passed through the bindings again, and if the values returned from the bindings is different from the previous value the UI widget gets updated. In our case, the &lt;code>update&lt;/code> method increments the count, so the value of the one way binding would increment from 0 to 1, and the UI would be updated to show 1.&lt;/p>
&lt;p>The final thing to do is wire everything up to make the app kick off the elmish functions. Add the following to the &lt;code>App&lt;/code> class:&lt;/p>
&lt;pre tabindex="0">&lt;code>let runner =
Program.mkSimple init update view
|&amp;gt; Program.withStaticView
|&amp;gt; Program.run
do base.MainPage &amp;lt;- runner.InitialMainPage
&lt;/code>&lt;/pre>&lt;p>In addition, remove the setting of the &lt;code>MainPage&lt;/code> when inheriting from &lt;code>App&lt;/code>:&lt;/p>
&lt;pre tabindex="0">&lt;code>type App() =
inherit Application()
&lt;/code>&lt;/pre>&lt;p>This code creates a &lt;code>runner&lt;/code> that creates an elmish program using our &lt;code>init&lt;/code>, &lt;code>update&lt;/code> and &lt;code>view&lt;/code> functions. It uses a static view that tells elmish that the page is created once and updated via binding. The &lt;strong>full-elmish&lt;/strong> implementation doesn&amp;rsquo;t use XAML pages, instead it creates the UI on the fly and the whole UI is rebuilt after each update (with a lot of logic inside the elmish code to reuse stuff for performance). Full-elmish is outside the scope of this post.&lt;/p>
&lt;p>This runner has an initial main page property that is set as the &lt;code>MainPage&lt;/code> for your &lt;code>App&lt;/code> class. The elmish architecture supports navigation and multiple pages, and I&amp;rsquo;ll cover this in a later blog post.&lt;/p>
&lt;p>Build everything and run the app. You&amp;rsquo;ll be able to click the button and see the count increment.&lt;/p>
&lt;div class="image-div" style="max-width: 322px;">
&lt;p>&lt;img src="2018-05-05_15-44-50-2.gif" alt="Animated Gif showing the value being incremented">&lt;/p>
&lt;/div>
&lt;h4 id="getting-more-advanced">Getting more advanced&lt;/h4>
&lt;p>Lets make this a bit more advanced by adding a decrement button. Start by adding a new button to the &lt;code>StackLayout&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-xml" data-lang="xml">&lt;span style="display:flex;">&lt;span>...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;lt;Button&lt;/span> &lt;span style="color:#a6e22e">Text=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;Decrement&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">Command=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;{Binding Path=[Decrement]}&amp;#34;&lt;/span>&lt;span style="color:#f92672">/&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>...
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Next add a message type for this:&lt;/p>
&lt;pre tabindex="0">&lt;code>type Msg =
| Increment
| Decrement
&lt;/code>&lt;/pre>&lt;p>Then add code to the &lt;code>update&lt;/code> function to handle this message:&lt;/p>
&lt;pre tabindex="0">&lt;code>let update msg model =
match msg with
| Increment -&amp;gt; { Count = model.Count + 1 }
| Decrement -&amp;gt; { Count = model.Count - 1 }
&lt;/code>&lt;/pre>&lt;p>Then finally wire up the message in the &lt;code>view&lt;/code> function:&lt;/p>
&lt;pre tabindex="0">&lt;code>let view () =
MainPage(),
[ &amp;#34;Count&amp;#34; |&amp;gt; Binding.oneWay (fun m -&amp;gt; m.Count.ToString())
&amp;#34;Increment&amp;#34; |&amp;gt; Binding.msg Increment
&amp;#34;Decrement&amp;#34; |&amp;gt; Binding.msg Decrement
]
&lt;/code>&lt;/pre>&lt;p>Run the app and you&amp;rsquo;ll be able to increment and decrement the value.&lt;/p>
&lt;div class="image-div" style="max-width: 322px;">
&lt;p>&lt;img src="2018-05-05_15-47-58.gif" alt="Animated Gif showing the value being incremented and decremented">&lt;/p>
&lt;/div>
&lt;p>The code for this is on &lt;a href="https://github.com/jimbobbennett/HelloElmish">GitHub&lt;/a>.&lt;/p>
&lt;h3 id="learn-more">Learn more&lt;/h3>
&lt;p>We&amp;rsquo;ve seen a very simple example of how to use F# to build Xamarin.Forms apps using the elmish architecture. For a more complicated example, check out my &lt;a href="https://github.com/jimbobbennett/TicTacToe">Tic Tac Toe game on GitHub&lt;/a> or any of the &lt;a href="https://github.com/fsprojects/Elmish.XamarinForms/tree/master/Samples">Elmish.XamarinForms samples&lt;/a>.&lt;/p>
&lt;p>Also check out my video from &lt;a href="http://fsharpconf.com">F#Conf&lt;/a> on using F# to build Xamarin apps below or on &lt;a href="https://channel9.msdn.com/Events/FSharp-Events/fsharpConf-2018/05/?WT.mc_id=fsharpconf-channel9-jabenn">Channel9&lt;/a>, and don&amp;rsquo;t forget there is plenty of official &lt;a href="https://www.microsoft.com/net/learn/languages/fsharp/?WT.mc_id=fsharp-blog-jabenn">Xamarin F# documentation&lt;/a> available.&lt;/p>
&lt;iframe src="https://channel9.msdn.com/Events/FSharp-Events/fsharpConf-2018/05/player" width="960" height="540" allowFullScreen frameBorder="0">&lt;/iframe></description></item><item><title>The Jim and Tonic show</title><link>https://jimbobbennett.dev/blogs/the-jim-tonic-podcast/</link><pubDate>Wed, 02 May 2018 13:16:53 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/the-jim-tonic-podcast/</guid><description>&lt;p>Since starting at Microsoft as a &lt;a href="https://developer.microsoft.com/en-us/advocates/jim-bennett/?WT.mc_id=podcast-blog-jabenn">Senior Cloud Developer Advocate&lt;/a> I&amp;rsquo;ve been hugely privileged surrounded on a daily basis by some of the most awesome people across a wide range of developer communities - the rest of the Cloud Developer Advocacy team. These are engineers who constantly work to make the world amazing for developers across a wide range of technologies and disciplines.&lt;/p>
&lt;p>To help me get to know the rest of the team, I&amp;rsquo;ve decided to record a podcast. This is a regular show where I chat to different members of the team to get to know who they are, how they got to where they are now, and just talk about whatever geeky stuff excites them.&lt;/p>
&lt;p>It&amp;rsquo;s called the &lt;strong>Jim and Tonic Show&lt;/strong>.&lt;/p>
&lt;p>You can find it at &lt;a href="https://www.jimandtonic.show">https://www.jimandtonic.show&lt;/a>.&lt;/p>
&lt;div class="image-div" style="max-width: 800px;">
&lt;p>&lt;img src="header.png" alt="Jim and tonic show logo">&lt;/p>
&lt;/div>
&lt;p>Currently two episodes are published:&lt;/p>
&lt;p>&lt;strong>Asim Hussain&lt;/strong>&lt;/p>
&lt;iframe width="560" height="80" scrolling="no" frameborder="no" src="https://fireside.fm/s/e8qyFYwX+MWQA3mBl/iframe">&lt;/iframe>
&lt;br/>
&lt;p>&lt;strong>Cecil Phillip&lt;/strong>&lt;/p>
&lt;iframe width="560" height="80" scrolling="no" frameborder="no" src="https://fireside.fm/s/e8qyFYwX+bLwdlG85/iframe">&lt;/iframe>
&lt;br/>
&lt;p>You can also subscribe on iTunes.&lt;/p>
&lt;div class="image-div" style="max-width: 200px;">
&lt;a href="https://itunes.apple.com/gb/podcast/jim-tonic/id1377604526">
&lt;p>&lt;img src="Listen_on_Apple_Podcasts_sRGB_US.svg" alt="">&lt;/p>
&lt;/a>
&lt;/div></description></item><item><title>Face identification with Azure Cognitive Services Face API</title><link>https://jimbobbennett.dev/blogs/face-identification-with-azure-faceapi/</link><pubDate>Fri, 02 Mar 2018 20:27:18 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/face-identification-with-azure-faceapi/</guid><description>&lt;p>Recently I&amp;rsquo;ve been playing with a lot AI and seeing how it can be used in mobile apps to enhance the experience offered to the user. Currently I am playing with facial recognition using the &lt;a href="https://aka.ms/Vd514y">Azure Cognitive Services Face API&lt;/a>. This is a stupidly powerful API that can do a LOT of different things:&lt;/p>
&lt;ul>
&lt;li>Detect faces in images&lt;/li>
&lt;li>Analyze those faces to detect characteristics such as hair color, gender, age&lt;/li>
&lt;li>Detect the different points on a face, such as the pupils or lips&lt;/li>
&lt;li>Compare two faces and verify if they are from the same person&lt;/li>
&lt;li>Group faces by similar facial characteristics&lt;/li>
&lt;li>Identify faces from a repository of up to a million images&lt;/li>
&lt;/ul>
&lt;p>This is a very powerful set of APIs with a large number of different use cases. For example if you were building a social network you could use the facial identification to automatically tag peoples friends in images. If you were building a ride share system you could use facial verification to ensure the driver is who you expect it to be. For now I&amp;rsquo;m going to focus on one particular example - identifying faces from a photo in a mobile app.&lt;/p>
&lt;h2 id="face-finder">Face Finder&lt;/h2>
&lt;p>I&amp;rsquo;ve built a sample mobile app to show off the facial recognition tools in this API, and you can grab the code from &lt;a href="https://github.com/jimbobbennett/FaceFinder">my GitHub repo&lt;/a>. This app takes a photo, then finds all the faces in that photo, giving a breakdown of the details of each face.&lt;/p>
&lt;div class="image-div" style="max-width: 300px;">
&lt;p>&lt;img src="FaceAPI.gif" alt="Animated GIF of the Face Finder app in action">&lt;/p>
&lt;/div>
&lt;p>In the rest of this post I&amp;rsquo;ll go through you can get signed up for FaceAPI, and how the app works.&lt;/p>
&lt;h4 id="getting-started-with-faceapi">Getting started with FaceAPI&lt;/h4>
&lt;p>From the &lt;a href="https://portal.azure.com/?WT.mc_id=azureportal-blog-jabenn">Azure Portal&lt;/a>, select &lt;strong>Create a resource&lt;/strong>, search for &lt;em>&amp;ldquo;Face&amp;rdquo;&lt;/em>, and select &lt;strong>Face&lt;/strong> from the &lt;strong>AI + Machine Learning&lt;/strong> category. The click &lt;strong>Create&lt;/strong>.&lt;/p>
&lt;div class="image-div" style="max-width:480px;">
&lt;p>&lt;img src="2018-11-05_11-20-49.png" alt="Selecting the Face API">&lt;/p>
&lt;/div>
&lt;p>Enter a name for this resource, select your subscription and the location nearest to you. For the pricing tier, there is a free tier called &lt;strong>F0&lt;/strong> that gives you 30,000 calls per month at a rate of no more than 20 per minute, and you can have one face resource per subscription with this tier. After this there is a paid tier limited to 10 calls per second and you pay per 1,000 calls - at the time of writing this is US$0.25 per 1,000 calls.&lt;/p>
&lt;div class="image-div" style="max-width:300px;">
&lt;p>&lt;img src="2018-11-05_11-24-47.png" alt="The pricing matrix for Face calls">&lt;/p>
&lt;/div>
&lt;p>Choose a resource group, or create a new one and click &lt;strong>Create&lt;/strong>. Once it has been created, head to it and grab an API key from &lt;em>Resource Management-&amp;gt;Keys&lt;/em>, and the endpoint from the &lt;em>Overview&lt;/em> blade.&lt;/p>
&lt;h4 id="building-and-running-the-app">Building and running the app&lt;/h4>
&lt;p>The Face Finder app is pretty complete, all you need to do is update the &lt;code>ApiKeys.cs&lt;/code> file with your API key and endpoint. For the &lt;code>FaceApiKey&lt;/code>, copy yours and paste it in. For the &lt;code>FaceApiEndpoint&lt;/code>, paste the value for the endpoint, removing everything past &lt;code>microsoft.com&lt;/code>. For example, for me the endpoint shown in the Azure portal is &lt;em>&lt;a href="https://westeurope.api.cognitive.microsoft.com/face/v1.0">https://westeurope.api.cognitive.microsoft.com/face/v1.0&lt;/a>&lt;/em>, so I would set the endpoint to &lt;code>https://westeurope.api.cognitive.microsoft.com&lt;/code>.&lt;/p>
&lt;blockquote>
&lt;p>If you get a &lt;em>Not Found&lt;/em> exception, then check your endpoint - this exception is thrown if you don&amp;rsquo;t remove everything past &lt;code>microsoft.com&lt;/code>.&lt;/p>
&lt;/blockquote>
&lt;p>Once you have done this, build and run the app. When it loads, tap the &lt;strong>Take photo&lt;/strong> button and take a picture of one or more faces. The app will then show a list of all the faces detected, describing them using the detected age and gender. Tap on a face in the list to see more details, including if that person is smiling, if they are wearing glasses, what hair, facial hair and makeup they have, and their emotion.&lt;/p>
&lt;h4 id="so-how-does-it-work">So how does it work&lt;/h4>
&lt;p>This app is a simple Xamarin.Forms app, with three pages and some view models. The first page, &lt;code>FaceFinderPage.xaml&lt;/code> has a button you tap to take a photo, wired up to a command on the &lt;code>FaceFinderViewModel&lt;/code>. This uses the &lt;a href="https://www.nuget.org/packages/Xam.Plugin.Media/">Xam.Plugin.Media&lt;/a> plugin from &lt;a href="https://twitter.com/JamesMontemagno">James Montemagno&lt;/a> to launch the camera and take a picture. This picture is then run through the face API.&lt;/p>
&lt;p>The face API is accessed via an SDK from a NuGet package. Currently there are a load of NuGet packages from Microsoft with names containing &lt;strong>ProjectOxford&lt;/strong> - the code name for the various vision cognitive services. These are being replaced with new packages that are called &lt;strong>Microsoft.Azure.CognitiveServices.*&lt;/strong>, and these packages are currently in pre-release. For the face API, I&amp;rsquo;m using the &lt;strong>Microsoft.Azure.CognitiveServices.Vision.Face&lt;/strong> package, currently available as a pre-release package.&lt;/p>
&lt;div class="image-div" style="max-width: 600px;">
&lt;p>&lt;img src="2018-11-05_11-34-13.png" alt="Adding the Vision.Face package">&lt;/p>
&lt;/div>
&lt;p>The important class to note here is &lt;code>FaceClient&lt;/code>, this wraps a connection to the Azure Face Api and is configured using your API key and endpoint.&lt;/p>
&lt;p>&lt;strong>Initializing the FaceClient&lt;/strong>&lt;/p>
&lt;p>Before you can use the Face API you have to configure it to use one of your keys and the appropriate endpoint. When constructing an instance of &lt;code>FaceClient&lt;/code> you need to pass it credentials, in the form of an instance of &lt;code>ApiKeyServiceClientCredentials&lt;/code> which takes one of the API keys assigned to your account as a string in a constructor argument:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> creds = &lt;span style="color:#66d9ef">new&lt;/span> ApiKeyServiceClientCredentials(&lt;span style="color:#e6db74">&amp;#34;&amp;lt;your api key&amp;gt;&amp;#34;&lt;/span>);
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>You can then pass this to the constructor of the &lt;code>FaceClient&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> faceClient = &lt;span style="color:#66d9ef">new&lt;/span> FaceClient(creds);
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Finally you set the appropriate endpoint to match the endpoint shown with your keys:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>faceClient.Endpoint = &lt;span style="color:#e6db74">&amp;#34;https://westeurope.api.cognitive.microsoft.com&amp;#34;&lt;/span>;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Detecting faces&lt;/strong>&lt;/p>
&lt;p>Once you have your instance of the &lt;code>FaceClient&lt;/code> you can then use that to detect faces using the &lt;code>Face&lt;/code> property to access all the different face operations the API supports. The method I&amp;rsquo;m interested in is the &lt;code>DetectWithStreamAsync&lt;/code> method. This takes a stream containing the image, and sends it up to Azure to detect faces. The &lt;code>Async&lt;/code> suffix is because it is an &lt;code>async&lt;/code> method that you can await (not sure why they&amp;rsquo;ve added this suffix - they don&amp;rsquo;t have non-async versions on the API).&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> faces = faceClient.Face.DetectInStreamAsync(imageStream);
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The &lt;code>imageStream&lt;/code> comes from the media plugin. When you use this plugin to take a photo it returns a &lt;code>MediaFile&lt;/code> which has a method to get the image as a stream that can be passed to the detect call. This method has some other parameters on it which we&amp;rsquo;ll look at later.&lt;/p>
&lt;p>The results of this call is a list of detected faces - literally a &lt;code>List&amp;lt;DetectedFace&amp;gt;&lt;/code>, with one entry per face that was detected in the image. Each &lt;code>DetectedFace&lt;/code> in the list contains a set of properties about that face, including coordinates of a rectangle that shows where the face is in the image. The picture below shows a face with this rectangle drawn on top.&lt;/p>
&lt;div class="image-div" style="max-width: 300px;">
&lt;p>&lt;img src="2018-03-02_17-08-06.png" alt="A picture of the author with a bounding box showing the face rectangle">&lt;/p>
&lt;/div>
&lt;p>&lt;strong>Detecting face attributes&lt;/strong>&lt;/p>
&lt;p>So far, so good - we can find where a face is. Now what about more details about the face? This is where the extra parameters on the &lt;code>DetectWithStreamAsync&lt;/code> method come in.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>DetectWithStreamAsync(Stream image,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">bool?&lt;/span> returnFaceId = &lt;span style="color:#66d9ef">true&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">bool?&lt;/span> returnFaceLandmarks = &lt;span style="color:#66d9ef">false&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> IList&amp;lt;FaceAttributeType&amp;gt; returnFaceAttributes = &lt;span style="color:#66d9ef">null&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> CancellationToken cancellationToken = &lt;span style="color:#66d9ef">default&lt;/span>(CancellationToken));
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>So what do these parameters do:&lt;/p>
&lt;ul>
&lt;li>&lt;code>returnFaceId&lt;/code> - set this to &lt;code>true&lt;/code> (the default) to return an Id for the face. This Id can then be used for face searching operations - outside the scope of this post!&lt;/li>
&lt;li>&lt;code>returnFaceLandmarks&lt;/code> - set this to &lt;code>true&lt;/code> (default is &lt;code>false&lt;/code>) to return the coordinates of the facial landmarks, for example the positions of the pupils, nose, lips etc.&lt;/li>
&lt;li>&lt;code>returnFaceAttributes&lt;/code> - this is a list of the different face attributes you want returned. There are a lot of these! In the Face Finder app I get them all, and they are:
&lt;ul>
&lt;li>&lt;code>Age&lt;/code> - a guess at the age of the face. Seeing as it predicted me at 9 years older than I am in the image above it&amp;rsquo;s either buggy, or (more likely) I need more sleep and to look after myself!&lt;/li>
&lt;li>&lt;code>Gender&lt;/code> - a guess at the presented gender. Just limited to male or female.&lt;/li>
&lt;li>&lt;code>HeadPose&lt;/code> - what position the head is in, pitch, roll and yaw.&lt;/li>
&lt;li>&lt;code>Smile&lt;/code> - the percentage certainty that the face is smiling.&lt;/li>
&lt;li>&lt;code>FacialHair&lt;/code> - the percentage certainty that the face has a beard, mustache or sideburns.&lt;/li>
&lt;li>&lt;code>Glasses&lt;/code> - the type of glasses (if any) the person is wearing, so normal glasses, sun glasses etc.&lt;/li>
&lt;li>&lt;code>Emotion&lt;/code> - the percentages that the face is displaying a set of emotions (e.g. anger, happiness, surprise)&lt;/li>
&lt;li>&lt;code>Hair&lt;/code> - the percentages certainty that the face has different colored hair. If no hair is detected then this list is empty, otherwise it covers all natural hair colors and &amp;lsquo;other&amp;rsquo;. This also specifies if the face is bald or if the hair is invisible (such as under a hat or scarf).&lt;/li>
&lt;li>&lt;code>Makeup&lt;/code> - The percentage certainty that the face has eye or lip makeup on.&lt;/li>
&lt;li>&lt;code>Occlusion&lt;/code> - how much of the face is occluded (such as by a mask, bandana, hair etc.)&lt;/li>
&lt;li>&lt;code>Accessories&lt;/code> - any accessories on the face, such as glasses or a hat&lt;/li>
&lt;li>&lt;code>Blur&lt;/code> - how blurry the face is.&lt;/li>
&lt;li>&lt;code>Exposure&lt;/code> - how well exposed the picture is.&lt;/li>
&lt;li>&lt;code>Noise&lt;/code> - how much noise there is in the image.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>These landmarks and attributes come back on the &lt;code>DetectedFace&lt;/code> instances, and are present for all faces in the image.&lt;/p>
&lt;h4 id="what-sort-of-apps-can-i-build-with-this">What sort of apps can I build with this?&lt;/h4>
&lt;p>This API is great and can provide a LOT of power, but are they just for mucking around, or can we build real-world apps with them? Well a few examples I can think of without trying too hard are:&lt;/p>
&lt;ul>
&lt;li>Passport photo app. Passports have strict requirements about photos, so you could use this API to ensure the person was looking at the camera (&lt;code>HeadPose&lt;/code>), no glasses (&lt;code>Glasses&lt;/code>) or make-up (&lt;code>Makeup&lt;/code>), and a neutral expression (&lt;code>Emotion&lt;/code>). The photo needs to be of good quality (&lt;code>Exposure&lt;/code>, &lt;code>Blur&lt;/code>, &lt;code>Noise&lt;/code>).&lt;/li>
&lt;li>Facial blurring. You could detect the face rectangle and blur out faces automatically, for example in apps that make photos public. You could even do it by age to only blur out children if needed.&lt;/li>
&lt;li>Adding decoration to faces. Using the landmarks you could add fake glasses, hats, dog noses or other things to a face to make a comedy picture. I&amp;rsquo;ve even seen an example replacing faces with emojis that match the emotion being shown.&lt;/li>
&lt;li>Auto-picture selection. You could take a selection of pictures and have it choose the best one based on quality (&lt;code>Exposure&lt;/code>, &lt;code>Blur&lt;/code>, &lt;code>Noise&lt;/code>) and if the people in it are smiling (&lt;code>Emotion&lt;/code>).&lt;/li>
&lt;/ul>
&lt;h4 id="where-can-i-learn-more">Where can I learn more?&lt;/h4>
&lt;p>We&amp;rsquo;ve got loads of great content on-line showing all the cool things you ca do with this API, from all different languages. Check them out:&lt;/p>
&lt;ul>
&lt;li>Read the offical docs at &lt;a href="https://aka.ms/I5y8t7">docs.microsoft.com&lt;/a>&lt;/li>
&lt;li>Work through some great tutorials from the &lt;a href="https://aka.ms/Hz3eo7">Microsoft AI School&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Identifying my daughters toys using AI - Part 5, Plugin for on-device models</title><link>https://jimbobbennett.dev/blogs/identifying-my-daughters-toys-using-ai-part-5-plugin-for-on-device-models/</link><pubDate>Mon, 26 Feb 2018 15:22:18 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/identifying-my-daughters-toys-using-ai-part-5-plugin-for-on-device-models/</guid><description>&lt;p>In the &lt;a href="https://jimbobbennett.dev/blogs/identifying-my-daughters-toys-using-ai/">first part of this series&lt;/a> I used the &lt;a href="http://customvision.ai/?wt.mc_id=toyidentifier-blog-jabenn">Azure Custom Vision service&lt;/a> to create an image classifier to allow me to easily identify my daughters cuddly toys. Once created I tested it by uploading an image and seeing what tags the classifier found for the image.&lt;/p>
&lt;p>In the &lt;a href="https://jimbobbennett.dev/blogs/identifying-my-daughters-toys-using-ai-part-2-using-the-model/">second part&lt;/a> I accessed this model from a Xamarin app, so that I could use the camera to take a photo to run through the classifier using a NuGet package that talks to the Custom Vision service.&lt;/p>
&lt;p>In the &lt;a href="https://jimbobbennett.dev/blogs/identifying-my-daughters-toys-using-ai-part-3-offline-ios/">third part&lt;/a> I showed how to download this model for iOS and run it locally, on device, using CoreML.&lt;/p>
&lt;p>In the &lt;a href="https://jimbobbennett.dev/blogs/https://www.jimbobbennett.io/identifying-my-daughters-toys-using-ai-part-4-offline-android/">fourth part&lt;/a> I showed how to download this model for Android and run it locally, on device, using Tensorflow.&lt;/p>
&lt;p>To run these models locally is a lot of boilerplate code, so I decided to make it easier and create a NuGet package containing a Xamarin plugin that can be used from iOS, Android and Xamarin.Forms apps.&lt;/p>
&lt;p>This plugin makes it easy to download and use these models offline from inside your mobile app, using CoreML on iOS or Tensorflow on Android. These models can then be called from a .NET standard library, using something like Xam.Plugins.Media to take photos for classification.&lt;/p>
&lt;h4 id="setup">Setup&lt;/h4>
&lt;ul>
&lt;li>Available on NuGet: &lt;a href="https://www.nuget.org/packages/Xam.Plugins.OnDeviceCustomVision/">https://www.nuget.org/packages/Xam.Plugins.OnDeviceCustomVision/&lt;/a> &lt;a href="https://www.nuget.org/packages/Xam.Plugins.OnDeviceCustomVision/">&lt;img src="https://img.shields.io/nuget/v/Xam.Plugins.OnDeviceCustomVision.svg?label=NuGet" alt="NuGet">&lt;/a>&lt;/li>
&lt;li>Install into your .NET Standard project and iOS and Android client projects.&lt;/li>
&lt;/ul>
&lt;h4 id="platform-support">Platform Support&lt;/h4>
&lt;p>This requires iOS 11 and up to use models from CoreML. For Android with Tensorflow the minimum supported SDK version is 21.&lt;/p>
&lt;h4 id="usage">Usage&lt;/h4>
&lt;p>Before you can use this API, you need to initialise it with the model file downloaded from CustomVision. Trying to classify an image without calling &lt;code>Init&lt;/code> will result in a &lt;code>ImageClassifierException&lt;/code> being thrown.&lt;/p>
&lt;h5 id="ios">iOS&lt;/h5>
&lt;p>Download the Core ML model from Custom Vision.&lt;/p>
&lt;h6 id="pre-compiled-models">Pre-compiled models&lt;/h6>
&lt;p>Models can be compiled before beiong used, or compiled on the device. To use a pre-compiled model, compile the downloaded model using:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>xcrun coremlcompiler compile &amp;lt;model_file_name&amp;gt;.mlmodel &amp;lt;model_name&amp;gt;.mlmodelc
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This will spit out a folder called &lt;code>&amp;lt;model_name&amp;gt;.mlmodelc&lt;/code> containing a number of files. Add this entire folder to the &lt;code>Resources&lt;/code> folder in your iOS app. Once this has been added, add a call to &lt;code>Init&lt;/code> to your app delegate, passing in the name of your compiled model without the extension (i.e. the name of the model folder &lt;strong>without&lt;/strong> &lt;code>mlmodelc&lt;/code>) and the type of model downloaded from the custom vision service:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">override&lt;/span> &lt;span style="color:#66d9ef">bool&lt;/span> FinishedLaunching(UIApplication uiApplication, NSDictionary launchOptions)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> CrossImageClassifier.Current.Init(&lt;span style="color:#e6db74">&amp;#34;&amp;lt;model_name&amp;gt;&amp;#34;&lt;/span>, ModelType.General);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#66d9ef">base&lt;/span>.FinishedLaunching(uiApplication, launchOptions);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h6 id="uncompiled-models">Uncompiled models&lt;/h6>
&lt;p>Add the downloaded model, called &lt;code>&amp;lt;model_name&amp;gt;.mlmodel&lt;/code>, to the &lt;code>Resources&lt;/code> folder in your iOS app.Once this has been added, add a call to &lt;code>Init&lt;/code> to your app delegate, passing in the name of your model without the extension (i.e. the name of the model folder &lt;strong>without&lt;/strong> &lt;code>mlmodel&lt;/code>) and the type of model downloaded from the custom vision service:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">override&lt;/span> &lt;span style="color:#66d9ef">bool&lt;/span> FinishedLaunching(UIApplication uiApplication, NSDictionary launchOptions)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> CrossImageClassifier.Current.Init(&lt;span style="color:#e6db74">&amp;#34;&amp;lt;model_name&amp;gt;&amp;#34;&lt;/span>, ModelType.General);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#66d9ef">base&lt;/span>.FinishedLaunching(uiApplication, launchOptions);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The call to &lt;code>Init&lt;/code> will attempt to compile the model, throwning a &lt;code>ImageClassifierException&lt;/code> if the compile fails.&lt;/p>
&lt;h5 id="android">Android&lt;/h5>
&lt;p>Download the tensorflow model from Custom Vision. This will be a folder containing two files.&lt;/p>
&lt;ul>
&lt;li>&lt;code>labels.txt&lt;/code>&lt;/li>
&lt;li>&lt;code>model.pb&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>Add both these files to the &lt;code>Assets&lt;/code> folder in your Android app. Once these are added, add a call to &lt;code>Init&lt;/code> to your main activity passing in the name of the model file and the type of model downloaded from the custom vision service:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">protected&lt;/span> &lt;span style="color:#66d9ef">override&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> OnCreate(Bundle savedInstanceState)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> CrossImageClassifier.Current.Init(&lt;span style="color:#e6db74">&amp;#34;model.pb&amp;#34;&lt;/span>, ModelType.General);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Note - the labels file must be present and called &lt;code>labels.txt&lt;/code>.&lt;/p>
&lt;h5 id="calling-this-from-your-net-standard-library">Calling this from your .NET Standard library&lt;/h5>
&lt;p>To classify an image, call:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> tags = &lt;span style="color:#66d9ef">await&lt;/span> CrossImageClassifier.Current.ClassifyImage(stream);
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Passing in an image as a stream. You can use a library like &lt;a href="https://github.com/jamesmontemagno/MediaPlugin">Xam.Plugins.Media&lt;/a> to get an image as a stream from the camera or image library.&lt;/p>
&lt;p>This will return a list of &lt;code>ImageClassification&lt;/code> instances, one per tag in the model with the probabilty that the image matches that tag. Probabilities are doubles in the range of 0 - 1, with 1 being 100% probability that the image matches the tag. To find the most likely classification use:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>tags.OrderByDescending(t =&amp;gt; t.Probability)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> .First().Tag;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h5 id="using-with-an-ioc-container">Using with an IoC container&lt;/h5>
&lt;p>&lt;code>CrossImageClassifier.Current&lt;/code> returns an instance of the &lt;code>IImageClassifier&lt;/code> interface, and this can be stored inside your IoC container and injected where required.&lt;/p>
&lt;h4 id="getting-the-code">Getting the code&lt;/h4>
&lt;p>If you want to see the code for this, head to &lt;a href="https://github.com/jimbobbennett/Xam.Plugins.OnDeviceCustomVision">https://github.com/jimbobbennett/Xam.Plugins.OnDeviceCustomVision&lt;/a>.&lt;/p></description></item><item><title>Identifying my daughters toys using AI - Part 4, using the models offline on Android</title><link>https://jimbobbennett.dev/blogs/identifying-my-daughters-toys-using-ai-part-4-offline-android/</link><pubDate>Wed, 24 Jan 2018 17:43:53 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/identifying-my-daughters-toys-using-ai-part-4-offline-android/</guid><description>&lt;p>In the &lt;a href="https://jimbobbennett.dev/blogs/identifying-my-daughters-toys-using-ai/">first part of this series&lt;/a> I used the &lt;a href="http://customvision.ai/?wt.mc_id=toyidentifier-blog-jabenn">Azure Custom Vision service&lt;/a> to create an image classifier to allow me to easily identify my daughters cuddly toys. Once created I tested it by uploading an image and seeing what tags the classifier found for the image.&lt;/p>
&lt;p>In the &lt;a href="https://jimbobbennett.dev/blogs/identifying-my-daughters-toys-using-ai-part-2-using-the-model/">second part&lt;/a> I accessed this model from a Xamarin app, so that I could use the camera to take a photo to run through the classifier using a NuGet package that talks to the Custom Vision service.&lt;/p>
&lt;p>In the &lt;a href="https://jimbobbennett.dev/blogs/identifying-my-daughters-toys-using-ai-part-3-offline-ios/">third part&lt;/a> I showed how to download this model for iOS and run it locally, on device, using CoreML.&lt;/p>
&lt;p>In this part we&amp;rsquo;re going to switch OS and run these models on Android. Like with iOS, Android offers some APIs to run AI models on device, taking advantage of the hardware. Unlike iOS this is not an API that is baked into the OS, instead it is a separate library you can add to your project and run. The upside of this is it has more OS support, working all the way back to API 21.&lt;/p>
&lt;div class="image-div" style="max-width: 128px;">
&lt;p>&lt;img src="https://www.tensorflow.org/_static/images/tensorflow/logo.png" alt="TensorFlow logo">&lt;/p>
&lt;/div>
&lt;p>The library in question is called &lt;a href="https://www.tensorflow.org">TensorFlow&lt;/a>, and is actually an open source AI library that came from Google that can run on pretty much any platform and is accessible from most languages. When running on device you can think of it as similar to CoreML on iOS, a generic way of running all sorts of machine learning models including the ones generated by the custom vision service.&lt;/p>
&lt;h4 id="running-models-with-tensorflow">Running models with TensorFlow&lt;/h4>
&lt;p>For mobile apps we can use the Android bindings for the TensorFlow library. Like with CoreML these bindings contain a full API for running all sorts of models, as well as an easy API surface that we can use to do image classification - similar to the CoreML Vision APIs.&lt;/p>
&lt;p>To download the TensorFlow model, head to the &lt;strong>Performance&lt;/strong> tab in the Custom Vision portal, selected the latest iteration from the list on the left (we&amp;rsquo;ll cover iterations in a future post), and click the &lt;strong>Export&lt;/strong> link at the top. Select &lt;strong>Android (TensorFlow)&lt;/strong> then click &lt;strong>Download&lt;/strong>. This will download a zip file containing 2 files:&lt;/p>
&lt;ul>
&lt;li>&lt;code>model.pb&lt;/code> - This is the actual TensorFlow model&lt;/li>
&lt;li>&lt;code>labels.txt&lt;/code> - The labels for the tags&lt;/li>
&lt;/ul>
&lt;p>Once these files have been downloaded you will need to add them to the &lt;code>Assets&lt;/code> folder in your Android app.&lt;/p>
&lt;p>&lt;strong>Importing the Android TensorFlow bindings&lt;/strong>&lt;/p>
&lt;p>The TensorFlow Android bindings consist of a native library with a Jar binding. To use these from a Xamarin app we need to add Xamarin bindings, and this has been done for us already by Larry O&amp;rsquo;Brien from Xamarin and is available on GitHub here: &lt;a href="https://github.com/lobrien/TensorFlow.Xamarin.Android">https://github.com/lobrien/TensorFlow.Xamarin.Android&lt;/a>. This binding is not available on NuGet yet, so you will need to clone this repo and compile it yourself. Once you&amp;rsquo;ve compiled it you will need to add the resulting &lt;code>TensorFlowXamain.dll&lt;/code> to your Android app.&lt;/p>
&lt;p>&lt;strong>Creating the model&lt;/strong>&lt;/p>
&lt;p>The TensorFlow binding includes a class called &lt;code>TensorFlowInferenceInterface&lt;/code> which can be used to easily run image classification models.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">using&lt;/span> Org.Tensorflow.Contrib.Android;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> assets = Android.App.Application.Context.Assets;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> inferenceInterface = &lt;span style="color:#66d9ef">new&lt;/span> TensorFlowInferenceInterface(assets, &lt;span style="color:#e6db74">&amp;#34;model.pb&amp;#34;&lt;/span>);
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This will then load the &lt;code>model.pb&lt;/code> model file from the asset catalog into a model.&lt;/p>
&lt;p>Once we have the model we need to feed it some data, run it, then extract and interpret the output.&lt;/p>
&lt;p>&lt;strong>Feeding the model&lt;/strong>&lt;/p>
&lt;div class="image-div" style="max-width: 250px;">
&lt;p>&lt;img src="cec2a9217e2ee21f01abc6ae2d41b910264bd545610339ad2dbd06631e163d45.jpg" alt="Feed me Seymour">&lt;/p>
&lt;/div>
&lt;p>Just like with CoreML the model doesn&amp;rsquo;t understand images as such, instead it needs binary data in the same format - a 227x227 sized array of 32-bit ARGB values. Again this is sort of pretty easy to create from an Android &lt;code>Bitmap&lt;/code>, we just need to convert the bitmap to one of the right size and color space. Once it&amp;rsquo;s in the right color space we need to average out the colors - models work better when the average of all the color values is 0 (neural networks work better when the average of all inputs is 0, thanks to the ever awesome &lt;a href="https://twitter.com/praeclarum">Frank Krueger&lt;/a> for teaching me this). Different domains are trained in different ways, so will need different adjustments.&lt;/p>
&lt;p>You can see some Java sample code for this at &lt;a href="https://github.com/Azure-Samples/cognitive-services-android-customvision-sample">https://github.com/Azure-Samples/cognitive-services-android-customvision-sample&lt;/a>, with details on the adjustments you need to make to the image bytes detailed in the ReadMe.&lt;/p>
&lt;p>Luckily I&amp;rsquo;ve done the hard work converting it to Xamarin for you and it&amp;rsquo;s on GitHub &lt;a href="https://github.com/jimbobbennett/Xam.Plugins.OnDeviceCustomVision/blob/master/Xam.Plugins.OnDeviceCustomVision.Droid/ImageExtensions.cs">here&lt;/a>.&lt;/p>
&lt;p>Once you have the binary data, you pass it to the TensorFlow inference interface as named data, called &amp;ldquo;Placeholder&amp;rdquo;. This name is required by the models exported from the Custom Vision service:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>inferenceInterface.Feed(&lt;span style="color:#e6db74">&amp;#34;Placeholder&amp;#34;&lt;/span>, floatValues, &lt;span style="color:#ae81ff">1&lt;/span>, InputSize, InputSize, &lt;span style="color:#ae81ff">3&lt;/span>);
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The additional parameters provide details on the float buffer - I honestly don&amp;rsquo;t know what the &amp;ldquo;1&amp;rdquo; parameter is for, the next three are the size of the buffer (in our case 227 for both) and the number of floats per pixel in the buffer - 3 for R, G and B.&lt;/p>
&lt;p>&lt;strong>Running the model&lt;/strong>&lt;/p>
&lt;p>Once the model has been fed, it needs to be run for a list of outputs - models can produce multiple outputs so we need to run it for all the outputs we need. In our case the only output we need is called &amp;ldquo;loss&amp;rdquo;:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>inferenceInterface.Run(&lt;span style="color:#66d9ef">new&lt;/span>[] { &lt;span style="color:#e6db74">&amp;#34;loss&amp;#34;&lt;/span> });
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Getting the outputs&lt;/strong>&lt;/p>
&lt;p>Once the model has run, we can extract the output that we are interested in - in our case the &amp;ldquo;loss&amp;rdquo; output. This comes back as an array of floats containing one entry per tag, with the values representing the probability of the image matching that tag as a value between 0 and 1, 1 being 100% probability. We have to pre-create this array before passing it in - so how do we know how big it is, and how do we know which tag value is which?&lt;/p>
&lt;p>The answer comes from the &lt;code>labels.txt&lt;/code> file that was downloaded along with the &lt;code>model.pb&lt;/code> file. This file contains a list of tags, one per line. Add this file to your apps assets, then load it using:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> assets = Android.App.Application.Context.Assets;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">using&lt;/span> (&lt;span style="color:#66d9ef">var&lt;/span> sr = &lt;span style="color:#66d9ef">new&lt;/span> StreamReader(assets.Open(&lt;span style="color:#e6db74">&amp;#34;labels.txt&amp;#34;&lt;/span>)))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">var&lt;/span> content = sr.ReadToEnd();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">var&lt;/span> labels = content.Split(&lt;span style="color:#e6db74">&amp;#39;\n&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> .Select(s =&amp;gt; s.Trim())
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> .Where(s =&amp;gt; !&lt;span style="color:#66d9ef">string&lt;/span>.IsNullOrEmpty(s))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> .ToList();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This will give you a list of labels - the file contains an empty line on the end by default, so remember to trim whitespace and remove any empty lines. You can then create a float array of the same size and put the output in there:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> outputs = &lt;span style="color:#66d9ef">new&lt;/span> &lt;span style="color:#66d9ef">float&lt;/span>[labels.Count];
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>inferenceInterface.Fetch(&lt;span style="color:#e6db74">&amp;#34;loss&amp;#34;&lt;/span>, outputs);
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The float values map index for index with the label - so if &lt;code>labels[0]&lt;/code> was &lt;code>foo&lt;/code> and &lt;code>labels[1]&lt;/code> was &lt;code>bar&lt;/code>, &lt;code>outputs[0]&lt;/code> would be the probability of the image being &lt;code>foo&lt;/code>, and &lt;code>outputs[1]&lt;/code> would be the probability of the image being &lt;code>bar&lt;/code>.&lt;/p>
&lt;blockquote>
&lt;p>TensorFlow is only supported on API 21 and above - so don&amp;rsquo;t forget to set your minimum supported version to 21 in your &lt;code>application.manifest&lt;/code>&lt;/p>
&lt;/blockquote>
&lt;p>You can read more on exporting and using models &lt;a href="https://docs.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/export-your-model?wt.mc_id=toyidentifier-blog-jabenn">here&lt;/a>. In the &lt;a href="https://jimbobbennett.dev/blogs/identifying-my-daughters-toys-using-ai-part-5-plugin-for-on-device-models/">next post&lt;/a> in this series we&amp;rsquo;ll look at the plugin NuGet package I&amp;rsquo;ve created to make it easy to use these models from a cross platform app.&lt;/p></description></item><item><title>Identifying my daughters toys using AI - Part 3, using the models offline in iOS</title><link>https://jimbobbennett.dev/blogs/identifying-my-daughters-toys-using-ai-part-3-offline-ios/</link><pubDate>Wed, 17 Jan 2018 17:13:02 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/identifying-my-daughters-toys-using-ai-part-3-offline-ios/</guid><description>&lt;p>In the &lt;a href="https://jimbobbennett.dev/blogs/identifying-my-daughters-toys-using-ai/">first part of this series&lt;/a> I used the &lt;a href="http://customvision.ai/?wt.mc_id=toyidentifier-blog-jabenn">Azure Custom Vision service&lt;/a> to create an image classifier to allow me to easily identify my daughters cuddly toys. Once created I tested it by uploading an image and seeing what tags the classifier found for the image.&lt;/p>
&lt;p>In the &lt;a href="https://jimbobbennett.dev/blogs/identifying-my-daughters-toys-using-ai-part-2-using-the-model/">second part&lt;/a> I accessed this model from a Xamarin app, so that I could use the camera to take a photo to run through the classifier using a NuGet package that talks to the Custom Vision service.&lt;/p>
&lt;p>The limitation with this NuGet package is that it requires internet access. Not such a huge problem for classifying single images with fast, cheap data contracts, but not so good in countries where data is expensive, or when classifying a live video feed.&lt;/p>
&lt;p>Identifying toys is fun, and is a great project I can share with my daughter, but there are a lot or serious uses for this kind of technology, especially in medical imaging.&lt;/p>
&lt;p>Imagine an app where you can run your phone over moles on your skin and have it tell you in real-time if you are at risk of skin cancer. You&amp;rsquo;d want this to run on device for a couple of reasons. Firstly for speed, uploading a lot of images is slow. Secondly, and more importantly, this kind of technology is incredibly useful for third-world countries who have little in the way of education around health issues, or access to medical screening services. These countries also have little or no, or incredibly expensive internet access, especially away from big cities where people are more likely to be lacking medical screening. If you could take a phone on the road with these models running locally you could easily screen whole villages in a short space of time.&lt;/p>
&lt;p>This kind of app is not a sci-fi dream, but is a real thing. You can see an example iOS app and download actual trained models for identifying skin cancer at &lt;a href="https://github.com/Azure/ai-toolkit-iot-edge/tree/master/Skin%20cancer%20detection">https://github.com/Azure/ai-toolkit-iot-edge/tree/master/Skin%20cancer%20detection&lt;/a>.&lt;/p>
&lt;p>These models run on device using CoreML on iOS and TensorFlow on Android. In this post we&amp;rsquo;ll look at CoreML, in the next post we&amp;rsquo;ll look at TensorFlow.&lt;/p>
&lt;div class="image-div" style="max-width: 128px;">
&lt;p>&lt;img src="core-ml-128x128_2x.png" alt="CoreML logo">&lt;/p>
&lt;/div>
&lt;h4 id="running-models-on-coreml">Running models on CoreML&lt;/h4>
&lt;p>&lt;a href="https://developer.apple.com/documentation/coreml">CoreML&lt;/a> was introduced in iOS 11 and macOS High Sierra, and is a set of APIs for running models on device instead of up in the cloud. The models used are compressed and optimized to run on device GPUs, and they run pretty quickly. CoreML can run all sorts of models, and has a specialized API designed for running image classification models that we can take advantage of.&lt;/p>
&lt;div class="image-div" style="max-width: 400px;">
&lt;p>&lt;img src="https://docs-assets.developer.apple.com/published/72e22672fd/c35ebf2d-ee94-4448-8fae-16420e7cc4ed.png" alt="CoreML runs models inside your app">&lt;/p>
&lt;/div>
&lt;p>To download the CoreML model, head to the &lt;strong>Performance&lt;/strong> tab in the Custom Vision portal, selected the latest iteration from the list on the left (we&amp;rsquo;ll cover iterations in a future post), and click the &lt;strong>Export&lt;/strong> link at the top. Select &lt;strong>iOS 11 (CoreML)&lt;/strong> then click &lt;strong>Download&lt;/strong>. This will download a &lt;code>.mlmodel&lt;/code> file. Before you can use this model, you will need to compile it - either in advance or at run time.&lt;/p>
&lt;p>To compile in advance on a Mac using the following:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>xcrun coremlcompiler compile &amp;lt;model_name&amp;gt;.mlmodel &amp;lt;compiled_model_name&amp;gt;.mlmodelc
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The &lt;code>model_name&lt;/code> will be a GUID, so set the &lt;code>compiled_model_name&lt;/code> to be something more user friendly. Once this is compiled you will have a folder called &lt;code>compiled_model_name.mlmodelc&lt;/code> containing some model files. You will need to add this entire folder to your &lt;code>Resources&lt;/code> folder in your iOS app, so drag this into Visual Studio.&lt;/p>
&lt;div class="image-div" style="max-width: 200px;">
&lt;p>&lt;img src="2018-01-17_13-16-07.png" alt="The Resources folder with a compiled model in it">&lt;/p>
&lt;/div>
&lt;br>
&lt;p>You can also compile it at runtime. This is useful especially if you want to download new models without updating your app. If you want to compile at runtime, just add the &lt;code>&amp;lt;model_name&amp;gt;.mlmodel&lt;/code> file to your resources folder, renaming the model to something easier to read than the default Guid.&lt;/p>
&lt;p>To run CoreML models you need three components:&lt;/p>
&lt;ul>
&lt;li>The model&lt;/li>
&lt;li>A request for the model with a callback&lt;/li>
&lt;li>A request handler to issue the request&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>The model&lt;/strong>&lt;/p>
&lt;p>Once we have the model as a resource, we need to load it into a CoreML model, then convert it to a vision model:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">using&lt;/span> CoreML;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">using&lt;/span> Vision;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> assetPath = GetModel();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> mlModel = MLModel.Create(assetPath, &lt;span style="color:#66d9ef">out&lt;/span> NSError err);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> model = VNCoreMLModel.FromMLModel(mlModel, &lt;span style="color:#66d9ef">out&lt;/span> err);
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The &lt;code>GetModel&lt;/code> method varies depending on if the model is compiled or not. For compiled models use:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">private&lt;/span> NSUrl GetModel()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> NSBundle.MainBundle.GetUrlForResource(&lt;span style="color:#e6db74">&amp;#34;&amp;lt;compiled_model_name&amp;gt;&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;mlmodelc&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>To compile your model on device use:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">private&lt;/span> NSUrl GetModel()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">var&lt;/span> url = NSBundle.MainBundle.GetUrlForResource(&lt;span style="color:#e6db74">&amp;#34;&amp;lt;model_name&amp;gt;&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;mlmodel&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> MLModel.CompileModel(url, our NSError err);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;blockquote>
&lt;p>In a real app you should check the NSError out variables for any errors&lt;/p>
&lt;/blockquote>
&lt;p>This code creates a &lt;code>MLModel&lt;/code> from a URL to a resource, then converts this to a &lt;code>VNCoreMLModel&lt;/code> - a &amp;lsquo;Vision&amp;rsquo; CoreML model for image classification constructed using the custom vision model. The &lt;code>Vision&lt;/code> namespace also contains some built in models for bar code recognition and facial recognition, amongst others.&lt;/p>
&lt;p>If you want more information on this class, the docs for VNCoreMLModel are &lt;a href="https://developer.xamarin.com/api/type/Vision.VNCoreMLModel/?wt.mc_id=toyidentifier-blog-jabenn">here&lt;/a>.&lt;/p>
&lt;p>&lt;strong>The request&lt;/strong>&lt;/p>
&lt;p>The CoreML request wraps our model and provides a callback. Running these models is asynchronous - once you start it, it will run on the GPU in a background thread and invoke the callback once done.&lt;/p>
&lt;p>The code to create the request is:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> request = &lt;span style="color:#66d9ef">new&lt;/span> VNCoreMLRequest(_model, (response, e) =&amp;gt; {});
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The second parameter is the callback, with the &lt;code>response&lt;/code> parameter containing the results from the model, and the &lt;code>e&lt;/code> parameter being an NSError instance in case of an error.&lt;/p>
&lt;p>If you want more information on this class, the docs for VNCoreMLRequest are &lt;a href="https://developer.xamarin.com/api/type/Vision.VNCoreMLRequest/?wt.mc_id=toyidentifier-blog-jabenn">here&lt;/a>.&lt;/p>
&lt;p>&lt;strong>The request handler&lt;/strong>&lt;/p>
&lt;p>Although this model is for image classification, it actually doesn&amp;rsquo;t understand what an image is - it works on raw binary data only. The custom vision models expects this binary data to be in a specific format, namely a 227x227 CoreVision pixel buffer using 32-bit ARGB, whatever that is! Luckily it&amp;rsquo;s easy to create one of these using code I found on &lt;a href="https://github.com/xamarin/ios-samples/blob/master/ios11/CoreMLImageRecognition/CoreMLImageRecognition/ClassExtensions/UIImageExtensions.cs">one of the Xamarin iOS CoreML samples&lt;/a>. Follow that link for an extension method that converts from a &lt;code>UIImage&lt;/code> to a pixel buffer.&lt;/p>
&lt;p>Once we have the pixel buffer, we create a request handler for our buffer:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> buffer = source.ToCVPixelBuffer(_targetImageSize);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> requestHandler = &lt;span style="color:#66d9ef">new&lt;/span> VNImageRequestHandler(buffer, &lt;span style="color:#66d9ef">new&lt;/span> NSDictionary());
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>We can then invoke the request handler with our request:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>requestHandler.Perform(&lt;span style="color:#66d9ef">new&lt;/span>[] { request }, &lt;span style="color:#66d9ef">out&lt;/span> NSError error);
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This handler can be used to run multiple requests at once on the same pixel buffer, just pass all the requests you want to run as items in the array in the first parameter. This is useful if you wanted to screen for multiple conditions in a medical imaging app, with multiple models for each condition run against the same image.&lt;/p>
&lt;p>If you want more information on this class, the docs for VNImageRequestHandler are &lt;a href="https://developer.xamarin.com/api/type/Vision.VNImageRequestHandler/?wt.mc_id=toyidentifier-blog-jabenn">here&lt;/a>.&lt;/p>
&lt;p>&lt;strong>Handling the response&lt;/strong>&lt;/p>
&lt;p>Once the model has been run, it will call the callback you passed to the request, passing in the response (or an error if it failed). This response has a method on it, &lt;code>GetResults&amp;lt;T&amp;gt;()&lt;/code> that returns an array of results of whatever type the model spits out. For vision models, the results are of type &lt;code>VNClassificationObservation&lt;/code>, so inside our callback we would do:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> results = response.GetResults&amp;lt;VNClassificationObservation&amp;gt;();
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;code>VNClassificationObservation&lt;/code> has two fields that we are interested in:&lt;/p>
&lt;ul>
&lt;li>&lt;code>Identifier&lt;/code> - this is the tag we set in our model&lt;/li>
&lt;li>&lt;code>Confidence&lt;/code> - this is the probability that our image matches our tag, from 0 to 1 with 1 being 100% confidence.&lt;/li>
&lt;/ul>
&lt;p>These values match up to the &lt;code>Tag&lt;/code> and &lt;code>Probability&lt;/code> fields from the &lt;code>ImageTagPredictionModel&lt;/code> class in the Custom Vision NuGet package. You can read more on the VNClassificationObservation class &lt;a href="https://developer.xamarin.com/api/type/Vision.VNClassificationObservation/?WT.mc_id=toyidentifier-blog-jabenn">here&lt;/a>.&lt;/p>
&lt;p>For an example of this code in action, check out my &lt;a href="https://github.com/jimbobbennett/Xam.Plugins.OnDeviceCustomVision">Xamarin.PlugIn.OnDeviceCustomVision&lt;/a> NuGet package. This wraps the code above, along with an Android implementation using TensorFlow (which we&amp;rsquo;ll look at in the next post) in an easy to use Xamarin Plugin.&lt;/p>
&lt;blockquote>
&lt;p>CoreML is only supported on iOS 11 and above - so don&amp;rsquo;t forget to set your deployment target to iOS 11 in your &lt;code>info.plist&lt;/code>&lt;/p>
&lt;/blockquote>
&lt;p>You can read more on exporting and using models &lt;a href="https://docs.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/export-your-model?wt.mc_id=toyidentifier-blog-jabenn">here&lt;/a>. In the &lt;a href="https://jimbobbennett.dev/blogs/identifying-my-daughters-toys-using-ai-part-4-offline-android/">next post&lt;/a> in this series we&amp;rsquo;ll see how to run models on device on Android using TensorFlow.&lt;/p></description></item><item><title>Identifying my daughters toys using AI - Part 2, using the model</title><link>https://jimbobbennett.dev/blogs/identifying-my-daughters-toys-using-ai-part-2-using-the-model/</link><pubDate>Tue, 02 Jan 2018 17:43:37 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/identifying-my-daughters-toys-using-ai-part-2-using-the-model/</guid><description>&lt;p>In the &lt;a href="https://jimbobbennett.dev/blogs/identifying-my-daughters-toys-using-ai/">first part of this post&lt;/a> I used the &lt;a href="http://customvision.ai/?wt.mc_id=toyidentifier-blog-jabenn">Azure Custom Vision service&lt;/a> to create an image classifier to allow me to easily identify my daughters cuddly toys. Once created I tested it by uploading an image and seeing what tags the classifier found for the image.&lt;/p>
&lt;p>Although this works, it&amp;rsquo;s a long winded way of using the model. Ideally I&amp;rsquo;d want it in a mobile app (after all, I am a bit of a Xamarin fan) so in this post we&amp;rsquo;ll look at calling the classifier from a Xamarin app.&lt;/p>
&lt;p>The first thing to do is to create a new blank Xamarin Forms app, I&amp;rsquo;m going to call mine &lt;strong>Toy Identifier&lt;/strong>. This app will be pretty simple to start with - one screen with a big button to launch the camera, then after a photo is take I&amp;rsquo;ll use text to speech to say the name of the toy.&lt;/p>
&lt;div class="image-div" style="max-width: 800px;">
&lt;p>&lt;img src="2017-12-27_16-39-46.png" alt="The main screen launches the camera to identify the toy">&lt;/p>
&lt;/div>
&lt;p>Like a lot of Xamarin apps, the bulk of this will just be some of James Montemagno&amp;rsquo;s Plugins joined together, so add the following packages to all the projects (core, iOS and Android):&lt;/p>
&lt;ul>
&lt;li>&lt;code>Xam.Plugin.Media&lt;/code>&lt;/li>
&lt;li>&lt;code>Xam.Plugins.TextToSpeech&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>The Media plugin has some permissions you need to set, so follow the instructions at &lt;a href="https://github.com/jamesmontemagno/MediaPlugin">https://github.com/jamesmontemagno/MediaPlugin&lt;/a> to configure this.&lt;/p>
&lt;p>We&amp;rsquo;ll also need the Custom Vision client side SDKs, so add:&lt;/p>
&lt;ul>
&lt;li>&lt;code>Microsoft.Cognitive.CustomVision.Prediction&lt;/code>&lt;/li>
&lt;li>&lt;code>Microsoft.Rest.ClientRuntime&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>as well to all your projects.&lt;/p>
&lt;p>You can find all the source code for this app on GitHub at &lt;a href="https://github.com/jimbobbennett/ToyIdentifier">https://github.com/jimbobbennett/ToyIdentifier&lt;/a>, so grab the code now.&lt;/p>
&lt;p>The UI is simple - a button and a label. Tap the button and the camera appears, take a photo and the label shows the name of the toy. I am using MVVM, but not bothering with a framework at this point as the app is too simple, so I&amp;rsquo;ve got a view model that is created inside my XAML which has all the fun logic.&lt;/p>
&lt;p>If you open &lt;code>ToyIdentifierViewModel.cs&lt;/code> you&amp;rsquo;ll see how simple it is to take photos and upload them to the custom vision service. Taking a photo is easy thanks to James Montemagno&amp;rsquo;s Media plugin:&lt;/p>
&lt;pre tabindex="0">&lt;code>var options = new StoreCameraMediaOptions { PhotoSize = PhotoSize.Medium };
var file = await CrossMedia.Current.TakePhotoAsync(options);
&lt;/code>&lt;/pre>&lt;p>I&amp;rsquo;m using a medium sized photo - this returns an image which is 50% of the size of the one that comes out of the camera. This is fine as we don&amp;rsquo;t need a high res image for recognition, and the serviced apartment I&amp;rsquo;m staying in at the moment has crappy internet so the smaller the better.&lt;/p>
&lt;p>The &lt;code>TakePhotoAsync&lt;/code> call returns a &lt;code>MediaFile&lt;/code> object, with a method on it to return the file as a stream, and we can pass this stream to a call to the custom vision SDK.&lt;/p>
&lt;p>To use the custom vision SDK we need to start by creating a &lt;code>PredictionEndpoint&lt;/code>. Uploading an image to get the percentage chance of it matching the tags is called prediction.&lt;/p>
&lt;pre tabindex="0">&lt;code>private PredictionEndpoint _endpoint = new PredictionEndpoint { ApiKey = ApiKeys.PredictionKey };
&lt;/code>&lt;/pre>&lt;p>The &lt;code>PredictionKey&lt;/code> I&amp;rsquo;m passing in comes from a constants file - you&amp;rsquo;ll need to update this file with your own API key. You can find this by going to the settings on your project in the custom vision portal and getting the value of the &lt;strong>Prediction Key&lt;/strong>. There is also a &lt;code>ProjectId&lt;/code> in that same file you need to set, again this comes from the settings page.&lt;/p>
&lt;p>Using the prediction endpoint is easy - there is a &lt;code>PredictImage&lt;/code> method on this class, and this takes the project id as a Guid, and a stream containing the image to use for the prediction.&lt;/p>
&lt;pre tabindex="0">&lt;code>_endpoint.PredictImage(ApiKeys.ProjectId, stream)
&lt;/code>&lt;/pre>&lt;p>This call uploads the image to the custom vision service and returns a model containing information about the custom vision project, and a list of predictions - essentially a list of all the tags the a numerical probability that the image matches the tag in the range of 0 to 1, the higher the number, the more likely the match.&lt;/p>
&lt;p>Once we have these predictions we can sort them by probability then get the highest. We then need to add a threshold - after all if we match all tags with a probability &amp;lt; 0.01 then it&amp;rsquo;s unlikely the image is one of our tags. In my code I&amp;rsquo;ve got a threshold of 0.5 to start with, but I might increase this after playing some more.&lt;/p>
&lt;pre tabindex="0">&lt;code>_endpoint.PredictImage(ApiKeys.ProjectId, stream)
.Predictions
.OrderByDescending(p =&amp;gt; p.Probability)
.FirstOrDefault(p =&amp;gt; p.Probability &amp;gt; 0.5);
&lt;/code>&lt;/pre>&lt;p>Once I have the best match I update the label to say hello to the particular toy, then use the text to speech plugin from James Montemagno to actually say hello to the toy. If there are no matches the label is changed to say &amp;ldquo;I don&amp;rsquo;t know who that is&amp;rdquo;.&lt;/p>
&lt;p>If you want to see more on the SDK, it is on GitHub at &lt;a href="https://github.com/Microsoft/Cognitive-CustomVision-Windows">https://github.com/Microsoft/Cognitive-CustomVision-Windows&lt;/a>. At the time of writing the code in there is a bit out of date and doesn&amp;rsquo;t match the NuGet package, so check out &lt;a href="https://github.com/Microsoft/Cognitive-CustomVision-Windows/pull/11">this pull request&lt;/a> to find the latest code.&lt;/p>
&lt;p>Check out this short demo:&lt;/p>
&lt;div class="image-div" style="max-width: 300px;">
&lt;p>&lt;img src="Porg.gif" alt="Demo of identifying a Porg">&lt;/p>
&lt;/div>
&lt;p>Want to read more on how to get started with the Custom Vision APIs? Check out the docs &lt;a href="https://docs.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/home?wt.mc_id=toyidentifier-blog-jabenn">here&lt;/a>.&lt;/p>
&lt;p>In the &lt;a href="https://jimbobbennett.dev/blogs/identifying-my-daughters-toys-using-ai-part-3-offline-ios/">next post&lt;/a> we&amp;rsquo;ll look at exporting these models to run on an iOS device.&lt;/p></description></item><item><title>Hiding API keys from Git</title><link>https://jimbobbennett.dev/blogs/hiding-api-keys-from-git/</link><pubDate>Thu, 28 Dec 2017 19:35:50 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/hiding-api-keys-from-git/</guid><description>&lt;p>I&amp;rsquo;ve been working on a &lt;a href="https://jimbobbennett.dev/blogs/identifying-my-daughters-toys-using-ai/">Xamarin app using Azure Cognitive Services to do image recognition&lt;/a>, and one of the stumbling blocks I&amp;rsquo;ve faced is what to do with my API keys. I want to make the app open source as an example of how to use these services, but don&amp;rsquo;t want to check my API keys into Git to be available to all - after all, &lt;a href="https://www.theregister.co.uk/2015/01/06/dev_blunder_shows_github_crawling_with_keyslurping_bots/">bad things can happen&lt;/a>.&lt;/p>
&lt;p>I hit up twitter, and got a really awesome solution from &lt;a href="https://twitter.com/bartlannoeye">Bart Lannoeye&lt;/a>:&lt;/p>
&lt;blockquote class="twitter-tweet" data-conversation="none" data-lang="en">&lt;p lang="en" dir="ltr">You can add the file with *your key here* then change locally and git update-index --assume-unchanged .\pathtofile. Shows file as unchanged =&amp;gt; can&amp;#39;t commit by accident. &lt;a href="https://twitter.com/hashtag/protip?src=hash&amp;amp;ref_src=twsrc%5Etfw">#protip&lt;/a> We do the same for Kliva.&lt;/p>&amp;mdash; Bart Lannoeye (@bartlannoeye) &lt;a href="https://twitter.com/bartlannoeye/status/946437185372413952?ref_src=twsrc%5Etfw">December 28, 2017&lt;/a>&lt;/blockquote> &lt;script async src="https://platform.twitter.com/widgets.js" charset="utf-8">&lt;/script>
&lt;p>This is exactly what I did, and it works perfectly. I&amp;rsquo;ve created a static class called &lt;code>ApiKeys&lt;/code> which contains all my keys using &amp;ldquo;Your Key Here&amp;rdquo; values:&lt;/p>
&lt;pre tabindex="0">&lt;code>public static class ApiKeys
{
public static string PredictionKey = &amp;#34;&amp;lt;Your API Key&amp;gt;&amp;#34;;
public static Guid ProjectId = Guid.Parse(&amp;#34;&amp;lt;Your Project GUID&amp;gt;&amp;#34;);
}
&lt;/code>&lt;/pre>&lt;p>I then added this to Git and commited. After my commit I ran:&lt;/p>
&lt;pre tabindex="0">&lt;code>git update-index --assume-unchanged ./ApiKeys.cs
&lt;/code>&lt;/pre>&lt;p>Done. I can then change the values to my actual API keys and Git doesn&amp;rsquo;t see the change.&lt;/p>
&lt;p>Obviously if I need to add any more keys to this file I&amp;rsquo;d have to revert this change, remove all keys, add the new one with a &amp;ldquo;your key&amp;rdquo; type value, commit, re-run the update-index and put the keys back. A bit of work, but at least no worries about anyone abusing my API limits!&lt;/p>
&lt;p>Thanks Bart!&lt;/p>
&lt;hr>
&lt;p>&lt;strong>Update - how to tell users what they need to do with this code&lt;/strong>&lt;/p>
&lt;p>I&amp;rsquo;ve just had another great suggestion from &lt;a href="https://developer.microsoft.com/en-gb/advocates/brandon-minnick">Brandon Minnick&lt;/a>, a fellow CDA here at Microsoft. He suggests adding a &lt;code>#error&lt;/code> to the keys file so that when someone grabs the code and builds it they get an error telling them what to do, rather than a crash when the app is run:&lt;/p>
&lt;pre tabindex="0">&lt;code>public static class ApiKeys
{
# error You need to set up your API keys.
// Start by registering for an account at https://customvision.ai
// Then create a new project.
// From the settings tab, find:
// Prediction Key
// Project Id
// and update the values below
public static string PredictionKey = &amp;#34;&amp;lt;Your Prediction Key&amp;gt;&amp;#34;;
public static Guid ProjectId = Guid.Parse(&amp;#34;&amp;lt;Your Project GUID&amp;gt;&amp;#34;);
}
&lt;/code>&lt;/pre>&lt;hr>
&lt;p>&lt;strong>Update 2 - how to fix it if you forget and add your keys&lt;/strong>&lt;/p>
&lt;p>Another great tip from &lt;a href="https://developer.microsoft.com/en-gb/advocates/brandon-minnick">Brandon Minnick&lt;/a> is the &lt;a href="https://rtyley.github.io/bfg-repo-cleaner/">BFG Repo-CLeaner&lt;/a>. If you accidentally checked in some API keys, this tool can remove them from the Git history.&lt;/p>
&lt;p>Obviously it could be too late by the time you realize, so if you check any API keys in to a public repo you &lt;strong>MUST&lt;/strong> regenerate them as there are &lt;a href="http://www.timbroder.com/2015/01/my-2375-amazon-ec2-mistake.html">bots that can GitHub for API keys&lt;/a>. But this is good for a private repo that you are planning to make public or accidentally add personal keys to.&lt;/p></description></item><item><title>Identifying my daughters toys using AI - Part 1, creating the model</title><link>https://jimbobbennett.dev/blogs/identifying-my-daughters-toys-using-ai/</link><pubDate>Wed, 27 Dec 2017 14:30:09 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/identifying-my-daughters-toys-using-ai/</guid><description>&lt;p>&lt;em>Prefer to watch instead of read? - &lt;a href="https://youtu.be/3sjInlJcpBs">https://youtu.be/3sjInlJcpBs&lt;/a>&lt;/em>&lt;/p>
&lt;p>It&amp;rsquo;s currently just after Christmas, and my 4 year old daughter has received a fair few cuddly toys from Santa. These bring her total collection up to way too many, and like most parents I have a hard time remembering all their names, especially the least favorite ones that rarely come out.&lt;/p>
&lt;p>I&amp;rsquo;ve thought what would be really useful would be a mobile app that allows me to easily identify each toy. Luckily such an app is really, really easy to build using the power of AI.&lt;/p>
&lt;p>One of the cool things you can do with neural networks is image classification. You set up the network with a training set of images and assign tags to each one. Once trained you can pump any image into the network and it will return a set of percentages that show how much it thinks the image matches all the tags it&amp;rsquo;s learned about. For my app idea I can upload images of each toy, and tag those image with the name of the toy.&lt;/p>
&lt;p>Normally training these networks takes a LOT of images - think hundreds or thousands. This could be problematic as I really cannot be bothered to take thousands of pictures of my daughters toys, not when there&amp;rsquo;s Christmas leftovers to be eaten.&lt;/p>
&lt;p>As it turns out, we actually don&amp;rsquo;t need thousands of images. Microsoft have created a custom vision service as part of their Azure Cognitive Services that can do it with 5. Yup, only 5. Their neural network has already been partially trained for image recognition using some very clever technology that I have absolutely no chance of understanding, so you just upload a small set of pictures, assign a tag and away you go. 5 is a minimum, they do recommend at least 30 for better accuracy, but you can start with 5.&lt;/p>
&lt;p>You can access this at &lt;a href="https://customvision.ai/?wt.mc_id=toyidentifier-blog-jabenn">https://customvision.ai&lt;/a>. Head there, sign up or log in with a Microsoft account. This service is currently in preview, so is available for free for now.&lt;/p>
&lt;p>Once you have logged in, click &amp;lsquo;New Project&amp;rsquo; to create a new image classifier project.&lt;/p>
&lt;div class="image-div" style="max-width: 200px;">
&lt;p>&lt;img src="newProject.png" alt="Select New Project to start a new project">&lt;/p>
&lt;/div>
&lt;p>A side bar will pop out where you can enter a name for this project, a description and select a domain. These domains are part of why this classifier can run with only a few images per tag in its training set - it&amp;rsquo;s configured to be an image classifier, and they have a number of pre-configured networks to specialize in certain things. For example they have a version which is better when it comes to food, another that is better for landscapes, another that is better for filtering out adult content.&lt;/p>
&lt;div class="image-div" style="max-width: 400px;">
&lt;p>&lt;img src="2017-12-27_13-30-12.png" alt="Enter a name, description and choose general (compact)">&lt;/p>
&lt;/div>
&lt;p>You can read more on the different domains in the &lt;a href="https://docs.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/getting-started-build-a-classifier?wt.mc_id=toyidentifier-blog-jabenn%22">developer docs&lt;/a>.&lt;/p>
&lt;p>After entering a name and description, select a domain. You&amp;rsquo;ll notice there are two versions of some domains - normal and compact. The compact ones are smaller models that can be downloaded as either a CoreML file or a TensorFlow file. These are model files you can import into a mobile app to run on the device. Create a &lt;strong>General (compact)&lt;/strong> model for now so we can download it later on (I&amp;rsquo;ll cover this in more detail in a later post).&lt;/p>
&lt;p>Once your project is created you need to train it, so select the &lt;strong>Training Images&lt;/strong> tab and upload a set of images that match one of the tags you&amp;rsquo;re interested in. In may case, I&amp;rsquo;m starting by uploading 7 images of a cuddly duck who goes by the name of &amp;lsquo;Baby Duck&amp;rsquo;.&lt;/p>
&lt;div class="image-div" style="max-width: 500px;">
&lt;p>&lt;img src="2017-12-27_13-45-51.png" alt="Uploading images with a tag">&lt;/p>
&lt;/div>
&lt;p>I then repeat the process with her remaining toys. Once I&amp;rsquo;ve uploaded the photos of a few toys my model is ready to train.&lt;/p>
&lt;p>Training is easy - click the green &lt;strong>Train&lt;/strong> button at the top of the page.&lt;/p>
&lt;div class="image-div" style="max-width: 300px;">
&lt;p>&lt;img src="2017-12-27_14-01-19.png" alt="The green Train button trains the model">&lt;/p>
&lt;/div>
&lt;p>This kicks of the model training, and it will take a few seconds. More if you have a lot of images. Once done you have a working model, so it&amp;rsquo;s time to try it out. Click the &lt;strong>Quick Test&lt;/strong> button and upload an image. After a few seconds your image will be classified - against each tag you will see a percentage chance that the image matches the tag. I tested mine using Miss 4&amp;rsquo;s Porg and it recognized it with a 99.9% probability.&lt;/p>
&lt;div class="image-div" style="max-width: 400px;">
&lt;p>&lt;img src="2017-12-27_14-13-10.png" alt="Recognizing a Porg">&lt;/p>
&lt;/div>
&lt;p>Every time your model is run against an image, the image is stored along with it&amp;rsquo;s scores so that you can use it to validate and re-train your model. These images appear in the &lt;strong>Predictions&lt;/strong> tab. You can select each image and add the correct tag to help improve the model - either by clicking on them one by one or by ticking them all and selecting &lt;strong>Tag Images&lt;/strong>. Once you&amp;rsquo;ve added tags you will need to retrain the model using the &lt;strong>Train&lt;/strong> button.&lt;/p>
&lt;p>We now have a trained model. In the &lt;a href="https://jimbobbennett.dev/blogs/identifying-my-daughters-toys-using-ai-part-2-using-the-model/">next post&lt;/a>, we&amp;rsquo;ll look at using it from a Xamarin app.&lt;/p>
&lt;p>Want to read more on how to get started with the Custom Vision APIs? Check out the docs &lt;a href="https://docs.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/home?wt.mc_id=toyidentifier-blog-jabenn">here&lt;/a>.&lt;/p></description></item><item><title>Getting a users Facebook profile after Authenticating your Xamarin app with Azure</title><link>https://jimbobbennett.dev/blogs/authenticating-your-xamarin-app-with-azure-and-facebook/</link><pubDate>Fri, 17 Nov 2017 23:54:08 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/authenticating-your-xamarin-app-with-azure-and-facebook/</guid><description>&lt;p>I&amp;rsquo;ve recently been looking at the authentication offered by Azure for use in a mobile app, specifically using social auth providers like Facebook to allow a user to sign up for my app. The auth setup is incredibly easy, with Azure taking care of a lot of the hard stuff. There are also loads of great docs on how to get it set up - including the Microsoft docs available here - &lt;a href="https://docs.microsoft.com/en-us/azure/app-service-mobile/app-service-mobile-xamarin-forms-get-started-users?wt.mc_id=toyidentifier-blog-jabenn">https://docs.microsoft.com/en-us/azure/app-service-mobile/app-service-mobile-xamarin-forms-get-started-users&lt;/a>.&lt;/p>
&lt;p>The whole login flow is very well documented, so I won&amp;rsquo;t repeat what&amp;rsquo;s in the previous link. Just follow the instructions in that link and you can use your Xamarin app to authenticate with Facebook and get back a logged in user.&lt;/p>
&lt;p>What does seem to be missing from the docs though, is what happens next. When you log in using the &lt;code>MobileServiceClient.LoginAsync&lt;/code> method you get back an access token, and that&amp;rsquo;s it. So what is this access token, and how can it be used to access the users personal information, such as Facebook photo or friends? That&amp;rsquo;s what we are going to look at in this post.&lt;/p>
&lt;p>When you make a call to &lt;code>LoginAsync&lt;/code>, the SDK opens a web view pointing to your app service, which in turn redirects to the Facebook login. When you log in, the web view redirects to your app service, which redirects back to your app. Along the way, the Azure app service picks up an access token from Facebook, which it keeps hold of, and returns you an access token from Azure.&lt;/p>
&lt;div class="image-div" style="max-width: 600px;">
&lt;p>&lt;img src="LoginFlow.png" alt="Your app calls loginasync to log in to azure, which logs into Facebook. Azure gets the Facebook access token and returns an Azure access token">&lt;/p>
&lt;/div>
&lt;br>
&lt;p>Your app doesn&amp;rsquo;t get the Facebook access token, just an Azure one. Instead your app service keeps hold of the Facebook access token. This I imagine is intentional - your app can authenticate with multiple providers at the same time, for example linking to both a Facebook and Twitter account. Instead of returning access tokens to your mobile app for all of these providers, it returns just one, and this can be used to extract all the information you require via an auth service built into the Azure app service.&lt;/p>
&lt;p>This auth service is available from the &lt;code>https://&amp;lt;my azure website&amp;gt;/.auth/me&lt;/code> end point on your app service, passing the access token as a &lt;code>X-ZUMO-AUTH&lt;/code> header. This returns a JSON document containing information from all social auth providers that the user has signed in with, including the access tokens, as well as some basic personal information such as first and last name. The Facebook access token that comes back can then be used with the Facebook Graph API to download whatever details we&amp;rsquo;ve granted to the app, such as our profile pic or friends list.&lt;/p>
&lt;p>From my mobile app I want to download the users Facebook profile, but I don&amp;rsquo;t want to make multiple server calls to do it. From my app I could call the &lt;code>/.auth/me&lt;/code> endpoint, get the access token, then make another call to the Facebook graph, but it might be better to do it in one call, handling all the steps server side (including the logic around which social provider to use if more than one was provided). By doing this server side I can also cache information in my app service, maybe for later processing. The easiest way to do this is via an Azure Function.&lt;/p>
&lt;div class="image-div" style="max-width: 300px;">
&lt;p>&lt;img src="woz9sESR.jpg" alt="Azure functions logo">&lt;/p>
&lt;/div>
&lt;p>If you&amp;rsquo;ve been living under a rock for the past few years you may have missed out on the rise of serverless, but I imagine most of you are familiar with the concept. Azure functions are simple functions that are run in response to a trigger, such as a web request, a timer or a message on a queue. These run on someone else&amp;rsquo;s hardware (hence the same serverless - you don&amp;rsquo;t have to provision a server to run them on, someone else does it for you), and you only pay for the CPU/RAM usage, not a monthly cost for hardware. This means they are cheap - potentially millions of calls for less than a cup of coffee. They are also infinitely scalable, if your function gets hit a bazillion times it will scale up automatically. If you want to learn more, check out &lt;a href="https://channel9.msdn.com/events/Connect/2017/E102?term=azure%20functions">this Channel9 video from Jeremy Likness, a Cloud Developer Advocate at Microsoft.&lt;/a>&lt;/p>
&lt;p>We can use a simple function to do all our server side processing for us. Log into the Azure portal and create a new Function App. Fill in all the normal details, making the name something simple to remember such as &lt;code>&amp;lt;my app service name&amp;gt;_functions&lt;/code>. The hosting plan is a new option, specific to functions. You can choose to link it to an existing app service so that it will only use those resources (and not end up costing any more than the app service rate), or a consumption plan where you pay per usage - with a &lt;em>very&lt;/em> generous free tier including being able to run a million function calls before you start paying.&lt;/p>
&lt;div class="image-div" style="max-width: 300px;">
&lt;p>&lt;img src="one-million-free-function-calls.jpg" alt="One million free function calls">&lt;/p>
&lt;/div>
&lt;br>
&lt;p>Fill in all the details and click &lt;strong>Create&lt;/strong>. Wait a couple of minutes for your function to be created then head to it. Select the functions node in the tree under your functions app, then select &lt;strong>+ New Function&lt;/strong>. From here you can choose from a set of function templates with different triggers and languages. We want a function that uses an Http trigger so that we can call it from our mobile app, and I&amp;rsquo;m using C# but you can use F# or Javascript if you prefer. Select &lt;strong>HttpTrigger - C#&lt;/strong>, give your function a name such as &lt;code>GetUserDetails&lt;/code>, set the authorization level to anonymous (I&amp;rsquo;ll look at security more in a later blog post), then click &lt;strong>Create&lt;/strong>.&lt;/p>
&lt;p>When created you will see your new function, which is essentially a C# script file that you can edit in your browser, with one method in it - &lt;code>public static async Task&amp;lt;HttpResponseMessage&amp;gt; Run(HttpRequestMessage req, TraceWriter log)&lt;/code>. This method is passed the Http request used to make the call to your function, and returns an Http response with all the usual response stuff, like status code and any content. The function has a sample implementation that looks for a &lt;code>name&lt;/code> field in a JSON body and returns a hello message to that name - the canonical Azure functions &amp;lsquo;Hello World&amp;rsquo;. If you click the &lt;strong>Run&lt;/strong> button, a pane will slide out from the right with a &amp;lsquo;Test&amp;rsquo; tab that can be used to test the function. You&amp;rsquo;ll see the response from the call in the &amp;lsquo;Output&amp;rsquo; box, so run this function to see it in action, changing the name in the request body to see how it all works. The browser experience is limited though, so you can&amp;rsquo;t debug your functions, just run them (but you can write to the &lt;code>log&lt;/code> parameter to see output in the log box on the bottom).&lt;/p>
&lt;p>The first thing our function needs to do is to call the auth endpoint to download the user details including access tokens for our social providers. To do this, it needs the access token from our mobile app, so we&amp;rsquo;ll assume this will be passed as an Http header called &lt;code>ACCESS_TOKEN&lt;/code>. Delete the code inside the function, and start by adding the line below to read the access token from the headers:&lt;/p>
&lt;pre tabindex="0">&lt;code>var accessToken = req.Headers.GetValues(&amp;#34;ACCESS_TOKEN&amp;#34;).FirstOrDefault();
&lt;/code>&lt;/pre>&lt;p>Now we have the token, we need to pass it to our auth end point using the standard C# HttpClient. Add the code below, changing &lt;code>&amp;lt;my site&amp;gt;&lt;/code> to the address of your Azure app service (this is your app service used for authentication, &lt;strong>NOT&lt;/strong> your Azure function service):&lt;/p>
&lt;pre tabindex="0">&lt;code>var client = new HttpClient();
client.DefaultRequestHeaders.Add(&amp;#34;X-ZUMO-AUTH&amp;#34;, accessToken);
var meResponse = await client.GetAsync(&amp;#34;https://&amp;lt;my site&amp;gt;/.auth/me&amp;#34;);
var content = await meResponse.Content.ReadAsStringAsync();
&lt;/code>&lt;/pre>&lt;p>This code creates a new HttpClient, adds a &lt;code>X-ZUMO-AUTH&lt;/code> header using the access token from the headers, and downloads the content. To see this in action, run your Xamarin mobile app through a debugger, log in using facebook, then copy the value of the &lt;code>MobileServiceAuthenticationToken&lt;/code> property on the &lt;code>MobileServiceUser&lt;/code> returned by the call to &lt;code>LoginAsync&lt;/code>. From the Azure function, go to the test tab, set the Http method to &amp;lsquo;Get&amp;rsquo;, and add a new &lt;code>ACCESS_TOKEN&lt;/code> header with the value set to the &lt;code>MobileServiceAuthenticationToken&lt;/code> property. Finally add some code to the end of the function to return the auth response:&lt;/p>
&lt;pre tabindex="0">&lt;code>var response = req.CreateResponse(HttpStatusCode.OK);
response.Content = new StringContent(content, System.Text.Encoding.UTF8, &amp;#34;application/json&amp;#34;);
return response;
&lt;/code>&lt;/pre>&lt;p>If you now run your function, you will see the response from the auth endpoint in the output window as JSON. If you tidy this up, such as using the Prettify JSON extension in VS Code you will see it is an array of objects that contain information for each social auth provider the user is authenticated against, with fields such as the &lt;code>provider_name&lt;/code>, a list of &lt;code>user_claims&lt;/code>, which is assorted data about the user relevant to the provider, such as name, gender and location. It also contains a field called &lt;code>access_token&lt;/code>, which is the provider specific access token that we can use to access the Facebook graph API.&lt;/p>
&lt;p>We can get this field from the JSON using our old friend Json.Net. Azure functions have a few NuGet packages that are always available, and one of these is Json.Net. To use it we have to start by referencing the assembly, then add a &lt;code>using&lt;/code> directive to the top of the function:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#960050;background-color:#1e0010">#&lt;/span> r &lt;span style="color:#e6db74">&amp;#34;Newtonsoft.Json&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">using&lt;/span> Newtonsoft.Json.Linq;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>We can then use it to parse out the Facebook access token:&lt;/p>
&lt;pre tabindex="0">&lt;code>var fbAccessToken = JArray.Parse(content)[0][&amp;#34;access_token&amp;#34;].ToString();
&lt;/code>&lt;/pre>&lt;p>If you want to test this out, change the content of the response to show the &lt;code>fbAccessToken&lt;/code> instead of &lt;code>content&lt;/code> and run the function. You&amp;rsquo;ll then see a nice long access token string in the output.&lt;/p>
&lt;p>Once we have this access token it can be used to query the Facebook Graph API. You can read the &lt;a href="https://developers.facebook.com/docs/graph-api">docs on the Graph API here&lt;/a> and try it out using their &lt;a href="https://developers.facebook.com/tools/explorer">Graph API explorer&lt;/a>.&lt;/p>
&lt;p>Essentially it is an API that you make GET requests to, passing a query string defining the fields you are interested in, and using the access token for bearer authorization. Create a new &lt;code>HttpClient&lt;/code> and set the bearer authorization using the &lt;code>Authorization&lt;/code> header and a value of &lt;code>Bearer &amp;lt;facebook_access_token&amp;gt;&lt;/code> as shown below:&lt;/p>
&lt;pre tabindex="0">&lt;code>var graphClient = new HttpClient();
graphClient.DefaultRequestHeaders.Add(&amp;#34;Authorization&amp;#34;, $&amp;#34;Bearer {fbAccessToken}&amp;#34;);
&lt;/code>&lt;/pre>&lt;p>Then we can make a call to the Graph API, in this case loading the users first name, last name and profile picture. The fields we want are passed to the graph API call as a comma-separate list passed as a query parameter:&lt;/p>
&lt;pre tabindex="0">&lt;code>var graphResponse = await graphClient.GetAsync(&amp;#34;https://graph.facebook.com/v2.11/me?fields=first_name,last_name,picture&amp;#34;);
var graphContent = await graphResponse.Content.ReadAsStringAsync();
&lt;/code>&lt;/pre>&lt;p>Finally change the response to return the graph content:&lt;/p>
&lt;pre tabindex="0">&lt;code>response.Content = new StringContent(graphContent, System.Text.Encoding.UTF8, &amp;#34;application/json&amp;#34;);
&lt;/code>&lt;/pre>&lt;p>Now if you run this, you will see the output from the Facebook Graph API, providing the URL of the users picture, their first name, last name and unique Facebook Id. A sanitized version is shown below:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-json" data-lang="json">&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;picture&amp;#34;&lt;/span>: {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;data&amp;#34;&lt;/span>: {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;height&amp;#34;&lt;/span>: &lt;span style="color:#ae81ff">50&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;is_silhouette&amp;#34;&lt;/span>: &lt;span style="color:#66d9ef">false&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;url&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;&amp;lt;url of my facebook profile pic&amp;gt;&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;width&amp;#34;&lt;/span>: &lt;span style="color:#ae81ff">50&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> },
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;first_name&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;Jim&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;last_name&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;Bennett&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;id&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;&amp;lt;my id&amp;gt;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The basic flow is:&lt;/p>
&lt;div class="image-div" style="max-width: 600px;">
&lt;p>&lt;img src="GetDetailsFlow-1.png" alt="The function calls Azure to get the facebook access token, then uses it to call the Facebook Graph API">&lt;/p>
&lt;/div>
&lt;br>
&lt;p>Now we have our function, we can call this from our Xamarin mobile app as soon as the user is logged in. Once we have the user object, we can call our Azure function as if it was any other REST API using the code below:&lt;/p>
&lt;pre tabindex="0">&lt;code>var client = new HttpClient();
client.DefaultRequestHeaders.Add(&amp;#34;ACCESS_TOKEN&amp;#34;, user.MobileServiceAuthenticationToken);
var response = await client.GetAsync(&amp;#34;https://&amp;lt;my function app&amp;gt;/api/GetUserDetails&amp;#34;);
var content = await response.Content.ReadAsStringAsync();
&lt;/code>&lt;/pre>&lt;p>We pass the &lt;code>MobileServiceAuthenticationToken&lt;/code> property from the user object as an Http header - this is the access token from our Azure app service. We then call the new function which is at &lt;code>https://&amp;lt;my function app&amp;gt;/api/GetUserDetails&lt;/code>. The URL of your function app is &lt;code>&amp;lt;the name you gave it&amp;gt;.azurewebsites.net&lt;/code>, unless you have decided to use a custom domain, and you can find this value by clicking on your function app in the tree in the Azure portal and looking at the details on the right.&lt;/p>
&lt;p>The content that comes back is the JSON from Facebook, and you can convert this into useful data by building a simple class to represent the data and deserializing the JSON into it using Json.Net. The classes to use to deserialize are:&lt;/p>
&lt;pre tabindex="0">&lt;code>public class FacebookPictureData
{
public string Url { get; set; }
}
public class FacebookPicture
{
public FacebookPictureData Data { get; set; }
}
public class FacebookDetails
{
[JsonProperty(&amp;#34;first_name&amp;#34;)]
public string FirstName { get; set; }
[JsonProperty(&amp;#34;last_name&amp;#34;)]
public string LastName { get; set; }
public FacebookPicture Picture { get; set; }
}
&lt;/code>&lt;/pre>&lt;p>You can then deserialize the content from the function call using:&lt;/p>
&lt;pre tabindex="0">&lt;code>var facebookData = JsonConvert.DeserializeObject&amp;lt;FacebookDetails&amp;gt;(content);
&lt;/code>&lt;/pre>&lt;p>Done - you now have the users first name, last name and a URL of their public Facebook picture that you can use as an image source for a Xamarin.Forms Image control. If you want more data from Facebook just add more fields to the Graph API call an the details class on your mobile app.&lt;/p></description></item><item><title>Creating Visual Studio project and solution templates - Part 3, VS for Mac extension</title><link>https://jimbobbennett.dev/blogs/creating-visual-studio-project-and-solution-templates-part-3-vs-for-mac-extension/</link><pubDate>Wed, 08 Nov 2017 07:06:26 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/creating-visual-studio-project-and-solution-templates-part-3-vs-for-mac-extension/</guid><description>&lt;p>In the &lt;a href="https://jimbobbennett.dev/blogs/creating-dotnet-new-and-visual-studio-project-and-solution-templates/">first part of this set of posts&lt;/a> I looked at creating a dotnet new project template, and in the &lt;a href="https://jimbobbennett.dev/blogs/creating-visual-studio-project-and-solution-templates-part-2-vs-for-windows-extension-2/">second part&lt;/a> I showed how you could easily add this to a Visual Studio for Windows extension. Lets now look at adding it to a Visual Studio for Mac extension, so that our template is available everywhere.&lt;/p>
&lt;p>It&amp;rsquo;s really easy to create extensions for VS for Mac for new project types. In a &lt;a href="https://jimbobbennett.dev/blogs/creating-an-add-in-for-xamarin-studio/">previous blog post&lt;/a> I discussed the old way of doing it which, like for VS on Windows, involved a load of files that couldn&amp;rsquo;t be compiled as they had replacement tokens, and no easy way to test the output projects without debugging the extension.&lt;/p>
&lt;p>This all changes now. Instead of adding all the project files, you just need to add the NuGet package created for &lt;code>dotnet new&lt;/code> with a build action of Add-In File, then add an entry into the &lt;code>Manifest.addin.xml&lt;/code> file to make it available:&lt;/p>
&lt;pre tabindex="0">&lt;code>&amp;lt;Extension path=&amp;#34;/MonoDevelop/Ide/Templates&amp;#34;&amp;gt;
&amp;lt;Template
id=&amp;#34;MvvmCrossNativeSinglePage.CSharp&amp;#34;
_overrideDescription=&amp;#34;Creates a new single page native MvvmCross app.&amp;#34;
path=&amp;#34;Templates/MvvmCross.Templates.CSharp.Native.SinglePage.iOS.Android.nupkg&amp;#34;
category=&amp;#34;other/net/mvvmcross&amp;#34;
icon=&amp;#34;res:MVVMCross.XSAddIn.Icons.MvvmCross.png&amp;#34;/&amp;gt;
&amp;lt;/Extension&amp;gt;
&lt;/code>&lt;/pre>&lt;p>This manifest entry provides a description to show in the File-&amp;gt;New dialog, the category in that dialog to put the template into, an icon and the path in the addin to the NuGet package. You can add as many NuGet packages as you want, with one &lt;code>Template&lt;/code> entry per NuGet package. And that&amp;rsquo;s it - no need to add the project files, &lt;code>xpt.xml&lt;/code> files or anything hard like that. You can see an example of this with my MvvmCross templates on &lt;a href="https://github.com/jimbobbennett/MvvmCross-Templates">my GitHub&lt;/a>.&lt;/p></description></item><item><title>Creating Visual Studio project and solution templates - Part 2, VS for Windows extension</title><link>https://jimbobbennett.dev/blogs/creating-visual-studio-project-and-solution-templates-part-2-vs-for-windows-extension-2/</link><pubDate>Mon, 06 Nov 2017 23:42:10 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/creating-visual-studio-project-and-solution-templates-part-2-vs-for-windows-extension-2/</guid><description>&lt;p>In the &lt;a href="https://jimbobbennett.dev/blogs/creating-dotnet-new-and-visual-studio-project-and-solution-templates/">first part of this set of posts&lt;/a> I looked at creating a dotnet new project template. These are great if you like the cli, but if, like me, you&amp;rsquo;d rather be able to do File-&amp;gt;New then dotnet new is not much use. Instead you need a Visual Studio extension that provides a new project or solution type to the IDE. The good news is that you can easily take what you&amp;rsquo;ve built for your dotnet new templates and create extensions for Visual Studio for both Windows and Mac with not much extra work.&lt;/p>
&lt;p>In this post I&amp;rsquo;ll look at VS 2017 for Windows, in the next post I&amp;rsquo;ll cover VS for Mac. Although I&amp;rsquo;ll look is not really correct - instead I&amp;rsquo;ll be lazy and link to someone else&amp;rsquo;s content ;op.&lt;/p>
&lt;p>There is an extension for VS for Windows called &lt;a href="https://marketplace.visualstudio.com/items?itemName=Sayed-Ibrahim-Hashimi.SidewaffleCreator2017">Sidewaffle Creator&lt;/a> from &lt;a href="https://twitter.com/sayedihashimi">Sayed I. Hashimi&lt;/a> that provides all the help you need. You load up the project that you generated your NuGet package from into VS, then add a new Template Pack Template project from the SideWaffle extension - this new project is your VSIX.&lt;/p>
&lt;p>You can see all this in detail in this YouTube video from Sayed:&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/g6az_N95dVM" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div></description></item><item><title>Introducing Visual Studio Mobile Center</title><link>https://jimbobbennett.dev/blogs/introducing-visual-studio-mobile-center/</link><pubDate>Sat, 04 Nov 2017 06:52:09 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/introducing-visual-studio-mobile-center/</guid><description>&lt;p>In this article, excerpted from chapter 15 of &lt;a href="http://xam.jbb.io">Xamarin in Action&lt;/a>, we’ll be looking at using Visual Studio Mobile Center’ mobile-optimized lifecycle to build, test, deploy, and monitor applications.&lt;/p>
&lt;p>&lt;strong>Save 37% off Xamarin in Action with code &lt;code>fccbennett&lt;/code> at &lt;a href="http://xam.jbb.io">manning.com&lt;/a>.&lt;/strong>&lt;/p>
&lt;hr/>
&lt;h4 id="introducing-visual-studio-mobile-center">Introducing Visual Studio Mobile Center&lt;/h4>
&lt;p>Visual Studio Mobile Center is billed as &amp;lsquo;Mission Control for apps&amp;rsquo; and provides a one-stop shop to managing the mobile-optimized developer lifecycle in your mobile apps, covering testing, building, deployment and monitoring.&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Build&lt;/strong> - Mobile Center has tools to take your code and build it either on demand, or when you push to source code control.&lt;/li>
&lt;li>&lt;strong>Test&lt;/strong> - Mobile Center integrates with Test Cloud, which allows you to take the UI tests and run them on real devices in the cloud (in this case the &amp;lsquo;cloud&amp;rsquo; is a warehouse in Denmark with racks and racks of phones and tablets).&lt;/li>
&lt;li>&lt;strong>Monitor&lt;/strong> - Using Mobile Center, you can get analytics around the users who’re using your apps, and crash reports that upload automatically if your app crashes for your users.&lt;/li>
&lt;li>&lt;strong>Distribute&lt;/strong> - From Mobile Center you can distribute your builds to beta testers, including adding notifications inside your app when an update is available. You can also distribute to the Google Play and Apple App Stores.&lt;/li>
&lt;/ul>
&lt;p>This is slightly out of order in terms of the lifecycle, but makes sense to developers—we should set up the build before we can test it and we should add analytics before we distribute to see the results as soon as possible.&lt;/p>
&lt;p>You can access Mobile Center at &lt;a href="https://mobile.azure.com">https://mobile.azure.com&lt;/a>. At the time of writing, it’s available as a public preview and is free for light usage. You can log in using either a Microsoft account (you probably set one of these up when installing Xamarin), or by connecting it to your GitHub, Facebook, or Google account.&lt;/p>
&lt;div class="image-div" style="max-width: 600px;">
&lt;p>&lt;img src="ch15_mobile_center_first_page.png" alt="Mobile center sign in page">&lt;/p>
&lt;/div>
&lt;small>_Figure 1. Visual Studio Mobile Center: Mission Control for apps_&lt;/small>
&lt;p>Once you’ve connected to Mobile Center, it’s worth setting up a Mobile Center password associated with the email address used by the service you connected with. This allows you to log in from the command line later, which is needed to run UI tests. To do this, click on the cog icon next to your name to see the user settings, go to the password tab and click the &amp;lsquo;Send set password email&amp;rsquo; button. You’ll receive an email with a link to follow to set a password; click this link and set a password.&lt;/p>
&lt;blockquote>
&lt;p>&lt;strong>NOTE:&lt;/strong> Mobile Center is a continuously evolving service
At the time of writing, Mobile Center is in preview, and it’s being actively worked on. Hopefully, the implementation shouldn’t change too much, the concepts certainly should not.&lt;/p>
&lt;/blockquote>
&lt;p>Mobile Center is based around the concept of &amp;lsquo;Apps&amp;rsquo;, and apps can belong to users or organizations.&lt;/p>
&lt;h6 id="apps">Apps&lt;/h6>
&lt;p>Mobile Center is built around the concept of &amp;lsquo;Apps&amp;rsquo;, with each app being a single, releasable app for a single platform. Imagine that we are developing an app called Countr (if you would like to follow along, you can fork the source code from &lt;a href="https://github.com/jimbobbennett/Countr)">https://github.com/jimbobbennett/Countr)&lt;/a>. Although we may think of Countr as a single app available on iOS and Android, from the perspective of Mobile Center it’s two apps, one Android, one iOS.&lt;/p>
&lt;blockquote>
&lt;p>&lt;strong>TIP:&lt;/strong> Mobile Center covers more than Microsoft products
As part of the new &amp;lsquo;Any developer, any platform,&amp;rsquo; Microsoft has made sure that Mobile Center works for all mobile developers, not only Xamarin developers. They support native iOS and Android apps built using Objective-C, Swift and Java, Xamarin, Windows UWP and React Native—and they supported native iOS and Android before Xamarin. This means that if you work with a mixture of app technologies you can still use Mobile Center to manage everything.&lt;/p>
&lt;/blockquote>
&lt;p>For each app Mobile Center provides a number of services:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Build&lt;/strong> - Mobile Center can connect to a source code repository (currently GitHub, VSTS and BitBucket are supported), and for each branch in your repo you can create a build to compile your solution or an individual project using any available build configuration, either on demand or whenever the code is updated in the repo, when you sign your build using an Android keystore or iOS provisioning profile, or even launch it on a real device using Test Cloud as a sanity check that your app runs and doesn’t crash on startup.&lt;/li>
&lt;li>&lt;strong>Test&lt;/strong> - Xamarin has a huge datacenter in Denmark with thousands of real devices that you can run your app on using automated UI testing. Mobile Center can be used to configure, start and see the results of these test runs.&lt;/li>
&lt;li>&lt;strong>Distribute&lt;/strong> - Mobile Center can distribute your app as soon as it’s built, to beta testers or to the Google Play or Apple App stores. Beta test users get an email with a link to download your app to test it, and can even get notifications inside their apps that an update is available.&lt;/li>
&lt;li>&lt;strong>Crashes&lt;/strong> - Most apps crash at some point and Mobile Center has an SDK you can add to your apps that can track crashes. If your app crashes, the Mobile Center SDK tracks this, and the next time your app is run and is online it uploads the crash details, including the stack trace, to Mobile Center.&lt;/li>
&lt;li>&lt;strong>Analytics&lt;/strong> - It’s always good to know how your users are using your app to track pain points, see what features are popular or aren’t being used to know which areas to work on. It also helps to see user demographics—if your app is in English, but it’s popular in Italy, you might want to offer it in Italian. The Mobile Center SDK can help to track this kind of information.&lt;/li>
&lt;/ul>
&lt;h6 id="users-and-organizations">Users and Organizations&lt;/h6>
&lt;p>When you log into Mobile Center, you’re logged in as a user and you can have apps assigned to you as an individual. Users can also be part of an organization—a named group of users with different permissions. You can be an &amp;lsquo;admin&amp;rsquo; user and have full control over the organization, or a &amp;lsquo;collaborator&amp;rsquo; who creates and manages apps inside the organization. You can read more on organizations at &lt;a href="https://docs.microsoft.com/en-us/mobile-center/dashboard/creating-andmanaging-organizations">https://docs.microsoft.com/en-us/mobile-center/dashboard/creating-andmanaging-organizations&lt;/a>.&lt;/p>
&lt;h6 id="api">API&lt;/h6>
&lt;p>Mobile Center was written to be API first—the development team at Microsoft created public APIs for managing your apps, and the web portal was written to use these APIs. This means that anything you can do in the Mobile Center web portal, you can also do using a public REST API. You can easily integrate Mobile Center into any existing build or CI tools that you already use. For example, if you already have an automated build and release process using a tool, like Jenkins, you can replace the steps for building your app with calls to Mobile Center and use that to run your builds. API documentation is available at &lt;a href="https://docs.microsoft.com/en-us/mobile-center/api-docs/">https://docs.microsoft.com/en-us/mobile-center/api-docs/&lt;/a>.&lt;/p>
&lt;h6 id="cli">CLI&lt;/h6>
&lt;p>Mobile Center also has a command line interface that you can use to do everything Mobile Center can do from a command line. The Mobile Center docs at &lt;a href="https://docs.microsoft.com/en-us/mobilecenter/cli/index">https://docs.microsoft.com/en-us/mobilecenter/cli/index&lt;/a> have more information on the CLI, covering the huge range of features it offers. We’ll look at getting this set up and using it later in this article to run automated tests.&lt;/p>
&lt;h6 id="getting-help">Getting Help&lt;/h6>
&lt;p>Mobile Center has excellent documentation available by clicking the question mark icon in the bottom of the menu, or at &lt;a href="https://docs.microsoft.com/en-us/mobile-center/">https://docs.microsoft.com/en-us/mobile-center/&lt;/a>. You can also interact directly with the Mobile Center team at Microsoft if you get stuck, find bugs or have feature suggestions by clicking the blue and white speech bubble button. From here you can start conversations with the team, see their responses and see messages about new features.&lt;/p>
&lt;h4 id="setting-up-builds">Setting up Builds&lt;/h4>
&lt;p>Mobile Center apps are based around code for a mobile app from a source control repository, and before we can set up a build we need to put the source code for our app into a repository that Mobile Center can access. At the time of writing Mobile Center supports three providers: Git repos in &lt;a href="https://github.com">GitHub&lt;/a> and &lt;a href="https://bitbucket.org">BitBucket&lt;/a>; and Git or TFS repos in &lt;a href="https://www.visualstudio.com/team-services/">Visual Studio Team Services&lt;/a>. Source code control is outside the scope of this article, and if Git’s new to you I’d recommend &lt;a href="https://www.manning.com/books/learn-git-in-a-month-of-lunches">Learn Git in a Month of Lunches by Rick Umali&lt;/a>. For the rest of this article you’ll need to have a basic understanding including being aware of branches, commits, and pushes.&lt;/p>
&lt;p>Let’s have a look at setting up Countr, our fictitious app that we mentioned earlier. You’ll need to add your Countr code to one of the three source code providers to get started. Each one has comprehensive documentation to get you started. I personally use GitHub as you can use a GitHub account to log into Mobile Center, and this automatically gives Mobile Center access to your repos, but use what you feel most comfortable with.&lt;/p>
&lt;h6 id="creating-your-first-mobile-center-app">Creating your first Mobile Center app&lt;/h6>
&lt;p>Once your code is in source control, start by creating an app in Mobile Center. We’ll begin by creating an Android app, and then the iOS version. From the Mobile Center landing page, click the &amp;lsquo;Add new app&amp;rsquo; button on the top right.&lt;/p>
&lt;div class="image-div" style="max-width: 400px;">
&lt;p>&lt;img src="ch15_add_new_app.png" alt="Setting up our app in Mobile Center">&lt;/p>
&lt;/div>
&lt;small>_Figure 2. Setting up our app in Mobile Center_&lt;/small>
&lt;p>A panel slides out on the right where you can enter details for your app. Set the name as &lt;strong>Countr - Android&lt;/strong>, add a description, set the OS to Android and the Platform to Xamarin, then click Add new app. This creates the app and shows a &amp;lsquo;Getting started&amp;rsquo; page with details on how to set up the Mobile Center SDK for crash reporting and analytics.&lt;/p>
&lt;div class="image-div" style="max-width: 600px;">
&lt;p>&lt;img src="ch15_mobile_center_connect_repo.png" alt="To create a build you first need to connect Mobile Center to your source code provider">&lt;/p>
&lt;/div>
&lt;small>_Figure 3. To create a build you first need to connect Mobile Center to your source code provider_&lt;/small>
&lt;p>The next step is to configure a build, and to do this we need to connect Mobile Center to our source code provider. Click the &amp;lsquo;Build&amp;rsquo; tab on the menu on the right, select your source code provider of choice and follow the instructions to connect it to Mobile Center. Once connected, choose the repo that you put the source code for Countr into.&lt;/p>
&lt;h6 id="configuring-the-android-build">Configuring the Android build&lt;/h6>
&lt;p>Once you’ve set up your repo, the build tab shows all available branches in that repo, and if you set up a new Git repo you’ll probably only see one branch called master. Click on the master branch, and then click &amp;lsquo;Set up branch&amp;rsquo;. A panel will slide out with options to configure your branch.&lt;/p>
&lt;div class="image-div" style="max-width: 800px;">
&lt;p>&lt;img src="ch15_set_up_android_branch_annotated.png" alt="Mobile Center can build your branch, as well as sign it, test it and set it up for distribution">&lt;/p>
&lt;/div>
&lt;small>_Figure 4. Mobile Center can build your branch, as well as sign it, test it and set it up for distribution_&lt;/small>
&lt;p>This configuration is divided into four sections:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Build app&lt;/strong> - In this section you can configure how your app should be built.&lt;/li>
&lt;li>&lt;strong>Project&lt;/strong> - The first option is the project to build - your solution could contain multiple Android apps, and here you can select the one to build. Our solution only has one Android app; Counter.Droid should be selected.&lt;/li>
&lt;li>&lt;strong>Configuration&lt;/strong> - From here you can set the build configuration to compile with—either Debug or Release (or any others if you’ve more set up). We’ll need a release build for running UI tests later; set this to Release.&lt;/li>
&lt;li>&lt;strong>Build frequency&lt;/strong> - The build frequency can be set to every push to this branch or on demand. Leave this as Build this branch on every push; every time you push one or more commits to GitHub, BitBucket or VSTS the app is rebuilt.&lt;/li>
&lt;li>&lt;strong>Sign builds&lt;/strong> - Mobile Center can sign your builds using your Android keystore. Turn on &amp;lsquo;Sign builds,&amp;rsquo; upload your keystore from the safe place where you keep it, enter the alias you used when creating it into the KEY_ALIAS, then enter your keystore password into both the KEYSTORE_PASSWORD and KEY_PASSWORD fields (when you set up a keystore using Xamarin it uses the same password for both the keystore and the signing key inside it).&lt;/li>
&lt;li>&lt;strong>Tests on a real device&lt;/strong> - By turning this option on your app is launched on a real device inside Mobile Center’s Test Cloud service, and the test verifies that your app launched successfully. This is a great sanity check that your build has worked and your app starts up. You have no control over which device it runs on—it’s compatible with at least your app’s minimum SDK installed, but other than that you have no control. It also makes your build take longer as you’ll have to wait for an available device. It runs using UITest, and you’ll need to use a release build to prevent the shared Mono runtime from being used.
You need a valid Test Cloud subscription for this to work, but as part of your Mobile Center free trial you’ll get a valid subscription; turn this option on.&lt;/li>
&lt;li>&lt;strong>Distribute builds&lt;/strong> - These options allow you to distribute your final builds to either beta testers or the store.&lt;/li>
&lt;/ul>
&lt;p>Once your build’s configured, click &amp;lsquo;Save.&amp;rsquo; This will queue up a first build under the master branch.&lt;/p>
&lt;div class="image-div" style="max-width: 600px;">
&lt;p>&lt;img src="ch15_master_branch_build_queued.png" alt="All builds for a branch can be seen by clicking on the branch">&lt;/p>
&lt;/div>
&lt;small>_Figure 5. All builds for a branch can be seen by clicking on the branch_&lt;/small>
&lt;p>Under each branch is a list of all the builds for that branch, with only one entry—the build that was kicked off by setting up the branch. If you click on the build you can see more information about it, including a full build log.&lt;/p>
&lt;div class="image-div" style="max-width: 600px;">
&lt;p>&lt;img src="ch15_android_successful_build.png" alt="Your Android app should build successfully">&lt;/p>
&lt;/div>
&lt;small>_Figure 6. Your Android app should build successfully_&lt;/small>
&lt;p>Once your app is built you’ll see the build marked as a success, as well as how long the build took and logs detailing everything that happened. The build has taken the code from your source control provider, restored the NuGet packages you use, compiled your Android app, signed the APK using your keystore, installed it on a device, and launched it to verify that everything worked. You’ll also have an option to download the Android APK and build logs if you want. If your app didn’t build, check the build output and fix whatever’s causing the issue.&lt;/p>
&lt;p>This is our Android app setup and built, now let’s setup the iOS app.&lt;/p>
&lt;h6 id="configuring-the-ios-build">Configuring the iOS build&lt;/h6>
&lt;p>Although we’re building a cross-platform Xamarin app, we’re building two apps, one iOS and one Android. This means we must set up our iOS app as a separate app in Mobile Center. Repeat the same steps as for the Android app, but call the app &lt;strong>Countr - iOS&lt;/strong> and set the OS to iOS.&lt;/p>
&lt;div class="image-div" style="max-width: 800px;">
&lt;p>&lt;img src="ch15_set_up_ios_branch_annotated.png" alt="iOS builds have a few more options than Android builds">&lt;/p>
&lt;/div>
&lt;small>_Figure 7. iOS builds have a few more options than Android builds_&lt;/small>
&lt;p>As before select the master branch to setup the build. The &amp;lsquo;Build app&amp;rsquo; section has a few different options to the Android version.&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Build app&lt;/strong>&lt;/li>
&lt;li>&lt;strong>Project&lt;/strong> - Unlike Android, from here you can only select the solution to build, not the project. This means to avoid confusion you should only have one iOS app in your solution—if you have more than one, it might be worth breaking them out into separate solutions. This should default to Countr.sln.&lt;/li>
&lt;li>&lt;strong>Configuration&lt;/strong> - This is the same as the Android configuration section. To be able to run a launch test on our builds using UITest we need to use the Debug configuration; set this to Debug instead of Release.&lt;/li>
&lt;li>&lt;strong>Xcode version&lt;/strong> - You can configure which version of Xcode to use when building. Only recent versions are available (at the time of writing, 8.3.2 is the latest and you can only select versions starting at 8.0), but this is useful if you have a reason for needing an earlier version. We can leave this as the default which is the latest released version.&lt;/li>
&lt;li>&lt;strong>Build type&lt;/strong> - Unlike Android, iOS builds come in two types: simulator and device builds. Set this to Device
build to run a launch test on a real device (launch tests aren’t available on simulators).&lt;/li>
&lt;li>&lt;strong>Build frequency&lt;/strong> - Leave this as Build this branch on every push.&lt;/li>
&lt;li>&lt;strong>Sign builds&lt;/strong> - Mobile Center can sign our iOS builds using our certificate and provisioning profile.&lt;/li>
&lt;li>&lt;strong>Provisioning profile&lt;/strong> - The easiest way to set the provisioning profile is to head to the &lt;a href="https://developer.apple.com">Apple developer site&lt;/a>, log in, head to the provisioning profiles section of &amp;lsquo;Certificates,
identifiers and profiles,&amp;rsquo; and download your developer profile. Once downloaded, upload it
to Mobile Center.&lt;/li>
&lt;li>&lt;strong>Certificate&lt;/strong> - Mobile Center needs your signing certificate as a .p12 file. You can’t download this from the
Apple developer website, instead you need to export it from your keychain. Open &amp;lsquo;Keychain Access&amp;rsquo; on your Mac and search for a certificate with a name that starts with &amp;lsquo;iPhone Developer.&amp;rsquo; Select this certificate and click &amp;lsquo;File→Export Items…&amp;rsquo;, enter a name, select a sensible location, and click Save. When prompted, enter a password to use to encrypt this certificate.&lt;/li>
&lt;/ul>
&lt;div class="image-div" style="max-width: 600px;">
&lt;p>&lt;img src="ch15_export_p12.png" alt="Use Keychain Access to export your certificate">&lt;/p>
&lt;/div>
&lt;small>_Figure 8. Use Keychain Access to export your certificate_&lt;/small>
&lt;p>From Mobile Center upload this &lt;code>.p12&lt;/code> file and enter the password you used.&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Tests on a real device&lt;/strong> - Turn this option on again to sanity check out app on a real iOS device.&lt;/li>
&lt;li>&lt;strong>Distribute builds&lt;/strong> - Leave this off for now.
Once your build is set up, click Save and watch the logs to see it build and run the launch test. Again, if the build fails check the build output and fix any issues.&lt;/li>
&lt;/ul>
&lt;p>That’s the basics using Mobile Center. If you want to learn more about making cross-platform mobile apps using Xamarin, download the free first chapter of &lt;a href="http://xam.jbb.io">Xamarin in Action&lt;/a> and see &lt;a href="https://www.slideshare.net/ManningBooks/xamarin-in-action">this Slideshare presentation&lt;/a>.&lt;/p></description></item><item><title>Creating Visual Studio project and solution templates - Part 1, dotnet new</title><link>https://jimbobbennett.dev/blogs/creating-dotnet-new-and-visual-studio-project-and-solution-templates/</link><pubDate>Wed, 25 Oct 2017 06:42:53 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/creating-dotnet-new-and-visual-studio-project-and-solution-templates/</guid><description>&lt;p>I&amp;rsquo;ve recently updated my &lt;a href="https://github.com/jimbobbennett/MvvmCross-Templates">MvvmCross templates&lt;/a> to support .NET Standard to be ready for the awesome future. Unfortunately this meant a complete rewrite of my templates as the out of the box Visual Studio project template extensions on both Windows and Mac don&amp;rsquo;t support .NET Standard. As it turned out though, this rewrite was a blessing in disguise as there is a new way to do templates, and this can be used with the &lt;code>dotnet&lt;/code> cli as well as inside extensions for VS on Windows and Mac, meaning I can now create one template and use it on all platforms.&lt;/p>
&lt;p>This post shows how to create templates for the .NET cli, and in the next two posts these templates will be ported to Visual Studio, first Windows then Mac.&lt;/p>
&lt;h4 id="dotnet-new">dotnet new&lt;/h4>
&lt;p>As part of the new .NET Core awesomeness, there is a new cli for .NET. You can install this manually from &lt;a href="https://www.microsoft.com/net/core">https://www.microsoft.com/net/core&lt;/a>, otherwise you can install it with Visual Studio.&lt;/p>
&lt;p>Once you have the .NET cli installed you can use the command line to create new apps based off templates using &lt;code>dotnet new &amp;lt;template name&amp;gt;&lt;/code>. Some templates come pre-installed, and you can download and install others to provide any kind of project your heart desires. This post is not going to cover the cli, you can read up on that from the previous link, instead we are going to look at creating templates.&lt;/p>
&lt;h4 id="dotnet-new-templates">dotnet new templates&lt;/h4>
&lt;p>The templates used by &lt;code>dotnet new&lt;/code> are actually really simple - they are fully working projects or solutions with a config file. If you&amp;rsquo;ve ever created a project or solution extension for Visual Studio you&amp;rsquo;ve probably had the fun of creating a project then changing namespaces and project references to be &lt;code>$ProjectName&lt;/code> or other such replacement tokens. These projects then cannot be run, so to change them you have to change the code, build the extension, create a project, find problems, rinse and repeat. With dotnet new templates you don&amp;rsquo;t have to do this.&lt;/p>
&lt;h6 id="step-1---create-a-project">Step 1 - create a project&lt;/h6>
&lt;p>The first thing to do is a create a project or solution that you want to create the template from. Add the relevant NuGet packages, add classes, resources, whatever you need. This is a normal project, the same you use every day so you can run it at any time for testing.&lt;/p>
&lt;h6 id="step-2---create-a-templateconfig-file">Step 2 - create a template.config file&lt;/h6>
&lt;p>At the root of your project or solution, create a folder called &lt;code>.template.config&lt;/code> and add a json file called &lt;code>template.json&lt;/code> to that folder. This file defines the structure of the template, including providing a base namespace that you used in your project. When a new project is created using your template, all the files in your source project will be used, with the namespace changed to the namespace passed to dotnet new.&lt;/p>
&lt;p>For example if your project had the namespace &lt;code>MvvmCrossApp&lt;/code>, you set this in the &lt;code>template.json&lt;/code> file. If the end user tells dotnet new to use the namespace &lt;code>Foo&lt;/code>, any occurrences of &lt;code>MvvmCrossApp&lt;/code> in source files or project files will be replaced with &lt;code>Foo&lt;/code> automatically - no need to use replacement tokens.&lt;/p>
&lt;p>You can read about all the fields in this file at &lt;a href="https://blogs.msdn.microsoft.com/dotnet/2017/04/02/how-to-create-your-own-templates-for-dotnet-new/">https://blogs.msdn.microsoft.com/dotnet/2017/04/02/how-to-create-your-own-templates-for-dotnet-new/&lt;/a>. You can also install an extension to Visual Studio for Windows called &lt;a href="https://marketplace.visualstudio.com/items?itemName=Sayed-Ibrahim-Hashimi.SidewaffleCreator2017">Sidewaffle Creator&lt;/a> that has a wizard to help create these files.&lt;/p>
&lt;h6 id="step-3---create-a-nuget-package">Step 3 - create a NuGet package&lt;/h6>
&lt;p>These templates are packaged as NuGet packages, so you will need to create a &lt;code>.nuspec&lt;/code> and package up your files. This NuSpec needs to have the usual id, description, version, as well a package type of template set in the metadata. All the source files for your project need to be added as files. You can see an example I use for my MvvmCross templates below:&lt;/p>
&lt;pre tabindex="0">&lt;code>&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;utf-8&amp;#34;?&amp;gt;
&amp;lt;package xmlns=&amp;#34;http://schemas.microsoft.com/packaging/2012/06/nuspec.xsd&amp;#34;&amp;gt;
&amp;lt;metadata&amp;gt;
&amp;lt;id&amp;gt;MvvmCross.Templates.CSharp.Native.SinglePage.iOS.Android&amp;lt;/id&amp;gt;
&amp;lt;version&amp;gt;1.0.0&amp;lt;/version&amp;gt;
&amp;lt;description&amp;gt;
Creates an example single page MvvmCross app for iOS, Android, UWP and WPF.
&amp;lt;/description&amp;gt;
&amp;lt;authors&amp;gt;Jim Bennett&amp;lt;/authors&amp;gt;
&amp;lt;packageTypes&amp;gt;
&amp;lt;packageType name=&amp;#34;Template&amp;#34; /&amp;gt;
&amp;lt;/packageTypes&amp;gt;
&amp;lt;/metadata&amp;gt;
&amp;lt;files&amp;gt;
&amp;lt;file src=&amp;#34;.\MvvmCrossNativeSinglePage\**&amp;#34; target=&amp;#34;content&amp;#34; exclude=&amp;#34;.\MvvmCrossNativeSinglePage\packages\**;.\MvvmCrossNativeSinglePage\*.UWP\**;.\MvvmCrossNativeSinglePage\*.WPF\**;.\MvvmCrossNativeSinglePage\.template.config\template.json;**\bin\**;**\obj\**;**\.vs\**;**\*.user;&amp;#34;/&amp;gt;
&amp;lt;file src=&amp;#34;.\MVVMCross.XSAddIn\MvvmCrossNativeSinglePage.template.json&amp;#34; target=&amp;#34;content\.template.config\template.json&amp;#34;/&amp;gt;
&amp;lt;/files&amp;gt;
&amp;lt;/package&amp;gt;
&lt;/code>&lt;/pre>&lt;p>This is packaged up using the NuGet command line to give a standard NuGet package.&lt;/p>
&lt;h6 id="step-4---install-the-template">Step 4 - install the template&lt;/h6>
&lt;p>Templates can be installed in one of two ways. To test locally, you can install using:&lt;/p>
&lt;pre tabindex="0">&lt;code>dotnet new --install &amp;lt;path_to_nuget_package&amp;gt;
&lt;/code>&lt;/pre>&lt;p>Then if you run &lt;code>dotnet new&lt;/code> you should see your template in the list of available templates. You can then create a new project or solution using your template by using:&lt;/p>
&lt;pre tabindex="0">&lt;code>dotnet new &amp;lt;template_short_name&amp;gt; -o &amp;lt;output_folder_and_namespace_name&amp;gt;
&lt;/code>&lt;/pre>&lt;h6 id="step-5---distribute-the-template">Step 5 - distribute the template&lt;/h6>
&lt;p>Once you&amp;rsquo;ve verified locally, you can upload your NuGet package to &lt;a href="https://NuGet.org">NuGet.org&lt;/a>. From there anyone can install your template using:&lt;/p>
&lt;pre tabindex="0">&lt;code>dotnet new --install &amp;lt;NuGet_package_id&amp;gt;
&lt;/code>&lt;/pre>&lt;p>You can see an example of this for my MvvmCross templates at &lt;a href="https://github.com/jimbobbennett/MvvmCross-Templates">https://github.com/jimbobbennett/MvvmCross-Templates&lt;/a>&lt;/p>
&lt;hr/>
&lt;p>In the next post we&amp;rsquo;ll look at using this template inside a Visual Studio for Windows extension.&lt;/p></description></item><item><title>Hitting refresh on my career</title><link>https://jimbobbennett.dev/blogs/hitting-refresh-on-my-career/</link><pubDate>Tue, 24 Oct 2017 06:56:55 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/hitting-refresh-on-my-career/</guid><description>&lt;p>Inspired by &lt;a href="http://amzn.to/2lcaLDa">Satya Nadella&amp;rsquo;s Hit Refresh&lt;/a>, a book well worth reading, I thought I&amp;rsquo;d write about my Hit Refresh moment.&lt;/p>
&lt;p>Hit Refresh is inspired by refreshing your browser - it doesn&amp;rsquo;t reload everything, instead it just reloads part of the page. This is reflected in how we can change our lives, not by a complete change, but by refreshing a part. In my case it was three and a half years ago. I was working in finance for some of the worlds largest institutions writing desktop apps, and I was bored. By doing boring work using old technology for people who only cared about how much money they could make I&amp;rsquo;d lost my passion. No longer did I code at weekends or keep up to date with the latest cool things. In the end, enough was enough. I needed a change.&lt;/p>
&lt;p>I decided mobile was the way to go, as I felt a strong interest in these new paradigms - the ability to take our content creation and consumption with us wherever we went. Looking around the technology landscape I discovered Xamarin. I could write mobile apps using C#, a language I was very familiar with, in Visual Studio, a tool I was also very familiar with. In a short space of time I took the plunge - I quit a job I hated and parked in a co-working space in Thailand with my MacBook, a Surface and a Xamarin license (and a very understanding wife and toddler). I spent 4 months learning this new, exciting technology.&lt;/p>
&lt;p>At that point I couldn&amp;rsquo;t find a job as a Xamarin developer, instead I went back to finance to pay the bills, but got heavily involved in the community. My passion was back so I wanted to spread this love around the world. I published code again, I blogged again, and for the first time I spoke at events, starting with meetups, then moving to international conferences. I&amp;rsquo;d truly found my passion. Later I got a job as a Xamarin developer, moving to New Zealand. Here I got involved running the local meetups, spending time with the local Microsoft team helping at all day events. I even ended up writing a &lt;a href="http://xam.jbb.io">book on Xamarin&lt;/a>!&lt;/p>
&lt;p>&lt;img src="2017-10-24_19-53-48.png" alt="Jim talking at Dev Days">&lt;/p>
&lt;p>I went from bored, to full of passion for a technology that made mobile so easy. I&amp;rsquo;d learned how much I loved presenting, so do it at every opportunity. I&amp;rsquo;d reinvented myself, not by a conscious effort to become someone else, but by discovering who I truly am. I am more content with my life, I love what I do. And career-wise, it has played out incredibly well, with another Hit Refresh moment coming, that I will blog about soon!&lt;/p>
&lt;p>There is a moral to this story - find what you love and use it to hit refresh on your life, who knows where it will lead!&lt;/p>
&lt;hr/>
&lt;p>This post is part of the collection of #HitRefresh moments. Read more at &lt;a href="https://www.hitrefreshbook.com">www.hitrefreshbook.com&lt;/a>&lt;/p></description></item><item><title>Using LiveXAML to improve your Xamarin Forms UIs</title><link>https://jimbobbennett.dev/blogs/using-livexaml-to-improve-your-xamarin-forms-uis/</link><pubDate>Tue, 17 Oct 2017 07:53:52 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/using-livexaml-to-improve-your-xamarin-forms-uis/</guid><description>&lt;p>One of the downsides to UI development is how long it takes to get a good looking UI. You spend an inordinate amount of time setting up the UI, running your app to see how it looks, tweaking the UI, running again, tweaking again, running again. Then of course you have to repeat on multiple devices with different OSes or screen sizes.&lt;/p>
&lt;p>For Xamarin Forms there are a number of tools to help you when building UIs using XAML. The one that comes out of the box is the previewer - a preview of what your XAML will look like on iOS or Android, phones or tablets. This preview updates as you update your XAML but is limited. If your UI relies on bound data you can&amp;rsquo;t see the full experience, and anything that relies on resources doesn&amp;rsquo;t always work so well.&lt;/p>
&lt;p>Another good tool is the Xamarin Live Player, which I&amp;rsquo;ll look at in a later blog post.&lt;/p>
&lt;p>Currently though the tool that is interesting me the most is LiveXAML for Xamarin Forms from Mihhail Maslakov - &lt;a href="http://www.livexaml.com">http://www.livexaml.com&lt;/a>.&lt;/p>
&lt;div class="image-div" style="max-width: 487;">
&lt;p>&lt;img src="logo.png" alt="LiveXAML">&lt;/p>
&lt;/div>
&lt;br/>
&lt;p>This tool is an extension for Visual Studio (both Windows and Mac which is cool) that injects some code inside your app to listen for XAML updates. You update a XAML file inside Visual Studio and the extension tells your app to update the UI. This means you can tweak your code and instantly see the updates in your actual app running under real world conditions. Essentially magic!&lt;/p>
&lt;p>Lets now see it in action. Start by installing the LiveXAMl extension from the extensions gallery, then create a new blank Xamarin Forms app, adding the LiveXAML NuGet package to your core Forms project.&lt;/p>
&lt;p>The out of the box forms template creates a single page app with a label. saying &amp;ldquo;Welcome to Xamarin Forms!&amp;rdquo;. If you run your app you will see this label. Try changing the text color in your XAML page and saving it - you will see the text color update on your app.&lt;/p>
&lt;p>&lt;img src="2017-10-14_11-42-19.gif" alt="LiveXAML updating text color">&lt;/p>
&lt;p>Magic! This is a very simplistic example, but the power here is obvious. I&amp;rsquo;ve wasted countless hours making minor tweaks, especially to margins, font sizes and colors, time that could be saved by using LiveXAML.&lt;/p>
&lt;p>Lets look at a more complicated example, using the sample app I built for a talk at NDC Sydney and MonkeyFest on Xamarin Forms effects and custom renderers. If I change a property on an effect, the UI updates.&lt;/p>
&lt;p>&lt;img src="2017-10-16_12-17-52.gif" alt="Updating an effect also updates the UI">&lt;/p>
&lt;p>This works for pages and styles - so if you update a style in your &lt;code>app.xaml&lt;/code> file, the UI will update, something very important if you use styles a lot (which I do). It also works for controls, so if you have a control defined using XAML on your page, updating the control updates the page.&lt;/p>
&lt;p>You can also use Visual Studio for Mac&amp;rsquo;s run configurations to run two apps at the same time, such as an iOS and an Android app, then update a XAML page and see the UI update on both platforms. Another huge time saver.&lt;/p>
&lt;p>&lt;img src="2017-10-17_20-31-59.gif" alt="Updating an iOS and Android app at the same time">&lt;/p>
&lt;p>You don&amp;rsquo;t just have to use emulators, you can use physical devices. This happens via WiFi over port 53030 and 53031, so if you are on a corporate WiFi network you&amp;rsquo;ll need to have these ports open. I couldn&amp;rsquo;t get this working at the office, but it worked at home.&lt;/p>
&lt;p>Support seems to be pretty good as well. When I first tried it out I had issues with resources and controls not working, but the latest NuGet package seems to have fixed everything, having regular releases adding new features is always a good sign.&lt;/p>
&lt;p>As great as this tool is, there is a downside. As the name suggests it is XAML focused, so updates to C# code will not be rendered on screen.&lt;/p>
&lt;p>Overall opinion - this is great. It&amp;rsquo;s a paid for tool, but has a free version to allow you to try it out. I would say it&amp;rsquo;s probably worth the money, especially if your company pays for it as the time you save would more than pay for the license cost.&lt;/p></description></item><item><title>Introduction to UI Testing with Xamarin</title><link>https://jimbobbennett.dev/blogs/ui-testing-your-xamarin-apps/</link><pubDate>Sun, 20 Aug 2017 04:10:12 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/ui-testing-your-xamarin-apps/</guid><description>&lt;p>This article is an excerpt from &lt;a href="http://xam.jbb.io">Xamarin in Action&lt;/a>. Save 37% off the cover price using code &lt;strong>fccbennett&lt;/strong> at &lt;a href="http://xam.jbb.io">http://xam.jbb.io&lt;/a>.&lt;/p>
&lt;a href="http://xam.jbb.io">
&lt;div class="image-div" style="max-width: 500px;">
&lt;p>&lt;img src="Xamarin-In-Action-Cover-Small.png" alt="Xamarin in Action">&lt;/p>
&lt;/div>
&lt;/a>
&lt;hr/>
&lt;p>One of the great things about the MVVM design pattern is that it allows us to maximize the code in our cross-platform model and view-model layers. This means we’ve written the bulk of our code and we’ve also written unit tests for it, giving us a degree of confidence that our code works. This article introduces UI testing in Xamarin.&lt;/p>
&lt;p>Unit tests are great, but they don’t cover two important areas - have we used the correct controls on our view and bound them correctly, and does our app run on the device. It’s great to have a property on a view model that we bind to a text field to allow the user to enter the name of a counter, but what if we accidentally use the wrong control, such as a label instead of a text box, or even use the right control but forget to add the binding code? What if we’ve used a feature that was only added to the Android SDK in API 21 but our app manifest shows our app runs on API 19 and higher? This is where UI testing comes in - it allows us to run our app on emulators, simulators, and devices, and to write automated tests in code against it.&lt;/p>
&lt;p>The concept behind UI testing is simple - run your app and have something interact with it using the user interface components (such as tapping buttons or entering text in text boxes), and validate that everything is working by ensuring the app doesn’t crash and that the results of the users’ actions are shown on the UI as expected. This kind of testing started out life for desktop apps, where the aim was to make testing more reliable and cheaper - after all, humans are expensive and after testing the same screen many, many times they can get bored and make mistakes or miss problems. Automated UI testing also allowed for better time usage with tests being run overnight and developers discovering if they’ve broken anything the next morning.&lt;/p>
&lt;p>For desktop apps, UI testing was reasonably simple - launch the app and test it, maybe testing on a few different screen sizes, but always on one OS with maybe one or two different versions as desktop OSes don’t change often. With mobile, things are more complicated. We want to support two major OSes with our cross-platform app, with multiple versions. We also have different hardware with different screen sizes. On iOS this isn’t too bad - we only need to support a small number of OS versions (maybe the current one and the previous) and a small number of different devices, but on Android, as we’ve already seen it’s a mess with multiple OS versions in regular use, a huge range of screen sizes available, and worst of all customizations to the OS from both the hardware manufacturer and carrier.&lt;/p>
&lt;p>This is why UI testing is hugely important for mobile apps. A human can’t test on a wide range of devices without needing a lot of time or lots of humans involved in the process (expensive) and without them all going mad as they install the app on another device and run the same test for the millionth time.&lt;/p>
&lt;h5 id="writing-ui-tests-using-xamarin-uitest">Writing UI tests using Xamarin UITest&lt;/h5>
&lt;p>You write UI tests in the same way that you write a unit test – you decide what you want to test, then write some code to create a test. This code uses some kind of framework that is able to launch your app and interact with it as if it was a real user. Many different frameworks are around for testing, and the table below shows some of these.&lt;/p>
&lt;table>
&lt;tr>
&lt;th>Framework&lt;/th>
&lt;th>Platforms&lt;/th>
&lt;th>Language&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;tr>
&lt;td>Espresso&lt;/td>
&lt;td>Android&lt;/td>
&lt;td>Java&lt;/td>
&lt;td>Google’s testing framework for Android apps has deep integration with Android.
&lt;br>
https://google.github.io/androidtesting-support-library/docs/espresso/&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>XCTest&lt;/td>
&lt;td>iOS&lt;/td>
&lt;td>Objective-C/Swift&lt;/td>
&lt;td>
Apple’s UI testing framework has deep integration with iOS.
&lt;br>
https://developer.apple.com/reference/xctest&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Appium&lt;/td>
&lt;td>iOS/Android&lt;/td>
&lt;td>Any (Java/C#/PHP/Ruby etc.)&lt;/td>
&lt;td>Open source cross-platform testing
framework based off of Selenium (a web UI testing framework).
&lt;br>
http://appium.io
&lt;/tr>
&lt;tr>
&lt;td>UITest&lt;/td>
&lt;td>iOS/Android&lt;/td>
&lt;td>C#/F#&lt;/td>
&lt;td>Xamarin’s testing framework heavily integrated into Visual Studio for Windows (Android) and Mac (iOS and Android).
&lt;br>
https://developer.xamarin.com/guides/testcloud/uitest/
&lt;/tr>
&lt;/table>
&lt;p>For this article, I’ll focus on Xamarin UITest, which is well integrated into Visual Studio. For testing Android apps, you can use either Windows or Mac, but for testing iOS apps you’ll need to use a Mac - it’s not supported on Windows at the moment.&lt;/p>
&lt;p>Xamarin UITest is based off a testing framework called Calabash which was written in Ruby and is fully open source and maintained by Xamarin. UITest is a layer on top of this that allows you to write your tests in C# and run them using NUnit. These tests are written in the same way as unit tests using the arrange, act, assert pattern, with the arrange part launching the app and getting it to the relevant state ready to test, the act interacts with the UI as if it was a user, and the assert queries the UI to ensure it’s in the correct state.&lt;/p>
&lt;p>&lt;img src="ch14_arrange_act_assert.svg" alt="UI tests, like unit tests, follow the arrange, act, assert pattern">&lt;/p>
&lt;p>&lt;small>&lt;strong>UI tests, like unit tests, follow the arrange, act, assert pattern&lt;/strong>&lt;/small>&lt;/p>
&lt;h5 id="setting-up-your-app-for-ui-testing">Setting up your app for UI testing&lt;/h5>
&lt;p>For this section, we’ll focus on the Countr app, as there’s more to test here. You can download the source code from this book &lt;a href="https://manning-content.s3.amazonaws.com/download/8/b102481-f2a9-4cf5-884b-fc5f273ed0c9/source-code.zip">here&lt;/a>, so download this and open the completed Countr solution from chapter 13. When we built the model layer in our app, we added a new unit test project that we used for unit tests for both the model and view model layers. For our UI tests, we also need a new project that contains and runs our UI tests.&lt;/p>
&lt;h6 id="creating-the-ui-test-project">Creating the UI test project&lt;/h6>
&lt;p>Add a new UITest project to the Countr solution using Visual Studio for Windows by right-clicking on the solution, selecting &amp;lsquo;Add→New Project…&amp;rsquo; and from the &amp;lsquo;Add new project&amp;rsquo; dialog select &amp;lsquo;Visual C#→Cross-Platform&amp;rsquo; on the left and select &amp;lsquo;UI Test App&amp;rsquo; from the middle. For Mac, right-click on the solution and select &amp;lsquo;Add→Add New Project…&amp;rsquo;, select &amp;lsquo;Multiplatform→Tests&amp;rsquo; on the left and &amp;lsquo;UI Test App&amp;rsquo; from the middle and tap &amp;lsquo;Next&amp;rsquo;. Name your project &amp;lsquo;Countr.UITests&amp;rsquo; and click &amp;lsquo;OK&amp;rsquo; (Windows) or &amp;lsquo;Create&amp;rsquo; (Mac).&lt;/p>
&lt;div class="image-div" style="max-width: 500px;">
&lt;p>&lt;img src="ch14_add_new_uitest_project_mac.png" alt="Adding a new UITest project using Visual Studio for Mac">&lt;/p>
&lt;/div>
&lt;small>&lt;strong>Adding a new UITest project using Visual Studio for Mac&lt;/strong>&lt;/small>
&lt;div class="image-div" style="max-width: 500px;">
&lt;p>&lt;img src="ch14_add_new_uitest_project_windows.png" alt="Adding a new UITest project using Visual Studio 2017">&lt;/p>
&lt;/div>
&lt;small>&lt;strong>Adding a new UITest project using Visual Studio 2017&lt;/strong>&lt;/small>
&lt;p>Once the test project has been added it’ll install two NuGet packages that UITest needs - &lt;em>NUnit&lt;/em> and &lt;em>Xamarin.UITest&lt;/em>. It’s worth updating the &lt;em>Xamarin.UITest&lt;/em> NuGet package to the latest version, as they often push out bug fixes to ensure it works on the latest mobile OS versions. &lt;em>Don’t&lt;/em> update &lt;em>NUnit&lt;/em>. UITest only works with NUnit 2, not NUnit 3 and if you update this package your tests won’t work and you’ll need to remove the package and re-install NUnit 2.&lt;/p>
&lt;p>The UI test project has two files auto-generated for you - &lt;code>AppInitializer.cs&lt;/code> and &lt;code>Tests.cs&lt;/code>.&lt;/p>
&lt;ul>
&lt;li>&lt;code>AppInitializer.cs&lt;/code>: This is a static helper class with a single static method which is used to start your app. UITest has an &lt;code>IApp&lt;/code> interface used to represent your running app, and this has methods on it for interacting with the UI elements in your app or to a limited extent the device hardware (for example rotating the device). The &lt;code>StartApp&lt;/code> method returns an instance of &lt;code>IApp&lt;/code> that your tests can use. This method uses a helper class called &lt;code>ConfigureApp&lt;/code> to start the app, and this helper class has a fluent API that allows you to configure and run your app. The auto-generated code doesn’t do much to configure the app, it specifies its type (Android or iOS) based on the platform passed in to the method.&lt;/li>
&lt;li>&lt;code>Tests.cs&lt;/code>: This file contains an UI test to run. This test fixture has a parameterized constructor that takes the platform to run the tests on as one of the values from the &lt;code>Platform&lt;/code> enum, either &lt;code>Platform.iOS&lt;/code> or &lt;code>Platform.Android&lt;/code>, and has two &lt;code>TestFixture&lt;/code> attributes, one for each platform. This means that we have two test fixtures - one Android and one iOS. This fixture has a setup method that uses the &lt;code>AppInitializer&lt;/code> to start the app before each test, and a single test that calls the Screenshot method on the &lt;code>IApp&lt;/code> returned from the app initializer to take a screenshot.&lt;/li>
&lt;/ul>
&lt;h6 id="setting-up-your-android-apps-for-ui-testing">Setting up your Android apps for UI testing&lt;/h6>
&lt;p>By default, Xamarin Android apps are configured in debug builds to use the shared mono runtime. When you deploy your app to a device or emulator, time is taken copying the code over, and anything that can make your app smaller is a good thing as this reduces the time to install. Xamarin Android apps use a mono runtime (mono being the cross-platform version of .Net that Xamarin is based on) to provide the .Net framework, and this is a large piece of code bundled in your app. Rather than bundling it in, for debug builds you can use a shared version which is installed separately, making your app smaller. Unfortunately, when doing UI tests you can’t use the shared runtime, and you’ve two options:&lt;/p>
&lt;ul>
&lt;li>Don’t use the shared runtime: You can turn off the shared mono runtime from the project properties. In Visual Studio for Windows you’ll find it in the &amp;lsquo;Android Options&amp;rsquo; tab at the top of the &amp;lsquo;Packaging&amp;rsquo; page, on Mac it’s on the &amp;lsquo;Android Build&amp;rsquo; tab at the top of the &amp;lsquo;General&amp;rsquo; page. Untick the &amp;lsquo;Use Shared Mono Runtime&amp;rsquo; box to turn this off, but be aware that this increases your build times.&lt;/li>
&lt;li>Release builds: Release builds don’t have the shared mono runtime turned on. After all, when you build a release version it’s usually for deployment such as to the store, and your users won’t have the shared mono runtime installed. The downside to using a release build is that you need to grant your app permission to access the internet. This isn’t a problem if your app already accesses the internet, but if it doesn’t you many not want to ask your users for this extra permission as they might not want to grant it. If you want to use a release build, then you can grant this permission in Visual Studio by opening the project properties, heading to the &amp;lsquo;Android Manifest&amp;rsquo; tab and finding the &lt;strong>INTERNET&lt;/strong> permission in the &amp;lsquo;Required Permissions&amp;rsquo; list and ticking it. On Mac, double-click on the &lt;code>AndroidManifest.xml&lt;/code> file in the Properties folder and tick the permission.&lt;/li>
&lt;/ul>
&lt;div class="image-div" style="max-width: 500px;">
&lt;p>&lt;img src="ch14_internet_permissions.png" alt="Adding the internet permission to the AndroidManifest.xml">&lt;/p>
&lt;/div>
&lt;small>&lt;strong>Adding the internet permission to the AndroidManifest.xml&lt;/strong>&lt;/small>
&lt;h6 id="setting-up-your-ios-apps-for-ui-testing">Setting up your iOS apps for UI testing&lt;/h6>
&lt;p>Apart from the shared mono runtime, out of the box UITest works with Android – UITest is able to connect to your running Android app on a device or an emulator and interact with it. iOS, on the other hand, isn’t quite as simple. Due to the stricter security on iOS you can’t connect to a simulator or device and interact with the app. Instead we need to install an extra component into your iOS apps that you initialize before your UI tests can run. To do this, add the &lt;em>Xamarin.TestCloud.Agent&lt;/em> NuGet package to the Countr iOS app (Test Cloud is the Xamarin cloud-based testing service – you’ll see the name used in a few places with UITest).&lt;/p>
&lt;div class="image-div" style="max-width: 500px;">
&lt;p>&lt;img src="ch14_add_testcloud_agent_nuget.png" alt="Adding the Xamarin Test Cloud Agent NuGet package">&lt;/p>
&lt;/div>
&lt;small>&lt;strong>Adding the Xamarin Test Cloud Agent NuGet package&lt;/strong>&lt;/small>
&lt;p>Once this NuGet is installed you’ll need to add a single line of code to initialize it. Open &lt;code>AppDelegate.cs&lt;/code> and add the following code:&lt;/p>
&lt;pre tabindex="0">&lt;code>public override bool FinishedLaunching(UIApplication app,
NSDictionary options)
{
#if DEBUG
Xamarin.Calabash.Start();
#endif
...
}
&lt;/code>&lt;/pre>&lt;p>This code starts the Calabash server for debug builds only. The Calabash server is an HTTP server that runs inside your app, and the UITest framework connects to this to allow it to interact with your app. Apple is strict about security in their apps, and they’d never allow an app with an open HTTP port like this on the app store. To avoid this the Calabash server is only enabled for debug builds - for release builds this code won’t get run, the linker strips it out and your app won’t get rejected from the app store (at least not due to the Calabash server).&lt;/p>
&lt;h5 id="running-the-auto-generated-tests">Running the auto-generated tests&lt;/h5>
&lt;p>UI tests are run in the same way as any other unit test - you can run them from the test pad/explorer. UI tests rely on having a compiled and packaged app to run, and the first step is to build and either deploy to device, emulator or simulator or run the app you want to test. Note that doing a build isn’t enough for Android – a build compiles the code, it doesn’t package it up. The easiest way to ensure you have a compiled and packaged app is to run it once. On Android build in release, for iOS you need to use a debug build to enable the Calabash server. You also need to set what device, emulator or simulator you want to run your tests on in the same way that you’d select the target for debugging.&lt;/p>
&lt;h6 id="getting-ready-to-run-the-tests">Getting ready to run the tests&lt;/h6>
&lt;p>If you open the test pad or explorer you may not see the UI tests if the project hasn’t been built. If you don’t see the tests then build the UITest project and you should see the tests appear. If you expand the test tree in Visual Studio for Mac you’ll see two fixtures - Tests(Android) and Tests(iOS).&lt;/p>
&lt;div class="image-div" style="max-width: 700px;">
&lt;p>&lt;img src="ch14_test_pad_and_explorer.png" alt="The Test Explorer (Windows) and Test pad (Mac)">&lt;/p>
&lt;/div>
&lt;small>&lt;strong>The Test Explorer (Windows) and Test pad (Mac)&lt;/strong>&lt;/small>
&lt;p>Two fixtures are declared with the two &lt;code>TestFixture&lt;/code> attributes on the Tests class. When you run the tests from Tests(Android) it constructs the test fixture by passing &lt;code>Platform.Android&lt;/code> to the constructor, which in turn uses the &lt;code>AppInitializer&lt;/code> to start the Android app. Tests(iOS) is the same, but for the iOS app. Under each fixture you’ll see the same test called &lt;code>AppLaunches&lt;/code>.&lt;/p>
&lt;div class="image-div" style="max-width: 500px;">
&lt;p>&lt;img src="ch14_visual_studio_group_tests.png" alt="Grouping tests in the Visual Studio test explorer ">&lt;/p>
&lt;/div>
&lt;small>&lt;strong>Grouping tests in the Visual Studio test explorer&lt;/strong>&lt;/small>
&lt;p>In Visual Studio, you don’t see the same hierarchy out of the box; drop down the &amp;lsquo;Group By&amp;rsquo; box and select &amp;lsquo;Class&amp;rsquo; to see the tests grouped by test fixture. You can only test Android apps using Visual Studio. Feel free to comment out the &lt;code>[TestFixture(Platform.iOS)]&lt;/code> attribute from the Tests class to remove these tests from the explorer.&lt;/p>
&lt;p>Before we can run the test, we need to make a small tweak. Despite the test calling &lt;code>app.Screenshot&lt;/code>, this test won’t spit out a screenshot. For some reason, out of the box UITest is configured to only create screenshots if the tests are run on Xamarin’s Test Cloud, and we need to change the configuration to always generate screenshots. To do this, add the code in the following listing to &lt;code>AppInitializer.cs&lt;/code>.&lt;/p>
&lt;pre tabindex="0">&lt;code>public static IApp StartApp(Platform platform)
{
if (platform == Platform.Android)
{
return ConfigureApp
.Android
.EnableLocalScreenshots()
.StartApp();
}
return ConfigureApp
.iOS
.EnableLocalScreenshots()
.StartApp();
}
&lt;/code>&lt;/pre>&lt;p>By default, the &lt;code>StartApp&lt;/code> method doesn’t do anything to configure the app which is being tested, and this means that it expects the app to be tested to be a part of the current solution. You also need to configure UI test to know which apps in the solution to use as there could be multiple.&lt;/p>
&lt;h6 id="setting-the-app-to-test-in-visual-studio-for-mac">Setting the app to test in Visual Studio for Mac&lt;/h6>
&lt;p>Open the test pad and expand the &lt;code>Countr.UITests&lt;/code> node. Under this you’ll see the test fixtures, as well as a node called Test Apps shown next to a stack of green arrows. Right-click on this and select &amp;lsquo;Add App Project&amp;rsquo;. From the dialog that appears tick &amp;lsquo;Countr.Droid&amp;rsquo; and &amp;lsquo;Countr.iOS&amp;rsquo; and click &amp;lsquo;OK&amp;rsquo;. You’ll see these two apps appear under the &amp;lsquo;Test Apps&amp;rsquo; node. If you right-click on one of them you’ll see a number of options, including a list of possible target devices to run against, with &amp;lsquo;Current device&amp;rsquo; ticked. This list is used to set which device the UI tests are run against when you run them from the pad. If you leave &amp;lsquo;Current Device&amp;rsquo; selected it’ll use whatever target is set from the main toolbar, but if you always want the tests to run against a particular emulator, simulator or device you can select it from here.&lt;/p>
&lt;h6 id="setting-the-app-to-test-in-visual-studio-2017">Setting the app to test in Visual Studio 2017&lt;/h6>
&lt;p>UITest uses NUnit to run tests, and we need to ensure Visual is configured to run NUnit tests. As I mentioned, to use UITest we need to install the NUnit 2 adapter. From &amp;lsquo;Tools→Extensions and Updates&amp;rsquo;, select the &amp;lsquo;Online&amp;rsquo; tab on the left and search for &amp;lsquo;NUnit 2&amp;rsquo;. Click on &amp;lsquo;NUnit 2 Test Adapter&amp;rsquo; in the list in the middle and click the &amp;lsquo;Download&amp;rsquo; button. You’ll need to close Visual Studio for this to be installed; relaunch it after the install and re-load the Countr solution.&lt;/p>
&lt;div class="image-div" style="max-width: 500px;">
&lt;p>&lt;img src="ch14_installing_nunit2_test_adapter.png" alt="Installing the NUnit 2 test adapter">&lt;/p>
&lt;/div>
&lt;small>&lt;strong>Installing the NUnit 2 test adapter&lt;/strong>&lt;/small>
&lt;p>Visual Studio only supports testing Android; delete the &lt;code>[TestFixture(Platform.iOS)]&lt;/code> attribute from the &lt;code>Tests&lt;/code> class. This stops iOS tests showing up in the test explorer.&lt;/p>
&lt;p>Unlike Visual Studio for Mac, there is no way on Windows to set the test apps. Instead we need to configure this in code by giving it the path to the Android &amp;lsquo;APK&amp;rsquo;, which is in the output folder and is named based on the Android package name with the file extension .apk, with release builds having the suffix of ‐Signed to indicate that they’ve been signed with our keystore. We set the package name in the Android manifest in the last chapter based off a reverse domain name (mine was set to &lt;code>io.jimbobbennett.Countr&lt;/code>), and you can find this file in &lt;code>Countr.Droid\bin\Release&lt;/code> (assuming you’ve built using the release configuration) or &lt;code>Countr.Droid\bin\Debug&lt;/code> for the debug configuration. We’ll be using release Android builds for the purposes of this book; add the code in the following listing to point UITest to the right APK, substituting in your package name.&lt;/p>
&lt;pre tabindex="0">&lt;code>if (platform == Platform.Android)
{
return ConfigureApp
.Android
.EnableLocalScreenshots()
.ApkFile (&amp;#34;../../../Countr.Droid/bin/Release/&amp;lt;your package name&amp;gt;‐Signed.apk&amp;#34;)
.StartApp();
}
&lt;/code>&lt;/pre>&lt;p>When tests are run they’re run on the device or emulator that you selected for the build configuration, the same as for debugging your apps. This makes it easy to change which device tests are run on by changing the dropdown in the toolbar, the same way you’d change the target for debugging.&lt;/p>
&lt;h6 id="running-the-test">Running the test&lt;/h6>
&lt;p>Once the test apps are configured you can run the tests by double-clicking on them in the test pad in Visual Studio for Mac, or by right-clicking on them in the Visual Studio for Windows Test Explorer and selecting &amp;lsquo;Run Selected Tests.&amp;rsquo; If you’re testing Android set the build configuration to release, for iOS set it to debug.&lt;/p>
&lt;div class="image-div" style="max-width: 500px;">
&lt;p>&lt;img src="ch14_selecting_test_device.png" alt="The device to test on is set in the same way as the device for debugging">&lt;/p>
&lt;/div>
&lt;small>&lt;strong>The device to test on is set in the same way as the device for debugging&lt;/strong>&lt;/small>
&lt;p>That’s all for UI testing. If you want to learn more about making cross-platform mobile apps using Xamarin, download the free first chapter of &lt;a href="http://xam.jbb.io">Xamarin in Action&lt;/a> and see this &lt;a href="http://www.slideshare.net/ManningBooks/xamarin-in-action">Slideshare presentation&lt;/a>.&lt;/p></description></item><item><title>Firewall issues with iOS simulators</title><link>https://jimbobbennett.dev/blogs/firewall-issues-with-ios-simulators/</link><pubDate>Thu, 10 Aug 2017 01:19:54 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/firewall-issues-with-ios-simulators/</guid><description>&lt;p>I keep getting an annoying issue with my iOS simulators. When I run an app in a simulator that needs any form of network connection I get a dialog box popup from the built in Mac firewall asking if I want to allow incoming connections. Even though I click &amp;lsquo;allow&amp;rsquo;, I get asked this every time and it&amp;rsquo;s getting tedious.&lt;/p>
&lt;div class="image-div" style="max-width: 500px;">
&lt;p>&lt;img src="Screen-Shot-2017-08-10-at-13.10.13-1.png" alt="Firewall request from the simulator">&lt;/p>
&lt;/div>
&lt;p>The issue seems to be in the firewall. When I allow an iOS app it permits the app to access the network, but the iOS simulator does not seem to have permissions. The firewall gets confused - the simulator doesn&amp;rsquo;t have permissions so the network request is blocked pending approval from me, but the firewall doesn&amp;rsquo;t &amp;lsquo;see&amp;rsquo; the simulator, instead it sees the iOS app and gives that permission.&lt;/p>
&lt;p>The problems comes from Xcode, it should set the firewall permissions when you install it but sometimes it fails. There is an easy fix - I&amp;rsquo;ve got a script that opens up the firewall to the simulator. It turns the firewall off (so make sure you are disconnected from the internet or not anywhere dodgy), enables Xcode and the iOS simulator as a firewall exception, then turns it back on.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># temporarily shut firewall off:&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sudo /usr/libexec/ApplicationFirewall/socketfilterfw --setglobalstate off
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># put Xcode as an exception:&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/usr/libexec/ApplicationFirewall/socketfilterfw --add /Applications/Xcode.app/Contents/MacOS/Xcode
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># put iOS Simulator as an exception:&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/usr/libexec/ApplicationFirewall/socketfilterfw --add /Applications/Xcode.app/Contents/Developer/Applications/Simulator.app/Contents/MacOS/Simulator
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># re-enable firewall:&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sudo /usr/libexec/ApplicationFirewall/socketfilterfw --setglobalstate on
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Run this, give it your password as it needs &lt;code>sudo&lt;/code> access and bingo, problem goes away. You may need to run this every time Xcode is updated though&amp;hellip;&lt;/p></description></item><item><title>Game of Phones - Winter is coming</title><link>https://jimbobbennett.dev/blogs/game-of-phones-winter-is-coming/</link><pubDate>Wed, 07 Jun 2017 07:38:09 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/game-of-phones-winter-is-coming/</guid><description>&lt;p>Winter of Xamarin - register now at &lt;a href="http://aka.ms/winterofxamarin">http://aka.ms/winterofxamarin&lt;/a>.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/8-D2o4eVnnY" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div></description></item><item><title>Stay warm with Microsoft &amp; Xamarin!</title><link>https://jimbobbennett.dev/blogs/stay-warm-with-microsoft-xamarin/</link><pubDate>Thu, 01 Jun 2017 08:16:52 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/stay-warm-with-microsoft-xamarin/</guid><description>&lt;p>For those in New Zealand, Microsoft and Xamarin have announced some cool events:&lt;/p>
&lt;p>Brr! It’s getting cold outside. Microsoft has a plan to get you through winter with some awesome Xamarin events and competitions and apparel!&lt;/p>
&lt;p>Are you ready to sharpen your skills in a fun, fast-paced environment? Microsoft is hosting FREE Xamarin training events around New Zealand! Xamarin lets you write code once for a mobile app and deploy it to Android, iOS and Windows in one go. We’ll teach you how to build on the same tool top Fortune 500 companies use, and help you make your next big app!&lt;/p>
&lt;p>To keep you warm, we’ve got limited edition Xamarin Beanies for every event attendee, completed with limited edition Xamarin socks for every competition entry. The top app developers also get Xbox Ones and hard cash to splurge over the winter months!&lt;/p>
&lt;p>Agenda for the Events&lt;/p>
&lt;p>9:00am – 9:30am Registration
9:30am – 10:00am Introduction to Xamarin
10:00am – 11:00am Building Cross Platform Apps
12:00pm – 1:00pm Lunch
1:00pm – 4:30pm Xamarin App Hackathon&lt;/p>
&lt;p>Dates and Locations&lt;/p>
&lt;p>Auckland Event 1 - &lt;a href="http://aka.ms/woxakl1">http://aka.ms/woxakl1&lt;/a>
Friday 16th of June - Beca House Auditorium, 21 Pitt Street,&lt;/p>
&lt;p>Auckland Event 2 - &lt;a href="http://aka.ms/woxakl2">http://aka.ms/woxakl2&lt;/a>
Saturday 17th of June - Beca House Auditorium, 21 Pitt Street,&lt;/p>
&lt;p>Tauranga Event - &lt;a href="http://aka.ms/woxtaudev">http://aka.ms/woxtaudev&lt;/a>
Friday 9th of June Toi-Ohomai, 200 Cameron Road, Tauranga&lt;/p>
&lt;p>Christchurch Event - &lt;a href="http://aka.ms/woxchch1">http://aka.ms/woxchch1&lt;/a>
Saturday 24th of June Ara Polytechnic, Madras Street Campus,&lt;/p></description></item><item><title>Specflow support in Visual Studio for Mac</title><link>https://jimbobbennett.dev/blogs/specflow-support-in-visual-studio-for-mac/</link><pubDate>Thu, 01 Jun 2017 08:10:50 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/specflow-support-in-visual-studio-for-mac/</guid><description>&lt;p>Love Specflow and Visual Studio for Mac? Well you are in luck as there is now a working extension for Visual Studio for Mac to enable full specflow support including generating feature files with syntax highlighting.&lt;/p>
&lt;p>It&amp;rsquo;s all open source and built upon the amazing work by &lt;a href="https://twitter.com/MikeyJones78">Mike Jones&lt;/a>. You can find it on GitHub at &lt;a href="https://github.com/straighteight/SpecFlow-VS-Mac-Integration">https://github.com/straighteight/SpecFlow-VS-Mac-Integration&lt;/a> or in the VS extension gallery:&lt;/p>
&lt;div class="image-div" style="max-width: 700px;">
&lt;p>&lt;img src="DBMFg6UUMAAPjWa.png" alt="Specflow extension in the gallery">&lt;/p>
&lt;/div>
&lt;p>As always a big thank you to &lt;a href="https://twitter.com/mjhutchinson">Mikayla Hutchinson&lt;/a> for her continued help in getting this all working.&lt;/p></description></item><item><title>Opening multiple solutions in Visual Studio for Mac</title><link>https://jimbobbennett.dev/blogs/opening-multiple-solutions-in-visual-studio-for-mac/</link><pubDate>Tue, 23 May 2017 23:28:34 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/opening-multiple-solutions-in-visual-studio-for-mac/</guid><description>&lt;p>One area Macs are very different to Windows PCs is in the way documents are opened. Mac apps manage documents internally instead of being able to tap a start button again and open a second instance of your app to load a new document.&lt;/p>
&lt;p>This means that on Windows Xamarin developers can open multiple instances of Visual Studio at the same time, allowing them to have multiple solutions open. On the Mac this ability has been missing - you click VS again and it just focuses on the same instance that&amp;rsquo;s already running. There have been a number of workarounds for Xamarin Studio and Visual Studio the apps you can run that will launch another instance, but actually - you don&amp;rsquo;t need to!&lt;/p>
&lt;p>Unlike VS on Windows, VS on Mac (and Xamarin Studio for those who haven&amp;rsquo;t updated) can open multiple solutions at the same time in the same window. The option to do so is a bit hidden, but it&amp;rsquo;s there.&lt;/p>
&lt;p>What you do is:&lt;/p>
&lt;ul>
&lt;li>Open your first solution&lt;/li>
&lt;li>Select &amp;lsquo;File-&amp;gt;Open&amp;rsquo;&lt;/li>
&lt;li>Select your solution in the Open dialog (just a single click, don&amp;rsquo;t double click to open it)&lt;/li>
&lt;li>Click the &amp;lsquo;Options&amp;rsquo; button&lt;/li>
&lt;li>Uncheck &amp;lsquo;Close current workspace&amp;rsquo;&lt;/li>
&lt;/ul>
&lt;div class="image-div" style="max-width: 500px;">
&lt;p>&lt;img src="Screen-Shot-2017-05-24-at-11.29.14-AM.png" alt="Uncheck &amp;lsquo;Close current workspace&amp;rsquo;">&lt;/p>
&lt;/div>
&lt;ul>
&lt;li>Now click &amp;lsquo;Open&amp;rsquo;&lt;/li>
&lt;/ul>
&lt;p>Viola! Multiple solutions in the same solution pad.&lt;/p>
&lt;div class="image-div" style="max-width: 300px;">
&lt;p>&lt;img src="Screen-Shot-2017-05-24-at-11.29.46-AM.png" alt="Multiple solutions in the same solution pad">&lt;/p>
&lt;/div>
&lt;p>If the solution is in your recent list you can also open it in the same workspace by holding down the Control key whilst clicking on the solution. Thanks to &lt;a href="https://twitter.com/slluis">Lluis Sanchez Gual&lt;/a> for this one.&lt;/p>
&lt;blockquote class="twitter-tweet" data-lang="en">&lt;p lang="en" dir="ltr">&lt;a href="https://twitter.com/CodeMillMatt">@CodeMillMatt&lt;/a> A little trick: to quickly open a solution without closing the current one, hold Control while clicking on a file in Recent Solutions&lt;/p>&amp;mdash; Lluis Sanchez Gual (@slluis) &lt;a href="https://twitter.com/slluis/status/867662561663234048">May 25, 2017&lt;/a>&lt;/blockquote> &lt;script async src="//platform.twitter.com/widgets.js" charset="utf-8">&lt;/script></description></item><item><title>Upcoming talks</title><link>https://jimbobbennett.dev/blogs/upcoming-talks/</link><pubDate>Wed, 10 May 2017 08:48:31 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/upcoming-talks/</guid><description>&lt;p>I&amp;rsquo;m excited to announce that I&amp;rsquo;ll be talking at a couple of major conferences this year:&lt;/p>
&lt;a href="https://www.monkeyfest.io">
&lt;div class="image-div" style="max-width: 300px;">
&lt;p>&lt;img src="5b1dd6_4ad2b54b49fa4823a277dc7d8c5dedbb-mv2.jpeg" alt="">&lt;/p>
&lt;/div>
&lt;/a>
&lt;p>&lt;a href="https://www.monkeyfest.io">MonkeyFest 2017&lt;/a>&lt;/p>
&lt;a href="http://ndcsydney.com/speaker/jim-bennett/">
&lt;div class="image-div" style="max-width: 300px;">
&lt;p>&lt;img src="I_speaking_NDC_Sydneyx2.png" alt="">&lt;/p>
&lt;/div>
&lt;/a>
&lt;p>&lt;a href="http://ndcsydney.com/speaker/jim-bennett/">NDC Sydney&lt;/a>&lt;/p>
&lt;p>At both of these conferences I&amp;rsquo;ll be talking about adding platform specifics to Xamarin Forms apps. Hope to see you there!&lt;/p></description></item><item><title>Nugetizer 3000</title><link>https://jimbobbennett.dev/blogs/nugetizer-3000/</link><pubDate>Wed, 10 May 2017 07:58:00 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/nugetizer-3000/</guid><description>&lt;p>One cool new feature in Visual Studio for Mac is the ability to create NuGet packages from your projects automatically whenever you compile. This new feature is thanks to a cool project started by Xamarin called the &lt;strong>Nugetizer 3000&lt;/strong> (I do love &lt;a href="https://twitter.com/migueldeicaza">Miguel&lt;/a>&amp;rsquo;s naming conventions).&lt;/p>
&lt;div class="image-div" style="max-width: 400px;">
&lt;img alt="Nugetizer 3000" src="https://raw.githubusercontent.com/NuGet/NuGet.Build.Packaging/master/Nugetizer-3000.png"/>
&lt;/div>
&lt;p>It&amp;rsquo;s really easy to turn this on. From your project open the project properties and head to the &amp;lsquo;NuGet Package -&amp;gt; Build&amp;rsquo; tab. From there tick the &amp;lsquo;Create a NuGet package&amp;rsquo; box.&lt;/p>
&lt;div class="image-div" style="max-width: 600px;">
&lt;p>&lt;img src="NugetBuild.png" alt="Tick the &amp;lsquo;Create nuget package&amp;rsquo; box in the NuGet build tab of the project properties">&lt;/p>
&lt;/div>
&lt;p>Once this is ticked you need to set up the metadata for your package, and this can be done from the metadata tab. You have to fill in everything in the &amp;lsquo;General&amp;rsquo; tab, and you can optionally fill in the &amp;lsquo;Details&amp;rsquo; tab.&lt;/p>
&lt;div class="image-div" style="max-width: 600px;">
&lt;p>&lt;img src="metadata.png" alt="Add all the required NuGet metadata">&lt;/p>
&lt;/div>
&lt;p>Once you click &amp;lsquo;OK&amp;rsquo;, Visual Studio will add a new NuGet package to your project - &lt;code>NuGet.Build.Packaging&lt;/code>. This package doesn&amp;rsquo;t contain any assemblies, it just contains build targets to create the NuGet package.&lt;/p>
&lt;p>Once this package is installed you can compile your project and it will spit out a &lt;code>nupkg&lt;/code> file in the projects output directory. This package has everything all set up for it, including dependencies on all the packages and framework libraries used by your project.&lt;/p>
&lt;p>This makes package creation easy as there is no faffing around with &lt;code>nuspec&lt;/code> files and command lines. You can even control values such as the version by configuring project properties when calling MSBuild from the command line, very useful if you want to tweak the version number at build time.&lt;/p></description></item><item><title>Be quick - 50% off Xamarin In Action for one week</title><link>https://jimbobbennett.dev/blogs/be-quick-50-off-xamarin-in-action-for-one-week/</link><pubDate>Fri, 24 Feb 2017 17:55:54 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/be-quick-50-off-xamarin-in-action-for-one-week/</guid><description>&lt;p>The MEAP of my book, Xamarin In Action, has just been updated to include a new chapter covering building cross-platform view models. This chapter talks about how you can use view models to increase the amount of cross-platform, unit testable code in your Xamarin app by moving UI logic away from the platform specific layers down into your cross-platform code.&lt;/p>
&lt;p>To celebrate you can get 50% off my book for one week only. Head to &lt;a href="http://xam.jbb.io">http://xam.jbb.io&lt;/a> and use the code &lt;em>mlbennett&lt;/em>.&lt;/p>
&lt;p>Not sure if this is the book for you? Well if you are building or plan to build Xamarin apps then yes, this is the book for you. Rather than being a dry reference book that replicates what is in the on-line docs, this instead teaches you how to build and ship production quality Xamarin apps from idea to the store. I teaches MVVM as a way to ramp up the amount of cross-platform code in your app - after all large amounts of code sharing is the killer feature of Xamarin!&lt;/p>
&lt;p>This book is still being written, so if you buy it now you get the first 8 chapters, with new chapters as they are being written, and you can get involved with making the book better by giving feedback and suggesting improvements.&lt;/p>
&lt;p>You can download the first chapter for free from &lt;a href="https://manning-content.s3.amazonaws.com/download/8/a45b766-0a46-417f-8afa-724107f1c415/Bennett_Xamarin_MEAP_V05_ch1.pdf">here&lt;/a>. You can also read an excerpt all about MVVM on &lt;a href="https://dzone.com/articles/mvvm-the-design-pattern-for-xamarin-apps">DZONE&lt;/a>, &lt;a href="https://medium.com/@jimbobbennett/mvvm-the-design-pattern-for-xamarin-apps-9781e60ef587#.ibzk4lehv">Medium&lt;/a> or &lt;a href="https://jimbobbennett.dev/blogs/mvvm-the-design-pattern-for-xamarin-apps/">my own blog&lt;/a> (whichever is your preference).&lt;/p>
&lt;p>The current table of contents is:&lt;/p>
&lt;h6 id="part-1---getting-started-with-native-cross-platform-apps">Part 1 - Getting started with native cross-platform apps&lt;/h6>
&lt;p>1 &lt;a href="https://manning-content.s3.amazonaws.com/download/8/a45b766-0a46-417f-8afa-724107f1c415/Bennett_Xamarin_MEAP_V05_ch1.pdf">Introducing native cross-platform applications with Xamarin&lt;/a>
2 Hello MVVM
3 MVVM – a deeper dive
4 Hello MVVM – a deeper dive
5 What are we (a)waiting for? - An introduction to multithreaded code&lt;/p>
&lt;h6 id="part-2---from-blank-solution-to-an-empty-working-app">Part 2 - From blank solution to an empty, working app&lt;/h6>
&lt;p>6 Designing MVVM cross-platform apps
7 Building cross-platform models
8 Building cross-platform view models
9 Building platform specific views - Android
10 Building platform specific views - iOS
11 Running the app&lt;/p>
&lt;h6 id="part-3---from-a-working-app-to-a-production-ready-app">Part 3 - From a working app to a production ready app&lt;/h6>
&lt;p>12 Testing the app using UITest
13 Instrumentation and monitoring
14 Deploying the app&lt;/p>
&lt;h6 id="appendices">Appendices&lt;/h6>
&lt;p>A1 What are design patterns anyway?
A2 Using someone else&amp;rsquo;s code
A3 UI flows and threads for SquareRt and Countr&lt;/p></description></item><item><title>MvvmCross extension for Visual Studio 2017</title><link>https://jimbobbennett.dev/blogs/mvvmcross-extension-for-vs2017/</link><pubDate>Fri, 20 Jan 2017 21:50:37 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/mvvmcross-extension-for-vs2017/</guid><description>&lt;h6 id="update---its-now-on-the-marketplace">Update - it&amp;rsquo;s now on the marketplace!&lt;/h6>
&lt;p>Link here: &lt;a href="https://marketplace.visualstudio.com/items?itemName=JimBobBennett.MvvmCrossforVisualStudio">https://marketplace.visualstudio.com/items?itemName=JimBobBennett.MvvmCrossforVisualStudio&lt;/a>&lt;/p>
&lt;p>The awesome team at Microsoft have got it all working, so I&amp;rsquo;ve managed to upload the VS2017 version to the marketplace. You can now download it from Extensions and Updates.&lt;/p>
&lt;p>Thanks to everyone on the VS extensions team who helped make it all work!&lt;/p>
&lt;hr>
&lt;p>Visual Studio 2017 is now available as a release candidate, so I thought it was time to update my MvvmCross extension to support it.&lt;/p>
&lt;p>The update was really, really easy - and is well &lt;a href="http://www.visualstudioextensibility.com/2016/11/16/visual-studio-2017-rc-announced-extensions-need-some-changes/">documented by the VS team&lt;/a>. Unfortunately there is a bug in the marketplace, so although the upgraded extension works, I can&amp;rsquo;t upload it. Microsoft are aware of this issue and are working to fix it, so once they done so I&amp;rsquo;ll make the update available through the Extensions and Updates menu item.&lt;/p>
&lt;p>For now though you can download the VSIX from my GitHub page and manually install it.&lt;/p>
&lt;p>&lt;a href="https://github.com/jimbobbennett/MvvmCross-VisualStudioAddIn/releases/tag/v1.2.0">https://github.com/jimbobbennett/MvvmCross-VisualStudioAddIn/releases/tag/v1.2.0&lt;/a>&lt;/p></description></item><item><title>MVVM – the design pattern for Xamarin apps</title><link>https://jimbobbennett.dev/blogs/mvvm-the-design-pattern-for-xamarin-apps/</link><pubDate>Thu, 12 Jan 2017 23:09:30 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/mvvm-the-design-pattern-for-xamarin-apps/</guid><description>&lt;p>This article is an excerpt from &lt;a href="http://xam.jbb.io">Xamarin in Action&lt;/a>&lt;/p>
&lt;hr>
&lt;p>MVVM is the most popular design pattern for cross-platform apps built using Xamarin, and has a history of being a very successful design pattern for building Windows desktop apps using WPF, WinRT apps, and Windows 10 UWP apps – even web frameworks like knockout.js are using it. When Xamarin designed Xamarin.Forms (where the goal was to have as much code sharing as possible), the principles of MVVM were baked into the underlying framework right off the bat.&lt;/p>
&lt;p>For the purposes of this article, let’s consider a simple square root calculator app called “Sqrt” that has a text box you can put a number into, and a button. When you tap the button it calculates the square root of the number in the text box and shows this on a label. An example of this app is shown below.&lt;/p>
&lt;div class="image-div" style="max-width: 300px;">
&lt;p>&lt;img src="ch02_calculator.png" alt="A simple square root calculator app">&lt;/p>
&lt;/div>
&lt;small style="color:black">A simple square root calculator app that calculates the square root of a given number&lt;/small>
&lt;p>The simplest way to write this app is to wire up the button to an event that takes the value directly from the text box, calculates the square root, and writes the value to a label. All this can be done in the code behind file for the UI. Simple, and all in one class. Below is some pseudo-code for the kind of thing you might write.&lt;/p>
&lt;pre tabindex="0">&lt;code>MyAddButton.Click += CalcSquareRoot; ❶
...
private void CalcSquareRoot(object sender, EventArgs args)
{
var number = double.Parse(NumberTextBox.Text); ❷
var sqrt = Math.Sqrt(number);
MyResultLabel.Text = sqrt.ToString(); ❸
}
&lt;/code>&lt;/pre>&lt;p>❶ We are listening for the Click event of the button&lt;/p>
&lt;p>❷ The number comes from reading the value from the Text property of the text box&lt;/p>
&lt;p>❸ Once we have the square root the Text property of the label is set directly&lt;/p>
&lt;p>Whilst this seems simple, it has a number of flaws.&lt;/p>
&lt;p>First, this is not easily testable. Yes, you can launch the app, type in a number, and tap the button, but this takes a long time. We can only test this app by updating the value in the text box and tapping the button – it would be nice if the calculation code was self-contained so we could test it in isolation. It would be better if we could write unit tests so we can programmatically test our code, covering multiple cases – including edge cases such as missing inputs, or large or negative numbers. This way we can run a set of automated tests quickly, which can be repeated every time we change our code.&lt;/p>
&lt;p>Second, this is not cross-platform. One of the reasons for building our app using Xamarin is so that we can have parts of our app written in shared code that works on both iOS and Android. If our calculation is wired directly to the view, we can’t do this.&lt;/p>
&lt;div class="image-div" style="max-width: 500px;">
&lt;p>&lt;img src="ch01_xamarin_app.png" alt="The layers in a Xamarin App">&lt;/p>
&lt;/div>
&lt;small style="color:black">Xamarin apps are written in C#, so you can share any common business logic whilst having a platform-specific UI&lt;/small>
&lt;p>As you can see, a Xamarin app has three layers:&lt;/p>
&lt;ul>
&lt;li>The application layer is the small part of the code that makes your code runnable on each platform; it is separate and has different platform-specific implementations for iOS and Android.&lt;/li>
&lt;li>The UI layer is also separate, and has different platform-specific implementations for iOS and Android.&lt;/li>
&lt;li>The business logic layer is shared between the two platforms.&lt;/li>
&lt;/ul>
&lt;p>In the UI layer there are really two layers – the actual UI widgets and some logic around these widgets. For example, we could put some logic around our answer label to make it only be visible once we have calculated a square root. This expands our three layers to four. Let’s explore ways to maximize code re-use between layers.&lt;/p>
&lt;div class="image-div" style="max-width: 500px;">
&lt;p>&lt;img src="ch02_mvvm_app_layers-1.png" alt="">&lt;/p>
&lt;/div>
&lt;small style="color:black">To maximize code re-use, it would be good to have UI logic in shared code&lt;/small>
&lt;p>To increase the amount of code sharing, it would be great to be able to move the UI logic into shared code as well. The image above shows how the layers would look if we could do this. If we did this, the label in our example would be in the UI layer, and the logic to decide whether it should be visible or hidden would be in the cross-platform UI logic layer. This is a great way to do things – we’re maximizing our code re-use by abstracting our UI logic into cross-platform code.&lt;/p>
&lt;div class="image-div" style="max-width: 600px;">
&lt;p>&lt;img src="ch02_mvvm.png" alt="">&lt;/p>
&lt;/div>
&lt;small style="black">MVVM has a model, a view model, a view, and a binding layer that keeps the view and view model in sync and connects events on the view to the view model&lt;/small>
&lt;p>MVVM helps split the UI from its logic. This pattern’s name is based off the three layers that you use in your app. Let’s look at these layers in the context of our calculator example:&lt;/p>
&lt;ul>
&lt;li>Model - your data and business logic
The model contains the number, the logic to calculate the square root, and the result.&lt;/li>
&lt;li>View - the actual UI, buttons, text controls and all other widgets
This holds the UI widgets – the text box, button and label. It is a passive view so it doesn’t have any code to get or set the values, or handle the events such as the button click.&lt;/li>
&lt;li>ViewModel - the UI data and logic&lt;/li>
&lt;/ul>
&lt;p>For our calculator app this would have properties that represent the numbers on the model – the input values and the result. It would also have a Command property that wraps the square root calculation logic on the model into an object. The view model would know about the model but have no knowledge of the view.&lt;/p>
&lt;p>In addition to these three layers it has a binder, a binding layer that you can think of as glue that connects the view model to the view. This removes the need to write boilerplate code to synchronize the UI – the binder can watch for changes in the view model and update the view to match, or update the view model to match changes made by the user in the UI. This binder is loosely-coupled rather than tightly-coupled, and the connection is often done based on wiring up properties in the view and view model based on their names (so in the case of a binding between a property called &amp;ldquo;Text&amp;rdquo; and a property called &amp;ldquo;Name&amp;rdquo;, at run time, the binder will use reflection to map these string values to the underlying properties).&lt;/p>
&lt;table style='border:0px;background:#F0F0F0'>
&lt;tr>
&lt;td style="width:48px">
&lt;img src="Group.png"/>
&lt;/td>
&lt;td>
&lt;h5>Reflecting on reflection&lt;/h5>
&lt;p style="text-align:justify;color:#686868;">If you’ve never heard of reflection before, it is a part of the C# API that allows you to query details about a class – you can discover properties, fields, methods, the whole shooting match. Once you’ve found out details you can also execute code – for example, you can find a property based on its name then get the value of that property from a particular instance of that class.
Reflection is also found in other languages, such as Java – C# reflection is basically the same as Java reflection.
This is great for binding – if you bind a property called "Name" the binding code can use reflection to find a property on your view model class with that same name, then it can get the value on your view model instance.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/table>
&lt;p>For our calculator app, the binding layer would wire up the text box, button, and label on our UI to the equivalent properties and a command on the view model.&lt;/p>
&lt;p>There is a bit of magic to make this binder work, and it is usually implemented in an MVVM framework – a third party library that gives a set of base classes that provide the implementation of this pattern for you.&lt;/p>
&lt;table style='border:0px;background:#F0F0F0'>
&lt;tr>
&lt;td style="width:48px">
&lt;img src="Group.png"/>
&lt;/td>
&lt;td>
&lt;h5>MVVM frameworks&lt;/h5>
&lt;p style="text-align:justify;color:#686868;">There are multiple MVVM frameworks around that work with Xamarin native apps such as &lt;a href="http://mvvmcross.com">MvvmCross&lt;/a>, &lt;a href="http://mvvmlight.net">MvvmLight&lt;/a>, or &lt;a href="http://caliburnmicro.com">Caliburn.Micro&lt;/a>. Although each one has differences, they all follow the same basic principles and do roughly the same things.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/table>
&lt;div class="image-div" style="max-width: 600px;">
&lt;p>&lt;img src="ch02_binding.png" alt="">&lt;/p>
&lt;/div>
&lt;small style="color:black">Binding keeps the value in the view in sync with the value in the view model&lt;/small>
&lt;p>For example, as shown above, we could have a text box on our calculator app UI that is bound to a Number property. This means at run time it will try to find a public property called “Number” on the view model that it is bound to using reflection, and will show the string contained in that property in the text box. If the user changes the value inside the text box, it will update the value of the Number property to match what the user has typed in. Conversely, if the value of the Number property on the view model changes, the binding will update the text box to match.&lt;/p>
&lt;p>The binder doesn’t care about the underlying class type of the view model that you are using, just that it has a public property called “Number” that it can extract the value from. In some of the MVVM frameworks it doesn’t even care if the property is there or not – if it can’t find one, it just treats it as an empty value. This loose coupling is what makes MVVM especially powerful – it allows view models to be completely agnostic to the view, meaning we can write unit tests against the view model that simulate the UI, without worrying about UI code getting in the way. It also supports code re-use, so a view could be glued to any view model that has properties with the names it is expecting.&lt;/p>
&lt;div class="image-div" style="max-width: 500px;">
&lt;p>&lt;img src="ch02_mvvm_app_layers_with_binding.png" alt="">&lt;/p>
&lt;/div>
&lt;small style="color:black">The different layers of MVVM, and how they fit in with the different layers of a Xamarin app&lt;/small>
&lt;p>The image above expands on the previous figures by showing how these layers map to the three layers of MVVM.&lt;/p>
&lt;ul>
&lt;li>The App layer is one that doesn’t really come under the pure MVVM design pattern, but the different MVVM frameworks do provide some application layer features. For this reason, we can have some cross-platform code in our app layer that can control app logic, such as which view is shown first and how the different classes in the app are wired together – for example, code defining which view model is used for each view.&lt;/li>
&lt;li>The UI layer is our view layer. This is platform-specific code.&lt;/li>
&lt;li>The binding between the UI layer and the UI logic layer is the binder, the glue that connects the UI layer to its logic layer. This is usually a mix of cross-platform and platform-specific code provided by a third party framework.&lt;/li>
&lt;li>The UI logic layer is our view model layer, and this provides logic for the UI and other device interactions in a cross-platform fashion. Part of this logic is value conversion – converting from data in your domain objects to data on the UI. For example, you could model a user in your domain with a first name and last name, but want to show the full name on the UI. The view model will provide this value conversion by concatenating the names and giving a single string value that will be shown by the UI.&lt;/li>
&lt;li>The business logic layer is the model layer. This contains data, domain objects, logic, and connectivity to external resources such as databases or web services. Again, this is cross-platform.&lt;/li>
&lt;/ul>
&lt;table style='border:0px;background:#F0F0F0'>
&lt;tr>
&lt;td style="width:48px">
&lt;img src="Group.png"/>
&lt;/td>
&lt;td>
&lt;h5>A quick history lesson&lt;/h5>
&lt;p style="text-align:justify;color:#686868;">MVVM has been around since 2005 and was developed by two architects from Microsoft, Ken Cooper and Ted Peters. It was primarily created for use with the new UI technology stack coming out of Microsoft, called WPF. It leverages the data binding that was a key feature of WPF. In WPF, you write your UI using XAML, a UI based markup language; in this XAML, you can bind properties of a UI widget to properties defined in the data context of the view – essentially the view model. This allowed UI/UX experts to design the UI using more designer-based tools, and to simply wire up the widgets (based off of names) to code written independently by developers.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/table>
&lt;hr>
&lt;p>If you want to learn more about making cross-platform mobile apps using Xamarin, download the free first chapter of &lt;a href="http://xam.jbb.io">Xamarin in Action&lt;/a> and see &lt;a href="http://www.slideshare.net/ManningBooks/xamarin-in-action">this Slideshare presentation&lt;/a> for a discount code.&lt;/p></description></item><item><title>MvvmCross Extension for Visual Studio for Mac</title><link>https://jimbobbennett.dev/blogs/mvvmcross-extension-for-visual-studio-for-mac/</link><pubDate>Tue, 10 Jan 2017 08:55:01 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/mvvmcross-extension-for-visual-studio-for-mac/</guid><description>&lt;p>I&amp;rsquo;ve been working to update the MvvmCross Xamarin Studio add-in to work with Visual Studio for Mac. The add-in has been updated thanks to some help from &lt;a href="https://twitter.com/matthewrdev">Matthew Robbins&lt;/a>, the author of the awesome &lt;a href="http://www.mfractor.com">MFractor add-in&lt;/a>, which if you don&amp;rsquo;t have you &lt;strong>MUST&lt;/strong> get, it&amp;rsquo;s awesome.&lt;/p>
&lt;p>This add-in is now available from the VS for Mac extension manager!&lt;/p>
&lt;div class="image-div" style="max-width: 800px;">
&lt;p>&lt;img src="Screen-Shot-2017-01-11-at-21.29.17.png" alt="Installing the MvvmCross add-in in VS for Mac">&lt;/p>
&lt;/div></description></item><item><title>Animating Xamarin Forms progress bars</title><link>https://jimbobbennett.dev/blogs/animating-xamarin-forms-progress-bars/</link><pubDate>Thu, 05 Jan 2017 08:43:11 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/animating-xamarin-forms-progress-bars/</guid><description>&lt;p>Don&amp;rsquo;t you just hate boring UIs? With no animations to bring them to life?&lt;/p>
&lt;p>Me too! Especially progress bars - they increment or decrement instantly giving a dull UI.&lt;/p>
&lt;div class="image-div" style="max-width: 300px;">
&lt;p>&lt;img src="Progress-1.gif" alt="Boring unanimated progress bar">&lt;/p>
&lt;/div>
&lt;p>As you can see from the image above, as the progress bar changes value, the UI updates instantly and it looks a bit dull. What would be nicer is if the progress bar smoothly animated its progress.&lt;/p>
&lt;p>Out of the box Xamarin.Forms provides a method to do this - an extension method called &lt;code>ProgressTo&lt;/code>. You can call this code from inside your UI to smoothly animate the progress value to whatever value you like. This is great, but it&amp;rsquo;s not ideal as it relies on the animation happening in the view, so the view needs to know what the value is to animate to. I&amp;rsquo;m a big fan of MVVM (true - I even &lt;a href="http://xam.jbb.io">written a book on how to use MVVM to build Xamarin apps&lt;/a>). The progress value should be in a view model, but then we&amp;rsquo;d have to wire up a number of UI components to watch view models for changes then start the animation. Ideally it would be better to have a bindable property that we could use to trigger this animation.&lt;/p>
&lt;p>We could get this bindable property by creating our own control derived from ProgressBar that has a property for the animation, but that involves a custom control. What would be even better is if we could use the existing progress bar and somehow add a property to it that we can bind to and when the value changes the progress animates to the new value. Happily for us, Xamarin Forms supports this in the form of &lt;a href="https://docs.microsoft.com/en-gb/xamarin/xamarin-forms/xaml/attached-properties/?WT.mc_id=formsanimations-blog-jabenn">Attached Properties&lt;/a>.&lt;/p>
&lt;p>Attached properties are bindable properties, just like the ones you would create in your own controls, except that they can be &amp;lsquo;attached&amp;rsquo; to any other control. You define them on one class, and attach them to another. Using these we can create a property on a utility class that is attached to &lt;code>ProgressBar&lt;/code>. These properties don&amp;rsquo;t directly change anything on the class they are attached to, instead you can hook into the property change mechanism to do whatever you need to do.&lt;/p>
&lt;p>For example, if we wanted an animated progress bar we could create a new attached property called &lt;code>AnimatedProgress&lt;/code> attached to &lt;code>ProgressBar&lt;/code>, and every time the value changes we could tell the progress bar to change it&amp;rsquo;s progress value via the &lt;code>ProgressTo&lt;/code> extension method:&lt;/p>
&lt;pre tabindex="0">&lt;code>public static class AttachedProperties
{
public static BindableProperty AnimatedProgressProperty =
BindableProperty.CreateAttached(&amp;#34;AnimatedProgress&amp;#34;,
typeof(double),
typeof(ProgressBar),
0.0d,
BindingMode.OneWay,
propertyChanged: (b, o, n) =&amp;gt;
ProgressBarProgressChanged((ProgressBar)b, (double)n));
private static void ProgressBarProgressChanged(ProgressBar progressBar, double progress)
{
ViewExtensions.CancelAnimations(progressBar);
progressBar.ProgressTo((double)progress, 800, Easing.SinOut);
}
}
&lt;/code>&lt;/pre>&lt;p>In this code we are defining a static helper class with the static attached property. This property is called &lt;code>&amp;quot;AnimatedProgress&amp;quot;&lt;/code>, has a &lt;code>double&lt;/code> value, is attached to &lt;code>ProgressBar&lt;/code>, has a default value of &lt;code>0.0&lt;/code>. It defaults to bind one way, and this is fine as users cannot interact with a progress bar to change this value. The cool part is the &lt;code>propertyChanged&lt;/code> action, this calls a method that animates the progress bar to the new value every time it changes.&lt;/p>
&lt;p>Once we&amp;rsquo;ve defined this property we can attach it to any progress bar we want, using XAML or code behind. The XAML way to set it is:&lt;/p>
&lt;pre tabindex="0">&lt;code>?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;utf-8&amp;#34;?&amp;gt;
&amp;lt;ContentPage xmlns=&amp;#34;http://xamarin.com/schemas/2014/forms&amp;#34;
xmlns:x=&amp;#34;http://schemas.microsoft.com/winfx/2009/xaml&amp;#34;
xmlns:local=&amp;#34;clr-namespace:AnimatedProgress&amp;#34;
x:Class=&amp;#34;AnimatedProgress.AnimatedProgressPage&amp;#34;&amp;gt;
&amp;lt;StackLayout Padding=&amp;#34;20,100&amp;#34; Spacing=&amp;#34;40&amp;#34;&amp;gt;
&amp;lt;ProgressBar local:AttachedProperties.AnimatedProgress=&amp;#34;{Binding Progress}&amp;#34;/&amp;gt;
&amp;lt;Entry Text=&amp;#34;{Binding ProgressPercent}&amp;#34;/&amp;gt;
&amp;lt;/StackLayout&amp;gt;
&amp;lt;/ContentPage&amp;gt;
&lt;/code>&lt;/pre>&lt;p>In this XAML we define the &lt;code>local&lt;/code> XML namespace pointing to our local C# namespace, then bind the property using &lt;code>local:AttachedProperties.AnimatedProgress=&amp;quot;{Binding Progress}&amp;quot;&lt;/code>. This code assumes you have a view model for the page with a property called &lt;code>Progress&lt;/code>.&lt;/p>
&lt;p>You can also set this in code:&lt;/p>
&lt;pre tabindex="0">&lt;code>MyProgressBar.SetBinding(AttachedProperties.AnimatedProgressProperty,
&amp;#34;Progress&amp;#34;);
&lt;/code>&lt;/pre>&lt;p>Once this is wired up we get a lovely animation when we change our progress!&lt;/p>
&lt;p>&lt;img src="AnimatedProgress-1.gif" alt="Nice, shiny animated progress changing">&lt;/p>
&lt;p>You can find the code for this post on my &lt;a href="https://github.com/jimbobbennett/AnimatedProgress">GitHub Repo&lt;/a>.&lt;/p></description></item><item><title>Missing Xamarin Studio add-ins</title><link>https://jimbobbennett.dev/blogs/missing-xamarin-studio-add-ins/</link><pubDate>Mon, 28 Nov 2016 23:42:58 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/missing-xamarin-studio-add-ins/</guid><description>&lt;p>In the latest Stable Xamarin Studio (6.1.2) there is a problem with add-ins - the add-in gallery is empty - the add-in endpoint for 6.1.2 is not returning any add-ins.&lt;/p>
&lt;p>&lt;img src="Screen-Shot-2016-11-29-at-12.33.02-PM.png" alt="Missing add-ins">&lt;/p>
&lt;p>This means if you are planning on using my &lt;a href="https://jimbobbennett.dev/blogs/mvvmcross-add-ins-for-visual-studio-and-xamarin-studio/">Xamarin Studio MvvmCross add-in&lt;/a> then you won&amp;rsquo;t be able to find it.&lt;/p>
&lt;p>Luckily there are a number of workarounds:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Use the Alpha channel - on 6.2 all the add-ins reappear.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Add the add-in repository from the previous version by opening the &amp;lsquo;Add-in manager&amp;rsquo;, going to the &amp;lsquo;Gallery&amp;rsquo; tab, selecting &amp;lsquo;Manage Repositories&amp;rsquo; from the &amp;lsquo;Repository&amp;rsquo; drop-down, tapping &amp;lsquo;Add&amp;rsquo; and entering this url - &lt;a href="http://addins.monodevelop.com/Stable/Mac/6.1.2/main.mrep">http://addins.monodevelop.com/Stable/Mac/6.1.2/main.mrep&lt;/a>
&lt;img src="Screen-Shot-2016-11-29-at-12.37.15-PM.png" alt="">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Install the add-in manually by downloading from &lt;a href="http://addins.monodevelop.com/Stable/Mac/6.0/MVVMCross.XSAddIn.MVVMCross.XSAddIn-1.1.8.mpack">here&lt;/a> and installing it using the &amp;lsquo;Install from file&amp;hellip;&amp;rsquo; option in the &amp;lsquo;Add-in manager&amp;rsquo;.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>This issue has been raised with Xamarin, so hopefully should be fixed soon.&lt;/p></description></item><item><title>Xamarin Dev Days!</title><link>https://jimbobbennett.dev/blogs/xamarin-dev-days/</link><pubDate>Sun, 27 Nov 2016 08:43:54 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/xamarin-dev-days/</guid><description>&lt;p>Our Xamarin Dev Days has been immortalized in a YouTube video! Thanks to &lt;a href="http://peaceofdreams.com">Peace of Dreams&lt;/a> for filming on the day.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/7GrO3UTB-wU" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div></description></item><item><title>Effects in Xamarin.Forms</title><link>https://jimbobbennett.dev/blogs/effects-in-xamarin-forms/</link><pubDate>Sat, 26 Nov 2016 00:19:40 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/effects-in-xamarin-forms/</guid><description>&lt;p>Xamarin.Forms is pretty awesome, it provides an abstraction over the UI layer of iOS, Android and UWP apps allowing you to define you UI once either in code (C# or F#), or using XAML - an XML markup language. Write your UI once and it works natively on all devices rendering your UI using the native controls for each platform.&lt;/p>
&lt;p>The upside is write-once UIs, the downside is to make this work you only have access to a subset of the APIs available to each UI control so that the Forms code you write will work on all platforms.&lt;/p>
&lt;p>Right from the first version of Forms there was a way around this - custom rendered. Forms uses a renderer for each UI control - a native class that takes the Forms element and renders it using a native control. For example if you have a forms &lt;code>Button&lt;/code>, the iOS renderer will put a &lt;code>UIKit.UIButton&lt;/code> on the screen, the Android renderer will use an &lt;code>Android.Widget.Button&lt;/code>. If you wanted to change the way the controls were rendered you could subclass the renderer and add any feature you wanted.&lt;/p>
&lt;p>This is good, but is a bit heavyweight if all you want to do is a single property change, and falls down if you want to apply this same property change to multiple elements (you end up writing multiple renderers, one for each element).&lt;/p>
&lt;p>Luckily Xamarin Forms has introduced a new technique - &lt;a href="https://developer.xamarin.com/guides/xamarin-forms/effects/introduction/">effects&lt;/a>. This are classes that you can attach to any Xamarin Forms view, and they can manipulate the Forms element or underlying control in any way you want.&lt;/p>
&lt;p>To create an effect you have to write a number of classes - a cross-platform &lt;code>RoutingEffect&lt;/code> class, and a &lt;code>PlatformEffect&lt;/code> for each platform you want to support.&lt;/p>
&lt;p>As an example lets create an effect to capitalize the keyboard for an &lt;code>Entry&lt;/code> control.&lt;/p>
&lt;p>First we create the cross-platform &lt;code>RoutingEffect&lt;/code> in our PCL:&lt;/p>
&lt;pre tabindex="0">&lt;code>namespace Organon.XForms.Effects
{
public class CapitalizeKeyboardEffect : RoutingEffect
{
public CapitalizeKeyboardEffect() :
base(&amp;#34;Organon.Effects.CapitalizeKeyboardEffect&amp;#34;)
{
}
}
}
&lt;/code>&lt;/pre>&lt;p>This class derives from &lt;code>RoutingEffect&lt;/code>, is named using &lt;something>Effect, and passes a &lt;code>string&lt;/code> to the base constructor. This string is used to route the effect to the relevant platform specific implementation.&lt;/p>
&lt;p>To write the iOS implementation we need to derive from &lt;code>PlatformEffect&lt;/code>:&lt;/p>
&lt;pre tabindex="0">&lt;code>[assembly: ResolutionGroupName(&amp;#34;Organon.Effects&amp;#34;)]
[assembly: ExportEffect(typeof(CapitalizeKeyboardEffect), nameof(CapitalizeKeyboardEffect))]
namespace Organon.XForms.Effects.iOS.Effects
{
[Preserve(AllMembers = true)]
public class CapitalizeKeyboardEffect : PlatformEffect
{
protected override void OnAttached()
{
var editText = Control as UITextField;
if (editText != null)
editText.AutocapitalizationType = UITextAutocapitalizationType.AllCharacters;
}
protected override void OnDetached()
{
}
}
}
&lt;/code>&lt;/pre>&lt;p>This class has 2 methods we need to implement - &lt;code>OnAttached&lt;/code> which is called when the effect is attached to a Forms view, and &lt;code>OnDetached&lt;/code> when the effect is detached. You update the native control by accessing the &lt;code>Control&lt;/code> property (this is a &lt;code>UIView&lt;/code> on iOS and &lt;code>View&lt;/code> on Android) and setting it up as needed in &lt;code>OnAttached&lt;/code>, then revert your changes in &lt;code>OnDetached&lt;/code>. You can also access the Forms element if needed via the &lt;code>Element&lt;/code> property. In this example we&amp;rsquo;re checking that the &lt;code>Control&lt;/code> is a &lt;code>UITextField&lt;/code>, and if set setting the auto caps to capitalize everything. We could then write something similar in Android.&lt;/p>
&lt;p>To use this effect you add it to the &lt;code>Effects&lt;/code> collection on your Forms control:&lt;/p>
&lt;pre tabindex="0">&lt;code>&amp;lt;Entry Placeholder=&amp;#34;start typing...&amp;#34; VerticalOptions=&amp;#34;Start&amp;#34;&amp;gt;
&amp;lt;Entry.Effects&amp;gt;
&amp;lt;effects:CapitalizeKeyboardEffect /&amp;gt;
&amp;lt;/Entry.Effects&amp;gt;
&amp;lt;/Entry&amp;gt;
&lt;/code>&lt;/pre>&lt;p>You can see a couple of effects including this one here:
&lt;img src="ClearEntryAndAllCaps_thumb.gif" alt="Clear entry and capitalize keyboard effects">&lt;/p>
&lt;p>I&amp;rsquo;ve been working with a few awesome people on creating an open source library of effects. It&amp;rsquo;s currently on &lt;a href="https://github.com/OrganonKit/Organon">GitHub&lt;/a> under the name &amp;lsquo;OrganonKit&amp;rsquo;, but is about to be renamed - watch this space for more details plus info on when it will be available as a nuget package.&lt;/p></description></item><item><title>Xamarin Dev Days Auckland - 19th November 2016</title><link>https://jimbobbennett.dev/blogs/xamarin-dev-days-auckland-19th-november-2016/</link><pubDate>Fri, 04 Nov 2016 07:16:27 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/xamarin-dev-days-auckland-19th-november-2016/</guid><description>&lt;p>There&amp;rsquo;s only 1 week to go until the first Xamarin Dev Days in Auckland, hosted by the &lt;a href="http://www.meetup.com/Auckland-Xamarin-Meetup/">Auckland Xamarin Meetup&lt;/a> on Saturday 19th November. We’ve got an awesome program lined up for this free day and evening, so we thought now would be a good time to share our plans. We have internationally recognized speakers, drinks in the evening and some seriously good prizes to give away!&lt;/p>
&lt;h6 id="location">Location:&lt;/h6>
&lt;p>Auckland University of Technology, Gov Fitzroy Pl, Auckland, 1010, New Zealand&lt;/p>
&lt;iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d3192.5271113704994!2d174.76381131529138!3d-36.853799979937556!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x0%3A0x0!2zMzbCsDUxJzEzLjciUyAxNzTCsDQ1JzU3LjYiRQ!5e0!3m2!1sen!2sus!4v1478215657098" width="300" height="225" frameborder="0" style="border:0" allowfullscreen>&lt;/iframe>
&lt;p>A big thank you to AUT for sponsoring the room.&lt;/p>
&lt;h6 id="guest-speakers">Guest speakers&lt;/h6>
&lt;p>We&amp;rsquo;ve privileged to have some amazing local and international speakers at this event. As well as listening to the three of us and a local Microsoft technical evangelist you get to hear from:&lt;/p>
&lt;p>&lt;a href="http://www.michaelridland.com">&lt;b>Michael Ridland&lt;/b>&lt;/a>&lt;/p>
&lt;table style="border:0px;">
&lt;tr style="background-color:rgba(0, 0, 0, 0);">
&lt;td>
&lt;a href="http://www.michaelridland.com">
&lt;div class="image-div" style="width: 200px;">
![](AVATAR-small-1.jpg)
&lt;/div>
&lt;/a>
&lt;/td>
&lt;td style="vertical-align:top">
&lt;p>
Michael Ridland, Xamarin MVP, Community Blogger and the founder of XAM Consulting. A Xamarin fan since the monotouch days and a even bigger Xamarin.Forms fan since it's release. Michael has been leading Xamarin projects years and delivered enterprise apps of the highest quality in the market. Michael (and his team) are the creators of a few Xamarin.Forms components including the FreshMvvm Framework, SlideOverKit and FreshEssentials. You can find him over at michaelridland.com and twitter.com/rid00z.
&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr style="background-color:rgba(0, 0, 0, 0);">
&lt;td>
&lt;div class="image-div" style="width: 200px;">
&lt;a href="http://www.xam-consulting.com">
![](xamconsulting-small-1.png)
&lt;/a>
&lt;/div>
&lt;/td>
&lt;td style="vertical-align:top">
&lt;/td>
&lt;/tr>
&lt;/table>
&lt;p>&lt;a href="https://twitter.com/matthewrdev">&lt;b>Matthew Robbins&lt;/b>&lt;/a>&lt;/p>
&lt;table style="border:0px;">
&lt;tr style="background-color:rgba(0, 0, 0, 0);">
&lt;td>
&lt;div class="image-div" style="width: 200px;">
&lt;a href="https://twitter.com/matthewrdev">
![](YWJ3tFCI_400x400-1.jpg)
&lt;/a>
&lt;/div>
&lt;/td>
&lt;td style="vertical-align:top">
&lt;p>
Matthew is the creator of &lt;a href="http://www.mfractor.com">MFractor&lt;/a> - the essential productivity tool for Xamarin.Forms. He's currently a Xamarin developer at JobAdder.
&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr style="background-color:rgba(0, 0, 0, 0);">
&lt;td>
&lt;div class="image-div" style="width: 200px;">
&lt;a href="http://www.mfractor.com">
![](logo-horizontal-1-1.png)
&lt;/a>
&lt;/div>
&lt;/td>
&lt;td style="vertical-align:top">
&lt;/td>
&lt;/tr>
&lt;/table>
&lt;p>&lt;a href="http://www.codingwithsam.com">&lt;b>Sam Williams&lt;/b>&lt;/a>&lt;/p>
&lt;table style="border:0px;">
&lt;tr style="background-color:rgba(0, 0, 0, 0);">
&lt;td>
&lt;div class="image-div" style="width: 200px;">
&lt;a href="http://www.codingwithsam.com">
![](hI0WZ08A_400x400-1.jpg)
&lt;/a>
&lt;/div>
&lt;/td>
&lt;td style="vertical-align:top">
&lt;p>
Sam is a passionate software developer who's obsessed with clean code and F#. In his spare time, you will find him on his VR watching videos or coding some more.
&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/table>
&lt;h6 id="program-for-the-day">Program for the day:&lt;/h6>
&lt;table style="border:0px;">
&lt;tr style="background-color:rgba(0, 0, 0, 0);">&lt;td style="text-align:right">9:00&lt;/td>&lt;td>Registration and introductions&lt;/td>&lt;/tr>
&lt;tr style="background-color:rgba(0, 0, 0, 0);">&lt;td style="text-align:right">9:20&lt;/td>&lt;td>Intro to Xamarin&lt;/td>&lt;/tr>
&lt;tr style="background-color:rgba(0, 0, 0, 0);">&lt;td style="text-align:right">10:00&lt;/td>&lt;td>Xamarin Forms&lt;/td>&lt;/tr>
&lt;tr style="background-color:rgba(0, 0, 0, 0);">&lt;td style="text-align:right">10:40&lt;/td>&lt;td>Break&lt;/td>&lt;/tr>
&lt;tr style="background-color:rgba(0, 0, 0, 0);">&lt;td style="text-align:right">10:50&lt;/td>&lt;td>Xamarin Forms performance, power controls and layout systems!&lt;/td>&lt;/tr>
&lt;tr style="background-color:rgba(0, 0, 0, 0);">&lt;td style="text-align:right">11:20&lt;/td>&lt;td>Xamarin + Azure&lt;/td>&lt;/tr>
&lt;tr style="background-color:rgba(0, 0, 0, 0);">&lt;td style="text-align:right">12:00&lt;/td>&lt;td>Lunch&lt;/td>&lt;/tr>
&lt;tr style="background-color:rgba(0, 0, 0, 0);">&lt;td style="text-align:right">1:00&lt;/td>&lt;td>Building Xamarin apps with F#&lt;/td>&lt;/tr>
&lt;tr style="background-color:rgba(0, 0, 0, 0);">&lt;td style="text-align:right">1:30&lt;/td>&lt;td>Hands on labs/hack time&lt;/td>&lt;/tr>
&lt;tr style="background-color:rgba(0, 0, 0, 0);">&lt;td style="text-align:right">3:45&lt;/td>&lt;td>Prize giving&lt;/td>&lt;/tr>
&lt;tr style="background-color:rgba(0, 0, 0, 0);">&lt;td style="text-align:right">5:00&lt;/td>&lt;td>Drinks/snacks at &lt;a href="http://www.thebluestoneroom.co.nz/home.aspx">The bluestone room&lt;/a>&lt;/td>&lt;/tr>
&lt;/table>
&lt;h6 id="refreshments">Refreshments&lt;/h6>
&lt;p>A big shout out to Datacom for sponsoring the refreshments during the day to keep everyone fueled up. There should be something for everyone but if you have any special dietary needs please let us know as soon as possible.&lt;/p>
&lt;h6 id="hands-on-labshackprizes">Hands on labs/hack/Prizes!&lt;/h6>
&lt;p>The afternoon session is a chance for you to do one of two things. If you are new to Xamarin we have a hands on lab to work through covering Xamarin Forms and Azure. If you have some experience and want to hack on your own thing instead then this will be a good time to do it - you&amp;rsquo;ll be surrounded by other experts to help with any queries you may have.&lt;/p>
&lt;p>In addition EROAD have kindly donated an iPad and a Samsung tablet (luckily not one that explodes) as prizes for the best hack. There&amp;rsquo;s so many cool features in iOS, Android and UWP, as well as some great toys to play with in Azure so if you can think of something awesome that&amp;rsquo;s related to transport or health and safety (maybe using Azure cognitive services to see if a driver is angry so shouldn&amp;rsquo;t drive) you could win big!&lt;/p>
&lt;p>There will also be a copy of Jim&amp;rsquo;s book &lt;a href="http://xam.jbb.io">Xamarin In Action&lt;/a> to be given away to one lucky attendee.&lt;/p>
&lt;h6 id="drinks">Drinks!&lt;/h6>
&lt;p>Who doesn&amp;rsquo;t love time to socialize with Xamarin developers? EROAD are sponsoring drinks and snacks at &lt;a href="http://www.thebluestoneroom.co.nz/home.aspx">The bluestone room&lt;/a>. We&amp;rsquo;ll be heading there once the day is done so come along for a free drink or two and a chance to talk Xamarin. EROAD is committed to health and safety so if you&amp;rsquo;re drinking with us, don&amp;rsquo;t drive home!&lt;/p>
&lt;h6 id="photos">Photos&lt;/h6>
&lt;p>&lt;a href="http://peaceofdreams.com">Peace of dreams&lt;/a> will be on site to photograph the goings on, a big thanks to them and to Microsoft for sponsoring.&lt;/p>
&lt;h6 id="what-should-you-bring">What should you bring?&lt;/h6>
&lt;p>Bring a laptop with Xamarin installed! There will be WiFi on the day but we can&amp;rsquo;t guarantee how fast it would be to download and install Xamarin, Android SDK&amp;rsquo;s etc, so please set everything up before you arrive. We can help if you have any problems but the more prepared you are the better. If you have a Windows laptop and want to build iOS apps then you can sign up with &lt;a href="https://www.macincloud.com/checkout/managed.html">MacInCloud&lt;/a> and take advantage of their 24 hour US$0.99 offer.&lt;/p>
&lt;br>
We look forward to seeing you on the 19th. Our spaces are limited so if you can no longer attend please let us know asap or cancel your registration as we have a lot of interest. If you have any questions about the event please reach out to one of us!
&lt;br>
&lt;p>Mohit Singh Baweja - &lt;a href="https://twitter.com/mohitbaweja">@mohitbaweja&lt;/a>
Jim Bennett - &lt;a href="https://twitter.com/jimbobbennett">@jimbobbennett&lt;/a>
Joshua Fenemore - &lt;a href="https://twitter.com/im_not_josh">@im_not_josh&lt;/a>&lt;/p>
&lt;div class="image-div" style="width: 400px;">
![](Xamarin-logo-copy.png)
&lt;/div></description></item><item><title>Using iOS 10 notifications with iBeacons</title><link>https://jimbobbennett.dev/blogs/using-ios-10-notifications-with-ibeacons/</link><pubDate>Sat, 22 Oct 2016 00:08:10 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/using-ios-10-notifications-with-ibeacons/</guid><description>&lt;p>I&amp;rsquo;m a huge fan of iBeacons (and if you&amp;rsquo;re coming to MS Ignite NZ 2016 then you can &lt;a href="https://msignite.nz/sessions?speakers=umfrvWR5E%2FqwjuDKCZL4bA%3D%3D">hear me talk about them&lt;/a>) and they are pretty easy to get started with on iOS. The most basic use case is beacon monitoring - when your app detects a signal from an iBeacon it can wake up and do some processing in the background.&lt;/p>
&lt;p>Some of the time this processing might just be showing the user a notification - in a retail example if an app user has looked at a product in your app and they walk into one of your stores you could notify them that the product they looked at was in stock (and direct them right to it using the indoor location capabilities available with iBeacons). This is pretty simple to do - create a location manager, authorize it, monitor for a beacon, detect the event and show a notification. The code below shows the sort of thing you would need to do.&lt;/p>
&lt;pre tabindex="0">&lt;code>var region = new CLBeaconRegion(proximityId, &amp;#34;My Region&amp;#34;);
region.NotifyOnEntry = true;
var locationManager = new CLLocationManager();
locationManager.AuthorizationChanged += (s, e) =&amp;gt;
{
if (e.Status == CLAuthorizationStatus.AuthorizedAlways)
locationManager.StartMonitoring(region);
};
locationManager.RegionEntered += (s, e) =&amp;gt; SendNotification();
locationManager.RequestAlwaysAuthorization();
&lt;/code>&lt;/pre>&lt;p>The &lt;code>SendNotification&lt;/code> method would then create an iOS local notification and display it.&lt;/p>
&lt;p>This is cool, and pretty simple. But thanks to iOS 10 it&amp;rsquo;s now even easier. As part of iOS 10, Apple introduced a &lt;a href="https://developer.xamarin.com/guides/ios/platform_features/introduction-to-ios10/user-notifications/enhanced-user-notifications/">new notifications API&lt;/a>, and part of this is a new set of notification triggers. These triggers are classes that trigger a notification - you create a notification request with some content and a trigger that determines when the notification will fire. The simplest example is a trigger that fires after a certain duration (called &lt;a href="https://developer.xamarin.com/api/type/UserNotifications.UNTimeIntervalNotificationTrigger/">UNTimeIntervalNotificationTrigger&lt;/a>), this will show a notification after a set time interval - and this is similar to the existing capabilities before iOS 10. The trigger we&amp;rsquo;re interested in though is a new capability - &lt;a href="https://developer.xamarin.com/api/type/UserNotifications.UNLocationNotificationTrigger/">UNLocationNotificationTrigger&lt;/a>. This is a trigger that fires when the device enters or leaves a region - be it a geographic region or an iBeacon region.&lt;/p>
&lt;p>We can use this new trigger to show a local notification when our app enters or leaves an iBeacon region. First we create the region in exactly the same way as for monitoring - using a proximity UUID and optionally a major and minor to define the region and setting the notify on entry or exit properties as applicable:&lt;/p>
&lt;pre tabindex="0">&lt;code>var region = new CLBeaconRegion(new NSUuid(ProximityUUID), &amp;#34;MyRegion&amp;#34;);
region.NotifyOnEntry = true;
region.NotifyOnExit = false;
&lt;/code>&lt;/pre>&lt;p>Then we ensure the correct permissions are set for notifications and locations:&lt;/p>
&lt;pre tabindex="0">&lt;code>UNUserNotificationCenter.Current.RequestAuthorization(UNAuthorizationOptions.Alert, (a, e) =&amp;gt; { });
var locationManager = new CLLocationManager();
locationManager.RequestWhenInUseAuthorization();
&lt;/code>&lt;/pre>&lt;p>Remembering of course to set the appropriate permission message for location monitoring in the &lt;code>info.plist&lt;/code>:&lt;/p>
&lt;pre tabindex="0">&lt;code>&amp;lt;key&amp;gt;NSLocationWhenInUseUsageDescription&amp;lt;/key&amp;gt;
&amp;lt;string&amp;gt;Detect beacons&amp;lt;/string&amp;gt;
&lt;/code>&lt;/pre>&lt;p>Next we create the notification:&lt;/p>
&lt;pre tabindex="0">&lt;code>// Create the content
var content = new UNMutableNotificationContent();
content.Title = &amp;#34;iBeacon notification test&amp;#34;;
content.Body = &amp;#34;iBeacon detected&amp;#34;;
// Create the location trigger
var trigger = UNLocationNotificationTrigger.CreateTrigger(region, true);
// Create the request
var requestID = Guid.NewGuid().ToString(&amp;#34;N&amp;#34;);
var request = UNNotificationRequest.FromIdentifier(requestID, content, trigger); UNUserNotificationCenter.Current.RemoveAllPendingNotificationRequests();
UNUserNotificationCenter.Current.AddNotificationRequest(request, e =&amp;gt; { });
&lt;/code>&lt;/pre>&lt;p>The notification code is fairly standard iOS 10 boilerplate notification code - we create content for the notification, create a trigger for it, create a notification request based off the content and trigger then add the request to the notification center.&lt;/p>
&lt;p>The interesting bit is the trigger - we create a trigger using a static method passing it the region:&lt;/p>
&lt;pre tabindex="0">&lt;code>UNLocationNotificationTrigger.CreateTrigger(region, true);
&lt;/code>&lt;/pre>&lt;p>The first parameter is our region - in our example this is an iBeacon region but it could also be a location region. The second parameter determines if the notification should be re-scheduled after it has been triggered - set this to true if you want the notification to pop up every time, or false if you don&amp;rsquo;t want it to repeat.&lt;/p>
&lt;p>Once this notification has been registered we can exit our app, and it will wake up as soon as the iBeacon region is entered and show the notification.&lt;/p>
&lt;p>&lt;img src="IMG_3951-1.png" alt="Our notification showing">&lt;/p>
&lt;h6 id="why-do-it-this-way">Why do it this way?&lt;/h6>
&lt;p>This may seem like a pointless thing to do - at first glance this doesn&amp;rsquo;t give us anything more than what we can get by showing the notification using the location managers &lt;code>RegionEntered&lt;/code> event. There is one important difference here though.&lt;/p>
&lt;p>When using the location manager directly we have to authorize the app always - the user has to agree to have our app monitor their location even when the app is not in use, something that some users don&amp;rsquo;t like. By using the location based notification triggers we only need to request when in use authorization, not always (you can see this in the code above). Despite only having when in use authorization you app can still detect entering the region even when the app is in the background or even terminated.&lt;/p>
&lt;h6 id="why-not-to-do-it-this-way">Why not to do it this way?&lt;/h6>
&lt;p>Your app isn&amp;rsquo;t actually run when the region is entered, all that happens is the local notification is shown. This is fine if that&amp;rsquo;s all you need (and the new iOS 10 notifications API can allow you to do some pretty neat stuff in a notification), but if you need your app to run then you have to monitor using the location manager and use always authorization.&lt;/p>
&lt;br>
&lt;p>You can find the example code for this &lt;a href="https://github.com/jimbobbennett/NotificationTrigger">on GitHub&lt;/a>.&lt;/p></description></item><item><title>Xamarin In Action</title><link>https://jimbobbennett.dev/blogs/xamarin-in-action/</link><pubDate>Tue, 20 Sep 2016 00:55:29 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/xamarin-in-action/</guid><description>&lt;p>Over the last few months I&amp;rsquo;ve been busily writing away on my first book - &lt;a href="https://manning.com/books/xamarin-in-action?a_aid=XamarinInAction&amp;amp;a_bid=4997cccc">Xamarin In Action for Manning publications&lt;/a>. Manning are a pretty serious publisher, they count Jon Skeet amongst their authors so it was quite an honor to be asked to write for them.&lt;/p>
&lt;p>The first 3 chapters are now available to buy under the Manning early access program - under this program you buy the book and get the first 3 chapters now, with more chapters as they are written. You also get to engage with me and give feedback on the book to help make it better for everyone.&lt;/p>
&lt;p>Xamarin In Action tries to be different to other book - it&amp;rsquo;s focused on answering the question of how to build a cross-platform Xamarin mobile app. Unlike other books that just focus on reference material for how to use the various iOS and Android UI widgets and services in C#, this book instead focuses on the main upside of Xamarin - the ability to write cross-platform apps. Unlike just writing for iOS and Android, to make a successful Xamarin app you need to be able to share a large amount of code, but still build your apps in a way that looks and feels like the platform you are targeting. You need to think all the time about what code can be cross-platform, and what code needs to be platform specific.&lt;/p>
&lt;p>The best design pattern for doing this is MVVM - you write your models and view models in cross-platform code, then write your views using platform specific iOS or Android code. You can also use cross-platform plugins from your cross-platform code to access device specific features thanks to the such awesome NuGet tricks as bait-and-switch. This book focuses on using MVVM, and specifically &lt;a href="https://mvvmcross.com">MvvmCross&lt;/a>, showing you how to build your apps to maximize code re-use and testability.&lt;/p>
&lt;p>After showing you how to best build your apps, the book then looks at how to turn them into production quality apps - after an app is only an app once it is on the store. It looks at testing, releasing and monitoring your app once it is released, to allow you to catch bugs early.&lt;/p>
&lt;p>You can buy this book from here: &lt;a href="https://manning.com/books/xamarin-in-action?a_aid=XamarinInAction&amp;a_bid=4997cccc">Xamarin In Action
&lt;br/>
&lt;img src="Screen-Shot-2016-09-17-at-12.18.07-2.png" alt="Xamarin In Action"/>
&lt;/a>&lt;/p></description></item><item><title>More upcoming talks</title><link>https://jimbobbennett.dev/blogs/more-upcoming-talks/</link><pubDate>Sat, 17 Sep 2016 02:51:28 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/more-upcoming-talks/</guid><description>&lt;p>Ive got a couple of talks coming up around Auckland next week:&lt;/p>
&lt;h4 id="xamarin-102---a-slightly-deeper-dive---north-shore-net-user-grouphttpnorthshorenetusergrouporgnzmeetingmeetupidm20160922">&lt;a href="http://northshore.netusergroup.org.nz/Meeting/Meetup/?id=M20160922">Xamarin 102 - a slightly deeper dive - North Shore .Net user group&lt;/a>&lt;/h4>
&lt;p>It’s hard to be a .Net developer and not have heard of Xamarin. It’s now part of Microsoft’s ‘Any developer, any platform’ strategy, and allows you to write C# code that runs on iOS and Android.&lt;/p>
&lt;p>In this talk we will briefly introduce Xamarin, then dive right into some code building a cross platform app that loads data from a REST service and shows it on screen - the kind of thing a real world app would want to do. We’ll see how much code can be shared between the iOS and Android app and how much has to be platform specific, look at what design patterns can help to increase the amount of code sharing, and briefly look at Xamarin.Forms as a way of targeting 99% code reuse.&lt;/p>
&lt;p>By the time we’re done you should be able to dive right into Xamarin using the free community versions of Visual Studio on Windows or Xamarin Studio on Mac and be ready to play with building your first app!&lt;/p>
&lt;p>Details here: &lt;a href="http://northshore.netusergroup.org.nz/Meeting/Meetup/?id=M20160922">http://northshore.netusergroup.org.nz/Meeting/Meetup/?id=M20160922&lt;/a>&lt;/p>
&lt;h4 id="ui-testing-in-the-real-world---auckland-xamarin-meetuphttpswwwmeetupcomauckland-xamarin-meetupevents233436741">&lt;a href="https://www.meetup.com/Auckland-Xamarin-Meetup/events/233436741/">UI Testing in the real world - Auckland Xamarin Meetup&lt;/a>&lt;/h4>
&lt;p>Testing your mobile apps manually is time consuming and error prone. It’s much better to be able to create automation tests that can reliably, reproducibly and repeatably test your apps.&lt;/p>
&lt;p>With Xamarin UITest you can write automation tests in C# that you can run against your apps on simulators or local devices. With Xamarin Test Cloud you can run these tests across thousands of devices in the cloud.&lt;/p>
&lt;p>In this talk Jim will give an overview of UITest, show how you can use it to interact with your apps, show how the REPL gives you a way to interact with your app live inside a console.&lt;/p>
&lt;p>After this Andrew will pick up the baton and talk about his experiences running these tests in the real world, discussing how to achieve the perfect balance between speed, reliability and ensuring your tests achieve their goal of proving your app works in the hands of actual users.&lt;/p>
&lt;p>Details here: &lt;a href="https://www.meetup.com/Auckland-Xamarin-Meetup/events/233436741/">https://www.meetup.com/Auckland-Xamarin-Meetup/events/233436741/&lt;/a>&lt;/p></description></item><item><title>Come hear me talk about iBeacons at MS Ignite NZ</title><link>https://jimbobbennett.dev/blogs/come-hear-me-talk-about-ibeacons-at-ms-ignite/</link><pubDate>Sat, 17 Sep 2016 01:29:51 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/come-hear-me-talk-about-ibeacons-at-ms-ignite/</guid><description>&lt;p>I&amp;rsquo;ll be at &lt;a href="https://msignite.nz">Microsoft Ignite New Zealand&lt;/a> this year talking about iBeacons, and show how to use them from a Xamarin app. This session will introduce iBeacons and discuss how to use them to build context aware applications, and what types of problems those applications can solve. It will look at how you can notify an app when you are near an iBeacon and how you can use them to track indoor location. It will also discuss the downsides, such as security concerns and problems around beacon deployments. As well as discussing the concepts it will also contain a live coding Xamarin demo showing just how easy it is to beacon-enable your apps, with live demos of notifications and indoor location tracking.&lt;/p>
&lt;p>MS Ignite runs from 25-28 October at the SkyCity convention centre in Auckland, New Zealand.&lt;/p>
&lt;hr>
&lt;p>Update - the video of this talk is now on Channel 9:&lt;/p>
&lt;p>&lt;a href="https://channel9.msdn.com/Events/Ignite/New-Zealand-2016/M324">https://channel9.msdn.com/Events/Ignite/New-Zealand-2016/M324&lt;/a>&lt;/p>
&lt;iframe src="https://channel9.msdn.com/Events/Ignite/New-Zealand-2016/M324/player" width="960" height="540" allowFullScreen frameBorder="0">&lt;/iframe></description></item><item><title>More on Xamarin Studio add-ins</title><link>https://jimbobbennett.dev/blogs/more-on-xamarin-studio-add-ins/</link><pubDate>Wed, 27 Jul 2016 08:48:05 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/more-on-xamarin-studio-add-ins/</guid><description>&lt;p>As a follow up to my previous post about &lt;a href="https://jimbobbennett.dev/blogs/creating-an-add-in-for-xamarin-studio/">creating an add-in for Xamarin Studio&lt;/a> I thought I&amp;rsquo;d go into the details of the project template XML.&lt;/p>
&lt;p>When creating an add-in that adds a new project type you define each project as a &lt;code>Project&lt;/code> node inside the &lt;code>xpt.xml&lt;/code> file. This project node has some attributes, and sub nodes made up of options, references, files and packages.&lt;/p>
&lt;p>Think of this post as a sort of API reference for these based on what I&amp;rsquo;ve discovered, or been taught. Once again this post would not be possible without the help of &lt;a href="https://twitter.com/mjhutchinson">Mikayla Hutchinson&lt;/a> - she is awesome.&lt;/p>
&lt;h3 id="variables">Variables&lt;/h3>
&lt;p>In this file you can use &lt;code>${ProjectName}&lt;/code> to refer to the name of the solution. This is not the file name, just the solution name, so &lt;code>MySolution.sln&lt;/code> would be called &lt;code>MySolution&lt;/code> and every instance of &lt;code>${ProjectName}&lt;/code> would be replaced with &lt;code>MySolution&lt;/code>.&lt;/p>
&lt;h3 id="the-project-node">The &lt;code>Project&lt;/code> node&lt;/h3>
&lt;pre tabindex="0">&lt;code>&amp;lt;Project name = &amp;#34;${ProjectName}.Core&amp;#34; directory = &amp;#34;./${ProjectName}.Core&amp;#34; type=&amp;#34;C#PortableLibrary&amp;#34;&amp;gt;
&lt;/code>&lt;/pre>&lt;p>The &lt;code>name&lt;/code> is the name of the &lt;code>.csproj&lt;/code> file. In the files for this project the &lt;code>${ProjectName}&lt;/code> is set to this name.&lt;/p>
&lt;p>The &lt;code>directory&lt;/code> is the subdirectory under the solution where this project is created.&lt;/p>
&lt;p>The &lt;code>type&lt;/code> is the type of the project. The 3 types I know about are:&lt;/p>
&lt;ul>
&lt;li>&lt;code>C#PortableLibrary&lt;/code> - PCL&lt;/li>
&lt;li>&lt;code>MonoDroid&lt;/code> - Android app&lt;/li>
&lt;li>&lt;code>XamarinIOS&lt;/code> - iOS app&lt;/li>
&lt;/ul>
&lt;h5 id="the-options-node">The &lt;code>Options&lt;/code> node&lt;/h5>
&lt;p>This is a sub-node of &lt;code>Project&lt;/code>, and is used to set options on the project file. The attributes I am aware of are:&lt;/p>
&lt;h6 id="pcl-projects">PCL projects:&lt;/h6>
&lt;pre tabindex="0">&lt;code>&amp;lt;Options Target=&amp;#34;Library&amp;#34; TargetProfile = &amp;#34;Profile259&amp;#34;/&amp;gt;
&lt;/code>&lt;/pre>&lt;ul>
&lt;li>&lt;code>Target=&amp;quot;Library&amp;quot;&lt;/code> - sets this project as a library&lt;/li>
&lt;li>&lt;code>TargetProfile=&amp;quot;Profile259&amp;quot;&lt;/code> - sets the target profile&lt;/li>
&lt;/ul>
&lt;h6 id="android-projects">Android projects:&lt;/h6>
&lt;pre tabindex="0">&lt;code>&amp;lt;Options AndroidApplication=&amp;#34;true&amp;#34; AndroidResgenFile=&amp;#34;Resources\Resource.Designer.cs&amp;#34; GenerateSerializationAssemblies=&amp;#34;Off&amp;#34; ProductVersion=&amp;#34;8.0.30703&amp;#34; SchemaVersion=&amp;#34;2.0&amp;#34; AppDesignerFolder=&amp;#34;Properties&amp;#34; FileAlignment=&amp;#34;512&amp;#34; JavaMaximumHeapSize=&amp;#34;1G&amp;#34;/&amp;gt;
&lt;/code>&lt;/pre>&lt;ul>
&lt;li>&lt;code>AndroidApplication=&amp;quot;true&amp;quot;&lt;/code> - Marks this project as an Android app&lt;/li>
&lt;li>&lt;code>AndroidResgenFile=&amp;quot;Resources\Resource.Designer.cs&amp;quot;&lt;/code> - Tells the Android app which file is autogenerated from the resources&lt;/li>
&lt;li>&lt;code>JavaMaximumHeapSize=&amp;quot;1G&amp;quot;&lt;/code> - Sets the Java heap size, 1G is better than the default 512M&lt;/li>
&lt;/ul>
&lt;p>Not sure exactly what the other attributes do - if you know please tell me and I&amp;rsquo;ll update this.&lt;/p>
&lt;h6 id="ios-projects">iOS projects:&lt;/h6>
&lt;pre tabindex="0">&lt;code>&amp;lt;Options /&amp;gt;
&lt;/code>&lt;/pre>&lt;p>I don&amp;rsquo;t know any of the options here, again if you know please tell me!&lt;/p>
&lt;h5 id="the-references-node">The &lt;code>References&lt;/code> node&lt;/h5>
&lt;p>This is where you define references to libraries or other projects. No need to add references to libraries that come from NuGet here, as these are set via the &lt;code>Packages&lt;/code> node.&lt;/p>
&lt;pre tabindex="0">&lt;code>&amp;lt;References&amp;gt;
&amp;lt;Reference type=&amp;#34;Package&amp;#34; refto=&amp;#34;Mono.Android.Export&amp;#34; /&amp;gt;
&amp;lt;Reference type=&amp;#34;Project&amp;#34; refto=&amp;#34;${ProjectName}.Core&amp;#34; /&amp;gt;
&amp;lt;/References&amp;gt;
&lt;/code>&lt;/pre>&lt;ul>
&lt;li>&lt;code>type&lt;/code> - &lt;code>Package&lt;/code> for an assembly either from the .Net framework or from a library that you are shipping, &lt;code>Project&lt;/code> for a reference to another project in your solution&lt;/li>
&lt;li>&lt;code>refto&lt;/code> - the assembly to reference (for framework assemblies), or the project name for other projects in the solution.&lt;/li>
&lt;li>&lt;code>HintPath=&amp;quot;xxx&amp;quot;&lt;/code> - specifies the hint path for references to libraries outside of the framework (such as one you are shipping with the add-in)&lt;/li>
&lt;/ul>
&lt;h5 id="the-files-node">The &lt;code>Files&lt;/code> node&lt;/h5>
&lt;p>This is where you define the actual files to copy to your project. These files must come from somewhere, so you need to add them to your project with &lt;code>Copy to output directory&lt;/code> ticked. You also need to add these files to your &lt;code>Manifest.addin.xml&lt;/code> file as &lt;code>Import&lt;/code> entries in the &lt;code>Runtime&lt;/code> node.&lt;/p>
&lt;pre tabindex="0">&lt;code>&amp;lt;Files&amp;gt;
&amp;lt;File name=&amp;#34;Properties/AndroidManifest.xml&amp;#34; src=&amp;#34;Droid/Properties/AndroidManifest.xml&amp;#34;/&amp;gt;
&amp;lt;RawFile name=&amp;#34;Resources/drawable/icon.png&amp;#34; src=&amp;#34;Droid/Resources/drawable/icon.png&amp;#34;/&amp;gt;
&amp;lt;File name=&amp;#34;Pages/FirstPage.xaml&amp;#34; BuildAction=&amp;#34;EmbeddedResource&amp;#34; src=&amp;#34;Core/Pages/FirstPage.xaml&amp;#34;/&amp;gt;
&amp;lt;File name=&amp;#34;Pages/FirstPage.xaml.cs&amp;#34; AddStandardHeader=&amp;#34;True&amp;#34; src=&amp;#34;Core/Pages/FirstPage.xaml.cs&amp;#34; DependsOn=&amp;#34;FirstPage.xaml&amp;#34; /&amp;gt;
&amp;lt;/Files&amp;gt;
&lt;/code>&lt;/pre>&lt;p>There are two possible nodes here, &lt;code>File&lt;/code> and &lt;code>RawFile&lt;/code>. Use &lt;code>File&lt;/code> for text files as this will do file ending/unicode conversion. Use &lt;code>RawFile&lt;/code> for binary files, such as images or libraries to avoid any conversion.&lt;/p>
&lt;ul>
&lt;li>&lt;code>name&lt;/code> - the file name including the directory for the file to write to&lt;/li>
&lt;li>&lt;code>src&lt;/code> - the file name and path of the source file inside your bundle&lt;/li>
&lt;li>&lt;code>BuildAction&lt;/code> - the build action for this file. For normal compile you don&amp;rsquo;t need this but for Xamarin.Forms &lt;code>Xaml&lt;/code> files you need to set this to &lt;code>EmbeddedResource &lt;/code>.&lt;/li>
&lt;li>&lt;code>AddStandardHeader=&amp;quot;True&amp;quot;&lt;/code> - don&amp;rsquo;t know what this does, but is used for xaml files for forms.&lt;/li>
&lt;li>&lt;code>DependsOn&lt;/code> - sets the file that this depends on, so used for specifying the &lt;code>Xaml&lt;/code> file for a &lt;code>xaml.cs&lt;/code> code behind file.&lt;/li>
&lt;/ul>
&lt;h5 id="the-packages-node">The &lt;code>Packages&lt;/code> node&lt;/h5>
&lt;p>Here you can define what NuGet packages to install in your app. These are installed as if you installed them manually, so all dependent packages are installed.&lt;/p>
&lt;pre tabindex="0">&lt;code>&amp;lt;Packages&amp;gt;
&amp;lt;Package Id=&amp;#34;Xamarin.Forms&amp;#34; Version=&amp;#34;2.3.0.107&amp;#34;/&amp;gt;
&amp;lt;Package id=&amp;#34;MvvmCross&amp;#34; version=&amp;#34;4.2.2&amp;#34;/&amp;gt;
&amp;lt;Package id=&amp;#34;MvvmCross.Forms.Presenter&amp;#34; version=&amp;#34;4.1.4&amp;#34;/&amp;gt;
&amp;lt;/Packages&amp;gt;
&lt;/code>&lt;/pre>&lt;ul>
&lt;li>&lt;code>id&lt;/code> - The Id of the NuGet package to install&lt;/li>
&lt;li>&lt;code>version&lt;/code> - The specific version to install if needed&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>This doc is nowhere near complete, so if you know of other things to add please let me know and I&amp;rsquo;ll update it.&lt;/p></description></item><item><title>Creating an add-in for Xamarin Studio</title><link>https://jimbobbennett.dev/blogs/creating-an-add-in-for-xamarin-studio/</link><pubDate>Fri, 01 Jul 2016 23:56:53 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/creating-an-add-in-for-xamarin-studio/</guid><description>&lt;p>All good IDE&amp;rsquo;s come with a framework for extending them, and Xamarin Studio is no different. It is built on top of MonoDevelop which makes extensive use of add-ins to provide a lot of it&amp;rsquo;s features, and it&amp;rsquo;s really easy to add your own.&lt;/p>
&lt;p>Recently I created my own add-in to help out when building &lt;a href="https://mvvmcross.com">MvvmCross&lt;/a> projects. If you wanted to do a &amp;lsquo;File -&amp;gt; New Solution&amp;rsquo; in Xamarin Studio and create a simple, working MvvmCross cross platform app targeting iOS and Android you had to do a few things to make it work - you had to create the solution, ensure you have a PCL core project, an iOS app and an Android app, manually add the nuget packages for MvvmCross and either write the code yourself, or install the MvvmCross starter pack nuget package. This starter was helpful, it contained sample code and instructions showing what you needed to change in the code files that were already created in your apps. As great as this is though, I thought it might be better if you could do a &amp;lsquo;File -&amp;gt; New Solution&amp;rsquo; and from the New Project dialog choose to create a fully working MvvmCross iOS and Android sample app to save a couple of minutes. &lt;span style="color:blue">#FirstWorldProblems&lt;/span>.&lt;/p>
&lt;p>Lets now walk through just how I did it and see how easy it was to create my add-in. I&amp;rsquo;ll be referring to my add-in in the examples, and you can find the code &lt;a href="https://github.com/jimbobbennett/MVVMCross.XSAddIn">on my github&lt;/a>.&lt;/p>
&lt;p>You can use Xamarin Studio to write add-ins, but first you need to install an add-in! Select &amp;lsquo;Xamarin Studio -&amp;gt; Add Ins&amp;hellip;&amp;rsquo; and add the &amp;lsquo;Add-in Maker&amp;rsquo; add-in.&lt;/p>
&lt;div class="image-div" style="width: 500px;">
&lt;p>&lt;img src="Screen-Shot-2016-07-02-at-10-58-20-1.png" alt="Adding the add-in maker add-in">&lt;/p>
&lt;/div>
&lt;p>Once this is added I&amp;rsquo;d recommend restarting Xamarin Studio. If you don&amp;rsquo;t restart after adding add-ins they don&amp;rsquo;t always work correctly - new project types can be missing or in the wrong place.&lt;/p>
&lt;p>To create your add-in do &amp;lsquo;File -&amp;gt; New Solution&amp;rsquo; and select &amp;lsquo;Xamarin Studio AddIn&amp;rsquo; from the &amp;lsquo;Other -&amp;gt; Miscellaneous&amp;rsquo; section.&lt;/p>
&lt;div class="image-div" style="width: 500px;">
&lt;p>&lt;img src="Screen-Shot-2016-07-02-at-11-08-54.png" alt="Xamarin Studio AddIn in the New Project dialog">&lt;/p>
&lt;/div>
&lt;p>When you create the add-in project you get a few things set up for you. Firstly you get a package reference to &lt;code>MonoDevelop.AddIns&lt;/code> which is the NuGet package that provides a lot of the features you need. Secondly you get a couple of extra files in the &lt;code>Properties&lt;/code> folder:&lt;/p>
&lt;ul>
&lt;li>&lt;code>AddInInfo.cs&lt;/code> - This file allows you to provide information about your add-in such as the name, category (so where it appears in the Add-In manager), description, author, version etc.&lt;/li>
&lt;li>&lt;code>Manifest.addin.xml&lt;/code> - This manifest file defines what your add-in actually does. It lists any files or resources that are shipped inside the add-in, and defines what features are available.&lt;/li>
&lt;/ul>
&lt;p>My MvvmCross add-in provides a new solution type containing 3 projects. Adding a new solution type is actually pretty easy - you create an xml file that defines what projects go into the solution, with each project defined inside that xml file, and the files inside the project are provided by you as raw files that get copied in.&lt;/p>
&lt;p>So if you look inside the &lt;code>Templates&lt;/code> folder in the add-in project you will see 3 folders and an xml file. The &lt;code>MvvmCross.Solution.xpt.xml&lt;/code> file is the one that defines the projects. If you open this file and browse the contents you will see the following sections:&lt;/p>
&lt;ul>
&lt;li>&lt;code>TemplateConfiguration&lt;/code> - This section defines the configuration for this solution template, such as it&amp;rsquo;s name, description, icon, programming language and where in the New Project dialog it should be.&lt;/li>
&lt;li>&lt;code>Combine&lt;/code> - This section is the actual &amp;lsquo;instructions&amp;rsquo; to to create the solution. This section has 3 &lt;code>Project&lt;/code> nodes in it, and these represent the actual projects that will be created in the solution. In the project node we define the project name, type, directory that it lives in. In the sub-nodes we define the options that are set on the project, as well as contents of the project such as references and the files to include. These files that are included point to an actual file inside the project - and it&amp;rsquo;s this that makes it easy to create such an add-in. What you do is create all the files yourself, so create a project that matches the output of your add-in and add these files to your add-in project without a build action but copied to output. When your add-in runs it will build the project based on the instructions given, copying the files you&amp;rsquo;ve added to the new project.&lt;/li>
&lt;/ul>
&lt;p>One thing to note is the variables that are used such as &lt;code>${ProjectName}&lt;/code>. There are a few of these. and these are replaced with appropriate values when your add-in is run. For example &lt;code>${ProjectName}&lt;/code> is replaced with the name you put into the &amp;lsquo;Project Name&amp;rsquo; in the &amp;lsquo;New Project&amp;rsquo; dialog. As well as putting these inside the xml file you also need to use these in the source files that are shipped with the add-in. You also have to be aware that these variables can change based on the scope - so for example is you created a new solution using the add-in called &amp;lsquo;Foo&amp;rsquo;, when building the solution &lt;code>${ProjectName}&lt;/code> would be &amp;lsquo;Foo&amp;rsquo;, but if the solution creates a project call &amp;lsquo;Foo.Core&amp;rsquo;, inside any code files for that project &lt;code>${ProjectName}&lt;/code> would actually be &amp;lsquo;Foo.Core&amp;rsquo;, and to get &amp;lsquo;Foo&amp;rsquo; you have to use &lt;code>${SolutionName}&lt;/code>.&lt;/p>
&lt;p>Have a look at the code in the MvvmCross add-in and you&amp;rsquo;ll see this in action. It&amp;rsquo;s actually pretty self-explanatory once you start reading a real example, which is one of the great things about the Xamarin Studio add-ins.&lt;/p>
&lt;p>Once you have built your add-in, you can run it and it will launch a new instance of Xamarin Studio with your add-in installed for you to test out. If you want to ship the add-in to other people to try out you need to package it using mdtool, which is buried inside the Xamarin Studio application package:&lt;/p>
&lt;pre tabindex="0">&lt;code>/Applications/Xamarin\ Studio.app/Contents/MacOS/mdtool setup pack SomeAddin.dll
&lt;/code>&lt;/pre>&lt;p>This will spit out an mpack file - a mono package that contains the add-in. You can send this file out and users can add it from the &amp;lsquo;AddIn Manager&amp;rsquo; using the &amp;lsquo;Install from file&amp;hellip;&amp;rsquo; option.&lt;/p>
&lt;p>The last file to note is `addin-project.xml&amp;rsquo;. You need to create one of these if you are want to ship the add-in to the gallery at &lt;a href="http://addins.monodevelop.com">http://addins.monodevelop.com&lt;/a>. When you ship an add-in it will grab code from your repo and compile it up, and this xml file is used to tell their compiler what to do.&lt;/p>
&lt;p>Easy, and awesome!&lt;/p>
&lt;p>Now go off and write an add-in, and ping me here or on twitter if you have any questions.&lt;/p>
&lt;hr>
&lt;p>This blog post would be complete without a shoutout to &lt;a href="https://twitter.com/mjhutchinson">Mikayla Hutchinson&lt;/a> and &lt;a href="https://twitter.com/slluis">Lluis Sanchez Gual&lt;/a> from Xamarin for being awesome and helping me get my add-in working and up on the add-ins gallery. You rock!&lt;/p></description></item><item><title>MvvmCross add-ins for Visual Studio and Xamarin Studio</title><link>https://jimbobbennett.dev/blogs/mvvmcross-add-ins-for-visual-studio-and-xamarin-studio/</link><pubDate>Thu, 26 May 2016 09:22:27 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/mvvmcross-add-ins-for-visual-studio-and-xamarin-studio/</guid><description>&lt;p>I&amp;rsquo;ve been using MvvmCross a lot at work and it&amp;rsquo;s pretty cool. I&amp;rsquo;ve got a big upcoming personal project that I&amp;rsquo;ve started working on (more info soon I promise - it&amp;rsquo;s something pretty awesome), and I&amp;rsquo;ve decided to use MvvmCross for it. Unfortunately despite all it&amp;rsquo;s awesomeness, creating a boilerplate cross platform solution using MvvmCross is still a bit of work. There is the &lt;a href="https://www.nuget.org/packages/MvvmCross.StarterPack/">starter pack nuget&lt;/a>, but using this still means a bit of work copying code, setting up projects and remembering to remove the starter pack once you are finished just from your &lt;code>packages.config&lt;/code> (not from your installed packages or you lose a load of files).&lt;/p>
&lt;p>Ideally I&amp;rsquo;d like an add-in for Visual Studio and Xamarin Studio where you can create a new solution and it creates all the projects you need for a cross platform app - so core/iOS/Droid/UWP/Wpf/Win8 on Visual Studio and core/iOS/Droid/Mac on Xamarin Studio. There is &lt;a href="https://visualstudiogallery.msdn.microsoft.com/618b51f0-6de8-4f85-95ce-a50c658c7767">Ninja Coder&lt;/a> but this is Visual Studio only and is overkill for my needs as it does pretty much everything you could want, all I want is a consistent way of creating projects using Visual Studio and Xamarin Studio that match the starter pack.&lt;/p>
&lt;p>I had a chat with &lt;a href="https://twitter.com/Cheesebaron">Tomasz Cielecki&lt;/a> (or &lt;a href="https://twitter.com/Cheesebaron">CheeseBaron&lt;/a> as you may know him), and we talked about creating an add-in that does just this. So over the past few evenings I&amp;rsquo;ve been teaching myself how to create add-ins for Visual Studio and Xamarin Studio and I&amp;rsquo;ve finally managed to get it working.&lt;/p>
&lt;p>The Visual Studio one is available &lt;a href="https://github.com/jimbobbennett/MvvmCross-VisualStudioAddIn">here&lt;/a>. Grab the source if you want a nose at how it works, or grab the release to try it out. Once I&amp;rsquo;ve had some feedback I&amp;rsquo;ll put it up on the Visual Studio gallery.&lt;/p>
&lt;p>The Xamarin Studio version is available &lt;a href="https://github.com/jimbobbennett/MvvmCross.XSAddIn">here&lt;/a>. Again, source is available and a release build is there you can try out. I&amp;rsquo;ve also submitted it to the alpha channel for Xamarin Studio add-ins for v6 and above, so once it&amp;rsquo;s accepted you should see it in the add-in gallery in the latest beta of Xamarin Studio. This one was hard to do as there is minimal documentation, so a big shout out to &lt;a href="https://twitter.com/mjhutchinson">Mikayla Hutchinson&lt;/a> for generally being awesome and answering my dumb questions.&lt;/p>
&lt;p>I&amp;rsquo;ll blog in more detail about how I created these add-ins at a later date. For now though please grab them and try them out. I&amp;rsquo;d appreciate as much feedback as possible!&lt;/p>
&lt;div class="image-div" style="width: 300px;">
&lt;p>&lt;img src="MvvmCross.png" alt="MVVMCross Logo">&lt;/p>
&lt;/div>
&lt;hr/>
&lt;h4 id="update">Update!&lt;/h4>
&lt;p>These add-ins are now live in the &lt;a href="http://addins.monodevelop.com/Project/Index/227">Xamarin Studio stable add-in repository&lt;/a> and on the &lt;a href="https://visualstudiogallery.msdn.microsoft.com/96b3d919-0277-4f63-92a3-a7bf3e7cd384?SRC=Home">Visual Studio Gallery&lt;/a>. This means you can install them from inside Xamarin Studio&amp;rsquo;s add-in manager and Visual Studio&amp;rsquo;s extensions and updates. The Xamarin Studio add-in needs XS 6 so you&amp;rsquo;ll need the latest Stable or Beta, the Visual Studio extension needs VS2015.&lt;/p>
&lt;div class="image-div" style="width: 400px;">
&lt;p>&lt;img src="XamarinStudioAddIn.png" alt="Xamarin Studio Add=in">&lt;/p>
&lt;/div>
&lt;div class="image-div" style="width: 400px;">
&lt;p>&lt;img src="VisualStudioAddIn.png" alt="Visual Studio Add-in">&lt;/p>
&lt;/div></description></item><item><title>Fixing issues with Multidex on pre-lollipop devices on Windows</title><link>https://jimbobbennett.dev/blogs/fixing-issues-with-multidex-on-pre-lollipop-devices-on-windows/</link><pubDate>Fri, 20 May 2016 08:20:16 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/fixing-issues-with-multidex-on-pre-lollipop-devices-on-windows/</guid><description>&lt;p>When building large apps on Android you may end up getting a weird &amp;lsquo;Java has exited with code 2&amp;rsquo;. This is caused by a limitation when building Android apps of 65,536 fields. Sounds odd I know, but your app can&amp;rsquo;t contain are than 65k fields - a field being a method, property or similar. You may think that this is a lot, but this also includes any other libraries you use, and just by including google maps you&amp;rsquo;re already half way there. You can get more information on this &lt;a href="https://developer.android.com/studio/build/multidex.html">on the Android developer page&lt;/a>.&lt;/p>
&lt;p>Luckily there is a way round this - multidex. When Android compiles your app it puts the code into a dex file and these dex files have the 64k limit. To exceed this limit the compiler can create multiple dex files, each with 64k fields in it. This seems like an overcomplicated solution, but from our perspective it&amp;rsquo;s simple - just tick a box on the project settings and the Xamarin SDK/Android SDK does the magic.&lt;/p>
&lt;div class="image-div" style="width: 300px;">
&lt;p>&lt;img src="Screen-Shot-2016-05-20-at-19-38-58.png" alt="">&lt;/p>
&lt;/div>
&lt;p>Your Android app needs an application class to run, and if you don&amp;rsquo;t have a custom application class in your app it gets the default Android one - Application. When you set your app to use multidex the default application class that is used is MultiDexApplication. Now if you have your own custom application class that derives from Application, then setting multidex will tweak your code so that it derives from MultiDexApplication.
In addition to this when your app is launched it needs to run the application. In the case of an app with multiple dex files it needs to look in all the dexes to find the application class. On Lollipop and above this is not a problem, the OS is built to understand this and teach for the application. However on previous versions such as KitKat multidex wasn&amp;rsquo;t built in, so the OS will only ever look in the first dex file as this is all it knows about. If the application class is not found, the app crashes on startup.
Again normally this is nothing to worry about. When your app is built it knows which classes to put in the first dex file - it creates a list of classes to put in the main dex and uses this during the build. This means when your app is launched on a pre-lollipop device the right code is in the main dex so your app is launched, and because it uses MultiDexApplication this will cause the other dexes to load.&lt;/p>
&lt;p>So for a developer - just tick the box and job done.&lt;/p>
&lt;p>Except when it goes wrong. I&amp;rsquo;ve spent the last few weeks with an issue where my large app crashes instantly on KitKat because it can&amp;rsquo;t find the application class.
Luckily I&amp;rsquo;ve had access to Xamarin support to help look into this.&lt;/p>
&lt;p>It seems the issue is caused by a bug in the Android SDK on Windows. See &lt;a href="https://code.google.com/p/android/issues/detail?id=187721">https://code.google.com/p/android/issues/detail?id=187721&lt;/a> for more details, but basically when it generates the list of classes to put in the first dex, the list ends up empty.&lt;/p>
&lt;p>This only affects the Android SDK on Windows, and so far it&amp;rsquo;s in the latest build tools versions - 23 and up. There is a simple fix, a big thanks to Jon Douglas at Xamarin for providing this.&lt;/p>
&lt;p>What you need to do is edit the &lt;code>mainDexClasses.bat&lt;/code> file inside &lt;code>android-sdk\build-tools\23.0.3&lt;/code> (or whatever is your latest version). It also helps to delete all earlier versions to ensure the wrong one doesn&amp;rsquo;t get used. In this file, near the bottom, change:&lt;/p>
&lt;pre tabindex="0">&lt;code>if DEFINED output goto redirect
call &amp;#34;%java_exe%&amp;#34; -Djava.ext.dirs=&amp;#34;%frameworkdir%&amp;#34; com.android.multidex.MainDexListBuilder &amp;#34;%disableKeepAnnotated%&amp;#34; &amp;#34;%tmpJar%&amp;#34; &amp;#34;%params%&amp;#34;
goto afterClassReferenceListBuilder
:redirect
call &amp;#34;%java_exe%&amp;#34; -Djava.ext.dirs=&amp;#34;%frameworkdir%&amp;#34; com.android.multidex.MainDexListBuilder &amp;#34;%disableKeepAnnotated%&amp;#34; &amp;#34;%tmpJar%&amp;#34; &amp;#34;%params%&amp;#34; 1&amp;gt;&amp;#34;%output%&amp;#34;
:afterClassReferenceListBuilder
&lt;/code>&lt;/pre>&lt;p>to:&lt;/p>
&lt;pre tabindex="0">&lt;code>SET params=%params:&amp;#39;=%
if DEFINED output goto redirect
call &amp;#34;%java_exe%&amp;#34; -Djava.ext.dirs=&amp;#34;%frameworkdir%&amp;#34; com.android.multidex.MainDexListBuilder %disableKeepAnnotated% &amp;#34;%tmpJar%&amp;#34; %params%
goto afterClassReferenceListBuilder
:redirect
call &amp;#34;%java_exe%&amp;#34; -Djava.ext.dirs=&amp;#34;%frameworkdir%&amp;#34; com.android.multidex.MainDexListBuilder %disableKeepAnnotated% &amp;#34;%tmpJar%&amp;#34; %params% 1&amp;gt;&amp;#34;%output%&amp;#34;
:afterClassReferenceListBuilder
&lt;/code>&lt;/pre>&lt;p>And that&amp;rsquo;s it! Rebuild your app and it should now run on pre-lollipop devices.&lt;/p>
&lt;p>This only affects Android builds on Windows, not on Mac. Also be aware though that there is a different bug in Xamarin on the alpha and beta channel that causes issues with Multidex, so if you&amp;rsquo;re running into a problem on these versions you&amp;rsquo;ll need to update to stable until a fix is released.&lt;/p>
&lt;hr>
&lt;p>And here&amp;rsquo;s a better blog post on it from the engineer at Xamarin who helped me solve the issue.&lt;/p>
&lt;p>&lt;a href="http://www.jon-douglas.com/2016/09/05/xamarin-android-multidex/">http://www.jon-douglas.com/2016/09/05/xamarin-android-multidex/&lt;/a>&lt;/p></description></item><item><title>Xamarin Evolve 2016 roundup</title><link>https://jimbobbennett.dev/blogs/xamarin-evolve-2016-roundup/</link><pubDate>Mon, 16 May 2016 04:27:20 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/xamarin-evolve-2016-roundup/</guid><description>&lt;p>As part of my work as a mobile developer at &lt;a href="http://eroad.co.nz">EROAD&lt;/a> I blogged about my experiences at Xamarin Evolve this year. You can read it &lt;a href="https://www.linkedin.com/pulse/xamarin-evolve-2016-roundup-jim-bennett?published=u">on LinkedIn&lt;/a>&lt;/p>
&lt;p>&lt;img src="Nat-keynote.jpg" alt="Nat at Evolve">&lt;/p></description></item><item><title>My talk from Xamarin Evolve 2016 is now on YouTube</title><link>https://jimbobbennett.dev/blogs/my-talk-from-xamarin-evolve/</link><pubDate>Wed, 11 May 2016 08:03:22 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/my-talk-from-xamarin-evolve/</guid><description>&lt;p>My talk from &lt;a href="http://evolve.xamarin.com">Xamarin Evolve 2016&lt;/a> is now up on YouTube!&lt;/p>
&lt;table style='border:0px;border-spacing:0px'>
&lt;tr style='background-color:rgba(0, 0, 0, 0)'>
&lt;td class='hide-for-small-only' style='vertical-align: top;'>&lt;span class='fa fa-quote-left' style='font-size:20px;color: rgb(238, 118, 0);'/>&lt;/td>
&lt;td>
&lt;p style='text-align:justify;color:#686868;'>Contextual awareness is a fast-growing trend in mobile development. In this session, Jim will take you through a quick overview of beacon technology, including Apple's iBeacons and Google's Eddystone, before diving into some code. We'll even build a simple app live on stage to demonstrate how you can detect and wake up beacons, as well as detect user proximity to beacons.&lt;/p>
&lt;/td>
&lt;td class='hide-for-small-only' style='vertical-align: top;'>&lt;span class='fa fa-quote-right' style='font-size:20px;color: rgb(238, 118, 0);'/>&lt;/td>
&lt;/tr>
&lt;/table>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/vQqIXKU98LI" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div></description></item><item><title>Building a Xamarin Android app - part 6</title><link>https://jimbobbennett.dev/blogs/building-a-xamarin-android-app-part-6-2/</link><pubDate>Thu, 24 Mar 2016 08:27:44 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/building-a-xamarin-android-app-part-6-2/</guid><description>&lt;p>This is the sixth part in the my series about building an Android app using Xamarin.Android. I highly recommend reading the rest of the series first.
The previous parts are:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://jimbobbennett.dev/blogs/building-an-android-app-part-1/">Creating the basic app&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://jimbobbennett.dev/blogs/building-an-android-app-part-2/">Defining our data&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://jimbobbennett.dev/blogs/building-a-xamarin-android-app-part-3/">Building view models&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://jimbobbennett.dev/blogs/building-a-xamarin-android-app-part-4/">Binding the view models to the UI&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://jimbobbennett.dev/blogs/building-a-xamarin-android-app-part-5/">Adding the add button&lt;/a>&lt;/li>
&lt;/ul>
&lt;h4 id="editing-and-deleting-our-counters">Editing and deleting our counters&lt;/h4>
&lt;p>So far we have a pretty nice but simple app - we can add new counters and increment them. The next thing we need to add is the ability to edit or delete a counter. Lets start at the bottom of our stack and work up to the UI.
We need to be able to edit or delete the counter - so we need a way to update the record or delete the row in out SQLite db, we need commands on our ViewModel to expose this, and we need a nice UI to handle the user interaction.&lt;/p>
&lt;h6 id="basic-ui-design">Basic UI design&lt;/h6>
&lt;p>Before we begin though, we should consider how the user will delete a counter, so that we can implement it in the correct way. Our recycler view showing the counters is our way to interact with them - tapping on the plus button will increment the counter, so it makes sense to use this to drive editing a counter. We already make use of tapping on the plus button, so a simple tap on the recycler view item may not be the best way to drive the edit (it would be too easy to tap the wrong thing and edit instead of incrementing the counter). Instead we can take advantage of one of Androids other UI paradigm - the long touch. If a user performs a long touch on the counter in our recycler view we can show a new activity where they can edit the name or description of the counter, or delete it (and we can re-use this screen later to show the counters history).&lt;/p>
&lt;div class="image-div" style="width: 300px;">
&lt;p>&lt;img src="AnimateLongPress.gif" alt="Gif showing the long press editing a counter">&lt;/p>
&lt;/div>
&lt;br/>
&lt;p>Lets crack on with the implementation.&lt;/p>
&lt;h6 id="database">Database&lt;/h6>
&lt;p>In our &lt;code>DatabaseHelper&lt;/code> we already have the ability to update counters using the &lt;code>AddOrUpdateCounterAsync&lt;/code> method, so all we need to do is add an async delete method that takes a counter and deletes the row from SQLite.
This needs to be added to the interface:&lt;/p>
&lt;pre tabindex="0">&lt;code>public interface IDatabaseHelper
{
Task DeleteCounterAsync(Counter counter);
...
}
&lt;/code>&lt;/pre>&lt;p>And the implementation:&lt;/p>
&lt;pre tabindex="0">&lt;code>public async Task DeleteCounterAsync(Counter counter)
{
var connection = new SQLiteAsyncConnection(_dbPath);
await connection.DeleteAsync(counter);
OnCountersChanged();
}
&lt;/code>&lt;/pre>&lt;p>After the row is deleted we also need to raise the &lt;code>CountersChanged&lt;/code> event to notify anything that is interested, such as our &lt;code>CountersViewModel&lt;/code> that the counters have changed.&lt;/p>
&lt;p>And obviously as we are good developers we need some tests for this in our Android unit test suite in the &lt;code>DatabaseHelperTests&lt;/code> fixture to cover the deleting of rows and raising the collection changed event:&lt;/p>
&lt;pre tabindex="0">&lt;code>[Test]
public void DeletingACounterShouldDeleteTheCounter()
{
var dbfile = Path.Combine(RootPath, Guid.NewGuid().ToString(&amp;#34;N&amp;#34;) + &amp;#34;.db3&amp;#34;);
DatabaseHelper.CreateDatabase(dbfile);
var db = new DatabaseHelper();
var counter = new Counter
{
Name = &amp;#34;TestCounter&amp;#34;,
Description = &amp;#34;A test counter&amp;#34;
};
var res = Task.Run(async () =&amp;gt;
{
await db.AddOrUpdateCounterAsync(counter);
return 0;
}).Result;
var counters = Task.Run(async () =&amp;gt; await db.GetAllCountersAsync()).Result;
counters.Should().HaveCount(1);
res = Task.Run(async () =&amp;gt;
{
await db.DeleteCounterAsync(counter);
return 0;
}).Result;
counters = Task.Run(async () =&amp;gt; await db.GetAllCountersAsync()).Result;
counters.Should().HaveCount(0);
}
[Test]
public void DeletingACounterShouldRaiseTheCollectionChangedEvent()
{
var dbfile = Path.Combine(RootPath, Guid.NewGuid().ToString(&amp;#34;N&amp;#34;) + &amp;#34;.db3&amp;#34;);
DatabaseHelper.CreateDatabase(dbfile);
var db = new DatabaseHelper();
var counter = new Counter
{
Name = &amp;#34;TestCounter&amp;#34;,
Description = &amp;#34;A test counter&amp;#34;
};
var res = Task.Run(async () =&amp;gt;
{
await db.AddOrUpdateCounterAsync(counter);
return 0;
}).Result;
var eventRecorder = new EventRecorder(db, nameof(DatabaseHelper.CountersChanged));
eventRecorder.RecordEvent();
res = Task.Run(async () =&amp;gt;
{
await db.DeleteCounterAsync(counter);
return 0;
}).Result;
eventRecorder.Should().HaveCount(1);
}
&lt;/code>&lt;/pre>&lt;h6 id="viewmodel">ViewModel&lt;/h6>
&lt;p>What we need here is a ViewModel that exposes properties for the name and description of our counter, as well as providing a mechanism to save or delete it. We could build a new ViewModel for this, but we already have 2 ViewModels that represent counters with various levels of functionality on them - a &lt;code>NewCounterViewModel&lt;/code> that allows the setting of the &lt;code>Name&lt;/code> and &lt;code>Description&lt;/code> properties, as well as a command to save the new counter to the database, and a &lt;code>CounterViewModel&lt;/code> that has a readonly view of the counters details with a command to increment it&amp;rsquo;s value. Ideally we should follow the &lt;a href="https://en.wikipedia.org/wiki/Don%27t_repeat_yourself">DRY principle&lt;/a> and only have one, so instead of adding a new one, lets take this opportunity of refactoring the code to have only one ViewModel, and add our new requirements to it.&lt;/p>
&lt;p>So lets take the &lt;code>CounterViewModel&lt;/code> and make this work for all our scenarios. First we need to change the &lt;code>Name&lt;/code> and &lt;code>Description&lt;/code> properties. These are currently read only and just return the value from the counter. What we&amp;rsquo;ll do with these is make them read/write properties with a property change notification and a backing field, and set them in the constructor. We don&amp;rsquo;t want to use passthrough properties, we need a backing field. This is because we want to allow the user to cancel their changes when they edit, if we pass the value straight through to the counter when we set it we will have to store the original value somewhere to allow us to revert it. It&amp;rsquo;s easier to save the values in a field and only apply them to the counter if the user saves the changes.&lt;/p>
&lt;pre tabindex="0">&lt;code>public CounterViewModel(Counter counter, IDatabaseHelper databaseHelper)
{
...
Name = counter.Name;
Description = counter.Description;
}
private string _name;
public string Name
{
get { return _name; }
set { Set(ref _name, value); }
}
private string _description;
public string Description
{
get { return _description; }
set { Set(ref _description, value); }
}
&lt;/code>&lt;/pre>&lt;p>The &lt;code>NewCounterViewModel&lt;/code> also has commands to add a new counter and navigate back. The call on the database helper to add the new counter is the same as the one we will need to use to save the edits, &lt;code>AddOrUpdateCounterAsync&lt;/code>, so lets copy the &lt;code>AddCounterCommand&lt;/code> from the &lt;code>NewCounterViewModel&lt;/code> and rename it to &lt;code>SaveCommand&lt;/code> so it can be used for both new and edits. We&amp;rsquo;ll also need to add the &lt;code>IDialogService&lt;/code> and &lt;code>INavigationService&lt;/code> to the constructor parameters so they can be used by this command.&lt;/p>
&lt;pre tabindex="0">&lt;code>public CounterViewModel(Counter counter, IDatabaseHelper databaseHelper, IDialogService dialogService, INavigationService navigationService)
{
_dialogService = dialogService;
_navigationService = navigationService;
...
}
private RelayCommand _saveCommand;
public RelayCommand SaveCommand =&amp;gt; _saveCommand ?? (_saveCommand = new RelayCommand(async () =&amp;gt; await SaveAsync()));
private async Task SaveAsync()
{
if (string.IsNullOrEmpty(Name))
{
await _dialogService.ShowError(&amp;#34;The name must be set&amp;#34;, &amp;#34;No name&amp;#34;, &amp;#34;OK&amp;#34;, null);
return;
}
if (string.IsNullOrEmpty(Description))
{
await _dialogService.ShowError(&amp;#34;The description must be set&amp;#34;, &amp;#34;No description&amp;#34;, &amp;#34;OK&amp;#34;, null);
return;
}
_counter.Name = Name;
_counter.Description = Description;
await _databaseHelper.AddOrUpdateCounterAsync(_counter);
_navigationService.GoBack();
}
&lt;/code>&lt;/pre>&lt;p>There is one code change made here as well - in the &lt;code>NewCounterViewModel&lt;/code> a new &lt;code>Counter&lt;/code> was created with the values from the properties. Here we use the &lt;code>_counter&lt;/code> field, and update the values from our properties.&lt;/p>
&lt;p>We can then add the &lt;code>GoBackCommand&lt;/code> as well.&lt;/p>
&lt;pre tabindex="0">&lt;code>private RelayCommand _goBackCommand;
public RelayCommand GoBackCommand =&amp;gt; _goBackCommand ?? (_goBackCommand = new RelayCommand(() =&amp;gt; _navigationService.GoBack()));
&lt;/code>&lt;/pre>&lt;p>Next we need to add the &lt;code>DeleteCommand&lt;/code> to expose the new delete functionality we&amp;rsquo;ve added to the database helper.&lt;/p>
&lt;pre tabindex="0">&lt;code>private RelayCommand _deleteCommand;
public RelayCommand DeleteCommand =&amp;gt; _deleteCommand ?? (_deleteCommand = new RelayCommand(async () =&amp;gt; await DeleteAsync()));
private async Task DeleteAsync()
{
if (await _dialogService.ShowMessage($&amp;#34;Are you sure you want to delete {Name}?&amp;#34;, &amp;#34;Delete counter&amp;#34;, &amp;#34;Yes&amp;#34;, &amp;#34;No&amp;#34;, null))
{
await _databaseHelper.DeleteCounterAsync(_counter);
_navigationService.GoBack();
}
}
&lt;/code>&lt;/pre>&lt;p>Nothing unexpected or new here - we show a dialog confirming with the user that they want to delete, and if they say yes delete the counter from the database and navigate back.&lt;/p>
&lt;p>To test this we also need to copy the tests from the &lt;code>NewCounterViewModelTests&lt;/code> fixture, making the relevant changes to change the type of view model that is constructed. We can then also add some tests for the &lt;code>DeleteCommand&lt;/code>, as well as ensuring the saving tests will copy the values to the counter.&lt;/p>
&lt;pre tabindex="0">&lt;code>[Test]
public void ExecutingTheSaveCommandUpdatesTheChangesOnTheCounter()
{
var counter = new Counter {Value = 10, Name = &amp;#34;Name&amp;#34;, Description = &amp;#34;Description&amp;#34;};
var vm = new CounterViewModel(counter, _mockDatabaseHelper.Object, _mockDialogService.Object, _mockNavigationService.Object);
vm.Name = &amp;#34;New Name&amp;#34;;
vm.Description = &amp;#34;New Description&amp;#34;;
vm.SaveCommand.Execute(null);
counter.Name.Should().Be(&amp;#34;New Name&amp;#34;);
counter.Description.Should().Be(&amp;#34;New Description&amp;#34;);
}
[Test]
public void ExecutingTheSaveCommandUpdatesTheCounterInTheDatabase()
{
var counter = new Counter { Value = 10, Name = &amp;#34;Name&amp;#34;, Description = &amp;#34;Description&amp;#34; };
var vm = new CounterViewModel(counter, _mockDatabaseHelper.Object, _mockDialogService.Object, _mockNavigationService.Object);
vm.Name = &amp;#34;New Name&amp;#34;;
vm.Description = &amp;#34;New Description&amp;#34;;
vm.SaveCommand.Execute(null);
_mockDatabaseHelper.Verify(d =&amp;gt; d.AddOrUpdateCounterAsync(counter));
}
[Test]
public void ExecutingTheSaveCommandNavigatesBack()
{
var vm = CreateCounterViewModel();
vm.SaveCommand.Execute(null);
_mockNavigationService.Verify(n =&amp;gt; n.GoBack());
}
[Test]
public void ExecutingTheDeleteCommandConfirmsTheDelete()
{
var vm = CreateCounterViewModel();
vm.DeleteCommand.Execute(null);
_mockDialogService.Verify(d =&amp;gt; d.ShowMessage($&amp;#34;Are you sure you want to delete {vm.Name}?&amp;#34;, &amp;#34;Delete counter&amp;#34;, &amp;#34;Yes&amp;#34;, &amp;#34;No&amp;#34;, null));
}
[Test]
public void ExecutingTheDeleteCommandAndSelectingYesOnTheDialogDeletesTheCounter()
{
var counter = new Counter { Value = 10, Name = &amp;#34;Name&amp;#34;, Description = &amp;#34;Description&amp;#34; };
var vm = new CounterViewModel(counter, _mockDatabaseHelper.Object, _mockDialogService.Object, _mockNavigationService.Object);
_mockDialogService.Setup(d =&amp;gt; d.ShowMessage($&amp;#34;Are you sure you want to delete {vm.Name}?&amp;#34;, &amp;#34;Delete counter&amp;#34;, &amp;#34;Yes&amp;#34;, &amp;#34;No&amp;#34;, null))
.ReturnsAsync(true);
vm.DeleteCommand.Execute(null);
_mockDatabaseHelper.Verify(d =&amp;gt; d.DeleteCounterAsync(counter), Times.Once);
}
[Test]
public void ExecutingTheDeleteCommandAndSelectingNoOnTheDialogDoesNotDeleteTheCounter()
{
var counter = new Counter { Value = 10, Name = &amp;#34;Name&amp;#34;, Description = &amp;#34;Description&amp;#34; };
var vm = new CounterViewModel(counter, _mockDatabaseHelper.Object, _mockDialogService.Object, _mockNavigationService.Object);
_mockDialogService.Setup(d =&amp;gt; d.ShowMessage($&amp;#34;Are you sure you want to delete {vm.Name}?&amp;#34;, &amp;#34;Delete counter&amp;#34;, &amp;#34;Yes&amp;#34;, &amp;#34;No&amp;#34;, null))
.ReturnsAsync(false);
vm.DeleteCommand.Execute(null);
_mockDatabaseHelper.Verify(d =&amp;gt; d.DeleteCounterAsync(counter), Times.Never);
}
&lt;/code>&lt;/pre>&lt;p>After doing this we can tidy up by deleting the &lt;code>NewCounterViewModel&lt;/code> and &lt;code>NewCounterViewModelTests&lt;/code> classes. We also need to make the new code work. At the moment the &lt;code>NewCounterActivity&lt;/code> uses a &lt;code>NewCounterViewModel&lt;/code>, and gets it from the &lt;code>ViewModelLocator&lt;/code>, clearing the values each time. We can delete it from the &lt;code>ViewModelLocator&lt;/code>, change the type of the &lt;code>ViewModel&lt;/code> property on the activity to be &lt;code>CounterViewModel&lt;/code>, change the command that gets called to save, and create a new one with a new counter.&lt;/p>
&lt;pre tabindex="0">&lt;code>public CounterViewModel ViewModel { get; private set; }
protected override void OnCreate(Bundle savedInstanceState)
{
...
ViewModel = GetCounterViewModel();
...
}
protected virtual CounterViewModel GetCounterViewModel()
{
return new CounterViewModel(new Counter(),
ViewModelLocator.DatabaseHelper,
ViewModelLocator.DialogService,
ViewModelLocator.NavigationService);
}
public override bool OnOptionsItemSelected(IMenuItem item)
{
switch (item.ItemId)
{
...
case Resource.Id.action_save_counter:
ViewModel.SaveCommand.Execute(null);
return true;
...
}
}
&lt;/code>&lt;/pre>&lt;p>Notice how the &lt;code>GetCounterViewModel&lt;/code> is protected and virtual? We&amp;rsquo;ll see why later when we look at creating the views.&lt;/p>
&lt;p>We then need to update the &lt;code>CountersViewModel&lt;/code> to pass the new parameters to the constructor for our &lt;code>CounterViewModel&lt;/code>. These extra parameters need to be added to the constructor so that the IoC container can populate them, then passed through once the &lt;code>CounterViewModels&lt;/code> are created.&lt;/p>
&lt;pre tabindex="0">&lt;code>public CountersViewModel(IDatabaseHelper databaseHelper, INavigationService navigationService, IDialogService dialogService)
{
_navigationService = navigationService;
_dialogService = dialogService;
...
}
public async Task LoadCountersAsync()
{
...
foreach (var counter in counters)
_counters.Add(new CounterViewModel(counter, _databaseHelper, _dialogService, _navigationService));
}
&lt;/code>&lt;/pre>&lt;p>Also here the &lt;code>CountersViewModelTests&lt;/code> should be updated to mock up these extra parameters and pass them through when constructing the &lt;code>CounterViewModels&lt;/code>.&lt;/p>
&lt;p>We&amp;rsquo;re almost there with the ViewModels part. The last thing to think about is how we are actually going to start the editing process. Android has a UI paradigm of a long press on an item in a list that leads to extra functionality, such as editing. We can use this here - the user can long press on the counters in our recycler view and we can open an edit activity. To make this work we need to add a command to our &lt;code>CounterViewModel&lt;/code> that using the &lt;code>INavigationService&lt;/code> to navigate to a new screen, passing the counter through. First we define a new key for this in our &lt;code>ViewModelLocator&lt;/code>.&lt;/p>
&lt;pre tabindex="0">&lt;code>public const string EditCounterPageKey = &amp;#34;EditCounterPage&amp;#34;;
&lt;/code>&lt;/pre>&lt;p>Then we add the command to our &lt;code>CounterViewModel&lt;/code>.&lt;/p>
&lt;pre tabindex="0">&lt;code>private RelayCommand _editCommand;
public RelayCommand EditCommand =&amp;gt; _editCommand ?? (_editCommand = new RelayCommand( Edit));
private void Edit()
{
_navigationService.NavigateTo(ViewModelLocator.EditCounterPageKey, _counter);
}
&lt;/code>&lt;/pre>&lt;p>Then we add a test to the &lt;code>CounterViewModelTests&lt;/code>.&lt;/p>
&lt;pre tabindex="0">&lt;code>[Test]
public void ExecutingTheEditCommandNavigatesToTheEditScreen()
{
var counter = new Counter();
var vm = new CounterViewModel(counter, _mockDatabaseHelper.Object, _mockDialogService.Object, _mockNavigationService.Object);
vm.EditCommand.Execute(null);
_mockNavigationService.Verify(n =&amp;gt; n.NavigateTo(ViewModelLocator.EditCounterPageKey, counter));
}
&lt;/code>&lt;/pre>&lt;p>Done. We now have everything in our ViewModels ready to start on the views.&lt;/p>
&lt;h6 id="views">Views&lt;/h6>
&lt;p>We need to do a few things with our views to get editing working - we need to handle the long press on the recycler view to launch the editing, then create a new activity and layout for the editing screen.&lt;/p>
&lt;p>Lets start with the long press. This is easy enough to implement in our existing &lt;code>CounterViewHolder&lt;/code> class - we just add an event handler and execute our command from there.&lt;/p>
&lt;pre tabindex="0">&lt;code>public CounterViewHolder(View itemView) : base(itemView)
{
..
itemView.LongClick += ItemLongClick;
}
private void ItemLongClick(object sender, View.LongClickEventArgs e)
{
_counterViewModel.EditCommand.Execute(null);
}
&lt;/code>&lt;/pre>&lt;p>Android also supports a nice animation for this - tap and see a highlight starting at the touch point and spreading out.&lt;/p>
&lt;div class="image-div" style="width: 600px;">
&lt;p>&lt;img src="AnimateLongPress-1.gif" alt="Long press animation">&lt;/p>
&lt;/div>
&lt;br/>
&lt;p>This is easy enough to implement, we just need to change the foreground of the &lt;code>CardView&lt;/code> in the &lt;code>counter_view.axml&lt;/code> layout file to use a stock Android selectable item background.&lt;/p>
&lt;pre tabindex="0">&lt;code>&amp;lt;android.support.v7.widget.CardView
...
android:foreground=&amp;#34;?android:attr/selectableItemBackground&amp;#34;&amp;gt;
&lt;/code>&lt;/pre>&lt;p>We&amp;rsquo;ve got the long click looking awesome, and we&amp;rsquo;ve got the command executing. Now lest create an activity that the command can launch. For this we can create &lt;code>EditCounterActivity&lt;/code>, and instead of deriving from &lt;code>BaseActivity&lt;/code> like all the others, instead we can derive from &lt;code>NewCounterActivity&lt;/code>. This activity already has most of what we need - it has a layout that shows the name and description in edit controls which we can reuse, it has a save button, it uses the right ViewModel type. All we need to change when we override it is how it creates the ViewModel, and add an extra menu item for the delete button.&lt;/p>
&lt;p>Remember earlier we created a protected virtual method in the &lt;code>NewCounterActvity&lt;/code> that creates a new &lt;code>CounterViewModel&lt;/code>? Well the reason for creating it as a virtual is that we can override it in our &lt;code>EditCounterViewModel&lt;/code> and create a new one wrapping the counter passed to our navigation call in the &lt;code>EditCommand&lt;/code> of the &lt;code>CounterViewModel&lt;/code>.&lt;/p>
&lt;pre tabindex="0">&lt;code>protected override CounterViewModel GetCounterViewModel()
{
var navigationService = ViewModelLocator.NavigationService;
var counter = (Counter) ((AppCompatNavigationService) navigationService).GetAndRemoveParameter(Intent);
return new CounterViewModel(counter,
ViewModelLocator.DatabaseHelper,
ViewModelLocator.DialogService,
navigationService);
}
&lt;/code>&lt;/pre>&lt;p>We have to cate the &lt;code>INavigationService&lt;/code> to a &lt;code>AppCompatNavigationService&lt;/code> to get data out of it. This is because data passing is very platform specific, we need to give it the &lt;code>Intent&lt;/code> that was used to launch the activity so that it can get the data out, and this is Android specific. The interface is designed to be portable so contains no platform specific code, so we cast to the Android variant to get the data out.&lt;/p>
&lt;p>Next we need the delete button on the menu. For this we need a new menu called &lt;code>edit_counter_menu.xml&lt;/code> containing this button.&lt;/p>
&lt;pre tabindex="0">&lt;code>&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;utf-8&amp;#34; ?&amp;gt;
&amp;lt;menu xmlns:android=&amp;#34;http://schemas.android.com/apk/res/android&amp;#34;
xmlns:app=&amp;#34;http://schemas.android.com/apk/res-auto&amp;#34;&amp;gt;
&amp;lt;item android:id=&amp;#34;@+id/action_delete_counter&amp;#34;
app:showAsAction=&amp;#34;always&amp;#34;
android:icon=&amp;#34;@drawable/ic_delete_white_48dp&amp;#34;/&amp;gt;
&amp;lt;/menu&amp;gt;
&lt;/code>&lt;/pre>&lt;p>Th image here, &lt;code>ic_delete_white_48dp&lt;/code> is once again dowloaded from &lt;a href="https://design.google.com/icons/">Google&amp;rsquo;s material icons&lt;/a> and dropped into all the drawable folders.&lt;/p>
&lt;p>In our activity we now need to create the menu, and handle when it gets pressed.&lt;/p>
&lt;pre tabindex="0">&lt;code>public override bool OnCreateOptionsMenu(IMenu menu)
{
base.OnCreateOptionsMenu(menu);
Toolbar.InflateMenu(Resource.Menu.edit_counter_menu);
return true;
}
public override bool OnOptionsItemSelected(IMenuItem item)
{
switch (item.ItemId)
{
case Resource.Id.action_delete_counter:
ViewModel.DeleteCommand.Execute(null);
return true;
default:
return base.OnOptionsItemSelected(item);
}
}
&lt;/code>&lt;/pre>&lt;p>These work the same way as the &lt;code>NewCounterActivity&lt;/code> described in an earlier post.. The base calls in both these methods call down to the &lt;code>NewCounterActivity&lt;/code> so that the original menu with the save button is created and handled.&lt;/p>
&lt;p>The last little but we need to do is a UI tweak. The &lt;code>NewCounterActivity&lt;/code> sets the title to &lt;strong>New Counter&lt;/strong>, but it would look nicer if we show that we are editing a counter. Also by default Android will set the focus on the first edit view, where MVVMLight sets the text, the focus ends up at the start of the text instead of the end. We can get round this by calling &lt;code>SetSelection&lt;/code> on the &lt;code>Name&lt;/code> edit view in our &lt;code>OnCreate&lt;/code> method after we bind the data in the base &lt;code>OnCreate&lt;/code> method.&lt;/p>
&lt;pre tabindex="0">&lt;code>protected override void OnCreate(Bundle savedInstanceState)
{
base.OnCreate(savedInstanceState);
Title = $&amp;#34;Edit {ViewModel.Name}&amp;#34;;
Name.SetSelection(Name.Text.Length);
}
&lt;/code>&lt;/pre>&lt;p>The last thing we need to do is wire up this activity to the new key we created for navigation in the &lt;code>ViewModelLocator&lt;/code>. All our wire ups are done in the &lt;code>MainActivity&lt;/code> so lets add another entry.&lt;/p>
&lt;pre tabindex="0">&lt;code>public MainActivity()
{
...
navigationService.Configure(ViewModelLocator.EditCounterPageKey, typeof(EditCounterActivity));
}
&lt;/code>&lt;/pre>&lt;p>Done!&lt;/p>
&lt;h6 id="lets-try-it-all-out">Lets try it all out&lt;/h6>
&lt;p>We have our database code written, we have our ViewModels working and our UI wired up. Lets try it out.&lt;/p>
&lt;div class="image-div" style="width: 400px;">
&lt;p>&lt;img src="AnimateLongPress-2.gif" alt="Edit and delete demo">&lt;/p>
&lt;/div>
&lt;br/>
&lt;p>The code for this can be found in GitHub on the Part6 branch at &lt;a href="https://github.com/jimbobbennett/StupendousCounter/tree/Part6">https://github.com/jimbobbennett/StupendousCounter/tree/Part6&lt;/a>&lt;/p>
&lt;p>In the next part we&amp;rsquo;ll look at showing the history information that we&amp;rsquo;re storing against each counter.&lt;/p></description></item><item><title>Installing Google Apps in a Marshmallow emulator</title><link>https://jimbobbennett.dev/blogs/installing-google-apps-in-a-virtual-machine/</link><pubDate>Tue, 01 Mar 2016 08:49:37 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/installing-google-apps-in-a-virtual-machine/</guid><description>&lt;p>I&amp;rsquo;ve been trying to play with the &lt;a href="https://developers.google.com/nearby/messages/overview">Google Nearby Message API&lt;/a> recently as this has capabilities to talk to Eddystone beacons. The problem I&amp;rsquo;ve come up against is that the example code uses the new Marshmallow permissions so I&amp;rsquo;m having a bit of a headache getting it working.&lt;/p>
&lt;p>I&amp;rsquo;ve got a Tesco Hudl 2 as my only physical device, and thanks to the annoying way Android is repackaged by each hardware provider I can&amp;rsquo;t update it past Lollipop.&lt;/p>
&lt;p>The other option is an emulator, but these need Google Play services to enable the Nearby APIs.&lt;/p>
&lt;p>You&amp;rsquo;d think this would be easy, it&amp;rsquo;s a pretty normal thing to do. Unfortunately it&amp;rsquo;s not so easy. All the emulators don&amp;rsquo;t come with these by default, which seems a strange oversight. Instead you need to install them later. Again, you&amp;rsquo;d expect this to be simple. But it&amp;rsquo;s not - at least not for Marshmallow. It&amp;rsquo;s taken about 6 hours of downloading, trying and googling to get it working.&lt;/p>
&lt;p>So here&amp;rsquo;s how. All links mentioned are working at the time of writing.&lt;/p>
&lt;p>First, install &lt;a href="https://www.genymotion.com">GenyMotion&lt;/a>. Normally I would be extolling the virtues of Xamarin Android Player, but in this case I could not get their Marshmallow preview to work by following the Xamarin instructions.&lt;/p>
&lt;p>Next create a new virtual device - I&amp;rsquo;ve been using the &lt;strong>Google Nexus 5X - 6.0.0 - API 23 - 1080x1920&lt;/strong> image. Start this up.&lt;/p>
&lt;p>Then you need to install an ARM translator, this is available &lt;a href="https://www.androidfilehost.com/?fid=23252070760974384">here&lt;/a>. Download it, drag it on to the running emulator. A dialog will pop up asking if you want to flash the ROM, click yes and let it install. Once done reboot the device from the ADB command prompt using the command:&lt;/p>
&lt;pre tabindex="0">&lt;code>adb reboot
&lt;/code>&lt;/pre>&lt;p>Then close and re-open the emulator.&lt;/p>
&lt;p>After the translator you need to install the Lollipop version of the Google Apps package from &lt;a href="https://www.androidfilehost.com/?fid=96042739161891406">here&lt;/a>. Yup - the Lollipop version. Same as for the translator, drag it on, click yes, then reboot using ADB once done.&lt;/p>
&lt;p>Once the Google Apps are installed, from Settings -&amp;gt; Accounts log in with your Google account.&lt;/p>
&lt;p>Now update to the Google Apps for Marshmallow, which is available &lt;a href="https://www.androidfilehost.com/?fid=24052804347835438">here&lt;/a>. Install, reboot as before. It&amp;rsquo;s important that you log in &lt;strong>before&lt;/strong> installing the Marshmallow version, otherwise logging in just won&amp;rsquo;t work.&lt;/p>
&lt;p>Now you can launch the Google Play Store and install and update apps as required.&lt;/p>
&lt;p>Done - An overly complicated solution to what should be a simple thing.&lt;/p>
&lt;div class="image-div" style="width: 500px;">
&lt;p>&lt;img src="Screen-Shot-2016-03-01-at-21-52-13.png" alt="Google Play Store running in an emulator">&lt;/p>
&lt;/div>
&lt;hr/>
&lt;h4 id="update">Update&lt;/h4>
&lt;p>A much better description with proper credit to everyone involved is up here, courtesy of &lt;a href="https://twitter.com/Cheesebaron">@cheesebaron&lt;/a>:&lt;/p>
&lt;p>&lt;a href="http://blog.ostebaronen.dk/2016/04/installing-gapps-in-visual-studio.html">http://blog.ostebaronen.dk/2016/04/installing-gapps-in-visual-studio.html&lt;/a>&lt;/p></description></item><item><title>Building a Xamarin Android app - part 5</title><link>https://jimbobbennett.dev/blogs/building-a-xamarin-android-app-part-5/</link><pubDate>Thu, 18 Feb 2016 08:59:14 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/building-a-xamarin-android-app-part-5/</guid><description>&lt;p>This is the fifth part in the my series about building an Android app using Xamarin.Android. I highly recommend reading these first.
The previous parts are:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://jimbobbennett.dev/blogs/building-an-android-app-part-1/">Creating the basic app&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://jimbobbennett.dev/blogs/building-an-android-app-part-2/">Defining our data&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://jimbobbennett.dev/blogs/building-a-xamarin-android-app-part-3/">Building view models&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://jimbobbennett.dev/blogs/building-a-xamarin-android-app-part-4/">Binding the view models to the UI&lt;/a>&lt;/li>
&lt;/ul>
&lt;h4 id="adding-the-add-button">Adding the Add button&lt;/h4>
&lt;p>Currently we have a nice recycler view showing our dummy counters in card views. So the next step is to allow new counters to be added. The current way to add new items is using a floating action button - a button at the bottom of the screen that when pressed will add the new counter.&lt;/p>
&lt;div class="image-div" style="width: 300px;">
&lt;p>&lt;img src="floating-add-button.png" alt="Floating add button">&lt;/p>
&lt;/div>
&lt;br/>
&lt;p>First thing to do is add it to the layout in &lt;code>counters_fragment.axml&lt;/code>. At the moment this contains a &lt;code>LinearLayout&lt;/code> but we&amp;rsquo;ll need to change that to a &lt;code>FrameLayout&lt;/code> so that the add button is correctly placed on top. We&amp;rsquo;re not using a normal button here, but a &lt;code>FloatingActionButton&lt;/code>, a button designed to float above other controls in the view. This means we can add a load of counters and scroll the recycler view up and down without the add button moving from it&amp;rsquo;s floating location in the bottom right.&lt;/p>
&lt;pre tabindex="0">&lt;code>&amp;lt;FrameLayout xmlns:android=&amp;#34;http://schemas.android.com/apk/res/android&amp;#34;
xmlns:app=&amp;#34;http://schemas.android.com/apk/res-auto&amp;#34;
android:layout_width=&amp;#34;fill_parent&amp;#34;
android:layout_height=&amp;#34;fill_parent&amp;#34;&amp;gt;
&amp;lt;android.support.v7.widget.RecyclerView
android:id=&amp;#34;@+id/countersRecyclerView&amp;#34;
android:scrollbars=&amp;#34;vertical&amp;#34;
android:layout_width=&amp;#34;fill_parent&amp;#34;
android:layout_height=&amp;#34;fill_parent&amp;#34;
android:background=&amp;#34;@color/divider&amp;#34; /&amp;gt;
&amp;lt;android.support.design.widget.FloatingActionButton
android:id=&amp;#34;@+id/floatingAddNewCounterButton&amp;#34;
android:layout_width=&amp;#34;wrap_content&amp;#34;
android:layout_height=&amp;#34;wrap_content&amp;#34;
android:layout_gravity=&amp;#34;bottom|right&amp;#34;
android:layout_margin=&amp;#34;16dp&amp;#34;
android:elevation=&amp;#34;4dp&amp;#34;
android:scaleType=&amp;#34;fitXY&amp;#34;
android:src=&amp;#34;@drawable/ic_add_white_24dp&amp;#34;
app:borderWidth=&amp;#34;0dp&amp;#34; /&amp;gt;
&amp;lt;/FrameLayout&amp;gt;
&lt;/code>&lt;/pre>&lt;p>The icon being used here, &lt;code>ic_add_white_24dp&lt;/code>, also comes from Googles material icons at &lt;a href="https://design.google.com/icons/">https://design.google.com/icons/&lt;/a>. Its a 24dp icon, the recommended size for floating action buttons. We don&amp;rsquo;t need to set the colour of the action button, this automatically comes from the colours we added from Material Palette in &lt;a href="https://jimbobbennett.dev/blogs/building-an-android-app-part-1/">part 1&lt;/a>.&lt;/p>
&lt;h4 id="adding-navigation">Adding navigation&lt;/h4>
&lt;p>Now we have the add button, we need to think about what it needs to do. We need this button to navigate to another activity where the user can enter details about the new counter and save it. MVVMLight has a nice navigation system but we are limited in how we can use it because we are using AppCompat. Luckily I&amp;rsquo;ve already created a workaround which is documented &lt;a href="https://jimbobbennett.dev/blogs/mvvmlight-navigation-and-appcompatactivity/">on another blog post here&lt;/a>. To add this working navigation we just need to add &lt;a href="https://www.nuget.org/packages/JimBobBennett.MvvmLight.AppCompat/">the MVVMLight.AppCompat nuget package&lt;/a>, and set it up. We start with the set up by changing our &lt;code>BaseActivity&lt;/code> to derive from &lt;code>AppCompatActivityBase&lt;/code>.&lt;/p>
&lt;pre tabindex="0">&lt;code>public abstract class BaseActivity : AppCompatActivityBase
&lt;/code>&lt;/pre>&lt;p>Then we need to register the navigation and dialog services with the IoC container. The concrete implementations of the services are platform specific, so we can&amp;rsquo;t simply register them in the view model locator. Instead we have to expose methods to allow the registration to happen externally so that we can call it from our Android project. The following methods to register need to be added to the &lt;code>ViewModelLoator&lt;/code>:&lt;/p>
&lt;pre tabindex="0">&lt;code>public static void RegisterNavigationService(INavigationService navigationService)
{
SimpleIoc.Default.Register(() =&amp;gt; navigationService);
}
public static void RegisterDialogService(IDialogService dialogService)
{
SimpleIoc.Default.Register(() =&amp;gt; dialogService);
}
&lt;/code>&lt;/pre>&lt;p>These are then called from our &lt;code>MainActivity&lt;/code> in a new constructor:&lt;/p>
&lt;pre tabindex="0">&lt;code>public MainActivity()
{
var navigationService = new AppCompatNavigationService();
ViewModelLocator.RegisterNavigationService(navigationService);
ViewModelLocator.RegisterDialogService(new AppCompatDialogService());
}
&lt;/code>&lt;/pre>&lt;p>Whilst we&amp;rsquo;re editing the &lt;code>MainActivity&lt;/code> it makes sense to delete the dummy counter code as well - seeing as we are adding the ability to add new counters we don&amp;rsquo;t need to pre-populate the app with fake counters. Just delete the &lt;code>AddDummyData&lt;/code> method and the call to it.&lt;/p>
&lt;h4 id="creating-the-new-counter">Creating the new counter&lt;/h4>
&lt;p>To create the new counter we need to define a new activity to allow the user to enter details about the counter. This activity needs a layout, a view model and to be wired into the navigation so that we can navigate to it from our new add button.&lt;/p>
&lt;h6 id="layout">Layout&lt;/h6>
&lt;p>Lets start with the layout. This needs to have text boxes so the user can enter the name and description for the counter, along with a button to create the new counter. We&amp;rsquo;re not going to bother with a cancel option - the UI will require the create button to be clicked to create the counter with back acting as a cancel, either the back button on the tool bar or the hardware back button.&lt;/p>
&lt;pre tabindex="0">&lt;code>&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;utf-8&amp;#34;?&amp;gt;
&amp;lt;LinearLayout xmlns:android=&amp;#34;http://schemas.android.com/apk/res/android&amp;#34;
xmlns:app=&amp;#34;http://schemas.android.com/apk/res-auto&amp;#34;
android:orientation=&amp;#34;vertical&amp;#34;
android:layout_width=&amp;#34;match_parent&amp;#34;
android:layout_height=&amp;#34;match_parent&amp;#34;&amp;gt;
&amp;lt;android.support.design.widget.AppBarLayout
android:layout_height=&amp;#34;wrap_content&amp;#34;
android:layout_width=&amp;#34;match_parent&amp;#34;
android:id=&amp;#34;@+id/toolbar_layout&amp;#34;&amp;gt;
&amp;lt;include
android:id=&amp;#34;@+id/toolbar&amp;#34;
layout=&amp;#34;@layout/toolbar&amp;#34;
app:layout_scrollFlags=&amp;#34;scroll|enterAlways&amp;#34; /&amp;gt;
&amp;lt;/android.support.design.widget.AppBarLayout&amp;gt;
&amp;lt;LinearLayout
android:orientation=&amp;#34;vertical&amp;#34;
android:layout_width=&amp;#34;match_parent&amp;#34;
android:layout_height=&amp;#34;match_parent&amp;#34;
android:padding=&amp;#34;24dp&amp;#34;&amp;gt;
&amp;lt;android.support.design.widget.TextInputLayout
android:layout_width=&amp;#34;match_parent&amp;#34;
android:layout_height=&amp;#34;wrap_content&amp;#34;
android:layout_marginBottom=&amp;#34;24dp&amp;#34;&amp;gt;
&amp;lt;EditText
android:id=&amp;#34;@+id/new_counter_name&amp;#34;
android:layout_width=&amp;#34;fill_parent&amp;#34;
android:layout_height=&amp;#34;wrap_content&amp;#34;
android:hint=&amp;#34;Name&amp;#34; /&amp;gt;
&amp;lt;/android.support.design.widget.TextInputLayout&amp;gt;
&amp;lt;android.support.design.widget.TextInputLayout
android:layout_width=&amp;#34;match_parent&amp;#34;
android:layout_height=&amp;#34;wrap_content&amp;#34;
android:layout_marginBottom=&amp;#34;24dp&amp;#34;&amp;gt;
&amp;lt;EditText
android:id=&amp;#34;@+id/new_counter_description&amp;#34;
android:layout_width=&amp;#34;fill_parent&amp;#34;
android:layout_height=&amp;#34;wrap_content&amp;#34;
android:hint=&amp;#34;Description&amp;#34; /&amp;gt;
&amp;lt;/android.support.design.widget.TextInputLayout&amp;gt;
&amp;lt;Button
android:text=&amp;#34;Create Counter&amp;#34;
android:layout_width=&amp;#34;match_parent&amp;#34;
android:layout_height=&amp;#34;wrap_content&amp;#34;
android:id=&amp;#34;@+id/new_counter_create&amp;#34; /&amp;gt;
&amp;lt;/LinearLayout&amp;gt;
&amp;lt;/LinearLayout&amp;gt;
&lt;/code>&lt;/pre>&lt;p>This is a standard app bar layout showing the toolbar, same as the main layout, with text boxes for the name and description, and a &amp;lsquo;Create Counter&amp;rsquo; button. The cool thing we&amp;rsquo;re doing here is the edit boxes. We&amp;rsquo;re not just using a boring label with a text box below, instead we&amp;rsquo;re using a &lt;code>TextInputLayout&lt;/code>. This wraps the &lt;code>EditText&lt;/code> so you see a hint inside the text box, then when you touch inside to enter the text the hint moves to above the box.&lt;/p>
&lt;div class="image-div" style="width: 300px;">
&lt;p>&lt;img src="Hint.gif" alt="Hint inside the text input layout">&lt;/p>
&lt;/div>
&lt;br/>
&lt;h6 id="view-model">View model&lt;/h6>
&lt;p>Before we create an activity to show this layout, lets create the view model. We start by creating the &lt;code>NewCounterViewModel&lt;/code> in our &lt;code>ViewModel&lt;/code> folder. The first part of this is to create the properties to hold the name and description fields.&lt;/p>
&lt;pre tabindex="0">&lt;code>public class NewCounterViewModel : ViewModelBase
{
private string _name;
public string Name
{
get { return _name; }
set { Set(() =&amp;gt; Name, ref _name, value); }
}
private string _description;
public string Description
{
get { return _description; }
set { Set(() =&amp;gt; Description, ref _description, value); }
}
}
&lt;/code>&lt;/pre>&lt;p>This view model is derived from &lt;code>ViewModelBase&lt;/code>, and the property setters use the base class &lt;code>Set&lt;/code> method to not only set the value but to raise the relevant property change event.&lt;/p>
&lt;p>Now we have the data part sorted, it&amp;rsquo;s time to add some commands.&lt;/p>
&lt;pre tabindex="0">&lt;code>public class NewCounterViewModel : ViewModelBase
{
private readonly IDatabaseHelper _databaseHelper;
private readonly IDialogService _dialogService;
private readonly INavigationService _navigationService;
public NewCounterViewModel(IDatabaseHelper databaseHelper, IDialogService dialogService, INavigationService navigationService)
{
_databaseHelper = databaseHelper;
_dialogService = dialogService;
_navigationService = navigationService;
}
private RelayCommand _goBackCommand;
public RelayCommand GoBackCommand =&amp;gt; _goBackCommand ?? (_goBackCommand = new RelayCommand(() =&amp;gt; _navigationService.GoBack()));
private RelayCommand _addCounterCommand;
public RelayCommand AddCounterCommand =&amp;gt; _addCounterCommand ?? (_addCounterCommand = new RelayCommand(async () =&amp;gt; await AddCounter()));
private async Task AddCounter()
{
if (string.IsNullOrEmpty(Name))
{
await _dialogService.ShowError(&amp;#34;The name must be set&amp;#34;, &amp;#34;No name&amp;#34;, &amp;#34;OK&amp;#34;, null);
return;
}
if (string.IsNullOrEmpty(Description))
{
await _dialogService.ShowError(&amp;#34;The description must be set&amp;#34;, &amp;#34;No description&amp;#34;, &amp;#34;OK&amp;#34;, null);
return;
}
await _databaseHelper.AddOrUpdateCounterAsync(new Counter {Name = Name, Description = Description});
_navigationService.GoBack();
}
}
&lt;/code>&lt;/pre>&lt;p>This adds two commands.&lt;br>
The first is the &lt;code>GoBackCommand&lt;/code>, which will be wired up to the toolbars back button. This uses the navigation service that is injected into the constructor to navigate back - under the hood this pops the current activity off the stack and returns to the previous one, the same as the hardware back button.
The second command, &lt;code>AddCounterCommand&lt;/code> will create and add a new command. It starts with some simple validation to ensure the values are set, and if not raises an alert using the MVVMLight dialog service injected into the constructor. If this validation is passed the new counter is created, added to the database using the database helper injected into the constructor, and the activity is popped off the stack using the navigation service.&lt;/p>
&lt;p>Like all good coders we should be testing our view model, so lets add &lt;code>NewCounterViewModelTests&lt;/code> to the test project.&lt;/p>
&lt;pre tabindex="0">&lt;code>[TestFixture]
public class NewCounterViewModelTests
{
private Mock&amp;lt;IDatabaseHelper&amp;gt; _mockDatabaseHelper;
private Mock&amp;lt;IDialogService&amp;gt; _mockDialogService;
private Mock&amp;lt;INavigationService&amp;gt; _mockNavigationService;
[SetUp]
public void SetUp()
{
_mockDatabaseHelper = new Mock&amp;lt;IDatabaseHelper&amp;gt;();
_mockDialogService = new Mock&amp;lt;IDialogService&amp;gt;();
_mockNavigationService = new Mock&amp;lt;INavigationService&amp;gt;();
}
[Test]
public void SettingTheNameRaisesAPropertyChangedEvent()
{
var vm = new NewCounterViewModel(_mockDatabaseHelper.Object, _mockDialogService.Object, _mockNavigationService.Object);
vm.MonitorEvents();
vm.Name = &amp;#34;Foo&amp;#34;;
vm.ShouldRaisePropertyChangeFor(v =&amp;gt; v.Name);
}
[Test]
public void SettingTheDescriptionRaisesAPropertyChangedEvent()
{
var vm = new NewCounterViewModel(_mockDatabaseHelper.Object, _mockDialogService.Object, _mockNavigationService.Object);
vm.MonitorEvents();
vm.Description = &amp;#34;Foo&amp;#34;;
vm.ShouldRaisePropertyChangeFor(v =&amp;gt; v.Description);
}
[Test]
public void GoBackCommandNavigatesBackwards()
{
var vm = new NewCounterViewModel(_mockDatabaseHelper.Object, _mockDialogService.Object, _mockNavigationService.Object);
vm.GoBackCommand.Execute(null);
_mockNavigationService.Verify(n =&amp;gt; n.GoBack(), Times.Once);
}
[Test]
public void AddCommandRaisesAnErrorIfTheNameIsNotSet()
{
var vm = new NewCounterViewModel(_mockDatabaseHelper.Object, _mockDialogService.Object, _mockNavigationService.Object);
vm.Description = &amp;#34;Bar&amp;#34;;
vm.AddCounterCommand.Execute(null);
_mockDialogService.Verify(d =&amp;gt; d.ShowError(It.IsAny&amp;lt;string&amp;gt;(), It.IsAny&amp;lt;string&amp;gt;(), It.IsAny&amp;lt;string&amp;gt;(), null), Times.Once);
_mockDatabaseHelper.Verify(d =&amp;gt; d.AddOrUpdateCounterAsync(It.IsAny&amp;lt;Counter&amp;gt;()), Times.Never);
}
[Test]
public void AddCommandRaisesAnErrorIfTheDescriptionIsNotSet()
{
var vm = new NewCounterViewModel(_mockDatabaseHelper.Object, _mockDialogService.Object, _mockNavigationService.Object);
vm.Name = &amp;#34;Foo&amp;#34;;
vm.AddCounterCommand.Execute(null);
_mockDialogService.Verify(d =&amp;gt; d.ShowError(It.IsAny&amp;lt;string&amp;gt;(), It.IsAny&amp;lt;string&amp;gt;(), It.IsAny&amp;lt;string&amp;gt;(), null), Times.Once);
_mockDatabaseHelper.Verify(d =&amp;gt; d.AddOrUpdateCounterAsync(It.IsAny&amp;lt;Counter&amp;gt;()), Times.Never);
}
[Test]
public void AddComandAddsTheCounterAndNavigatesBack()
{
var vm = new NewCounterViewModel(_mockDatabaseHelper.Object, _mockDialogService.Object, _mockNavigationService.Object);
vm.Name = &amp;#34;Foo&amp;#34;;
vm.Description = &amp;#34;Bar&amp;#34;;
vm.AddCounterCommand.Execute(null);
_mockDialogService.Verify(d =&amp;gt; d.ShowError(It.IsAny&amp;lt;string&amp;gt;(), It.IsAny&amp;lt;string&amp;gt;(), It.IsAny&amp;lt;string&amp;gt;(), null), Times.Never);
_mockDatabaseHelper.Verify(d =&amp;gt; d.AddOrUpdateCounterAsync(It.IsAny&amp;lt;Counter&amp;gt;()), Times.Once);
_mockNavigationService.Verify(n =&amp;gt; n.GoBack(), Times.Once);
}
}
&lt;/code>&lt;/pre>&lt;p>Because we&amp;rsquo;re using dependency injection we can mock all the interfaces that are injected into the view model. This means we can test the behaviour of the commands ensuring the &lt;code>GoBackCommand&lt;/code> calls the relevant &lt;code>GoBack&lt;/code> method on the navigation service, that the navigation doesn&amp;rsquo;t happen if we add a counter with data missing and that if all the information is there the counter gets added to the database. We can also check that setting the properties raises the relevant property change events. We can get pretty awesome coverage here to ensure out view model works.&lt;/p>
&lt;p>The last thing to do with the view model is to add it to our locator. We need this so that the IoC container can resolve the constructor injection.&lt;/p>
&lt;pre tabindex="0">&lt;code>static ViewModelLocator()
{
...
SimpleIoc.Default.Register&amp;lt;NewCounterViewModel&amp;gt;();
}
public const string NewCounterPageKey = &amp;#34;NewCounterPage&amp;#34;;
public static NewCounterViewModel NewCounter =&amp;gt; ServiceLocator.Current.GetInstance&amp;lt;NewCounterViewModel&amp;gt;();
&lt;/code>&lt;/pre>&lt;p>Here we register it with the IoC container in the constructor. Unfortunately SimpleIoC only supports singletons, so we have to always deal with a single instance - something we will have to consider later on.
Once registered we can expose a static property to return the instance, and a constant that defines a key for it. This key will be registered with the navigation service once we have defined the activity.&lt;/p>
&lt;h6 id="activity">Activity&lt;/h6>
&lt;p>We have our layout and we have our view model, so now we can create the Activity that brings it all together.&lt;/p>
&lt;p>Lets start with the basics:&lt;/p>
&lt;pre tabindex="0">&lt;code>[Activity(Label = &amp;#34;New Counter&amp;#34;)]
public class NewCounterActivity : BaseActivity
{
protected override int LayoutResource =&amp;gt; Resource.Layout.new_counter;
public override bool OnOptionsItemSelected(IMenuItem item)
{
if (item.ItemId == Android.Resource.Id.Home)
{
ViewModel.GoBackCommand.Execute(null);
return true;
}
return base.OnOptionsItemSelected(item);
}
}
&lt;/code>&lt;/pre>&lt;p>Here we&amp;rsquo;re creating the activity, derived from our &lt;code>BaseActivity&lt;/code>. We override the &lt;code>LayoutResource&lt;/code> to point to our new layout. We also override &amp;lsquo;OnOptionsItemSelected&amp;rsquo; to detect if the &lt;code>Home&lt;/code> button is pressed, executing the command on our view model to navigate backwards.&lt;/p>
&lt;p>Next we need to wire up the &lt;code>NewCounterViewModel&lt;/code>. We do this in the &lt;code>OnCreate&lt;/code> method and store it in a public property (more on this later). As mentioned earlier the IoC container only stores singletons, so we need to clear the data before we can use it to stop the view showing the name and description of the previous counter that was added.&lt;/p>
&lt;pre tabindex="0">&lt;code>public NewCounterViewModel ViewModel { get; private set; }
protected override void OnCreate(Bundle savedInstanceState)
{
base.OnCreate(savedInstanceState);
ViewModel = ViewModelLocator.NewCounter;
ViewModel.Name = string.Empty;
ViewModel.Description = string.Empty;
}
&lt;/code>&lt;/pre>&lt;p>Then we need to add public properties for the controls on our view.&lt;/p>
&lt;pre tabindex="0">&lt;code>private EditText _name;
public EditText Name =&amp;gt; _name ?? (_name = FindViewById&amp;lt;EditText&amp;gt;(Resource.Id.new_counter_name));
private EditText _description;
public EditText Description =&amp;gt; _description ?? (_description = FindViewById&amp;lt;EditText&amp;gt;(Resource.Id.new_counter_description));
private Button _createCounter;
public Button CreateCounter =&amp;gt; _createCounter ?? (_createCounter = FindViewById&amp;lt;Button&amp;gt;(Resource.Id.new_counter_create));
&lt;/code>&lt;/pre>&lt;p>These properties will resolve the widgets by looking for them in the layout, and once found stored in a field so we only need to do one lookup.&lt;/p>
&lt;p>Lastly we need to bind the controls to the properties on the view model using the MVVMLight binding mechanism. And this is where the public visibility of the properties comes into play.&lt;/p>
&lt;pre tabindex="0">&lt;code>private readonly List&amp;lt;Binding&amp;gt; _bindings = new List&amp;lt;Binding&amp;gt;();
protected override void OnCreate(Bundle savedInstanceState)
{
...
Bind();
}
private void Bind()
{
_bindings.Add(this.SetBinding(() =&amp;gt; ViewModel.Name, () =&amp;gt; Name.Text, BindingMode.TwoWay));
_bindings.Add(this.SetBinding(() =&amp;gt; ViewModel.Description, () =&amp;gt; Description.Text, BindingMode.TwoWay));
CreateCounter.SetCommand(nameof(Button.Click), ViewModel.AddCounterCommand);
}
&lt;/code>&lt;/pre>&lt;p>In out &lt;code>OnCreate&lt;/code> method we call a new method, &lt;code>Bind&lt;/code>, that uses MVVMLight to bind up the properties. MVVMLight has extension methods for binding properties and commands. We call &lt;code>SetBinding&lt;/code> passing in an expression that points to the source for the binding, an expression that points to the target, and the binding mode.&lt;/p>
&lt;p>Behind the scenes the &lt;code>SetBinding&lt;/code> method will resolve the expressions to the public properties on the object that the extension method is called on. So for example in the first binding it looks at the source expression and finds the &lt;code>ViewModel&lt;/code> property (remember from before that we made this property public), and on that view model finds the &lt;code>Name&lt;/code> property. It then looks at the target expression and resolves the public &lt;code>Name&lt;/code> property on the Activity (the EditText public property we added earlier). It will start by copying the value from the source by evaluating the &lt;code>ViewModel.Name&lt;/code> property and setting it on the &lt;code>Name.Text&lt;/code> property. Then based on the binding mode it will wire up listeners for value changes. We&amp;rsquo;re using &lt;code>BindingMode.TwoWay&lt;/code> so we need a two-way binding - changes in the source update the target and changes in the target update the source. This means the binding will listen for property change events on the &lt;code>ViewModel&lt;/code> and if one is raised for the &lt;code>Name&lt;/code> property it will update the control, and it will listen for changes to the text of the &lt;code>Name&lt;/code> edit text control, and if the test changes it will update the view model.
The &lt;code>SetBinding&lt;/code> creates a weak binding, so we need to keep a reference to it to stop the garbage collector from cleaning up. This is what the &lt;code>_bindings&lt;/code> list is for.&lt;/p>
&lt;p>As well as binding the properties, we need to bind the command. This is done using the &lt;code>SetCommand&lt;/code> extension method. This takes the name of the event and a command to bind to. It will find the event with the given name on the object the extension method is called on, and when that event is fired it will execute the command. It also checks the &lt;code>CanExecute&lt;/code> status of the command and will enable or disable the button depending on the value. This is a nice way to enable or disable UI functionality from the view model.&lt;/p>
&lt;p>Almost there - we now have an activity with a UI and a view model. Now we need to navigate to it.&lt;/p>
&lt;h6 id="navigating-to-the-new-activity">Navigating to the new activity&lt;/h6>
&lt;p>Navigation in MVVMLight is based around the idea of registering an activity against a key in your platform specific code, and navigating to that key in the portable code.
Registration happens when we first register the navigation service in the &lt;code>MainActivity&lt;/code> constructor. We call the &lt;code>Configure&lt;/code> method passing in the key we defined in our &lt;code>ViewModelLocator&lt;/code> earlier, and the type of Activity we want created when we navigate to this key.&lt;/p>
&lt;pre tabindex="0">&lt;code>public MainActivity()
{
....
var navigationService = new AppCompatNavigationService();
navigationService.Configure(ViewModelLocator.NewCounterPageKey, typeof(NewCounterActivity));
...
}
&lt;/code>&lt;/pre>&lt;p>We can then add a command to the &lt;code>CountersViewModel&lt;/code> to do this navigation using an injected &lt;code>INavigationService&lt;/code>.&lt;/p>
&lt;pre tabindex="0">&lt;code>public CountersViewModel(IDatabaseHelper databaseHelper, INavigationService navigationService)
{
...
_navigationService = navigationService;
...
}
private RelayCommand _addNewCounterCommand;
public RelayCommand AddNewCounterCommand =&amp;gt; _addNewCounterCommand ?? (_addNewCounterCommand = new RelayCommand(AddNewCounter));
private void AddNewCounter()
{
_navigationService.NavigateTo(ViewModelLocator.NewCounterPageKey);
}
&lt;/code>&lt;/pre>&lt;p>This command when executed will call the &lt;code>NavigateTo&lt;/code> method on the &lt;code>INavigationService&lt;/code> passing the key that we defined earlier. Once we make this call the navigation service does everything for us - creating the activity and pushing it onto the top of the navigation stack. And because we&amp;rsquo;re good developers we can add a unit test to our &lt;code>CountersViewModelTests&lt;/code> to verify this as well.&lt;/p>
&lt;pre tabindex="0">&lt;code>[Test]
public void ExecutingAddNewCounterCommandShouldNavigateToTheNewCounterActivity()
{
var vm = new CountersViewModel(_mockDatabaseHelper.Object, _mockNavigationService.Object);
vm.AddNewCounterCommand.Execute(null);
_mockNavigationService.Verify(n =&amp;gt; n.NavigateTo(ViewModelLocator.NewCounterPageKey), Times.Once);
}
&lt;/code>&lt;/pre>&lt;p>Finally we need to bind this command to the UI inside the &lt;code>CountersFragment&lt;/code> using the MVVMLight &lt;code>SetCommand&lt;/code> extension method we discussed above.&lt;/p>
&lt;pre tabindex="0">&lt;code>private FloatingActionButton _floatingActionButton;
public override View OnCreateView(LayoutInflater inflater, ViewGroup container, Bundle savedInstanceState)
{
...
_floatingActionButton = view.FindViewById&amp;lt;FloatingActionButton&amp;gt;(Resource.Id.floatingAddNewCounterButton);
_floatingActionButton.SetCommand(nameof(FloatingActionButton.Click), ViewModelLocator.Counters.AddNewCounterCommand);
...
}
&lt;/code>&lt;/pre>&lt;p>Now this is all done we can run the app and test the navigation.&lt;/p>
&lt;div class="image-div" style="width: 400px;">
&lt;p>&lt;img src="Newcounter-1.gif" alt="Adding a new counter">&lt;/p>
&lt;/div>
&lt;br/>
&lt;h6 id="updating-the-counters-in-the-ui">Updating the counters in the UI&lt;/h6>
&lt;p>If you run and test this you will be able to add a new counter, but the list of counters won&amp;rsquo;t be updated. Recycler views are not able to automatically detect changes to the underlying collection. The final piece of the adding counters puzzle is to wire this up.
The best way to handle this is from the database layer up - we can raise an event in our database helper when the counters are changed, detect this in the counters view model and update our UI.&lt;/p>
&lt;p>Let&amp;rsquo;s start with the database helper by adding an event to our &lt;code>IDatabaseHelper&lt;/code> interface:&lt;/p>
&lt;pre tabindex="0">&lt;code>event EventHandler CountersChanged;
&lt;/code>&lt;/pre>&lt;p>Then we implement it in &lt;code>DatabaseHelper&lt;/code>.&lt;/p>
&lt;pre tabindex="0">&lt;code>public async Task AddOrUpdateCounterAsync(Counter counter)
{
...
OnCountersChanged();
}
public event EventHandler CountersChanged;
private void OnCountersChanged()
{
CountersChanged?.Invoke(this, new EventArgs());
}
&lt;/code>&lt;/pre>&lt;p>Notice the new C# 6 null-conditional operator. This will check the value of &lt;code>CountersChanged&lt;/code> and if this is null do nothing, otherwise it will call the &lt;code>Invoke&lt;/code> method. Lovely clean code!&lt;/p>
&lt;p>We have our event, so lets wire it up in our &lt;code>CountersViewModel&lt;/code> to update the counters we expose in the view model.&lt;/p>
&lt;pre tabindex="0">&lt;code>public CountersViewModel(IDatabaseHelper databaseHelper, INavigationService navigationService)
{
...
_databaseHelper.CountersChanged += async (s, e) =&amp;gt; await LoadCountersAsync();
...
}
public async Task LoadCountersAsync()
{
_counters.Clear();
...
}
&lt;/code>&lt;/pre>&lt;p>We&amp;rsquo;re listening on the event and when it is fired reloading the counters from the SQLite database. We&amp;rsquo;re re-using the &lt;code>LoadCountersAsync&lt;/code> method so we have to tweak it to always clear the collection before populating it with the data loaded from the database helper.&lt;/p>
&lt;p>We now have our observable collection changing when the database changes, so we can listen on this to update the view. This can be handled in the &lt;code>CountersAdapter&lt;/code> - the component in the recycler view that adapts the counters collection to the UI.&lt;/p>
&lt;pre tabindex="0">&lt;code>public CountersAdapter()
{
((INotifyCollectionChanged)ViewModelLocator.Counters.Counters).CollectionChanged += OnCollectionChanged;
}
private void OnCollectionChanged(object sender, NotifyCollectionChangedEventArgs notifyCollectionChangedEventArgs)
{
NotifyDataSetChanged();
}
&lt;/code>&lt;/pre>&lt;p>In here we handle the collection change method and when fired call &lt;code>NotifyDataSetChanged&lt;/code>, a method that tells the recycler view to update the items in the UI. The &lt;code>Counters&lt;/code> property on the &lt;code>CountersViewModel&lt;/code> is a &lt;code>ReadOnlyObservableCollection&lt;/code> which implements &lt;code>INotifyCollectionChanged&lt;/code> explicitly, so we have to cast it to get access to the &lt;code>CollectionChanged&lt;/code> event.&lt;/p>
&lt;p>Note that this is not the most performant way of doing this. Every action on the collection will cause the entire UI to be updated. The reload is a clear then add of items one by one, so for example if there are 5 counters the &lt;code>CollectionChanged&lt;/code> event will be raised 6 times and the UI will be fully rebuilt 6 times. The use of &lt;code>NotifyDataSetChanged&lt;/code> will also cause an entire UI rebuild - there are other notify methods that handle single item adds, deletes or moves which could be used to improve performance. We could also improve the performance by implementing our own collection and only raising the event once. In this case we don&amp;rsquo;t have to worry too much - we don&amp;rsquo;t need to be lightening fast as will only have a few items.&lt;/p>
&lt;h4 id="lets-test-it-all-out">Lets test it all out&lt;/h4>
&lt;p>Now everything is wired up, lets take the app for a spin.&lt;/p>
&lt;div class="image-div" style="width: 400px;">
&lt;p>&lt;img src="Newcounter-2.gif" alt="Working add new counter">&lt;/p>
&lt;/div>
&lt;br/>
&lt;hr/>
&lt;h4 id="update">Update&lt;/h4>
&lt;p>After feedback from the comments against this post, lets tweak the UI to have a button on the toolbar to create the counter instead of on the bottom of the view.&lt;/p>
&lt;p>First we need to remove the button from the bottom of the &lt;code>new_counter.axml&lt;/code> layout file - just need to delete the &lt;code>Button&lt;/code> element.&lt;/p>
&lt;p>Next we need a menu. The way extra items are added to the toolbar is by creating a menu and inflating it into the toolbar. There is a visual studio template for menus, so right click on the &amp;lsquo;Resources/menu&amp;rsquo; folder and add a new item using the Android menu template called &lt;code>new_counter_menu.xml&lt;/code>.&lt;/p>
&lt;div class="image-div" style="width: 700px;">
&lt;p>&lt;img src="Screen-Shot-2016-03-17-at-21-42-07.png" alt="Android menu template">&lt;/p>
&lt;/div>
&lt;p>In this menu we need to add one item for the new counter button.&lt;/p>
&lt;pre tabindex="0">&lt;code>&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;utf-8&amp;#34; ?&amp;gt;
&amp;lt;menu xmlns:android=&amp;#34;http://schemas.android.com/apk/res/android&amp;#34;
xmlns:app=&amp;#34;http://schemas.android.com/apk/res-auto&amp;#34;&amp;gt;
&amp;lt;item android:id=&amp;#34;@+id/action_create_counter&amp;#34;
app:showAsAction=&amp;#34;always&amp;#34;
android:icon=&amp;#34;@drawable/ic_done_white_48dp&amp;#34;/&amp;gt;
&amp;lt;/menu&amp;gt;
&lt;/code>&lt;/pre>&lt;p>The icon being used here is the done icon from Google&amp;rsquo;s material icons mentioned above. Download this one and copy it to the various drawable folders.
Notice as well the &lt;code>showAsAction&lt;/code> property comes from the &lt;code>xmlns:app=&amp;quot;http://schemas.android.com/apk/res-auto&amp;quot;&lt;/code> namespace - if you use it from the &lt;code>android&lt;/code> namespace then the menu item will appear on the overflow menu without an icon.&lt;/p>
&lt;p>Now we have our menu, we need to wire it up in the &lt;code>NewCounterActivity&lt;/code>. We can start here by deleting the &lt;code>CreateCounter&lt;/code> button and all references to it. Then we need to create the new menu in the toolbar. This is done by overriding the &lt;code>OnCreateMenuItems&lt;/code> method and loading our new menu into the toolbar in there.&lt;/p>
&lt;pre tabindex="0">&lt;code>public override bool OnCreateOptionsMenu(IMenu menu)
{
base.OnCreateOptionsMenu(menu);
Toolbar.InflateMenu(Resource.Menu.new_counter_menu);
return true;
}
&lt;/code>&lt;/pre>&lt;p>Last thing to do is to handle the menu click in the &lt;code>OnOptionsItemSelected&lt;/code> method. When the new menu item is selected we need to execute the same command the previous button used.&lt;/p>
&lt;pre tabindex="0">&lt;code>public override bool OnOptionsItemSelected(IMenuItem item)
{
switch (item.ItemId)
{
case Android.Resource.Id.Home:
ViewModel.GoBackCommand.Execute(null);
return true;
case Resource.Id.action_create_counter:
ViewModel.AddCounterCommand.Execute(null);
return true;
default:
return base.OnOptionsItemSelected(item);
}
}
&lt;/code>&lt;/pre>&lt;p>Done!&lt;/p>
&lt;div class="image-div" style="width: 400px;">
&lt;p>&lt;img src="Screen-Shot-2016-03-17-at-22-04-49.png" alt="New counter activity with new menu">&lt;/p>
&lt;/div>
&lt;br/>
&lt;p>The code for this can be found in GitHub on the Part5 branch at &lt;a href="https://github.com/jimbobbennett/StupendousCounter/tree/Part5">https://github.com/jimbobbennett/StupendousCounter/tree/Part5&lt;/a>&lt;/p>
&lt;p>In the next part we&amp;rsquo;ll work on deleting counters.&lt;/p></description></item><item><title>MVVMLight navigation and AppCompatActivity</title><link>https://jimbobbennett.dev/blogs/mvvmlight-navigation-and-appcompatactivity/</link><pubDate>Mon, 08 Feb 2016 00:16:50 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/mvvmlight-navigation-and-appcompatactivity/</guid><description>&lt;p>As much as I&amp;rsquo;m loving &lt;a href="http://mvvmlight.codeplex.com">MVVMLight&lt;/a> it does have some limitations. The one I&amp;rsquo;ve hit recently is how well it doesn&amp;rsquo;t work when you are using AppCompat (though to be honest I think it&amp;rsquo;s more down to how hacky AppCompat seems to be).&lt;/p>
&lt;p>I&amp;rsquo;m using &lt;a href="http://developer.android.com/reference/android/support/v7/app/AppCompatActivity.html">AppCompatActivity&lt;/a> as my base activity class to get an action bar supported on older API versions. The problem is MVVMLight implements it&amp;rsquo;s own &lt;code>ActivityBase&lt;/code> which is derived from &lt;code>Activity&lt;/code>, and it relies on a set of static methods and properties on this to handle things like navigation and dialogs. If you want to use &lt;code>AppCompatActivity&lt;/code> you are stuck - navigation will not work.&lt;/p>
&lt;blockquote class="twitter-tweet" data-lang="en">&lt;p lang="en" dir="ltr">Seems to get &lt;a href="https://twitter.com/hashtag/mvvmlight?src=hash">#mvvmlight&lt;/a> working with AppCompatActivity I have to write my own NavigationService. &lt;a href="https://twitter.com/LBugnion">@LBugnion&lt;/a> any thoughts?&lt;/p>&amp;mdash; Jim Bennett (@jimbobbennett) &lt;a href="https://twitter.com/jimbobbennett/status/696149246022520833">February 7, 2016&lt;/a>&lt;/blockquote> &lt;script async src="//platform.twitter.com/widgets.js" charset="utf-8">&lt;/script>
&lt;blockquote class="twitter-tweet" data-conversation="none" data-lang="en">&lt;p lang="en" dir="ltr">&lt;a href="https://twitter.com/jimbobbennett">@jimbobbennett&lt;/a> I don&amp;#39;t have a better proposal at this point. Android is severely broken when it comes to launching new activities.&lt;/p>&amp;mdash; Laurent Bugnion (@LBugnion) &lt;a href="https://twitter.com/LBugnion/status/696273172937760769">February 7, 2016&lt;/a>&lt;/blockquote> &lt;script async src="//platform.twitter.com/widgets.js" charset="utf-8">&lt;/script>
&lt;p>Luckily MVVMLight is really well designed with good separation of concerns, so everything is done via interface. This means we can write our own implementation of the navigation service and dialog service that will work with &lt;code>AppCompatActivity&lt;/code> and use it in our code. Being open source as well we can take the existing source and tweak it slightly to make it work for us. It&amp;rsquo;s a bit of a hack but it works.&lt;/p>
&lt;p>The first thing to do is to define our own base activity class that has the same functionality as the &lt;code>ActivityBase&lt;/code>, but derived from &lt;code>AppCompatActivity&lt;/code>.&lt;/p>
&lt;pre tabindex="0">&lt;code>using Android.Support.V7.App;
namespace JimBobBennett.MvvmLight.AppCompat
{
public abstract class AppCompatActivityBase : AppCompatActivity
{
public static AppCompatActivityBase CurrentActivity { get; private set; }
internal string ActivityKey { get; private set; }
internal static string NextPageKey { get; set; }
public static void GoBack()
{
CurrentActivity?.OnBackPressed();
}
protected override void OnResume()
{
CurrentActivity = this;
if (string.IsNullOrEmpty(ActivityKey))
{
ActivityKey = NextPageKey;
NextPageKey = null;
}
base.OnResume();
}
}
}
&lt;/code>&lt;/pre>&lt;p>This is identical to the MVVMLight &lt;code>ActivityBase&lt;/code> except the base class is &lt;code>AppCompatActivity&lt;/code>.&lt;/p>
&lt;p>Now we have our base activity we can use it for the navigation service. This is identical to the MVVMLight Android &lt;code>NavigationService&lt;/code> except instead of accessing the statics on &lt;code>AppCompatActivityBase&lt;/code> instead of on &lt;code>ActivityBase&lt;/code>.&lt;/p>
&lt;pre tabindex="0">&lt;code>using System;
using System.Collections.Generic;
using Android.Content;
using GalaSoft.MvvmLight.Views;
namespace JimBobBennett.MvvmLight.AppCompat
{
public class AppCompatNavigationService : INavigationService
{
private readonly Dictionary&amp;lt;string, Type&amp;gt; _pagesByKey = new Dictionary&amp;lt;string, Type&amp;gt;();
private readonly Dictionary&amp;lt;string, object&amp;gt; _parametersByKey = new Dictionary&amp;lt;string, object&amp;gt;();
private const string RootPageKey = &amp;#34;-- ROOT --&amp;#34;;
private const string ParameterKeyName = &amp;#34;ParameterKey&amp;#34;;
public string CurrentPageKey =&amp;gt; AppCompatActivityBase.CurrentActivity.ActivityKey ?? RootPageKey;
public void GoBack()
{
AppCompatActivityBase.GoBack();
}
public void NavigateTo(string pageKey)
{
NavigateTo(pageKey, null);
}
public void NavigateTo(string pageKey, object parameter)
{
AppCompatActivityBase.CurrentActivity.RunOnUiThread(() =&amp;gt;
{
if (AppCompatActivityBase.CurrentActivity == null)
throw new InvalidOperationException(&amp;#34;No CurrentActivity found&amp;#34;);
lock (_pagesByKey)
{
if (!_pagesByKey.ContainsKey(pageKey))
throw new ArgumentException($&amp;#34;No such page: {pageKey}. Did you forget to call NavigationService.Configure?&amp;#34;, nameof(pageKey));
var intent = new Intent(AppCompatActivityBase.CurrentActivity, _pagesByKey[pageKey]);
if (parameter != null)
{
lock (_parametersByKey)
{
var guid = Guid.NewGuid().ToString();
_parametersByKey.Add(guid, parameter);
intent.PutExtra(ParameterKeyName, guid);
}
}
AppCompatActivityBase.CurrentActivity.StartActivity(intent);
AppCompatActivityBase.NextPageKey = pageKey;
}
});
}
public void Configure(string key, Type activityType)
{
lock (_pagesByKey)
{
if (_pagesByKey.ContainsKey(key))
_pagesByKey[key] = activityType;
else
_pagesByKey.Add(key, activityType);
}
}
public object GetAndRemoveParameter(Intent intent)
{
if (intent == null)
throw new ArgumentNullException(nameof(intent), &amp;#34;This method must be called with a valid Activity intent&amp;#34;);
var stringExtra = intent.GetStringExtra(ParameterKeyName);
if (string.IsNullOrEmpty(stringExtra))
return null;
lock (_parametersByKey)
return _parametersByKey.ContainsKey(stringExtra) ? _parametersByKey[stringExtra] : null;
}
public T GetAndRemoveParameter&amp;lt;T&amp;gt;(Intent intent)
{
return (T)GetAndRemoveParameter(intent);
}
}
}
&lt;/code>&lt;/pre>&lt;p>We then do the same for the dialog service:&lt;/p>
&lt;pre tabindex="0">&lt;code>using System;
using System.Threading.Tasks;
using Android.App;
using Android.Content;
using GalaSoft.MvvmLight.Views;
namespace JimBobBennett.MvvmLight.AppCompat
{
public class AppCompatDialogService : IDialogService
{
public Task ShowError(string message, string title, string buttonText, Action afterHideCallback)
{
var afterHideCallbackWithResponse = (Action&amp;lt;bool&amp;gt;) (r =&amp;gt;
{
if (afterHideCallback == null)
return;
afterHideCallback();
afterHideCallback = null;
});
var dialog = CreateDialog(message, title, buttonText, null, afterHideCallbackWithResponse);
dialog.Dialog.Show();
return dialog.Tcs.Task;
}
public Task ShowError(Exception error, string title, string buttonText, Action afterHideCallback)
{
var afterHideCallbackWithResponse = (Action&amp;lt;bool&amp;gt;)(r =&amp;gt;
{
if (afterHideCallback == null)
return;
afterHideCallback();
afterHideCallback = null;
});
var dialog = CreateDialog(error.Message, title, buttonText, null, afterHideCallbackWithResponse);
dialog.Dialog.Show();
return dialog.Tcs.Task;
}
public Task ShowMessage(string message, string title)
{
var dialog = CreateDialog(message, title);
dialog.Dialog.Show();
return dialog.Tcs.Task;
}
public Task ShowMessage(string message, string title, string buttonText, Action afterHideCallback)
{
var afterHideCallbackWithResponse = (Action&amp;lt;bool&amp;gt;)(r =&amp;gt;
{
if (afterHideCallback == null)
return;
afterHideCallback();
afterHideCallback = null;
});
var dialog = CreateDialog(message, title, buttonText, null, afterHideCallbackWithResponse);
dialog.Dialog.Show();
return dialog.Tcs.Task;
}
public Task&amp;lt;bool&amp;gt; ShowMessage(string message, string title, string buttonConfirmText, string buttonCancelText, Action&amp;lt;bool&amp;gt; afterHideCallback)
{
var afterHideCallbackWithResponse = (Action&amp;lt;bool&amp;gt;)(r =&amp;gt;
{
if (afterHideCallback == null)
return;
afterHideCallback(r);
afterHideCallback = null;
});
var dialog = CreateDialog(message, title, buttonConfirmText, buttonCancelText ?? &amp;#34;Cancel&amp;#34;, afterHideCallbackWithResponse);
dialog.Dialog.Show();
return dialog.Tcs.Task;
}
public Task ShowMessageBox(string message, string title)
{
return ShowMessage(message, title);
}
private static AlertDialogInfo CreateDialog(string content, string title, string okText = null, string cancelText = null, Action&amp;lt;bool&amp;gt; afterHideCallbackWithResponse = null)
{
var tcs = new TaskCompletionSource&amp;lt;bool&amp;gt;();
var builder = new AlertDialog.Builder(AppCompatActivityBase.CurrentActivity);
builder.SetMessage(content);
builder.SetTitle(title);
var dialog = (AlertDialog)null;
builder.SetPositiveButton(okText ?? &amp;#34;OK&amp;#34;, (d, index) =&amp;gt;
{
tcs.TrySetResult(true);
if (dialog != null)
{
dialog.Dismiss();
dialog.Dispose();
}
if (afterHideCallbackWithResponse == null)
return;
afterHideCallbackWithResponse(true);
});
if (cancelText != null)
{
builder.SetNegativeButton(cancelText, (d, index) =&amp;gt;
{
tcs.TrySetResult(false);
if (dialog != null)
{
dialog.Dismiss();
dialog.Dispose();
}
if (afterHideCallbackWithResponse == null)
return;
afterHideCallbackWithResponse(false);
});
}
builder.SetOnDismissListener(new OnDismissListener(() =&amp;gt;
{
tcs.TrySetResult(false);
if (afterHideCallbackWithResponse == null)
return;
afterHideCallbackWithResponse(false);
}));
dialog = builder.Create();
return new AlertDialogInfo
{
Dialog = dialog,
Tcs = tcs
};
}
private struct AlertDialogInfo
{
public AlertDialog Dialog;
public TaskCompletionSource&amp;lt;bool&amp;gt; Tcs;
}
private sealed class OnDismissListener : Java.Lang.Object, IDialogInterfaceOnDismissListener
{
private readonly Action _action;
public OnDismissListener(Action action)
{
_action = action;
}
public void OnDismiss(IDialogInterface dialog)
{
_action();
}
}
}
}
&lt;/code>&lt;/pre>&lt;p>To use these all we need to do is derive all our activities from &lt;code>AppCompatActivityBase&lt;/code> and register the &lt;code>AppCompatNavigationService&lt;/code> and &lt;code>AppCompatDialogService&lt;/code> in our IoC container as implementations of &lt;code>INavigationService&lt;/code> and &lt;code>IDialogService&lt;/code>.&lt;/p>
&lt;p>The code for this is up on GitHub here: &lt;a href="https://github.com/jimbobbennett/JimBobBennett.MvvmLight.AppCompat">https://github.com/jimbobbennett/JimBobBennett.MvvmLight.AppCompat&lt;/a>&lt;/p>
&lt;p>I&amp;rsquo;ve also created a NuGet package available here: &lt;a href="https://www.nuget.org/packages/JimBobBennett.MvvmLight.AppCompat/">https://www.nuget.org/packages/JimBobBennett.MvvmLight.AppCompat/&lt;/a> or searchable from the Package Manager as &lt;code>JimBobBennett.MvvmLight.AppCompat&lt;/code>.&lt;/p>
&lt;hr/>
&lt;h4 id="update">Update&lt;/h4>
&lt;p>Thanks to &lt;a href="http://sa.muel.be">Samuel Debruyn&lt;/a> for adding an update to this package.&lt;/p>
&lt;p>MVVMLight has a helper class to aid in running code on the UI thread called &lt;a href="http://www.mvvmlight.net/help/SL5/html/5af6dede-4a22-2eb2-d0fa-5af0f2fe4fe5.htm">DispatcherHelper&lt;/a>. This will verify the current activity and use that to run the specified action on the UI thread using the &lt;code>RunOnUIThread&lt;/code> method.&lt;/p>
&lt;p>Unfortunately for us this relies on the &lt;code>CurrentActivity&lt;/code> property on &lt;code>ActivityBase&lt;/code>, something we are not using. Sam has added an &lt;code>AppCompatDispatcherHelper&lt;/code> which mimics the logic of the &lt;code>DispatcherHelper&lt;/code> but using the &lt;code>AppCompatActivityBase.CurrentActivity&lt;/code> instead.&lt;/p>
&lt;p>The &lt;a href="https://github.com/jimbobbennett/JimBobBennett.MvvmLight.AppCompat">code on GitHub&lt;/a> and &lt;a href="https://www.nuget.org/packages/JimBobBennett.MvvmLight.AppCompat/">NuGet package&lt;/a> have both been updated with these changes.&lt;/p></description></item><item><title>Building a Xamarin Android app - part 4</title><link>https://jimbobbennett.dev/blogs/building-a-xamarin-android-app-part-4/</link><pubDate>Mon, 01 Feb 2016 07:36:22 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/building-a-xamarin-android-app-part-4/</guid><description>&lt;p>This is the fourth part in the my series about building an Android app using Xamarin.Android. You can find the first part &lt;a href="https://jimbobbennett.dev/blogs/building-an-android-app-part-1/">here&lt;/a>, the second part &lt;a href="https://jimbobbennett.dev/blogs/building-an-android-app-part-2/">here&lt;/a> and the third part &lt;a href="https://jimbobbennett.dev/blogs/building-a-xamarin-android-app-part-3/">here&lt;/a>, and I highly recommend reading these first.&lt;/p>
&lt;h4 id="binding-our-view-models-to-the-ui">Binding our view models to the UI&lt;/h4>
&lt;p>We have our models, we have our view models, now to work on the views!
First thing we need to do is a bit of a tidy up - the default UI code we&amp;rsquo;ve picked up from our templates doesn&amp;rsquo;t match what we want to show in screen, so lets start by clearing everything up a bit.&lt;/p>
&lt;p>The UI we have has a navigation drawer with 2 screens you can select, as well as some sub menu options. The screen selection options load one of two possible fragments into our UI. We can repurpose these - one fragment to show our counters and one to show an about screen so we can tell the world who created such a stupendous counter app!&lt;/p>
&lt;p>Stating with the first fragment we can rename the class from &lt;code>Fragment1&lt;/code> to &lt;code>CountersFragment&lt;/code>, as well as renaming the associated layout from &lt;code>fragment1.axml&lt;/code> to &lt;code>counters_fragment.axml&lt;/code>. After renaming the layout file we also need to change the id that is used in the &lt;code>CountersFragment.OnCreateView&lt;/code> method to reflect the new name:&lt;/p>
&lt;pre tabindex="0">&lt;code>return inflater.Inflate(Resource.Layout.counters_fragment, null);
&lt;/code>&lt;/pre>&lt;p>For the second one we can rename it from &lt;code>Fragment2&lt;/code> to &lt;code>AboutFragment&lt;/code> and &lt;code>fragment2.axml&lt;/code> to &lt;code>about_fragment.axml&lt;/code>, and again updating the id:&lt;/p>
&lt;pre tabindex="0">&lt;code>return inflater.Inflate(Resource.Layout.about_fragment, null);
&lt;/code>&lt;/pre>&lt;div class="image-div" style="width: 300px;">
&lt;p>&lt;img src="RenamedFragments.png" alt="Renamed fragments">&lt;/p>
&lt;/div>
&lt;br/>
&lt;p>Now is also a good time to update the menu in &lt;code>menu\nav_menu.xml&lt;/code> to remove the unwanted sub items and rename the main items:&lt;/p>
&lt;pre tabindex="0">&lt;code>&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;UTF-8&amp;#34; ?&amp;gt;
&amp;lt;menu xmlns:android=&amp;#34;http://schemas.android.com/apk/res/android&amp;#34;&amp;gt;
&amp;lt;group android:checkableBehavior=&amp;#34;single&amp;#34;&amp;gt;
&amp;lt;item
android:id=&amp;#34;@+id/nav_counters&amp;#34;
android:icon=&amp;#34;@drawable/ic_add_circle_black_48dp&amp;#34;
android:title=&amp;#34;Counters&amp;#34; /&amp;gt;
&amp;lt;item
android:id=&amp;#34;@+id/nav_about&amp;#34;
android:icon=&amp;#34;@drawable/ic_settings_black_48dp&amp;#34;
android:title=&amp;#34;About&amp;#34; /&amp;gt;
&amp;lt;/group&amp;gt;
&amp;lt;/menu&amp;gt;
&lt;/code>&lt;/pre>&lt;p>You&amp;rsquo;ll notice the icons have changed to items not in our drawables folder, so we&amp;rsquo;ll need to add these. The icons we&amp;rsquo;re using are from the Google material icons - you can download them from &lt;a href="https://design.google.com/icons/">https://design.google.com/icons/&lt;/a>. You&amp;rsquo;ll need to download the &amp;lsquo;add circle&amp;rsquo; and &amp;lsquo;settings&amp;rsquo; icons as pngs and copy them from the drawables folders of the downloads to the same named drawables folders locally, then add them to the project.&lt;/p>
&lt;div class="image-div" style="width: 300px;">
&lt;p>&lt;img src="Screen-Shot-2016-02-01-at-17-53-47.png" alt="Icons added to the drawables">&lt;/p>
&lt;/div>
&lt;br/>
&lt;p>Changing the menu ids will break our &lt;code>MainActivity&lt;/code> so we need to fix the &lt;code>OnCreate&lt;/code> method by changing the subscription to the &lt;code>NavigationView.NavigationItemSelected&lt;/code> event. At the same time we can remove the snack bar call as we don&amp;rsquo;t want one popping up when we change the fragment.&lt;/p>
&lt;pre tabindex="0">&lt;code>navigationView.NavigationItemSelected += (sender, e) =&amp;gt;
{
e.MenuItem.SetChecked(true);
switch (e.MenuItem.ItemId)
{
case Resource.Id.nav_counters:
ListItemClicked(0);
break;
case Resource.Id.nav_about:
ListItemClicked(1);
break;
}
drawerLayout.CloseDrawers();
};
&lt;/code>&lt;/pre>&lt;h6 id="countersfragment">CountersFragment&lt;/h6>
&lt;p>In this fragment we want to display a list of all the counters that we have stored. The latest and greates way to do this is with a &lt;code>RecyclerView&lt;/code> which is documented &lt;a href="https://developer.xamarin.com/guides/android/user_interface/recyclerview/">here on the Xamarin docs&lt;/a>. This is like a list view but enforces good design and ensures the views created are always re-used when they go off screen reducing the memory footprint. It also enforces the use of the &lt;a href="https://blog.xamarin.com/creating-highly-performant-smooth-scrolling-android-listviews/">view holder pattern&lt;/a> to futher improve performance.&lt;/p>
&lt;p>To use the recycler view we need to add a nuget package to our &lt;code>StupendoudCounter.Droid&lt;/code> project - &lt;code>Xamarin.Android.Support.v7.RecyclerView&lt;/code>. This provides the recycler view for all versions of Android from API level 7 and above.&lt;/p>
&lt;div class="image-div" style="width: 600px;">
&lt;p>&lt;img src="RecyclerView-nuget.png" alt="Recycler view nuget package">&lt;/p>
&lt;/div>
&lt;br/>
&lt;p>Once we have our nuget package installed we can add the recycler view to our UI and create it&amp;rsquo;s backing field. In &lt;code>counters_fragment.axml&lt;/code> add the recycler view:&lt;/p>
&lt;pre tabindex="0">&lt;code>&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;utf-8&amp;#34;?&amp;gt;
&amp;lt;LinearLayout xmlns:android=&amp;#34;http://schemas.android.com/apk/res/android&amp;#34;
android:orientation=&amp;#34;vertical&amp;#34;
android:layout_width=&amp;#34;fill_parent&amp;#34;
android:layout_height=&amp;#34;fill_parent&amp;#34;&amp;gt;
&amp;lt;android.support.v7.widget.RecyclerView
android:id=&amp;#34;@+id/countersRecyclerView&amp;#34;
android:scrollbars=&amp;#34;vertical&amp;#34;
android:layout_width=&amp;#34;fill_parent&amp;#34;
android:layout_height=&amp;#34;fill_parent&amp;#34; /&amp;gt;
&amp;lt;/LinearLayout&amp;gt;
&lt;/code>&lt;/pre>&lt;p>In &lt;code>CountersFragment&lt;/code> add a field for the recycler view and find it from the view in the &lt;code>OnCreateView&lt;/code> method:&lt;/p>
&lt;pre tabindex="0">&lt;code>using Android.Support.V7.Widget;
...
private RecyclerView _recyclerView;
public override View OnCreateView(LayoutInflater inflater, ViewGroup container, Bundle savedInstanceState)
{
var ignored = base.OnCreateView(inflater, container, savedInstanceState);
var view = inflater.Inflate(Resource.Layout.counters_fragment, null);
_recyclerView = view.FindViewById&amp;lt;RecyclerView&amp;gt;(Resource.Id.countersRecyclerView);
return view;
}
&lt;/code>&lt;/pre>&lt;p>To use this recycler view we need to use or implement a few things:&lt;/p>
&lt;ul>
&lt;li>A layout manager&lt;/li>
&lt;li>An adapter&lt;/li>
&lt;li>A view holder&lt;/li>
&lt;/ul>
&lt;h6 id="layout-manager">Layout manager&lt;/h6>
&lt;p>Each instance of a recycler view has a layout manager - this determines how the items in the view are laid out. Android provides 3 basic ones which are good enough for most cases, but you can implement your own if you wish. There&amp;rsquo;s &lt;code>LinearLayoutManager&lt;/code> which displays the items in a horizontal or vertical list, &lt;code>GridLayoutManager&lt;/code> that displayes the items in a grid and &lt;code>StaggeredGridLayoutManager&lt;/code> which displays them in a grid with uneven rows or columns.
For what we need the &lt;code>LinearLayoutManager&lt;/code> is good enough, so we can create one and set it on our recycler view:&lt;/p>
&lt;pre tabindex="0">&lt;code>_recyclerView.SetLayoutManager(new LinearLayoutManager(Context, LinearLayoutManager.Vertical, false));
&lt;/code>&lt;/pre>&lt;p>The three parameters for the constructor are the current context which we can get from the &lt;code>Context&lt;/code> property, the orientation for which we are using the &lt;code>Vertical&lt;/code> constant defined on &lt;code>LinearLayoutManager&lt;/code>, and a boolean to say if the items should be reveresed or not when we show them - so should we show the items in our list from top to bottom, or bottom to top (reverse is useful when adding new items to the end of a list but showing them in latest-first order, such as an email client order by date).&lt;/p>
&lt;h6 id="adapter">Adapter&lt;/h6>
&lt;p>The adapter&amp;rsquo;s job is to act like a view model for the recycler view - it needs to know about the collection of items we are showing in the list and be able to tell the recycler view how many there are and needs to be able to create the views for items in the collection where necessary or recycle them to be used by other items in the collection.
All adapters need three things - a class derived from &lt;code>RecyclerView.Adapter&lt;/code>, a view to create to show the item and a view holder that maps the items in the collection to the view. To create the adapter create a class called &lt;code>CountersAdapter&lt;/code>:&lt;/p>
&lt;pre tabindex="0">&lt;code>using Android.Support.V7.Widget;
using Android.Views;
using StupendousCounter.Core.ViewModel;
namespace StupendousCounter.Droid.Fragments
{
public class CountersAdapter : RecyclerView.Adapter
{
public override void OnBindViewHolder(RecyclerView.ViewHolder holder, int position)
{
var item = ViewModelLocator.Counters.Counters[position];
((CounterViewHolder) holder).BindCounterViewModel(item);
}
public override RecyclerView.ViewHolder OnCreateViewHolder(ViewGroup parent, int viewType)
{
var itemView = LayoutInflater.From(parent.Context).Inflate(Resource.Layout.counter_view, parent, false);
return new CounterViewHolder(itemView);
}
public override int ItemCount =&amp;gt; ViewModelLocator.Counters.Counters.Count;
}
}
&lt;/code>&lt;/pre>&lt;p>When we override &lt;code>RecyclerView.Adapter&lt;/code> we have to implement three things - &lt;code>ItemCount&lt;/code>, &lt;code>OnCreateViewHolder&lt;/code> and &lt;code>OnBindVewHolder&lt;/code>.&lt;/p>
&lt;p>&lt;code>ItemCount&lt;/code> just needs to return the number of items in the collection. This just returns the count from the &lt;code>CountersViewModel&lt;/code> instance from the static &lt;code>ViewModelLocator&lt;/code>.&lt;/p>
&lt;p>&lt;code>OnCreateViewHolder&lt;/code> is called whenever an item in the recycler view is created for the first time. This needs to create a view and wrap it in a class derived from &lt;code>RecyclerView.ViewHolder&lt;/code>.&lt;/p>
&lt;p>&lt;code>OnBindViewHolder&lt;/code> is responsible for updating the view holder to reflect the relevant item in the collection. The item is given by the &lt;code>position&lt;/code> parameter - this indicates the position in the collection of the item we need to show in the view. In our code we are using this to get the item from our view model which we access using the static &lt;code>ViewModelLocator&lt;/code>, and this is passed to a method on the view holder to populate it. In a lot of code you will see the view holder updated directly here with the controls in the view holder exposed as public properties, but I prefer to encapsulate the controls inside the view holder and have a single method to call to update the view. This means if the view changes the adapter doesn&amp;rsquo;t need to change.&lt;/p>
&lt;p>These last two are the basis of how the recycler view works - it calls &lt;code>OnCreateViewHolder&lt;/code> to create just enough views to fill the screen, then calls &lt;code>OnBingViewHolder&lt;/code> to show the data. As the collection is scrolled instead of creating new views, the views that are no longer visible are re-used. So if you scroll down a a view disappears off the top it is moved to the bottom to remove the overhead of creating a new view. To make sure it shows the right data &lt;code>OnBindViewHolder&lt;/code> is called to update the view to show the correct data.&lt;/p>
&lt;p>To create the view add a new layout called &lt;code>counter_view.xml&lt;/code>:&lt;/p>
&lt;pre tabindex="0">&lt;code>&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;utf-8&amp;#34;?&amp;gt;
&amp;lt;android.support.v7.widget.CardView xmlns:android=&amp;#34;http://schemas.android.com/apk/res/android&amp;#34;
xmlns:card_view=&amp;#34;http://schemas.android.com/apk/res-auto&amp;#34;
android:layout_width=&amp;#34;match_parent&amp;#34;
android:layout_height=&amp;#34;wrap_content&amp;#34;
card_view:cardElevation=&amp;#34;8dp&amp;#34;
card_view:cardCornerRadius=&amp;#34;8dp&amp;#34;
android:layout_marginLeft=&amp;#34;8dp&amp;#34;
android:layout_marginRight=&amp;#34;8dp&amp;#34;
android:layout_marginTop=&amp;#34;8dp&amp;#34;&amp;gt;
&amp;lt;GridLayout
android:minWidth=&amp;#34;25px&amp;#34;
android:minHeight=&amp;#34;25px&amp;#34;
android:layout_width=&amp;#34;match_parent&amp;#34;
android:layout_height=&amp;#34;wrap_content&amp;#34;
android:columnCount=&amp;#34;3&amp;#34;
android:rowCount=&amp;#34;1&amp;#34;&amp;gt;
&amp;lt;TextView
android:id=&amp;#34;@+id/counter_value&amp;#34;
android:layout_width=&amp;#34;wrap_content&amp;#34;
android:layout_height=&amp;#34;wrap_content&amp;#34;
android:text=&amp;#34;10&amp;#34;
android:layout_row=&amp;#34;0&amp;#34;
android:layout_column=&amp;#34;1&amp;#34;
android:textSize=&amp;#34;48sp&amp;#34;
android:layout_gravity=&amp;#34;center_vertical&amp;#34;
android:layout_marginRight=&amp;#34;16sp&amp;#34;
android:textColor=&amp;#34;@color/primaryDark&amp;#34; /&amp;gt;
&amp;lt;ImageButton
android:id=&amp;#34;@+id/counter_increment&amp;#34;
android:layout_width=&amp;#34;wrap_content&amp;#34;
android:layout_height=&amp;#34;wrap_content&amp;#34;
android:layout_row=&amp;#34;0&amp;#34;
android:layout_column=&amp;#34;2&amp;#34;
android:layout_gravity=&amp;#34;center_vertical&amp;#34;
android:layout_margin=&amp;#34;16sp&amp;#34;
android:src=&amp;#34;@drawable/ic_add_circle_black_48dp&amp;#34;
android:background=&amp;#34;#00000000&amp;#34;/&amp;gt;
&amp;lt;LinearLayout
android:orientation=&amp;#34;vertical&amp;#34;
android:layout_gravity=&amp;#34;fill&amp;#34;
android:layout_row=&amp;#34;0&amp;#34;
android:layout_column=&amp;#34;0&amp;#34;
android:padding=&amp;#34;16sp&amp;#34;&amp;gt;
&amp;lt;TextView
android:id=&amp;#34;@+id/counter_name&amp;#34;
android:layout_width=&amp;#34;wrap_content&amp;#34;
android:layout_height=&amp;#34;wrap_content&amp;#34;
android:text=&amp;#34;Name&amp;#34;
android:padding=&amp;#34;4sp&amp;#34;
android:textSize=&amp;#34;24sp&amp;#34;
android:textColor=&amp;#34;@color/primaryText&amp;#34; /&amp;gt;
&amp;lt;TextView
android:id=&amp;#34;@+id/counter_description&amp;#34;
android:layout_width=&amp;#34;wrap_content&amp;#34;
android:layout_height=&amp;#34;wrap_content&amp;#34;
android:text=&amp;#34;The counters description&amp;#34;
android:padding=&amp;#34;4sp&amp;#34;
android:textSize=&amp;#34;16sp&amp;#34; /&amp;gt;
&amp;lt;/LinearLayout&amp;gt;
&amp;lt;/GridLayout&amp;gt;
&amp;lt;/android.support.v7.widget.CardView&amp;gt;
&lt;/code>&lt;/pre>&lt;p>This view uses a &lt;code>CardView&lt;/code> which is documented &lt;a href="https://developer.xamarin.com/guides/android/user_interface/cardview/">here on the Xamarin docs&lt;/a>. Inside the &lt;code>CardView&lt;/code> there is a &lt;code>GridLayout&lt;/code> and &lt;code>LinearLayout&lt;/code> to layout the various widgets, three &lt;code>TextViews&lt;/code> to show the counter details and value, and an &lt;code>ImageButton&lt;/code> to allow the counter to be incremented. The view looks like this:&lt;/p>
&lt;div class="image-div" style="width: 400px;">
&lt;p>&lt;img src="Screen-Shot-2016-02-01-at-18-38-10.png" alt="Item view">&lt;/p>
&lt;/div>
&lt;br/>
&lt;p>The &lt;code>GridLayout&lt;/code> is used to layout 3 columns - one for the counter details, one for the count and one for the increment button. Inside the first column is the &lt;code>LinearLayout&lt;/code> that shows the counters name and description as a vertical layout.&lt;/p>
&lt;h6 id="viewholder">ViewHolder&lt;/h6>
&lt;p>The view holder&amp;rsquo;s job is to create backing fields for the controls in the view to improve performance by only having to find the controls by id once per instance of the view. To create the view holder create a class called &lt;code>CounterViewHolder&lt;/code>:&lt;/p>
&lt;pre tabindex="0">&lt;code>using System;
using System.ComponentModel;
using Android.App;
using Android.Graphics;
using Android.Support.V4.Content;
using Android.Support.V7.Widget;
using Android.Views;
using Android.Widget;
using StupendousCounter.Core.ViewModel;
namespace StupendousCounter.Droid.Fragments
{
public class CounterViewHolder : RecyclerView.ViewHolder
{
private readonly TextView _name;
private readonly TextView _description;
private readonly TextView _value;
private CounterViewModel _counterViewModel;
public CounterViewHolder(View itemView) : base(itemView)
{
_name = itemView.FindViewById&amp;lt;TextView&amp;gt;(Resource.Id.counter_name);
_description = itemView.FindViewById&amp;lt;TextView&amp;gt;(Resource.Id.counter_description);
_value = itemView.FindViewById&amp;lt;TextView&amp;gt;(Resource.Id.counter_value);
var increment = itemView.FindViewById&amp;lt;ImageButton&amp;gt;(Resource.Id.counter_increment);
increment.SetColorFilter(new Color(ContextCompat.GetColor(Application.Context, Resource.Color.primaryDark)));
increment.Click += IncrementOnClick;
}
private void IncrementOnClick(object sender, EventArgs eventArgs)
{
_counterViewModel.IncrementCommand.Execute(null);
}
public void BindCounterViewModel(CounterViewModel counterViewModel)
{
if (_counterViewModel != null)
_counterViewModel.PropertyChanged -= CounterViewModelOnPropertyChanged;
_counterViewModel = counterViewModel;
_counterViewModel.PropertyChanged += CounterViewModelOnPropertyChanged;
_name.Text = counterViewModel.Name;
_description.Text = counterViewModel.Description;
_value.Text = counterViewModel.Value;
}
private void CounterViewModelOnPropertyChanged(object sender, PropertyChangedEventArgs args)
{
if (args.PropertyName == nameof(CounterViewModel.Value))
_value.Text = _counterViewModel.Value;
}
}
}
&lt;/code>&lt;/pre>&lt;p>This class derives from &lt;code>RecyclerView.ViewHolder&lt;/code>. In the constructor a view is passed in - and this is the view created by our adapter. In here we are manually going to wire up the values for the counter view model to the view. Although we are using MVVMLight for our view models which exposes a binding mechanism this currently doesn&amp;rsquo;t work with view holders (although Laurent tells me it should do in a couple of weeks time so stay tuned for an update), so we have to do it all manually.&lt;/p>
&lt;p>The first thing we do is grab the name, description and value text edit fields and store these. &lt;code>FindById&lt;/code> is slow, hence why we only want to do this once per view instance and store the found controls.
For the image button we don&amp;rsquo;t need to store it in our class, we just need to wire up the &lt;code>Click&lt;/code> event so we can respond to it. We also call &lt;code>SetColorFilter&lt;/code> on the button - this is because the icon that was downloaded from Google material design images is a black button and we want it to match our theme. &lt;code>SetColorFilter&lt;/code> will change the colour of the button to the given colour, giving a nice purple button.&lt;/p>
&lt;p>In the adapter in the &lt;code>OnBindViewHolder&lt;/code> method we delegated the updating of the UI to a method on the view holder, and this is implemented here in the &lt;code>BindCounterViewModel&lt;/code> method. This method takes a &lt;code>CounterViewModel&lt;/code> that refers to the item in the relevant position in the collection, and this is stored in a field. The name, description and value controls are updated to match the view model. We also subscribe to the &lt;code>PropertyChanged&lt;/code> event so that the value can be updated when it changes on the view model - such as when the increment button is pressed. To avoid the wrong counters being incremented we also unsubscribe from this event from the view model stored in our field if it is set before we update it to store the one passed in.&lt;/p>
&lt;p>Once the view model is stored, we can increment it when the increment button is clicked. In the click event handler (&lt;code>IncrementOnClick&lt;/code>) we execute the &lt;code>IncrementCommand&lt;/code> which will cause the value to increment and be updated in SQLite as shown in the previous post. This will also cause the &lt;code>PropertyChange&lt;/code> event to be fired for the &lt;code>Value&lt;/code> property, which we handle and update the UI to reflect the new value.&lt;/p>
&lt;h4 id="lets-try-it-out">Lets try it out&lt;/h4>
&lt;p>That should be everything we need to do to show some dummy data and increment the counters, so lets build it, run it and try it out. Click on the plus button to increment each counter, then try closing and re-opening the app - you&amp;rsquo;ll notice the values are persisted thanks to our SQLite db.&lt;/p>
&lt;div class="image-div" style="width: 400px;">
&lt;p>&lt;img src="IncrementingCounter.gif" alt="Incrementing counters">&lt;/p>
&lt;/div>
&lt;br/>
&lt;p>The code for this can be found in GitHub on the Part4 branch at &lt;a href="https://github.com/jimbobbennett/StupendousCounter/tree/Part4">https://github.com/jimbobbennett/StupendousCounter/tree/Part4&lt;/a>&lt;/p>
&lt;p>In the next part we&amp;rsquo;ll work on adding an Add button to add a new counter.&lt;/p>
&lt;hr/>
&lt;p>
&lt;table cellspacing="0" cellpadding="0" style='border: none;border-collapse: collapse;'>
&lt;tr style='padding: 0;'>
&lt;td style='padding: 0;vertical-align: top;'>
&lt;iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="//ws-eu.amazon-adsystem.com/widgets/q?ServiceVersion=20070822&amp;OneJS=1&amp;Operation=GetAdHtml&amp;MarketPlace=GB&amp;source=ss&amp;ref=ss_til&amp;ad_type=product_link&amp;tracking_id=expecti-21&amp;marketplace=amazon&amp;region=GB&amp;placement=B00L1WB9H4&amp;asins=B00L1WB9H4&amp;linkId=&amp;show_border=false&amp;link_opens_in_new_window=true">
&lt;/iframe>
&lt;/td>
&lt;td style='padding: 0px 30px;'>
&lt;p style='color:rgb(104, 104, 104);!important;'>Continuing on from the last post where I mentioned what I was listening to whilst developing, today I'm listening to &lt;a href='http://sleepingatlast.com'>Sleeping at Last&lt;/a>&lt;/p>
&lt;p style='color:rgb(104, 104, 104);!important;'>Note - these are an affiliate links - if you click them and buy I get a small cut.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/table>
&lt;/p></description></item><item><title>I'm now a Xamarin MVP!</title><link>https://jimbobbennett.dev/blogs/im-now-a-xamarin-mvp/</link><pubDate>Mon, 01 Feb 2016 07:06:17 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/im-now-a-xamarin-mvp/</guid><description>&lt;p>I&amp;rsquo;m very proud to have been recognised as a Xamarin MVP! Thanks to whoever nominated me. I hope the work I&amp;rsquo;ve been doing for the community through my talks and blog has helped some people, and will continue to do so in the future. Look out for my up coming talks in New Zealand and at &lt;a href="https://evolve.xamarin.com">Evolve&lt;/a>, and my upcoming blog posts and (hopefully) book.&lt;/p>
&lt;div class="image-div" style='width: 200px;'>
&lt;p>&lt;img src="MVP-Badge.png" alt="Xamarin MVP badge">&lt;/p>
&lt;/div></description></item><item><title>Building a Xamarin Android app - part 3</title><link>https://jimbobbennett.dev/blogs/building-a-xamarin-android-app-part-3/</link><pubDate>Sat, 30 Jan 2016 17:51:36 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/building-a-xamarin-android-app-part-3/</guid><description>&lt;p>This is the third part in the my series about building an Android app using Xamarin.Android. You can find the first part &lt;a href="https://jimbobbennett.dev/blogs/building-an-android-app-part-1/">here&lt;/a> and the second part &lt;a href="https://jimbobbennett.dev/blogs/building-an-android-app-part-2/">here&lt;/a>, and I highly recommend reading these first.&lt;/p>
&lt;h4 id="data-binding">Data binding&lt;/h4>
&lt;p>In the first 2 parts of this we created our basic app shell and built a core library with models that used SQLite to store and retrieve our data. We&amp;rsquo;re now going to expand on this by adding the layer in-between to bind the data to our UI.&lt;/p>
&lt;p>Having been a WPF developer in the past I&amp;rsquo;m a big fan of the &lt;a href="https://en.wikipedia.org/wiki/Model%E2%80%93view%E2%80%93viewmodel">MVVM pattern&lt;/a>, so I&amp;rsquo;m planning on using the same pattern here. I won&amp;rsquo;t go into the details of this pattern, so if you&amp;rsquo;ve never come across it before it&amp;rsquo;s worth reading up as it&amp;rsquo;s a useful pattern supported natively in Xamarin.Forms and on iOS and Android using tools like MVVMLight or &lt;a href="https://github.com/MvvmCross/MvvmCross">MVVMCross&lt;/a>. To help with this I&amp;rsquo;m going to use &lt;a href="http://www.mvvmlight.net">MVVMLight&lt;/a> by &lt;a href="http://www.galasoft.ch">Laurent Bugnion&lt;/a>. As the name suggests this is a light-weight MVVM library which provides the basic toolbox to allow you to use the pattern without constraining you to a particular architecture. MVVMLight has two different nuget packages to install - one for the Android app and one for our core project.&lt;/p>
&lt;p>For StupendousCounter.Droid install MVVMLight. This has all the platform specific code in (so for an Android project you get a library with Android specific code in) that allows for things like UI binding - this needs to know about the controls so needs to be platform-specific. When installing this you may get an error about not being able to find App.Xaml - just ignore this as it isn&amp;rsquo;t relevant for Android projects. Once this is installed you will see a new folder created called &lt;code>ViewModel&lt;/code> that contains a dummy view model and an example ViewModelLocator. We&amp;rsquo;ll come back to these later on.&lt;/p>
&lt;div class="image-div" style="width: 700px;">
&lt;p>&lt;img src="Screen-Shot-2016-01-22-at-13-14-29.png" alt="MVVMLight nuget package">&lt;/p>
&lt;/div>
&lt;br/>
&lt;div class="image-div" style="width: 300px;">
&lt;p>&lt;img src="Screen-Shot-2016-01-23-at-13-52-58.png" alt="ViewModel folder">&lt;/p>
&lt;/div>
&lt;br/>
&lt;p>For StupendousCounter.Core install the libs only one - MVVMLightLibs. This has things like the base view model but nothing platform specific.&lt;/p>
&lt;div class="image-div" style="width: 700px;">
&lt;p>&lt;img src="Screen-Shot-2016-01-22-at-13-24-39.png" alt="MVVMLightLibs nuget package">&lt;/p>
&lt;/div>
&lt;br/>
&lt;h6 id="showing-some-data">Showing some data&lt;/h6>
&lt;p>Lets start by showing some data on screen. To make it easier we&amp;rsquo;ll just mock some up on startup if we don&amp;rsquo;t have an existing counters. In our &lt;code>MainActivity.cs&lt;/code> we can add some dummy data if we are in debug (to save accidentally leaving this in in release code) just after we&amp;rsquo;ve setup the &lt;code>DatabaseHelper&lt;/code>:&lt;/p>
&lt;pre tabindex="0">&lt;code>private static async Task AddDummyData()
{
var dbHelper = new DatabaseHelper();
if (!(await dbHelper.GetAllCountersAsync()).Any())
{
var counter1 = new Counter
{
Name = &amp;#34;Monkey Count&amp;#34;,
Description = &amp;#34;The number of monkeys&amp;#34;,
Value = 10
};
var counter2 = new Counter
{
Name = &amp;#34;Playtpus Count&amp;#34;,
Description = &amp;#34;The number of duck-billed platypuses&amp;#34;,
Value = 4
};
await dbHelper.AddOrUpdateCounterAsync(counter1);
await dbHelper.AddOrUpdateCounterAsync(counter2);
}
}
&lt;/code>&lt;/pre>&lt;p>And call this if we&amp;rsquo;re in debug in our &amp;lsquo;OnCreate&amp;rsquo; method:&lt;/p>
&lt;pre tabindex="0">&lt;code>protected override async void OnCreate(Bundle savedInstanceState)
{
base.OnCreate(savedInstanceState);
var path = System.Environment.GetFolderPath(System.Environment.SpecialFolder.Personal);
var dbPath = Path.Combine(path, &amp;#34;counters.db3&amp;#34;);
DatabaseHelper.CreateDatabase(dbPath);
# if DEBUG
await AddDummyData();
# endif
&lt;/code>&lt;/pre>&lt;p>Notice how we&amp;rsquo;re awaiting the call to &lt;code>AddDummyData&lt;/code>? Yup - this is an async method we&amp;rsquo;re in. In the default &lt;code>OnCreate&lt;/code> it&amp;rsquo;s not async - but we can make it so by just adding the &lt;code>async&lt;/code> keyword and it just works. Which is really nice.&lt;/p>
&lt;div class="image-div" style="width: 300px;">
&lt;p>&lt;img src="meme2.jpg" alt="Async all the things!">&lt;/p>
&lt;/div>
&lt;br/>
&lt;p>We have some data, so lets create our first view model to display it.
When we added MVVMLight to the StupendousCounter.Droid project it created a dummy &lt;code>MainViewModel&lt;/code> and &amp;lsquo;ViewModelLocator&amp;rsquo;. These are useful starting points for our code but they are not in the right place - one of the big upsides of MVVM is the separation of concerns that is gives us, so the UI is completely independent of the Model (which contains our data) and the view model (which is a converter that converts from the UI view of our data to the Models view). Despite the view model converting from model to UI it should never contain any UI specific code - it converts the Models into a set of properties and commands that are bound to the UI in the View and allows the UI to get or set data or perform actions. Properties are simple data types that the view can show, update and detect updates to based off the &lt;a href="https://msdn.microsoft.com/en-us/library/system.componentmodel.inotifypropertychanged%28v=vs.110%29.aspx?f=255&amp;amp;MSPPError=-2147217396">INotifyPropertyChanged&lt;/a> interface. Commands are implementations of &lt;a href="https://msdn.microsoft.com/en-us/library/system.windows.input.icommand(v=vs.110).aspx">ICommand&lt;/a> that allow an event raised on the UI to run an action including checking if that action is allowed based on some criteria. These are all non-UI specific pieces and therefore do not need to be in the UI layer, nor do they need to be platform specific. So it&amp;rsquo;s better to put them in the Core project so that if we want to port this app to iOS we don&amp;rsquo;t have to re-implement the view models, just the Views. We can also then write unit tests against them simulating the View&amp;rsquo;s interaction by getting or setting properties, detecting the &lt;code>PropertyChanged&lt;/code> event on the &lt;code>INotifyPropertyChanged&lt;/code> interface and executing commands.&lt;/p>
&lt;p>To do this just drag the folder to the StupendousCounter.Core project and delete it from StupendousCounter.Droid. Then just update the namespaces in the 2 files to match the new location - using Resharper of course!&lt;/p>
&lt;p>We need a couple of view models - one for the individual counters and one for the overall collection of counters.&lt;/p>
&lt;h6 id="counterviewmodel">CounterViewModel&lt;/h6>
&lt;p>Lets start with the &lt;code>CounterViewModel&lt;/code>, a view model that wraps a &lt;code>Counter&lt;/code>:&lt;/p>
&lt;pre tabindex="0">&lt;code>using System.Threading.Tasks;
using GalaSoft.MvvmLight;
using GalaSoft.MvvmLight.Command;
namespace StupendousCounter.Core.ViewModel
{
public class CounterViewModel : ViewModelBase
{
private readonly Counter _counter;
private readonly IDatabaseHelper _databaseHelper;
public CounterViewModel(Counter counter, IDatabaseHelper databaseHelper)
{
_counter = counter;
_databaseHelper = databaseHelper;
}
public string Name =&amp;gt; _counter.Name;
public string Description =&amp;gt; _counter.Description;
public string Value =&amp;gt; _counter.Value.ToString(&amp;#34;N0&amp;#34;);
private RelayCommand _incrementCommand;
public RelayCommand IncrementCommand =&amp;gt; _incrementCommand ?? (_incrementCommand = new RelayCommand(async () =&amp;gt; await IncrementAsync()));
private async Task IncrementAsync()
{
await _databaseHelper.IncrementCounterAsync(_counter);
RaisePropertyChanged(() =&amp;gt; Value);
}
}
}
&lt;/code>&lt;/pre>&lt;p>This view model derives from &lt;code>GalaSoft.MvvmLightViewModelBase&lt;/code>. This base class provides a few useful bits of functionality including an implementation of &lt;code>INotifyPropertyChanged&lt;/code> to make it easy to raise events when properties change. It has other cool stuff as well, but that&amp;rsquo;s outside the scope of this but it&amp;rsquo;s worth reading up on it.&lt;/p>
&lt;p>The constructor takes a &lt;code>Counter&lt;/code> that will provide all our data, and an &lt;code>IDatabaseHelper&lt;/code> that we can use to update the counters value. Note that its the interface, not the concrete &lt;code>DatabaseHelper&lt;/code> that we use so that we can mock it later for unit tests.&lt;/p>
&lt;p>The &lt;code>Name&lt;/code> and &lt;code>Description&lt;/code> properties are simple read-only pass throughs to the properties on the underlying &lt;code>Counter&lt;/code>. The &lt;code>Value&lt;/code> property is slightly more complicated - I&amp;rsquo;m converting it to a string with no decimal places so it can be shown in a text view. I&amp;rsquo;m using the new, cleaner &lt;a href="https://visualstudiomagazine.com/articles/2015/06/03/c-sharp-6-expression-bodied-properties-dictionary-initializer.aspx">C# 6 expression bodied property&lt;/a> syntax for these which is so much cleaner than writing the properties out in full. These are read only as there is no need to update them directly - the only property that we can update is the value when the counter is incremented and we don&amp;rsquo;t want to do this with a direct property update, instead we want to do this in the &lt;code>IncrementCommand&lt;/code>. This command uses a MVVMLight &lt;code>RelayCommand&lt;/code> to wrap an async call to our &lt;code>Increment&lt;/code> method. This will increment the counter in the SQLite db using our database helper, then call &lt;code>RaisePropertyChanged&lt;/code> to indicate back to the view that the value has changed so the UI should update what it shows on screen. One thing I still think is odd is that there isn&amp;rsquo;t an implementation of &lt;code>ICommand&lt;/code> in the .Net framework - you either have to write your own or use one from a library like MVVMLight. Seems like a serious omission to me.&lt;/p>
&lt;h6 id="unit-testing-the-counterviewmodel">Unit testing the CounterViewModel&lt;/h6>
&lt;p>We&amp;rsquo;ve now got the view model for our counter, so before we use it we should test it (I know some people will say we should have written our tests before writing the view model but hey ho). For this we need a basic class library called &lt;code>StupendousCounter.Core.Tests&lt;/code>.&lt;/p>
&lt;div class="image-div" style="width: 700px;">
&lt;p>&lt;img src="Screen-Shot-2016-01-23-at-14-53-49.png" alt="Create StupendousCounter.Core.Tests class library">&lt;/p>
&lt;/div>
&lt;br/>
&lt;p>We can add the same &lt;code>NUnit&lt;/code> and &lt;code>FluentAssertions&lt;/code> nuget packages as we did for the Android bases tests, and &lt;code>MVVMLightLibs&lt;/code>. We also want to install &lt;a href="https://www.nuget.org/packages/Moq/">Moq&lt;/a>, an enjoyable mocking library that we can use to mock out the database layer. The &lt;code>CommonServiceLocator&lt;/code> shown in the picture below is a dependency of &lt;code>MVVMLightLibs&lt;/code> and is installed automatically.&lt;/p>
&lt;div class="image-div" style="width: 700px;">
&lt;p>&lt;img src="Screen-Shot-2016-01-23-at-15-01-14.png" alt="Installed nuget packages">&lt;/p>
&lt;/div>
&lt;br/>
&lt;p>Now we have our packages installed, lets delete the auto created &lt;code>Class1.cs&lt;/code> and add our &lt;code>CounterViewModelTests&lt;/code> class. I like to keep the structure of the tests project the same as the project it&amp;rsquo;s testing so I&amp;rsquo;ve created it in the &lt;code>ViewModel&lt;/code> folder.&lt;/p>
&lt;div class="image-div" style="width: 300px;">
&lt;p>&lt;img src="Screen-Shot-2016-01-23-at-15-05-00.png" alt="CounterViewModelTests class">&lt;/p>
&lt;/div>
&lt;br/>
&lt;pre tabindex="0">&lt;code>using FluentAssertions;
using Moq;
using NUnit.Framework;
using StupendousCounter.Core.ViewModel;
namespace StupendousCounter.Core.Tests.ViewModel
{
[TestFixture]
public class CounterViewModelTests
{
private Mock&amp;lt;IDatabaseHelper&amp;gt; _mockDatabaseHelper;
private CounterViewModel CreateCounterViewModel(int value = 10, string description = &amp;#34;Bar&amp;#34;, string name = &amp;#34;Foo&amp;#34;)
{
var counter = new Counter { Name = name, Description = description, Value = value };
return new CounterViewModel(counter, _mockDatabaseHelper.Object);
}
[SetUp]
public void SetUp()
{
_mockDatabaseHelper = new Mock&amp;lt;IDatabaseHelper&amp;gt;();
}
[Test]
public void NameShouldComeFromTheCounter()
{
CreateCounterViewModel().Name.Should().Be(&amp;#34;Foo&amp;#34;);
}
[Test]
public void DescriptionShouldComeFromTheCounter()
{
CreateCounterViewModel().Description.Should().Be(&amp;#34;Bar&amp;#34;);
}
[Test]
public void ValueShouldComeFromTheCounter()
{
CreateCounterViewModel().Value.Should().Be(&amp;#34;10&amp;#34;);
}
[Test]
public void ExecutingTheIncrementCommandShouldIncrementTheValueInTheDatabaseHelper()
{
_mockDatabaseHelper.Setup(d =&amp;gt; d.IncrementCounterAsync(It.IsAny&amp;lt;Counter&amp;gt;())).Callback&amp;lt;Counter&amp;gt;(c =&amp;gt; ++c.Value);
var counter = new Counter {Value = 10};
var vm = new CounterViewModel(counter, _mockDatabaseHelper.Object);
vm.IncrementCommand.Execute(null);
_mockDatabaseHelper.Verify(d =&amp;gt; d.IncrementCounterAsync(counter));
vm.Value.Should().Be(&amp;#34;11&amp;#34;);
}
[Test]
public void ExecutingTheIncrementCommandShouldRaiseAPropertyChangeForValue()
{
var vm = CreateCounterViewModel();
vm.MonitorEvents();
vm.IncrementCommand.Execute(null);
vm.ShouldRaisePropertyChangeFor(v =&amp;gt; vm.Value);
}
}
}
&lt;/code>&lt;/pre>&lt;p>Some of the tests should be self-explanatory. The &lt;code>xxxShouldComeFromTheCounter&lt;/code> tests verify that the values on the view model actually come from the counter. These are great sanity tests as it&amp;rsquo;s easy to copy/past properties when creating lots of passthroughs in bigger view models and forget to update the underlying property name. For the value test we are expecting a string value, so we&amp;rsquo;re comparing against a string representation of the set value.&lt;/p>
&lt;p>&lt;code>ExecutingTheIncrementCommandShouldIncrementTheValueInTheDatabaseHelper&lt;/code> is a bit more interesting. This tests 2 things - firstly that the database helper is used to increment the counter (remember our architecture is such that the incrementation is done in the database helper to ensure we store the history, and secondly that the value is updated in the view model. It&amp;rsquo;s in this test the &lt;code>Moq&lt;/code> is used. In the &lt;code>SetUp&lt;/code> method a &lt;code>Mock&amp;lt;IDatabaseHelper&amp;gt;&lt;/code> is created - this is a dummy object that we can use to provide our own implementation of the interface. It exposes an &lt;code>Object&lt;/code> property that is the interface we&amp;rsquo;re implementing and allows us to setup methods and properties to do what we want, and verify calls against them. In this case in the test were setting up the &lt;code>IncrementCounterAsync&lt;/code> method to increment the counters value. When we execute the &lt;code>IncrementCommand&lt;/code> it calls this method on the database helper stored in the view model, which is our mock, so our method gets called. After the command is executed we verify that the method on the Mock was actually called, and validate that the value was incremented. Mocks are really handy as we&amp;rsquo;ve managed to test code that calls the database helper without actually needing to set up a SQLite db.&lt;/p>
&lt;p>The final test &lt;code>ExecutingTheIncrementCommandShouldRaiseAPropertyChangeForValue&lt;/code> is interesting as well. This is to validate that our UI is going to be updated. We can take it for granted that if a &lt;code>PropertyChanged&lt;/code> event is fired then the UI will be updated as we will be binding this property using MVVMLight later, so all we need to do is ensure that when we execute the &lt;code>IncrementCommand&lt;/code> the correct property change event is fired. FluentAssertions has some nice extension methods to ensure property change events are fired and these take expressions allowing the property in question to be defined in code instead of using a magic string - less fragile if the property name changes.&lt;/p>
&lt;p>If you run these tests they should all pass allowing us to have some confidence in this view model.&lt;/p>
&lt;div class="image-div" style="width: 400px;">
&lt;p>&lt;img src="Screen-Shot-2016-01-23-at-15-42-22.png" alt="All tests passing">&lt;/p>
&lt;/div>
&lt;br/>
&lt;h6 id="countersviemodel">CountersVieModel&lt;/h6>
&lt;p>Once we have a view model for the individual counters we can create one for the overall list of counters. For this we will create a new class, &lt;code>CountersViewModel&lt;/code>. Like the &lt;code>CounterViewModel&lt;/code> above this will also derive from &lt;code>ViewModelBase&lt;/code>.&lt;/p>
&lt;pre tabindex="0">&lt;code>using System.Collections.ObjectModel;
using System.Threading.Tasks;
using GalaSoft.MvvmLight;
namespace StupendousCounter.Core.ViewModel
{
public class CountersViewModel : ViewModelBase
{
private readonly IDatabaseHelper _databaseHelper;
private readonly ObservableCollection&amp;lt;CounterViewModel&amp;gt; _counters = new ObservableCollection&amp;lt;CounterViewModel&amp;gt;();
public ReadOnlyObservableCollection&amp;lt;CounterViewModel&amp;gt; Counters { get; private set; }
public CountersViewModel(IDatabaseHelper databaseHelper)
{
_databaseHelper = databaseHelper;
Counters = new ReadOnlyObservableCollection&amp;lt;CounterViewModel&amp;gt;(_counters);
}
public async Task LoadCountersAsync()
{
var counters = await _databaseHelper.GetAllCountersAsync();
foreach (var counter in counters)
{
_counters.Add(new CounterViewModel(counter, _databaseHelper));
}
}
}
}
&lt;/code>&lt;/pre>&lt;p>This is quite a simple view model - it takes the database helper and exposes a method to load the counters from the database and wrap them all in the appropriate view model. These counters are exposed as a &lt;code>ReadonlyObservableCollection&amp;lt;CounterViewModel&amp;gt;&lt;/code>, as opposed to a standard &lt;code>ObservableCollection&amp;lt;CounterViewModel&amp;gt;&lt;/code>. Most people just use observable collections to expose collections of objects in the view model, but I prefer to expose them as a read only collection. The reason for this is the public properties and methods expose the intent and capabilities of a class, and to me exposng an observable collection that can be modified suggests that it is perfectly acceptable to modify the collection externally. In this case we don&amp;rsquo;t want it to be modified externally, and when we implement an add button we will do it via a command that adds the new counter instead of by modifiying the collection directly. Therefore by exposing it as a read only collection we are saying that we explicitly don&amp;rsquo;t want anyone else to modify it.&lt;/p>
&lt;h6 id="unit-testing-the-countersviewmodel">Unit testing the CountersViewModel&lt;/h6>
&lt;p>Despite being a simple view model we still shoudl write tests - always good to get as much converage as possible to catch any silly errors. At the moment all we need to test is that when we load the conters they are loaded correctly so this is a simple unit test class:&lt;/p>
&lt;pre tabindex="0">&lt;code>using System.Collections.Generic;
using System.Threading.Tasks;
using FluentAssertions;
using Moq;
using NUnit.Framework;
using StupendousCounter.Core.ViewModel;
namespace StupendousCounter.Core.Tests.ViewModel
{
[TestFixture]
public class CountersViewModelTests
{
private Mock&amp;lt;IDatabaseHelper&amp;gt; _mockDatabaseHelper;
private readonly Counter _monkeyCounter = new Counter
{
Name = &amp;#34;Monkey Count&amp;#34;,
Description = &amp;#34;The number of monkeys&amp;#34;,
Value = 10
};
private readonly Counter _platypusCounter = new Counter
{
Name = &amp;#34;Playtpus Count&amp;#34;,
Description = &amp;#34;The number of duck-billed platypuses&amp;#34;,
Value = 4
};
private static bool Matches(CounterViewModel cvm, Counter counter)
{
return cvm.Name == counter.Name &amp;amp;&amp;amp;
cvm.Description == counter.Description &amp;amp;&amp;amp;
cvm.Value == counter.Value.ToString(&amp;#34;N0&amp;#34;);
}
[SetUp]
public void SetUp()
{
_mockDatabaseHelper = new Mock&amp;lt;IDatabaseHelper&amp;gt;();
}
[Test]
public async Task LoadCountersAsyncShouldLoadTheCountersFromTheDatabase()
{
_mockDatabaseHelper.Setup(d =&amp;gt; d.GetAllCountersAsync()).ReturnsAsync(new List&amp;lt;Counter&amp;gt; {_monkeyCounter, _platypusCounter});
var vm = new CountersViewModel(_mockDatabaseHelper.Object);
await vm.LoadCountersAsync();
vm.Counters.Should().HaveCount(2);
vm.Counters.Should().Contain(c =&amp;gt; Matches(c, _monkeyCounter));
vm.Counters.Should().Contain(c =&amp;gt; Matches(c, _platypusCounter));
}
}
}
&lt;/code>&lt;/pre>&lt;p>The single test here will load the counters and ensure they match the ones we&amp;rsquo;ve mocked the database helper to return. The only lightly new thing here is this test is async - note the &lt;code>async Task&lt;/code> return type. This tells NUnit to run these using async/await so inside the tests we can &lt;code>await&lt;/code> any async calls, like the &lt;code>LoadCountersAsync&lt;/code> method on the database helper.&lt;/p>
&lt;h6 id="exposing-our-view-models">Exposing our view models&lt;/h6>
&lt;p>The autogenerated classes provided by MVVMLight expose a main view model and a view model locator. The &lt;code>MainViewModel.cs&lt;/code> file isn&amp;rsquo;t really of any use to us, so it can be deleted.
The &lt;code>ViewModelLocator&lt;/code> however is useful. It&amp;rsquo;s an implementation of the service locator pattern using SimpleIoC internally. Once tidied up and changed to suit our needs it looks like this:&lt;/p>
&lt;pre tabindex="0">&lt;code>using GalaSoft.MvvmLight.Ioc;
using Microsoft.Practices.ServiceLocation;
namespace StupendousCounter.Core.ViewModel
{
public class ViewModelLocator
{
static ViewModelLocator()
{
ServiceLocator.SetLocatorProvider(() =&amp;gt; SimpleIoc.Default);
SimpleIoc.Default.Register&amp;lt;IDatabaseHelper&amp;gt;(() =&amp;gt; new DatabaseHelper());
SimpleIoc.Default.Register&amp;lt;CountersViewModel&amp;gt;();
}
public static CountersViewModel Counters =&amp;gt; ServiceLocator.Current.GetInstance&amp;lt;CountersViewModel&amp;gt;();
}
}
&lt;/code>&lt;/pre>&lt;p>The hordes of comments have been removed as we don&amp;rsquo;t really need them. The clean method is also gone as again we don&amp;rsquo;t need it. The important change though is in the static constructor where we register a new &lt;code>DatabaseHelper&lt;/code> instance as an &lt;code>IDatabaseHelper&lt;/code>, as well as registering the &lt;code>CountersViewModel&lt;/code> type. These are registered against the &lt;code>SimpleIoc.Default&lt;/code> instance, which is set up as the locator provider for the &lt;code>ServiceLocator&lt;/code>. &lt;code>SimpleIoc.Default&lt;/code> is a default instance of the &lt;code>SimpleIoc&lt;/code> container, and anything registered in a container instance is effectively a singleton inside that instance. Having this default instance set up as the service locators provider means that whenever we access the &lt;code>ServiceLocator.Current&lt;/code> singleton and get an instance we will get the single instance that we registered.
For example out &lt;code>Counters&lt;/code> property gets the instance of &lt;code>CountersViewModel&lt;/code> from the service locator, which in turn gets it from the default SimpleIoc instance, which checks if it has an instance of the type and if so returns it, if not it creates a new one injecting any constructor parameters using types also registered in the SimpleIoc instance.
If none of this makes sense then I suggest you stop reading here and read up on the &lt;a href="https://en.wikipedia.org/wiki/Dependency_injection">dependency injection pattern&lt;/a> and &lt;a href="https://en.wikipedia.org/wiki/Service_locator_pattern">service locator patterns&lt;/a>. These are pretty standard, allow for nicely decoupled applications, and are pretty fundamental to a good MVVM implementation.&lt;/p>
&lt;p>The code for this can be found in GitHub on the Part3 branch at &lt;a href="https://github.com/jimbobbennett/StupendousCounter/tree/Part3">https://github.com/jimbobbennett/StupendousCounter/tree/Part3&lt;/a>&lt;/p>
&lt;p>In the &lt;a href="https://jimbobbennett.dev/blogs/building-a-xamarin-android-app-part-4/">next part&lt;/a> we&amp;rsquo;ll work on the actual UI and start wiring everything up.&lt;/p>
&lt;hr/>
&lt;p>
&lt;table cellspacing="0" cellpadding="0" style='border: none;border-collapse: collapse;'>
&lt;tr style='padding: 0;'>
&lt;td style='padding: 0;vertical-align: top;'>
&lt;iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="//ws-eu.amazon-adsystem.com/widgets/q?ServiceVersion=20070822&amp;OneJS=1&amp;Operation=GetAdHtml&amp;MarketPlace=GB&amp;source=ss&amp;ref=ss_til&amp;ad_type=product_link&amp;tracking_id=expecti-21&amp;marketplace=amazon&amp;region=GB&amp;placement=B0000250CZ&amp;asins=B0000250CZ&amp;linkId=&amp;show_border=false&amp;link_opens_in_new_window=true">
&lt;/iframe>
&lt;/td>
&lt;td style='padding: 0px 30px;vertical-align: top;'>
&lt;iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="//ws-eu.amazon-adsystem.com/widgets/q?ServiceVersion=20070822&amp;OneJS=1&amp;Operation=GetAdHtml&amp;MarketPlace=GB&amp;source=ss&amp;ref=ss_til&amp;ad_type=product_link&amp;tracking_id=expecti-21&amp;marketplace=amazon&amp;region=GB&amp;placement=B00W3G9LQI&amp;asins=B00W3G9LQI&amp;linkId=&amp;show_border=false&amp;link_opens_in_new_window=true">
&lt;/iframe>
&lt;/td>
&lt;td style='padding: 0px 30px;vertical-align: top;'>
&lt;iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="//ws-eu.amazon-adsystem.com/widgets/q?ServiceVersion=20070822&amp;OneJS=1&amp;Operation=GetAdHtml&amp;MarketPlace=GB&amp;source=ss&amp;ref=ss_til&amp;ad_type=product_link&amp;tracking_id=expecti-21&amp;marketplace=amazon&amp;region=GB&amp;placement=B00533Y2KI&amp;asins=B00533Y2KI&amp;linkId=&amp;show_border=false&amp;link_opens_in_new_window=true">
&lt;/iframe>
&lt;/td>
&lt;td style='padding: 0px 30px;'>
&lt;p style='color:rgb(104, 104, 104);!important;'>Continuing on from the last post where I mentioned what I was listening to whilst developing, today I'm listening to &lt;a href='http://www.heathernova.com'>Heather Nova&lt;/a>&lt;/p>
&lt;p style='color:rgb(104, 104, 104);!important;'>Note - these are an affiliate links - if you click them and buy I get a small cut.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/table>
&lt;/p></description></item><item><title>Come hear me speak at Xamarin Evolve</title><link>https://jimbobbennett.dev/blogs/come-hear-me-speak-at-xamarin-evolve/</link><pubDate>Fri, 22 Jan 2016 17:40:47 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/come-hear-me-speak-at-xamarin-evolve/</guid><description>&lt;p>If you&amp;rsquo;re going to &lt;a href="https://evolve.xamarin.com">Xamarin Evolve 2016&lt;/a> this year then come and hear me talk! I&amp;rsquo;ll be speaking about using iBeacons and Eddystone in your apps including showing how to use beacons to find a hidden monkey- and giving away a few beacons to anyone who who can find the monkey.&lt;/p>
&lt;p>The beacons I will be using will be from &lt;a href="http://estimote.com">Estimote&lt;/a> - they make fantastic hardware and software and have pushed beacons above and beyond what they were meant to do to allow you to do some awesome things. If you want to buy beacons, be sure to check them out. I have no affiliation with them, I don&amp;rsquo;t get anything if you buy their beacons, they just are that awesome that they are worth shouting about.&lt;/p></description></item><item><title>Building a Xamarin Android app - part 2</title><link>https://jimbobbennett.dev/blogs/building-an-android-app-part-2/</link><pubDate>Fri, 15 Jan 2016 21:12:13 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/building-an-android-app-part-2/</guid><description>&lt;p>This is the second part in the my series about building an Android app using Xamarin.Android. You can find the first part &lt;a href="https://jimbobbennett.dev/blogs/building-an-android-app-part-1/">here&lt;/a>, and I highly recommend reading that first.&lt;/p>
&lt;h4 id="time-to-think-about-data">Time to think about data&lt;/h4>
&lt;div class="image-div" style="width: 200px;">
&lt;p>&lt;img src="tumblr_inline_ns06dw2ek41qau8io_500.jpg" alt="Data">&lt;/p>
&lt;/div>
&lt;br/>
&lt;p>In the last post we put together the basic app shell, colour scheme etc. Now lets think about the data model, and how we are going to persist the data - it&amp;rsquo;s no good having a counter if the data is lost every time the app is restarted. For persistence we&amp;rsquo;ll simply use SQLite as we just need something to be stored locally for now.&lt;/p>
&lt;p>The basic set of classes we need are something to represent a counter with its name, description and current value, and a way of storing the dates the counters were incremented. This historical data would allow us to see when counters were incremented - for example it may be nice to see that your &amp;lsquo;cup of coffee&amp;rsquo; count is 74 but it would also be nice to show that in a chart showing cups per day instead of just the total.&lt;/p>
&lt;h6 id="pcl">PCL&lt;/h6>
&lt;p>Now &amp;lsquo;because we&amp;rsquo;re not animals&amp;rsquo; (phrase ©2016 &lt;a href="">Mike James&lt;/a>) I&amp;rsquo;ll be putting all the data and business logic into a portable class library (PCL) so that we can easily port this to another platform if required. If you don&amp;rsquo;t know what a PCL is I suggest you &lt;a href="https://developer.xamarin.com/guides/cross-platform/application_fundamentals/pcl/">read the docs&lt;/a>.&lt;/p>
&lt;p>First we create the PCL - I&amp;rsquo;m going to call it StupendousCounter.Core.&lt;/p>
&lt;div class="image-div" style="width: 700px;">
&lt;p>&lt;img src="Screen-Shot-2016-01-15-at-11-11-23.png" alt="PCL creation">&lt;/p>
&lt;/div>
&lt;br/>
&lt;p>When you create a PCL you have to select which targets it supports so that VS can ensure the right subset of the .Net framework is available. The following targets need to be selected:&lt;/p>
&lt;div class="image-div" style="width: 400px;">
&lt;p>&lt;img src="Screen-Shot-2016-01-15-at-11-56-22.png" alt="PCL targets">&lt;/p>
&lt;/div>
&lt;br/>
&lt;p>Once created we can delete the class1.cs file that is auto generated.&lt;/p>
&lt;h6 id="sqlite">SQLite&lt;/h6>
&lt;p>Next, we&amp;rsquo;re going to need to add SQLite. There&amp;rsquo;s a number of different nuget packages we could add, and a selection of ways we can do this but for this we&amp;rsquo;re going to use &lt;a href="https://www.nuget.org/packages/sqlite-net-pcl/">SQLite-net-pcl&lt;/a>. Note that this is the SQLite-net**-pcl** version, not the base SQLite-net version which won&amp;rsquo;t work with a PCL. This nuget package needs to be added to both projects - the .Core and the .Droid.&lt;/p>
&lt;p>It&amp;rsquo;s really easy to create classes that can be stored in SQLite - it can store simple data types out of the box and has attributes to handle fun things like auto-incrementing primary keys.&lt;/p>
&lt;p>This is the class we&amp;rsquo;ll be using for our counters. This is defined in &lt;code>Counter.cs&lt;/code>:&lt;/p>
&lt;pre tabindex="0">&lt;code>using SQLite;
namespace StupendousCounter.Core
{
public class Counter
{
[PrimaryKey, AutoIncrement]
public int Id { get; set; }
public string Name { get; set; }
public string Description { get; set; }
public long Value { get; set; }
}
}
&lt;/code>&lt;/pre>&lt;br/>
&lt;p>And this is the counter history, defined in &lt;code>CounterIncrementHistory.cs&lt;/code>:&lt;/p>
&lt;pre tabindex="0">&lt;code>using System;
namespace StupendousCounter.Core
{
public class CounterIncrementHistory
{
[Indexed]
public int CounterId { get; set; }
public DateTime IncrementDateTimeUtc { get; set; }
}
}
&lt;/code>&lt;/pre>&lt;br/>
&lt;p>Note the &lt;code>[Indexed]&lt;/code> attribute on the CounterId so that this column gets indexed.&lt;/p>
&lt;p>That&amp;rsquo;s the data classes sorted, now we need to think about how we store and retrieve this data.&lt;/p>
&lt;h6 id="database-connection">Database connection&lt;/h6>
&lt;p>To help us handle the relationships between the counter and it&amp;rsquo;s history, and to abstract away the database from the application (good &lt;a href="https://en.wikipedia.org/wiki/Separation_of_concerns">separation of concerns&lt;/a> helps with unit testing which we&amp;rsquo;ll add later), we&amp;rsquo;ll need to create a database helper. This will contain methods to retrieve all counters, create a new one, update an existing one or increment the counter (and persist the change to the history).
We start by creating an interface that defines our helper. It needs to be an interface so that we can &lt;a href="https://github.com/Moq/moq4">mock it out later when unit testing&lt;/a>.&lt;/p>
&lt;p>Here&amp;rsquo;s the interface code defined in &lt;code>IDatabaseHelper.cs&lt;/code>:&lt;/p>
&lt;pre tabindex="0">&lt;code>using System.Collections.Generic;
using System.Threading.Tasks;
namespace StupendousCounter.Core
{
public interface IDatabaseHelper
{
Task AddOrUpdateCounterAsync(Counter counter);
Task IncrementCounterAsync(Counter counter);
Task&amp;lt;IEnumerable&amp;lt;Counter&amp;gt;&amp;gt; GetAllCountersAsync();
Task&amp;lt;IEnumerable&amp;lt;CounterIncrementHistory&amp;gt;&amp;gt; GetCounterHistoryAsync(int counterId);
}
}
&lt;/code>&lt;/pre>&lt;br/>
&lt;p>Notice all the methods are set up ready to use async/await because we&amp;rsquo;re writing modern code and want to do it properly!&lt;/p>
&lt;p>Now lets start constructing the implementation (or to be honest lets get &lt;a href="https://www.jetbrains.com/resharper/">Resharper&lt;/a> to create our implementation) in &lt;code>DatabaseHelper.cs&lt;/code>:&lt;/p>
&lt;pre tabindex="0">&lt;code>using System.Collections.Generic;
using System.Threading.Tasks;
namespace StupendousCounter.Core
{
public class DatabaseHelper : IDatabaseHelper
{
public async Task AddOrUpdateCounterAsync(Counter counter)
{
throw new System.NotImplementedException();
}
public async Task IncrementCounterAsync(Counter counter)
{
throw new System.NotImplementedException();
}
public async Task&amp;lt;IEnumerable&amp;lt;Counter&amp;gt;&amp;gt; GetAllCountersAsync()
{
throw new System.NotImplementedException();
}
public async Task&amp;lt;IEnumerable&amp;lt;CounterIncrementHistory&amp;gt;&amp;gt; GetCounterHistoryAsync(int counterId)
{
throw new NotImplementedException();
}
}
}
&lt;/code>&lt;/pre>&lt;br/>
&lt;p>SQLite is a file based database - it stores it&amp;rsquo;s data in a single .db file that is stored locally on the device. This location is different depending on which OS it&amp;rsquo;s running on, so Android puts these files in one place, iOS somewhere different. This means that we have to do some work in the Android project itself to construct the path to the database file, and this path needs to be available to our database helper implementation. We also need to initialise the database to create the tables that will be storing our data. The simplest way to do this is to have a static initialisation method that we call from the MainActivity:&lt;/p>
&lt;pre tabindex="0">&lt;code> public class DatabaseHelper : IDatabaseHelper
{
public static void CreateDatabase(string dbPath)
{}
&lt;/code>&lt;/pre>&lt;br/>
&lt;p>In Android the correct place to store your SQLite database files according to Xamarin is in the personal folder, which is defined quite helpfully in &lt;code>System.Environment.SpecialFolder.Personal&lt;/code>. Honestly I&amp;rsquo;ve yet to find out exactly why this is the recommended place, so if you know please let me know!&lt;/p>
&lt;p>In our &lt;code>MainActivity.cs&lt;/code>, in the &lt;code>OnCreate&lt;/code> method we can grab this folder, add a db file and pass that to the CreateDatabase method on our database helper:&lt;/p>
&lt;pre tabindex="0">&lt;code>protected override void OnCreate(Bundle savedInstanceState)
{
base.OnCreate(savedInstanceState);
var path = System.Environment.GetFolderPath(System.Environment.SpecialFolder.Personal);
var dbPath = Path.Combine(path, &amp;#34;counters.db3&amp;#34;);
DatabaseHelper.CreateDatabase(dbPath);
&lt;/code>&lt;/pre>&lt;br/>
&lt;p>There are nicer ways of doing this, and we&amp;rsquo;ll improve this in a later part, so don&amp;rsquo;t be too offended by this implementation.&lt;/p>
&lt;p>For the body of the &lt;code>CreateDatabase&lt;/code> we store the db file path, open the database and create all the tables. Luckily SQLite is smart enough to not create the tables if they already exist, so this can be run as many times as you want without worrying about corrupting data.&lt;/p>
&lt;pre tabindex="0">&lt;code>private static string _dbPath;
public static void CreateDatabase(string dbPath)
{
_dbPath = dbPath;
using (var connection = new SQLiteConnection(dbPath, SQLiteOpenFlags.Create|SQLiteOpenFlags.ReadWrite))
{
connection.CreateTable&amp;lt;Counter&amp;gt;();
connection.CreateTable&amp;lt;CounterIncrementHistory&amp;gt;();
}
}
&lt;/code>&lt;/pre>&lt;br/>
&lt;p>Now lets implement the main logic. First up, &lt;code>AddOrUpdateCounterAsync&lt;/code>:&lt;/p>
&lt;pre tabindex="0">&lt;code>public async Task AddOrUpdateCounterAsync(Counter counter)
{
var connection = new SQLiteAsyncConnection(_dbPath);
if (counter.Id == 0)
await connection.InsertAsync(counter);
else
await connection.InsertOrReplaceAsync(counter);
}
&lt;/code>&lt;/pre>&lt;br/>
&lt;p>This method checks the id on the counter - if it&amp;rsquo;s 0 then its a new counter and is inserted, otherwise it&amp;rsquo;s updated. Remember our Id field had the &lt;code>[PrimaryKey]&lt;/code> attribute, so that&amp;rsquo;s how SQLite can know which counter to update.
For the update we use the &lt;code>InsertOrReplace&lt;/code> method, and this checks the Id against the database and if it&amp;rsquo;s not found then it inserts the item, otherwise it replaces it. Now this sounds a lot like what we&amp;rsquo;ve implemented ourselves, so why do we do the check for an Id of 0 and call &lt;code>Insert&lt;/code> if found? The reason is the &lt;code>[AutoIncrement]&lt;/code> attribute. This tells SQLite to automatically increment the id to get the next one - so if we have 10 items in the database and we insert one more it gets its id set to 11. If we insert this counter using &lt;code>Insert&lt;/code> then the id on our object gets updated - so we can see the new Id in the Counter instance that is passed in. If we call &lt;code>InsertOrReplace&lt;/code> it doesn&amp;rsquo;t update the instance passed id. I&amp;rsquo;m not sure if this is by design or a bug but it&amp;rsquo;s a bit annoying, hence the workaround of calling &lt;code>Insert&lt;/code> if the id is 0. This way once this method is called we can always trust the id of the Counter we passed in.&lt;/p>
&lt;p>Second up is &lt;code>IncrementCounterAsync&lt;/code>:&lt;/p>
&lt;pre tabindex="0">&lt;code>public async Task IncrementCounterAsync(Counter counter)
{
var connection = new SQLiteAsyncConnection(_dbPath);
counter.Value++;
await AddOrUpdateCounterAsync(counter);
var history = new CounterIncrementHistory
{
CounterId = counter.Id,
IncrementDateTimeUtc = DateTime.UtcNow
};
await connection.InsertAsync(history);
}
&lt;/code>&lt;/pre>&lt;br/>
&lt;p>This is a little bit more involved. First up it increments the value, then updates the entry in the database to reflect the new value (using our &lt;code>AddorUpdateAsync&lt;/code> method to ensure the Id on the Counter is updated). Next we create a history entry, then this history entry gets inserted. Note that the timestamp is stored as UTC time - this allows the times to be adjusted for wherever the user is and if they increment in a different time zone the data doesn&amp;rsquo;t get out of whack.&lt;/p>
&lt;p>Thirdly we need to implement &lt;code>GetAllCountersAsync&lt;/code>:&lt;/p>
&lt;pre tabindex="0">&lt;code>public async Task&amp;lt;IEnumerable&amp;lt;Counter&amp;gt;&amp;gt; GetAllCountersAsync()
{
var connection = new SQLiteAsyncConnection(_dbPath);
return await connection.Table&amp;lt;Counter&amp;gt;().ToListAsync();
}
&lt;/code>&lt;/pre>&lt;br/>
&lt;p>The generic &lt;code>Table&amp;lt;T&amp;gt;&lt;/code> method on the connection returns the table that stores the given type, and from there we get it back as a list of Counters from the database.
Just be aware though - these will be new instances. So if you add a Counter then get all the Counter you have added will be a different instance than the Counter in the collection with the same Id.&lt;/p>
&lt;p>Finally we need to implement &lt;code>GetCounterHistoryAsync&lt;/code>:&lt;/p>
&lt;pre tabindex="0">&lt;code>public async Task&amp;lt;IEnumerable&amp;lt;CounterIncrementHistory&amp;gt;&amp;gt; GetCounterHistory(int counterId)
{
var connection = new SQLiteAsyncConnection(_dbPath);
return await connection.Table&amp;lt;CounterIncrementHistory&amp;gt;().Where(c =&amp;gt; c.CounterId == counterId).ToListAsync();
}
&lt;/code>&lt;/pre>&lt;br/>
&lt;p>This queries the history based off the counter id.&lt;/p>
&lt;p>This is our database connection all finished - so now lets test it. We haven&amp;rsquo;t wired it up to the UI yet, so lets test it by building some unit tests.&lt;/p>
&lt;h4 id="unit-testing-our-database-connection">Unit testing our database connection&lt;/h4>
&lt;p>The best way to verify everything is working is with a stack of unit tests. Normally when writing C# code you create a console application or a class library and create your tests in there. This works well for simple cases, but with SQLite I don&amp;rsquo;t think it quite cuts the mustard. The problem is the platform specific implementation of SQLite might be different on Android (the platform we&amp;rsquo;re targeting) and Windows (the platform the tests would be run on).
Luckily there is a way to easily run unit tests on Android - a Xamarin Android Unit test project. So lets start be creating a new project of this type.&lt;/p>
&lt;div class="image-div" style="width: 700px;">
&lt;p>&lt;img src="Screen-Shot-2016-01-15-at-18-15-22.png" alt="Xamarin Android Unit Test project creation">&lt;/p>
&lt;/div>
&lt;br/>
&lt;p>This project creates an Android app that runs our unit tests. It uses a custom variant of NUnit called &lt;code>Xamarin.Android.NUnitLite&lt;/code>, but for all intents and purposes this can be used like NUnit.
The app runs like any other Android app and has a &amp;lsquo;Run Tests&amp;rsquo; button. This will work through all classes in the project with the NUnit &lt;code>[TestFixture]&lt;/code> attribute and run all methods with the &lt;code>[Test]&lt;/code> attribute, dumping their output to the screen.&lt;/p>
&lt;div class="image-div" style="width: 300px;">
&lt;p>&lt;img src="Screen-Shot-2016-01-15-at-18-48-34.png" alt="Xamarin Android Unit Test app">&lt;/p>
&lt;/div>
&lt;br/>
&lt;p>We do have to install a couple of other nuget packages as well - first we need SQLite-pcl-net of course. Second we need FluentAssertions.Xamarin - simply because I love the assertion syntax of Fluent Assertions and this is a version that runs on mobile.&lt;/p>
&lt;p>Once all these packages are installed, we can bin the auto-created tests file and create our own called &lt;code>DatabaseHelpersTests.cs&lt;/code>.&lt;/p>
&lt;h6 id="writing-our-first-test">Writing our first test&lt;/h6>
&lt;p>Lets start with a simple test to start with which is to test that a newly inserted Counter gets its Id set.
In our &lt;code>DatabaseHelpersTests.cs&lt;/code> first we mark the class with the &lt;code>[TestFixture]&lt;/code> attribute&lt;/p>
&lt;pre tabindex="0">&lt;code>[TestFixture]
public class DatabaseHelperTests
&lt;/code>&lt;/pre>&lt;br/>
&lt;p>Then we can create our first test:&lt;/p>
&lt;pre tabindex="0">&lt;code>[Test]
public void InsertingACounterShouldSetItsIdAsync()
{
var dbfile = Path.Combine(RootPath, Guid.NewGuid().ToString(&amp;#34;N&amp;#34;) + &amp;#34;.db3&amp;#34;);
DatabaseHelper.CreateDatabase(dbfile);
var db = new DatabaseHelper();
var counter = new Counter
{
Name = &amp;#34;TestCounter&amp;#34;,
Description = &amp;#34;A test counter&amp;#34;
};
counter.Id.Should().Be(0);
var res = Task.Run(async () =&amp;gt;
{
await db.AddOrUpdateCounterAsync(counter);
return 0;
}).Result;
counter.Id.Should().Be(1);
}
&lt;/code>&lt;/pre>&lt;br/>
&lt;p>What this test does is create a database with a new unique name (so we can ensure the database is clean), it then creates a new counter and verifies the Id is 0 (love me that assertion syntax!).
The next is the odd bit. If you create an async unit test it seems to hang when running it on the simulator, so to work around it I have to run the async code in a Task that is waited for. This works. Very annoying, but not much else we can do.
Once the counter is inserted we assert that the counter is updated to 1.&lt;/p>
&lt;p>Launching the test app and clicking &amp;lsquo;Run Tests&amp;rsquo; will run this test and you&amp;rsquo;ll see it pass, with &amp;lsquo;1 test passed&amp;rsquo; showing on the app.&lt;/p>
&lt;p>I&amp;rsquo;ll add a selection of other tests as well, and these can all be seen in the code on GitHub in the Part2 branch at &lt;a href="https://github.com/jimbobbennett/StupendousCounter/tree/Part2">https://github.com/jimbobbennett/StupendousCounter/tree/Part2&lt;/a>.&lt;/p>
&lt;p>In the &lt;a href="https://jimbobbennett.dev/blogs/building-a-xamarin-android-app-part-3/">next part&lt;/a> we&amp;rsquo;ll start wiring the UI up to the data using &lt;a href="http://www.mvvmlight.net">MVVMLight&lt;/a>.&lt;/p>
&lt;hr/>
&lt;p>
&lt;table cellspacing="0" cellpadding="0" style='border: none;border-collapse: collapse;'>
&lt;tr style='padding: 0;'>
&lt;td style='padding: 0;vertical-align: top;'>
&lt;iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="//ws-eu.amazon-adsystem.com/widgets/q?ServiceVersion=20070822&amp;OneJS=1&amp;Operation=GetAdHtml&amp;MarketPlace=GB&amp;source=ss&amp;ref=ss_til&amp;ad_type=product_link&amp;tracking_id=expecti-21&amp;marketplace=amazon&amp;region=GB&amp;placement=B00E4JGPO8&amp;asins=B00E4JGPO8&amp;linkId=&amp;show_border=false&amp;link_opens_in_new_window=true">
&lt;/iframe>
&lt;/td>
&lt;td style='padding: 0px 30px;vertical-align: top;'>
&lt;iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="//ws-eu.amazon-adsystem.com/widgets/q?ServiceVersion=20070822&amp;OneJS=1&amp;Operation=GetAdHtml&amp;MarketPlace=GB&amp;source=ss&amp;ref=ss_til&amp;ad_type=product_link&amp;tracking_id=expecti-21&amp;marketplace=amazon&amp;region=GB&amp;placement=B00JLZVJSM&amp;asins=B00JLZVJSM&amp;linkId=&amp;show_border=false&amp;link_opens_in_new_window=true">
&lt;/iframe>
&lt;/td>
&lt;td style='padding: 0px 30px;vertical-align: top;'>
&lt;iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="//ws-eu.amazon-adsystem.com/widgets/q?ServiceVersion=20070822&amp;OneJS=1&amp;Operation=GetAdHtml&amp;MarketPlace=GB&amp;source=ss&amp;ref=ss_til&amp;ad_type=product_link&amp;tracking_id=expecti-21&amp;marketplace=amazon&amp;region=GB&amp;placement=B008CYV046&amp;asins=B008CYV046&amp;linkId=&amp;show_border=false&amp;link_opens_in_new_window=true">
&lt;/iframe>
&lt;/td>
&lt;td style='padding: 0px 30px;'>
&lt;p style='color:rgb(104, 104, 104);!important;'>Continuing on from the last post where I mentioned what I was listening to whilst developing, today I'm listening to &lt;a href='http://www.nicolabenedetti.co.uk'>Nicola Benedetti&lt;/a>&lt;/p>
&lt;p style='color:rgb(104, 104, 104);!important;'>Note - these are an affiliate links - if you click them and buy I get a small cut.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/table>
&lt;/p></description></item><item><title>Building a Xamarin Android app - part 1</title><link>https://jimbobbennett.dev/blogs/building-an-android-app-part-1/</link><pubDate>Wed, 13 Jan 2016 17:26:15 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/building-an-android-app-part-1/</guid><description>&lt;p>I&amp;rsquo;ve got a bit of time off between finishing my career as a slave to the world of finance IT and starting a new and exciting job as a Xamarin mobile app developer in New Zealand, so I thought I&amp;rsquo;d try to brush up on my Xamarin.Android knowledge as in the past I&amp;rsquo;ve mainly focused on iOS.&lt;/p>
&lt;p>So to help me do this, I&amp;rsquo;ve decided to build and publish an app, and document the process. So over the next few posts I&amp;rsquo;ll be covering the development of Stupendous Counter - the most amazing counter app ever!&lt;/p>
&lt;h3 id="stupendous-counter">Stupendous Counter&lt;/h3>
&lt;p>The purpose of this app is simple - to count things. Think of it as an automated version of something like this:&lt;/p>
&lt;div class="image-div" style="width: 200px;">
&lt;p>&lt;img src="61WNfiRPhoL-_SX522_.jpg" alt="Click counter">&lt;/p>
&lt;/div>
&lt;p>Obviously being an app it should be a bit more advanced, so I&amp;rsquo;ll be adding multiple named counters, count history with fancy charts, location based counts and other funky tools.&lt;/p>
&lt;h4 id="design">Design&lt;/h4>
&lt;p>First thing to do is to design the UI and flow of the app. I find this a good way to start as it gives me a feel for the views I need to create, the structure of the data I need to store and manipulate and allows me to test the UI out on paper before committing to writing code.&lt;/p>
&lt;p>I&amp;rsquo;ve been playing with a few tools to aid in design, and currently using &lt;a href="https://www.fluidui.com">Fluid UI&lt;/a>. It has a free tier that allows wireframe design, which is what I&amp;rsquo;ve been using. As well as allowing you to wireframe your UI, you can also setup transitions between screens to test out your UI flow.&lt;/p>
&lt;p>The design I&amp;rsquo;ve come up with is a fairly boring, bog standard Android app with all the usual bits - a navigation drawer that&amp;rsquo;s poor UI, a &lt;a href="http://exisweb.net/mobile-menu-abtest">hamburger menu&lt;/a> and a &lt;a href="https://medium.com/tech-in-asia/material-design-why-the-floating-action-button-is-bad-ux-design-acd5b32c5ef#.babzdcoxi">floating action button that does something you don&amp;rsquo;t do very often&lt;/a>.&lt;/p>
&lt;p>Here&amp;rsquo;s a screenshot of the final design for the first version of the app:
&lt;img src="Screen-Shot-2016-01-13-at-14-13-13.png" alt="Final UI design">&lt;/p>
&lt;p>And heres the transitions:&lt;/p>
&lt;div class="image-div" style="width: 200px;">
&lt;p>&lt;img src="CounterTransitions.gif" alt="UI transitions">&lt;/p>
&lt;/div>
&lt;/br>
&lt;p>For the colour scheme I used &lt;a href="http://www.materialpalette.com">Material Palette&lt;/a> which is an awesome tool for choosing colours that work well together in a material design app or website. As a traditional developer I&amp;rsquo;m bad at design and UI so I enlisted the help of my 3 year old daughter to choose the colours - a process that took ages as she was enjoying &amp;lsquo;playing colours on daddy&amp;rsquo;s computer&amp;rsquo;.&lt;/p>
&lt;div class="image-div" style="width: 200px;">
&lt;p>&lt;img src="Screen-Shot-2016-01-13-at-16-13-24.png" alt="Colour scheme">&lt;/p>
&lt;/div>
&lt;/br>
&lt;h4 id="lets-get-coding">Let&amp;rsquo;s get coding&lt;/h4>
&lt;p>And the best way to write code? Get a tool to do it. To create the basic app structure with styles, navigation buttons etc. you need a lot of boiler plate code. Luckily James Montemagno from Xamarin has done the hard work for us with his &lt;a href="http://motzcod.es/post/123682330002/new-improved-xamarinandroid-templates-for">Xamarin.Android templates for Visual Studio&lt;/a>. These templates provide the boiler plate code for a basic AppCompat app, or an AppCompat app with a navigation drawer.&lt;/p>
&lt;div class="image-div" style="width: 700px;">
&lt;p>&lt;img src="Screen-Shot-2016-01-13-at-15-07-14.png" alt="New project types">&lt;/p>
&lt;/div>
&lt;/br>
&lt;p>To start with, I&amp;rsquo;m going to create a Navigation Drawer App called StupendousCounter.Droid. Note the name ends in .Droid, not .Android - otherwise you get a load of namespace clashes with the Android namespace).&lt;/p>
&lt;div class="image-div" style="width: 200px;">
&lt;p>&lt;img src="CYNmIrJWcAYuxrq.png" alt="Keep calm and .Droid it">&lt;/p>
&lt;/div>
&lt;/br>
&lt;p>Once the app is created, it looks like this:&lt;/p>
&lt;div class="image-div" style="width: 300px;">
&lt;p>&lt;img src="FirstAppVersion.gif" alt="Initial navigation drawer app">&lt;/p>
&lt;/div>
&lt;/br>
&lt;p>First thing to do is to make it more like what I&amp;rsquo;m after. The App name is wrong, the colours don&amp;rsquo;t match the scheme chosen by my daughter.&lt;/p>
&lt;h6 id="colours">Colours&lt;/h6>
&lt;p>Setting the colours is easy. In the template there is already a style defined in &lt;code>Resources/values/styles.xml&lt;/code> which references colours defined in &lt;code>Resources/values/colors.xml&lt;/code>. In the colors.xml file are a set of colour properties that match the output from Material Palette:&lt;/p>
&lt;/br>
&lt;p>&lt;img src="Screen-Shot-2016-01-13-at-16-20-45.png" alt="Colour values from material palette">&lt;/p>
&lt;/br>
&lt;p>These colours can be downloaded as an XML file and the values copied in - you can&amp;rsquo;t just drop the xml file in as the names don&amp;rsquo;t write match - for example it&amp;rsquo;s primaryDark in the template generated code and primary_dark in the material Palette output, but it&amp;rsquo;s pretty obvious which value to copy into each field.
Once done the app looks a bit more like what we&amp;rsquo;re after:&lt;/p>
&lt;div class="image-div" style="width: 500px;">
&lt;p>&lt;img src="Screen-Shot-2016-01-13-at-16-25-18.png" alt="Correctly coloured app">&lt;/p>
&lt;/div>
&lt;/br>
&lt;h6 id="app-name">App name&lt;/h6>
&lt;p>The App name is in two parts - first the app name in the manifest file which defines the name given in the app settings, second the activity name that appears on the launcher.
The app name in the manifest file (&lt;code>Properties\AndroidManifest.xml&lt;/code>) is defined as &lt;code>android:label=&amp;quot;@string/app_name&amp;quot;&lt;/code>, so correctly referring to a strings resource file located at &lt;code>Resouces\values\strings.xml&lt;/code>. This is the recommended way to handle all text in your app so that you can easily localise it as described on the &lt;a href="http://developer.android.com/training/basics/supporting-devices/languages.html">Android developer docs&lt;/a>. Setting the app name is therefore nice and easy, just change the strings.xml to have &lt;code>&amp;lt;string name=&amp;quot;app_name&amp;quot;&amp;gt;Stupendous Counter&amp;lt;/string&amp;gt;&lt;/code>. You may need to restart you emulator after re-deploying the app - XAP doesn&amp;rsquo;t update the name in the settings until you restart.&lt;/p>
&lt;p>The main activity is not set up like this though - the template creates it with a hard-coded label of &amp;ldquo;Home&amp;rdquo;. I&amp;rsquo;d like this to match the app name so it&amp;rsquo;s consistent, so it&amp;rsquo;s a simple case of changing it to match the manifest: &lt;code>[Activity(Label = &amp;quot;@string/app_name&amp;quot;, ...)]&lt;/code>. Android uses the @ symbol to indicate a resource, so this syntax will correctly load the activities label from the string resources.&lt;/p>
&lt;p>Once done it looks like this:&lt;/p>
&lt;table cellspacing="0" cellpadding="0" style='border: none;border-collapse: collapse;'>
&lt;tr style='padding: 0;vertical-align: top;'>
&lt;td style='padding: 0;vertical-align: top;'>
&lt;div class="image-div" style="width: 300px;">
&lt;p>&lt;img src="Screen-Shot-2016-01-13-at-17-19-14.png" alt="App settings">&lt;/p>
&lt;/div>
&lt;/td>
&lt;td style='padding: 0px 10px;vertical-align: top;'>
&lt;div class="image-div" style="width: 300px;">
&lt;p>&lt;img src="Screen-Shot-2016-01-13-at-16-42-22.png" alt="Activity">&lt;/p>
&lt;/div>
&lt;/td>
&lt;td style='padding: 0;vertical-align: top;'>
&lt;div class="image-div" style="width: 79px;">
&lt;p>&lt;img src="Screen-Shot-2016-01-13-at-16-42-08.png" alt="App icon">&lt;/p>
&lt;/div>
&lt;/td>
&lt;/tr>
&lt;/table>
&lt;/br>
&lt;p>Done! Now we have a nice navigation drawer based app shell with the right name and the correct colours. In the &lt;a href="https://jimbobbennett.dev/blogs/building-an-android-app-part-2/">next part&lt;/a> we&amp;rsquo;ll start adding some functionality.
The code for this is on Github here: &lt;a href="https://github.com/jimbobbennett/StupendousCounter/tree/Part1">https://github.com/jimbobbennett/StupendousCounter/tree/Part1&lt;/a>
The code in the Part1 branch is the code for this part. The changes we make in later blog posts will be in other branches.&lt;/p>
&lt;br/>
&lt;hr/>
&lt;h4 id="some-useful-bits">Some useful bits&lt;/h4>
&lt;p>Here&amp;rsquo;s a couple of useful tips I cam across when writing this:&lt;/p>
&lt;h6 id="debugging-xap-when-using-a-vm">Debugging XAP when using a VM&lt;/h6>
&lt;p>My developer setup is a MacBook Pro running Windows 10 through Parallels and using Visual Studio 2015, with Xamarin Android Player installed as a Mac app, not a windows App (I use it from Xamarin Studio running on the Mac as well, so saving space/download time when upgrading etc. by only having it once). It&amp;rsquo;s pretty easy to run and debug Android apps on a player running natively on the Mac from VS on a Windows VM - instructions are &lt;a href="https://developer.xamarin.com/guides/android/deployment,_testing,_and_metrics/android-player-with-visual-studio-in-vm/">here&lt;/a>.&lt;/p>
&lt;h6 id="big-shoutout-to-cockos">Big shoutout to Cockos&lt;/h6>
&lt;p>The animated Gifs in this blog post were captured using &lt;a href="http://www.cockos.com/licecap/">LICEcap from Cockos&lt;/a>, an awesome free .Gif capture tool.&lt;/p>
&lt;hr/>
&lt;p>
&lt;table cellspacing="0" cellpadding="0" style='border: none;border-collapse: collapse;'>
&lt;tr style='padding: 0;'>
&lt;td style='padding: 0;vertical-align: top;'>
&lt;iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="//ws-eu.amazon-adsystem.com/widgets/q?ServiceVersion=20070822&amp;OneJS=1&amp;Operation=GetAdHtml&amp;MarketPlace=GB&amp;source=ss&amp;ref=ss_til&amp;ad_type=product_link&amp;tracking_id=expecti-21&amp;marketplace=amazon&amp;region=GB&amp;placement=B00FLW5G74&amp;asins=B00FLW5G74&amp;linkId=&amp;show_border=false&amp;link_opens_in_new_window=true">
&lt;/iframe>
&lt;/td>
&lt;td style='padding: 0px 30px;'>
&lt;p style='color:rgb(104, 104, 104);!important;'>And as a side line I'll also be listing the music I'm listening to when developing. Right now I'm listening to 'The Shocking Miss Emerald' by &lt;a href='http://www.caroemerald.com'>Caro Emerald&lt;/a>.&lt;/p>
&lt;p style='color:rgb(104, 104, 104);!important;'>Note - this is an affiliate link - if you click here and buy I get a small cut.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/table>
&lt;/p></description></item><item><title>Building iBeacon apps using Xamarin.iOS Video Tutorial</title><link>https://jimbobbennett.dev/blogs/building-ibeacon-apps-using-xamarin-ios-video-tutorial/</link><pubDate>Thu, 12 Nov 2015 12:11:07 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/building-ibeacon-apps-using-xamarin-ios-video-tutorial/</guid><description>&lt;p>As a change from talking about iBeacons at events, I&amp;rsquo;ve decided to start a series of YouTube videos covering a number of topics around iBeacons.&lt;/p>
&lt;p>My first one, an introduction to building your first iBeacon app using Xamarin.iOS is now up on YouTube! You can check it out below.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/7mSPxrgWv_I" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;br/>
This is my first one, so would appreciate any feedback.</description></item><item><title>Free iBeacons</title><link>https://jimbobbennett.dev/blogs/freeibeacons/</link><pubDate>Thu, 20 Aug 2015 18:08:50 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/freeibeacons/</guid><description>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/dQw4w9WgXcQ" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div></description></item><item><title>Xamarin Dev Days - Birmingham, 2nd August</title><link>https://jimbobbennett.dev/blogs/xamarin-dev-days-birmingham-2nd-august/</link><pubDate>Mon, 27 Jul 2015 19:05:31 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/xamarin-dev-days-birmingham-2nd-august/</guid><description>&lt;div style='text-align:center'>
&lt;p>&lt;img src="https://d2z6c3c3r6k4bx.cloudfront.net/uploads/event/logo/1006068/Xamarin_Blue_Logo.png" alt="">&lt;/p>
&lt;/div>
&lt;br/>
&lt;p>Xamarin have announced they are doing their first European &lt;a href="http://xamarin.com/dev-days">Dev Day&lt;/a> in Birmingham, hosted by the Birmingham Mobile Cross Platform User Group. This is a great user group organised by &lt;a href="https://twitter.com/davedev">Dave Evans&lt;/a>, and recently they kindly allowed by to &lt;a href="https://jimbobbennett.dev/blogs/the-slides-from-my-ibeacon-mini-hack-are-now-available/">jabber on at them about iBeacons&lt;/a>.&lt;/p>
&lt;p>Details and tickets are available here:&lt;/p>
&lt;p>&lt;a href="https://ti.to/xamarin/dev-days-birmingham">https://ti.to/xamarin/dev-days-birmingham&lt;/a>&lt;/p>
&lt;p>I&amp;rsquo;m very excited by this - the team who will be there are a great bunch, and if you come along you also get the opportunity to meet me! And who would pass up on that ;op
I&amp;rsquo;ll be in town Saturday night through till Monday, so if you&amp;rsquo;re there and fancy a beer/curry etc. then give me a shout.&lt;/p></description></item><item><title>Reviewed - Xamarin Mobile Application Development</title><link>https://jimbobbennett.dev/blogs/reviewed-xamarin-mobile-application-development/</link><pubDate>Mon, 27 Jul 2015 18:03:59 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/reviewed-xamarin-mobile-application-development/</guid><description>&lt;h1 id="xamarin-mobile-application-development">Xamarin Mobile Application Development&lt;/h1>
&lt;h4 id="by-dan-hermes--lexiconsystemshttpstwittercomlexiconsystems">By &lt;a href="https://twitter.com/lexiconsystems">Dan Hermes (@ lexiconsystems)&lt;/a>&lt;/h4>
&lt;div style='text-align:center'>
&lt;a href='http://www.amazon.co.uk/gp/product/1484202155/ref=as_li_qf_sp_asin_il_tl?ie=UTF8&amp;camp=1634&amp;creative=6738&amp;creativeASIN=1484202155&amp;linkCode=as2&amp;tag=expecti-21'>
&lt;p>&lt;img src="51fV5TiEetL-_SX346_BO1-204-203-200_.jpg" alt="Xamarin Mobile Application Development">&lt;/p>
&lt;/a>
&lt;/div>
&lt;br/>
&lt;p>Recently I was lucky enough to get my hands on an early draft of Xamarin Mobile Application Development by Dan Hermes. This is a book aimed at the .Net developer who wants to get started with Xamarin, primarily with Xamarin.Forms.&lt;/p>
&lt;p>Let me start by saying this isn&amp;rsquo;t a &amp;lsquo;read it on the train&amp;rsquo; book - it&amp;rsquo;s very code heavy. As each new concept is introduced, you get sparse text with a code example to cement the concepts - so I would say it&amp;rsquo;s very much aimed at the developer sitting at their laptop who can read and then work through the example code. Luckily the examples are excellent and are available in pure C# code in the book, and in both C# and Xaml on GitHub. Personally I would have preferred if the code focused on Xaml, but then I am a huge Xaml fan. Perhaps a suggestion to the author is to have 2 versions - a pure C# version and a Xaml version (or even 3 and do an F# one).&lt;/p>
&lt;p>The book is primarily aimed at iOS and Android development, but it does sometimes dip in to Windows Phone - for example the Xamarin.Forms screenshots and sample code includes Windows Phone, as does some of the cross platform chapters. But this is about the limit of the Windows Phone code - there&amp;rsquo;s nothing on the platform specific Windows Phone controls for example, wheres iOS and Android controls are covered in detail. Seeing as the market for Windows Phone is so small, this is not a huge omission but Windows Phone developers need to be aware of this.&lt;/p>
&lt;p>The book starts off with a brief introduction to cross platform development before diving right into the UI - a sensible place to start and ideal for the new developer as it allows you to quickly get a &amp;lsquo;Hello, World!&amp;rsquo; type app running in next to no time. As it introduces the UI&amp;rsquo;s it discusses the different approaches - native or cross platform. This is an important choice for the developer to make and the pros and cons of each approach are discussed. It then jumps into the controls and provides simple examples of the standard control set available through Xamarin.Forms. This is followed up by describing the same controls from the native platforms, giving a thorough understanding of the widget sets available (although not Windows Phone). These examples are not API level depth - it doesn&amp;rsquo;t discuss all the properties, methods, events and usage patterns of each control, instead it gives you the basics providing a springboard for your own self discovery. As mentioned before - this is a book for someone who is reading it whilst writing code so can explore the depth of what each control has to offer in their own time.&lt;/p>
&lt;p>The controls take up a large part of the book- understandable as there are a lot, and these are the fundamental building blocks of a mobile app. The biggest difference between Mobile apps and other apps you may have been working on is primarily the UI, both the controls and the user interaction patterns so it makes sense to focus a lot on these. Server side code or business logic is the same regardless of platform, so this isn&amp;rsquo;t really covered here.
As well as the basic widgets, navigation patters and their associated control sets are also covered. This is important with a mobile app, as a user needs to navigate using a standard control set.&lt;/p>
&lt;p>What is covered next is how your app should integrate with the business logic and back end code, followed by how to do platform specific things in a cross platform code base. I would recommend reading the chapters in a different order to the book at this point though. It covers data access and binding, which is how you app will interact with data and how it can be updated on screen using the standard MVVM design pattern that all Xamarin.Forms apps uses, then talks about platform specific UI before discussing cross platform architectures. My recommendation is to read chapter 9 (Cross-platform architecture) before chapters 7 (Data access and data binding) and 8 (Custom rendered and platform-specific UI), so you can get an understanding of how and why to use the different cross platform techniques before you use them in anger. The coverage of the two different methods, PCLs and shared projects, is good, but I would personally like it to lean heavier on the PCL side - especially as Xamarin themselves are saying this is the preferred method.&lt;/p>
&lt;h2 id="tlrd">TL;RD&lt;/h2>
&lt;p>Overall it&amp;rsquo;s a good book for C# coders who want to get into Xamarin for cross platform development. I like Dan&amp;rsquo;s writing style - it is terse and to the point, but friendly to read. The nearest competitor to this book at the moment is &lt;span>&lt;a href="http://www.amazon.co.uk/gp/product/B00VYSSNJW/ref=as_li_tl?ie=UTF8&amp;camp=1634&amp;creative=19450&amp;creativeASIN=B00VYSSNJW&amp;linkCode=as2&amp;tag=expecti-21&amp;linkId=SDHB4LS764DZDT6Q">Creating Mobile Apps with Xamarin.Forms by Charles Petzold (affiliate link)&lt;/a>&lt;img src="http://ir-uk.amazon-adsystem.com/e/ir?t=expecti-21&amp;l=as2&amp;o=2&amp;a=B00VYSSNJW" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" />&lt;/span> and whilst this has the huge advantage of being free and written at the behest of Xamarin (with access to the newest features before they become available), I don&amp;rsquo;t like the writing style. This is something I&amp;rsquo;ve always found with Petzold - the guy is a genius and provides excellent materials in his books but they are hard to read with a very dry style. Dan&amp;rsquo;s book is easier to read.
The examples are good, and if you dive into this book willing to code as you read it provides a great introduction.&lt;/p>
&lt;p>There are downsides with this book. I would like it to go further - technology moves quickly and Xamarin.Forms is constantly changing including new features like styles and behaviours which are not covered. This is the downside to print, but hopefully the eBook will be able to be updated to cover the latest features, or a follow up will be written. I would also like more on custom renderers as this is a massively powerful way to extent a cross platform app. The basics are covered but this topic is huge. Again, perhaps a follow up book would cover this.&lt;br>
The other downside is the price - Petzold&amp;rsquo;s book is free and although it&amp;rsquo;s not as good I can imagine developers dipping into Xamarin for the first time might prefer the free option to get started.&lt;/p>
&lt;p>All in all though, it is a good book and well worth buying to work through armed with your favourite IDE in hand. I&amp;rsquo;m certainly looking forward to any follow ups that Dan writes.&lt;/p>
&lt;p>&lt;a href="http://www.amazon.co.uk/gp/product/1484202155/ref=as_li_qf_sp_asin_il_tl?ie=UTF8&amp;amp;camp=1634&amp;amp;creative=6738&amp;amp;creativeASIN=1484202155&amp;amp;linkCode=as2&amp;amp;tag=expecti-21">Buy it from Amazon here (affiliate link)&lt;/a>&lt;/p></description></item><item><title>The slides from my iBeacon mini-hack are now available</title><link>https://jimbobbennett.dev/blogs/the-slides-from-my-ibeacon-mini-hack-are-now-available/</link><pubDate>Thu, 09 Jul 2015 05:45:09 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/the-slides-from-my-ibeacon-mini-hack-are-now-available/</guid><description>&lt;p>I had a great time hosting an iBeacon mini-hack with the &lt;a href="http://www.meetup.com/Birmingham-Xamarin-Mobile-Cross-Platform-User-Group/">Birmingham Xamarin Mobile Cross Platform User Group&lt;/a>. A big thanks to &lt;a href="https://twitter.com/DaveDev">Dave Evans&lt;/a> for organising this.&lt;/p>
&lt;p>It was only a small group, which was great as I had enough &lt;a href="http://www.estimote.com">Estimote&lt;/a> iBeacons to give away to everyone. Due to hardware issues and phones not being set up we only got one app built, but everyone seemed to have fun. I&amp;rsquo;ll be planning a whole day hackathon soon so that more people can try them out and build some cool apps.&lt;/p>
&lt;p>I&amp;rsquo;ve put the slides up on &lt;a href="http://www.slideshare.net/JimBennett10/xamarin-ibeacon-minihack">Slideshare&lt;/a> and embedded them below.&lt;/p>
&lt;div style='text-align:center'>
&lt;iframe src="https://www.slideshare.net/slideshow/embed_code/key/caPM73QlHju5Mw" width="476" height="400" frameborder="0" marginwidth="0" marginheight="0" scrolling="no">&lt;/iframe>
&lt;/div></description></item><item><title>iBeacons and (lack of) security</title><link>https://jimbobbennett.dev/blogs/ibeacons-and-lack-of-security/</link><pubDate>Thu, 02 Jul 2015 19:07:05 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/ibeacons-and-lack-of-security/</guid><description>&lt;div style='text-align:center'>
&lt;p>&lt;img src="iBeaconLogo-1.png" alt="iBeacon">&lt;/p>
&lt;/div>
&lt;/br>
&lt;p>So in preparation for my &lt;a href="http://www.meetup.com/Birmingham-Xamarin-Mobile-Cross-Platform-User-Group/events/223173916/">upcoming iBeacon mini-hack&lt;/a> I&amp;rsquo;ve been thinking about iBeacon security. For such a simple device, there is a lot of complex issues around their security to consider.&lt;/p>
&lt;h6 id="ibeacons-are-defined-by-their-uuid-and-version">iBeacons are defined by their UUID and version&lt;/h6>
&lt;p>A simple statement but with large undertones. An iBeacon is defined by it&amp;rsquo;s UUID and version - something it broadcasts publicly to the world and is not locked down. There is nothing stoping you reading the id of an iBeacon and setting your app to detect it or your own iBeacon to use it.&lt;/p>
&lt;p>Imagine the scenario - &lt;a href="http://ibeaconsblog.com/asda-trials-in-store-beacons/">UK supermarket Asda are trailing iBeacons&lt;/a> to send customers offers and highlight their cheaper prices. The Asda app will monitor for the particular UUID/version combinations (or maybe just the UUID) and when it detects an iBeacon will send a notification to your phone with information. But whats to stop a rival supermarket doing the same thing? All it takes is someone to scan the iBeacons, get their Id&amp;rsquo;s and register them in the app for the rival supermarket - you walk into Asda and get a notification that the average basket of shopping is cheaper somewhere else. They could even get down to the level of individual offers - if Asda have an offer linked to a particular iBeacon version the rival app could detect the same version and show a price comparison.
There is nothing that can be done to stop this - Apple will let you monitor for any UUID, they don&amp;rsquo;t limit it based on your app. If two apps are listening for the same UUID they will both notify when the iBeacons are detected and nothing can be done to stop it. I have heard that in iOS 8.3 only one app will respond, I haven&amp;rsquo;t had time to test this yet but in such a case how do you know the right app will respond?&lt;/p>
&lt;p>Conversely what is to stop someone depositing iBeacons in a shop that doesn&amp;rsquo;t support them. If a companies app responds to iBeacons what would stop them from doing guerrilla marketing and dropping iBeacons all around another similar store that causes notifications on their app to guide you away from the store you are in and into their store. Or even environmental activists dropping beacons that send notifications to their app when you use a store that goes against their principles.&lt;/p>
&lt;p>A lawyer would be able to provide legal information on this, but I can&amp;rsquo;t imagine it is illegal to have an app for supermarket A monitor iBeacons owned by supermarket B until a test case comes to court.&lt;/p>
&lt;h6 id="ibeacons-can-be-spoofed">iBeacons can be spoofed&lt;/h6>
&lt;p>Yup - they can be. There is nothing stopping you setting the UUID/version to be whatever you want. iBeacons come with a default UUID so you can connect from the suppliers app and you then update the iBeacon to whatever UUID/version you want. So there is nothing stopping you setting the UUID to match someone else&amp;rsquo;s iBeacon and causing mischief or mayhem or worse.&lt;/p>
&lt;p>Imagine a restaurant uses iBeacons placed on each table to allow their app to locate you at that table. You can order from the app and your food comes over. You then pay from the app - it knows where you are sitting so it knows what bill you are paying. But imagine if someone spoofed the id of your table to match the id of theirs - maybe by sending a much stronger signal from another device. Without realising it you&amp;rsquo;ve just paid for someone else&amp;rsquo;s lunch.&lt;/p>
&lt;p>Imagine a worse scenario. iBeacons are great in stadiums to help locate your seat. In the event of an emergency a notification can be sent to your phone and based off your location you can be directed to the nearest exit. But in a terrorist scenario, what would stop them deploying iBeacons around so the app cannot locate you, or causes you to be directed towards the threat instead of away. This could lead to loss of life that is not easily prevented.&lt;/p>
&lt;h6 id="ibeacons-can-be-hacked">iBeacons can be hacked&lt;/h6>
&lt;p>Yup - they can be hacked. The mechanisms used to update the iBeacons from the factory can be used to update them maliciously. This is less of an issue as there are ways to secure access (for example the &lt;a href="https://cloud.estimote.com">Estimote cloud&lt;/a>), but if they are not secured what is to stop someone walking around a shop and changing all the UUID&amp;rsquo;s to match a rivals iBeacons so the rivals app is launched instead of the stores app. In these scenarios it&amp;rsquo;s easy to catch the rival so I can&amp;rsquo;t image a reputable company doing it - but activists might.&lt;/p>
&lt;h6 id="how-to-get-round-this">How to get round this?&lt;/h6>
&lt;p>Estimote offer &lt;a href="https://community.estimote.com/hc/en-us/articles/204233603-How-Secure-UUID-works-">Secure UUID&amp;rsquo;s&lt;/a> which claim to constantly change the UUID but allow your app to range for the iBeacons despite the UUID changing. I haven&amp;rsquo;t tried this out yet, but will do so soon and report back. Other than this, there is not much that can be done. I&amp;rsquo;m hoping Apple will allow you to lock down a range of UUID&amp;rsquo;s that your app can monitor for to disallow other apps for using them but I guess we will have to see what they do once iBeacon security hits the news.&lt;/p>
&lt;p>For more reading about this, I recommend this &lt;a href="http://blog.estimote.com/post/104765561910/ibeacon-security-understanding-the-risks">Fantastic blog post on the Estimote site&lt;/a>.&lt;/p></description></item><item><title>Comparing two mongoDB collections</title><link>https://jimbobbennett.dev/blogs/comparing-two-mongodb-instances/</link><pubDate>Thu, 18 Jun 2015 15:55:12 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/comparing-two-mongodb-instances/</guid><description>&lt;p>I&amp;rsquo;m doing some work for a client at the moment that involves storing files on disk and metadata about those files in a MongoDB instance. The service that manages all this needs to support replication between multiple so that as a file or metadata record gets added/deleted/updated etc., the same changes are applied to all other services that the first on is replicated with.
All fairly simple, and quite a normal use case.&lt;/p>
&lt;p>As part of my extensive automated testing I needed to be able to compare the resulting metadata after the replication to ensure that nothing is being missed. After a quick look round I couldn&amp;rsquo;t find anything to help with this, so I decided to write my own at home and open source it.&lt;/p>
&lt;p>It&amp;rsquo;s now on &lt;a href="https://github.com/jimbobbennett/MongoDBCompare">my GitHub page&lt;/a>, and on Nuget:&lt;/p>
&lt;pre tabindex="0">&lt;code>PM&amp;gt; Install-Package JimBobBennett.MongoDbCompare
&lt;/code>&lt;/pre>&lt;p>It&amp;rsquo;s a simple tool designed to be called from .Net code to compare 2 collections that are based off a known .Net type. You create the class using the type as the generic argument, passing in the connection details to the two MongoDB instances to compare. You then call &lt;code>CompareAsync&lt;/code> passing in a function that returns the unique id for each document so that it can marry up the collections and see if they match.
The comparison is done by using a simple &lt;code>Equals&lt;/code> on each property in each document. Properties marked as &lt;code>BsonIgnore&lt;/code> are ignored, as are properties marked as &lt;code>BsonId&lt;/code>. You can also provide a list of names for properties that are also ignored (for example I&amp;rsquo;m using it to ignore a &lt;code>LastAccessed&lt;/code> property that stores when the document was last accessed, which is different for each MongoDB instance).
The results that come back provide a list of documents that are only in the first collection, a list of documents that are only in the second, and a list of documents that are different. At the moment it doesn&amp;rsquo;t say which properties are different, but I&amp;rsquo;ll hopefully be making a change to include this in a later release.&lt;/p>
&lt;p>This is not PCL unfortunately, because the MongoDB drivers are not PCL compliant, an only supports .Net 4.5.&lt;/p>
&lt;p>Hope it&amp;rsquo;s helpful for someone. Feel free to raise a PR for anything else you want it to support.&lt;/p></description></item><item><title>A little less conversation, a little more iBeacons!</title><link>https://jimbobbennett.dev/blogs/a-little-less-conversation-a-little-more-ibeacons/</link><pubDate>Fri, 12 Jun 2015 18:47:03 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/a-little-less-conversation-a-little-more-ibeacons/</guid><description>&lt;p>iBeacons are a cool technology that allows you to add location awareness to you apps, not based on your location on a map, but based on your proximity to iBeacons, be they at a fixed or moving point. They allow your apps to have an accurate understanding of where you are both inside and out, from sending you offers when you are in a shop to knowing where you are in a sports stadium so you can be directed to your seat. iBeacons are a big up and coming thing - even Facebook are now sending them out to businesses so their app can become location aware. Companies like Estimote are creating and extending iBeacons to bring even more amazing features to the developer.&lt;/p>
&lt;p align="center">
![iBeacon logo](ibeacon.png)
&lt;/p>
&lt;p>On the 8th July 2015 I&amp;rsquo;ll be hosting an iBeacons mini-hack using Xamarin and Estimote beacons, at the Birmingham Xamarin Mobile Cross Platform User Group in Birmingham, UK. In this mini-hack I’ll be talking briefly about this technology and a little about it’s uses, then we’ll hit the code. Bring a Mac laptop, iPhone and lightning cable, and team up with others in building a treasure hunt app using the Estimote iOS Xamarin component and Estimote iBeacons. There will be a prize of an Estimote developer kit or two (containing 3 iBeacons, worth $100 each) for the team that can complete the treasure hunt the fastest.&lt;/p>
&lt;p align="center">
![Estimote logo](Estimote-1.png)
&lt;/p>
&lt;p>For more details and to join in visit the &lt;a href="http://www.meetup.com/Birmingham-Xamarin-Mobile-Cross-Platform-User-Group/events/223173916/">Meetup page&lt;/a>.&lt;/p>
&lt;p>Note - iBeacons are originally an Apple technology. Although Estimote do have limited support for Android we will be focusing purely on their iOS Xamarin component. The iPhone simulator also does not support iBeacons, so you will need an actual device to code against. I will however be splitting the attendees into teams so even if you don&amp;rsquo;t have an iPhone developer setup come along anyway and I&amp;rsquo;ll make sure you are teamed up with someone who does.&lt;/p></description></item><item><title>I'm certified</title><link>https://jimbobbennett.dev/blogs/im-certified/</link><pubDate>Thu, 16 Apr 2015 18:53:40 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/im-certified/</guid><description>&lt;p>Just a quick post to share with the world the good news!&lt;/p>
&lt;p>After a lot of lectures and a lot of effort I&amp;rsquo;m now a Xamarin Certified Developer!&lt;/p>
&lt;p>&lt;img src="Xamarin-Certified-Mobile-Developer-Badge-medium-res.png" alt="">&lt;/p></description></item><item><title>Device.StartTimer and iOS backgrounding</title><link>https://jimbobbennett.dev/blogs/timers-backgrounding/</link><pubDate>Sat, 07 Mar 2015 15:22:21 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/timers-backgrounding/</guid><description>&lt;p>I recently completed a lecture on backgrounding in iOS and Android as part of the &lt;a href="https://university.xamarin.com">Xamarin University&lt;/a>. During this lecture, one topic of discussion came up with no real answer - how &lt;code>Device.StartTimer()&lt;/code> in Xamarin.Forms affects backgrounding. With iOS, if you enable backgrounding using &lt;code>BeginBackgroundTask()&lt;/code>, you have 3 minutes to stop all background tasks before the OS kills your app, so I was wondering what would happen if you create a timer using Xamarin.Forms and background the app - will the timer continue or stop.&lt;/p>
&lt;p>So I did a little experimenting. I created a new Forms solution, deleting the &amp;lsquo;droid project&amp;rsquo; (it would be great to have some more project/solution types available such as forms apps for one platform). I then added the code to enable backgrounding, but commented it out:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">override&lt;/span> &lt;span style="color:#66d9ef">bool&lt;/span> FinishedLaunching (UIApplication app, NSDictionary options)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">global&lt;/span>::Xamarin.Forms.Forms.Init ();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> LoadApplication (&lt;span style="color:#66d9ef">new&lt;/span> App ());
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">//UIApplication.SharedApplication.BeginBackgroundTask(() =&amp;gt; {});&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#66d9ef">base&lt;/span>.FinishedLaunching (app, options);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Then I added a timer to my Forms app:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">public&lt;/span> App ()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> MainPage = &lt;span style="color:#66d9ef">new&lt;/span> ContentPage
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Content = &lt;span style="color:#66d9ef">new&lt;/span> StackLayout
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> VerticalOptions = LayoutOptions.Center,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Children =
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">new&lt;/span> Label
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> XAlign = TextAlignment.Center,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Text = &lt;span style="color:#e6db74">&amp;#34;Welcome to Xamarin Forms!&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> };
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Device.StartTimer(TimeSpan.FromSeconds(&lt;span style="color:#ae81ff">5&lt;/span>), () =&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Debug.WriteLine(&lt;span style="color:#e6db74">&amp;#34;Timer tick&amp;#34;&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#66d9ef">true&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> });
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The timer just logs to the console every 5 seconds so I can see that it is running.&lt;/p>
&lt;p>When I tested this out, all was as expected. I open the app, I see the timer ticks, I background the app, the timer stops ticking, I restore the app and ticks resume.&lt;/p>
&lt;p>I then uncommented the code to enable backgrounding and tried again. The result is as I expected/feared - the timer ticks, I background the app, it &lt;strong>still&lt;/strong> ticks. After 3 minutes, bang! iOS kills the app.&lt;/p>
&lt;p>So be wary - if you are using platform specific iOS code to do backgrounding beware of any Forms timers. Remember to stop them when the app is backgrounded and restart them once it is restored.&lt;/p>
&lt;p>The sample code for this is on &lt;a href="https://github.com/jimbobbennett/DeviceStartTimerTest">my GitHub repo&lt;/a>.&lt;/p></description></item><item><title>Xamarin Estimote iOS component</title><link>https://jimbobbennett.dev/blogs/xamarin-estimote-ios-component/</link><pubDate>Tue, 24 Feb 2015 21:29:51 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/xamarin-estimote-ios-component/</guid><description>&lt;p>After my &lt;a href="https://jimbobbennett.dev/blogs/binding-ios-libraries-in-xamarin/">Blog post about binding the Estimote iOS SDK&lt;/a>, James Montemagno (Developer evangelist at Xamarin) contacted me to say they were about to release an official Xamarin component for accessing Estimote iBeacons and nearables from iOS. This renders my binding library redundant - which is a good thing as its less work for me now to support it!&lt;/p>
&lt;p>I decided to have a quick play today, updating the test application that I created to quickly test my binding to use the new component. It was pretty much a one to one swap out, all that needed tweaking were the names. EST was removed from all the names, so things like &lt;code>ESTBeaconManager&lt;/code> became &lt;code>BeaconManager&lt;/code>. Other name tweaks included events being renamed from &lt;code>DidRangeBeacons&lt;/code> to &lt;code>RangedBeacons&lt;/code> - nice tidying really that I couldn&amp;rsquo;t be bothered to do when I bound the library.&lt;/p>
&lt;p>The only bad naming I&amp;rsquo;ve come across so far is their event args classes. Someone left Args on the name of the classes before binding. Remember that the binding project automatically adds &lt;code>EventArgs&lt;/code> to the name of the event args class when it is generated, erroring if it already has &lt;code>EventArgs&lt;/code> on the end of the name. In this case it looks like someone set it to end in &lt;code>Args&lt;/code>, which then gets &lt;code>EventArgs&lt;/code> prepended.
For example, the RangedBeacons event has the following signature:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">event&lt;/span> EventHandler&amp;lt;RangedBeaconsArgsEventArgs&amp;gt; RangedBeacons
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Note the rogue &lt;code>Args&lt;/code> in the middle.&lt;/p>
&lt;p>Other than this naming oddity, it all works perfectly. I&amp;rsquo;ve only had a quick look but what I&amp;rsquo;ve seen so far is great. I&amp;rsquo;m working on an app at the moment which should make a lot more use of the SDK so as I discover things I&amp;rsquo;ll report back.&lt;/p>
&lt;p>One big downside though - it&amp;rsquo;s iOS only. There is an existing component for Android but this is lacking in functionality. Hopefully Xamarin will do an offical Android component soon.&lt;/p>
&lt;p>I&amp;rsquo;ve updated my GitHub project to use the component, but left the original binding project there for reference. It&amp;rsquo;s at:&lt;/p>
&lt;p>&lt;a href="https://github.com/jimbobbennett/EstimoteBinding">https://github.com/jimbobbennett/EstimoteBinding&lt;/a>&lt;/p>
&lt;p>The sample project is a Xamarin.Forms project - only with the iOS and PCL projects at the moment until there is an Android component available. It uses the Forms &lt;code>DependencyService&lt;/code> to resolve a wrapper around the &lt;code>BeaconManager&lt;/code> and &lt;code>Beacon&lt;/code> classes from the component. Should be self explanatory but ping me if you want me to explain anything in more detail.&lt;/p>
&lt;p>&lt;img src="MCert.png" alt="iBeacon discovery app">&lt;/p></description></item><item><title>Binding iOS libraries in Xamarin</title><link>https://jimbobbennett.dev/blogs/binding-ios-libraries-in-xamarin/</link><pubDate>Thu, 19 Feb 2015 15:25:15 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/binding-ios-libraries-in-xamarin/</guid><description>&lt;p>Update: Since writing this, James Montemagno from Xamarin contacted me to say they are working on an Estimote component. This is now available on the Xamarin component store. Check out &lt;a href="http://blog.xamarin.com/adding-real-world-context-with-estimote-beacons-and-stickers/">his blog post here&lt;/a>.&lt;/p>
&lt;hr/>
&lt;p>I&amp;rsquo;ve been playing around with iBeacons a lot recently. They seem a really cool technology with a load of interesting potential use cases. My iBeacon of choice is from &lt;a href="http://estimote.com">Estimote&lt;/a>, I&amp;rsquo;ve got some of their beacons already and have a pack of stickers on pre-order. As well as providing the basic iBeacon functionality, they also provide a whole host of other features including accelerometers and temperature sensors.&lt;/p>
&lt;p>To access all their beacon functionality, above and beyond the basics that are part of the Apple iBeacon standard, you need to use their SDK. The Apple CoreLocation API will do the basics - ranging, notifications when going in and out of range etc., but for full access you need their SDK. They helpfully provide it for iOS and Android, but not for Xamarin.&lt;/p>
&lt;p>This is not a big deal though, as Xamarin provide an easy enough way to wrap the native SDK&amp;rsquo;s. This post will focus on how to do it for iOS. I&amp;rsquo;ll try to do it for Android later and blog about that separately.&lt;/p>
&lt;h5 id="step-1---grab-the-code">Step 1 - Grab the code&lt;/h5>
&lt;p>The SDK code is on the &lt;a href="https://github.com/Estimote/iOS-SDK">Estimote GitHub site&lt;/a>. Clone this locally.&lt;/p>
&lt;h4 id="step-2---create-a-binding-project">Step 2 - Create a binding project&lt;/h4>
&lt;p>Xamarin studio has project types for binding APIs. Start by selecting File -&amp;gt; New Solution, and choosing &amp;lsquo;iOS Binding Project&amp;rsquo; from the Unified API section of the iOS entry in the tree. Apple requires all new apps that are submitted to support 64-bit, so to support this in our apps we need to use the new Unified APIs.&lt;/p>
&lt;p>&lt;img src="Screen-Shot-2015-02-19-at-13-23-37.png" alt="Chose iOS Binding Project">&lt;/p>
&lt;p>This will create a project with a couple of files in it.&lt;/p>
&lt;ul>
&lt;li>&lt;code>ApiDefinition.cs&lt;/code> - This file will end up containing the classes created by wrapping the API.&lt;/li>
&lt;li>&lt;code>StructsAndEnums.cs&lt;/code> - This file will contain any structus or enums that are created from the API.&lt;/li>
&lt;/ul>
&lt;p>We now need to add the actual library to the project, so do this by dragging it from Finder/Explorer into the project in Xamarin Studio. Drag the &lt;code>iOS-SDK\EstimoteSDK\libEstimoteSDK.a&lt;/code> file into your project.
One this is in the project you&amp;rsquo;ll see it in the tree with an expander by it. Expanding this will show a new file &lt;code>libEstimoteSDK.linkwith.cs&lt;/code>. This file contains the instructions on how to link the library, and I&amp;rsquo;ll cover this in more detail later.&lt;/p>
&lt;h4 id="step-3---generate-the-api">Step 3 - Generate the API&lt;/h4>
&lt;p>Once we have the library in place, we need to generate the API code to call it. We could do it by hand, but that&amp;rsquo;s far too much trouble. Instead we&amp;rsquo;ll use &lt;a href="http://developer.xamarin.com/guides/ios/advanced_topics/binding_objective-c/objective_sharpie/">Objective Sharpie&lt;/a>, a tool from Xamarin to create the code for you. It&amp;rsquo;s currently a beta, but works fine for this SDK. I&amp;rsquo;m hoping one day it will be built into Xamarin Studio so creating binding projects is a one step thing.
Objective Sharpie is a command line tool, you give it the header files that come with the library, tell it what SDK to use, which namespace etc. and it will do the magic.&lt;/p>
&lt;p>In my case, I run the &lt;code>sharpie&lt;/code> command it from the EstimoteSDK folder in the SDK github repository, using the following options:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>sharpie bind --namespace&lt;span style="color:#f92672">=&lt;/span>Estimote --sdk&lt;span style="color:#f92672">=&lt;/span>iphoneos8.1 headers/*.h -unified
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The options are:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;code>bind&lt;/code> - this tells it to bind the header files&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>--namespace=Estimote&lt;/code> - this is the defult namespace used in the created files.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>--sdk=iphoneos8.1&lt;/code> - this tells it to use the iOS 8.1 SDK for code generation. You should always use the latest SDK.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>headers/*.h&lt;/code> - this is the path to the header files you want to generate code for.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>--unified&lt;/code> - this tells it to use the new Unified API for 64-bit support.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>The code generated is in two files - &lt;code>output.cs&lt;/code> and &lt;code>output.enums.cs&lt;/code>. For some reason it doesn&amp;rsquo;t output the files using the same naming convention as the binding projects (&lt;code>ApiDefinition.cs&lt;/code> and &lt;code>StructsAndEnums.cs&lt;/code>). It also doesn&amp;rsquo;t add using directives to the files.&lt;/p>
&lt;p>Once the code has been generated, simply copy the contents of &lt;code>output.cs&lt;/code> into &lt;code>ApiDefinition.cs&lt;/code> (keeping the namespaces) and &lt;code>output.enums.cs&lt;/code> into &lt;code>StructsAndEnums.cs&lt;/code>.&lt;/p>
&lt;h4 id="step-4---building-the-code">Step 4 - Building the code&lt;/h4>
&lt;p>Not as easy as you may think! If you do a build, there will be errors. This is because the API uses names for parameters etc. that are reserved words in C#.&lt;/p>
&lt;p>For example check out the ESTBeaconManager.Constructor method:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>IntPtr Constructor (ESTBeaconManagerDelegate &lt;span style="color:#66d9ef">delegate&lt;/span>);
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This has a parameter &lt;code>delegate&lt;/code>, which is a reserved word in C#. Luckily, the parameters can be renamed without any issues, so just rename this to &lt;code>del&lt;/code> or another name of your chosing. You&amp;rsquo;ll also have to do the same in &lt;code>ESTBeaconUpdateInfo&lt;/code>.&lt;/p>
&lt;p>After changing these, build again and you&amp;rsquo;ll get more errors. These next errors are due to the interfaces in the iOS SDK deriving from &lt;code>NSObject&amp;lt;NSCoding&amp;gt;&lt;/code> or &lt;code>NSObject &amp;lt;NSCopying, NSCoding&amp;gt;&lt;/code>. The resulting interfaces created by Objective Sharpie derive from &lt;code>NSCoding&lt;/code> or &lt;code>NSCopying&lt;/code>, and an interface cannot derive from a concrete class. Luckily, we can just remove the all base classes, so &lt;code>interface ESTBeaconVO : NSCoding&lt;/code> becomes &lt;code>interface ESTBeaconVO&lt;/code>. Do this for all other interfaces that the compiler complains about.&lt;/p>
&lt;p>Again, we build, and again, more errors. The next set are due to name casing being changed between iOS and Xamarin - namely &lt;code>NSUUID&lt;/code> is &lt;code>NSUuid&lt;/code>. A quick Replace all and these are fixed.&lt;/p>
&lt;p>The next set of errors are due to missing usings. Objective Sharpie doesn&amp;rsquo;t add any using directives to the generated code which is a shame. A right click -&amp;gt; Resolve -&amp;gt; using CoreLocation; on &lt;code>CLProximity&lt;/code> and Resolve -&amp;gt; using CoreBluetooth; on &lt;code>CBPeripheral&lt;/code> and the &lt;code>ApiDefinition.cs&lt;/code> file will now build. You&amp;rsquo;ll need to so Resolve -&amp;gt; using ObjCRuntime; on the &lt;code>[Native]&lt;/code> attribute in &lt;code>StructsAndEnums.cs&lt;/code> as well.&lt;/p>
&lt;p>The code should now build.&lt;/p>
&lt;h4 id="step-5---events-instead-of-delegates">Step 5 - Events instead of delegates.&lt;/h4>
&lt;p>Objective-C has an eventing mechanism based on delegates - you create a class that implements a specific delegate protocol and pass it to another class, which then calls back into the methods of your delegate class when things happen. The code generated by Objective Sharpie follows this pattern as it is a one-to-one mapping to the Objective-C code. Luckily, binding projects are smart enough to be able to translate this into events, with the help of a few attributes to help guide it when it generates these events.&lt;/p>
&lt;p>Working down through the code, the first one we come to is &lt;code>ESTBeaconDelegate&lt;/code>, used by the &lt;code>ESTBeacon&lt;/code> class. The delegate is used to allow the beacon to call back when the connection state changes, or if the accelerometer detects movement.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">[Protocol, Model]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">[BaseType (typeof (NSObject))]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">interface&lt;/span> &lt;span style="color:#a6e22e">ESTBeaconDelegate&lt;/span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// ...&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">[BaseType (typeof (NSObject))]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">interface&lt;/span> &lt;span style="color:#a6e22e">ESTBeacon&lt;/span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e"> [Export (&amp;#34;delegate&amp;#34;, ArgumentSemantic.Weak)]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e"> [NullAllowed]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> NSObject WeakDelegate { &lt;span style="color:#66d9ef">get&lt;/span>; &lt;span style="color:#66d9ef">set&lt;/span>; }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e"> [Wrap (&amp;#34;WeakDelegate&amp;#34;)]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ESTBeaconDelegate Delegate { &lt;span style="color:#66d9ef">get&lt;/span>; &lt;span style="color:#66d9ef">set&lt;/span>; }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// ...&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The code above has been trimmed down to just show the important stuff. The &lt;code>ESTBeacon&lt;/code> class has properties to store the delegate - the two different properties and the attributes allow it to strongly type the delegate class that is passed in (Objective-C uses weakly typed delegates).&lt;/p>
&lt;p>Rather than use a delegate, we want to use events. This is actually really easy, we mark the &lt;code>ESTBeacon&lt;/code> class with an attribute to tell it which properties are used for delegates, and to tell it which delegate types to generate events for.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">[BaseType (typeof (NSObject),
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e"> Delegates=new string []&lt;/span> { &lt;span style="color:#e6db74">&amp;#34;WeakDelegate&amp;#34;&lt;/span> },
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Events=&lt;span style="color:#66d9ef">new&lt;/span> Type [] {&lt;span style="color:#66d9ef">typeof&lt;/span>(ESTBeaconDelegate)})]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">interface&lt;/span> &lt;span style="color:#a6e22e">ESTBeacon&lt;/span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// ...&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This code tells the compiler to generate events for the &lt;code>ESTBeacon&lt;/code> class using the &lt;code>ESTBeaconDelegate&lt;/code> to define the events, and the delegate is set in the &lt;code>WeakDelegate&lt;/code> property. One of these days I&amp;rsquo;ll decompile the code to see how it does all this, but I imagine it will create a private class the exposes the delegate and calls back into the &lt;code>ESTBeacon&lt;/code> class to raise the events.&lt;/p>
&lt;p>We also need to tell the compiler how to generate the event signatures for the delegate. This is also done using an attribute, one that provides the name of the event args class.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">interface&lt;/span> &lt;span style="color:#a6e22e">ESTBeaconDelegate&lt;/span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// @optional -(void)beaconConnectionDidSucceeded:(ESTBeacon *)beacon;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e"> [Export (&amp;#34;beaconConnectionDidSucceeded:&amp;#34;)]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">void&lt;/span> BeaconConnectionDidSucceeded (ESTBeacon beacon);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// ...&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>becomes:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">interface&lt;/span> &lt;span style="color:#a6e22e">ESTBeaconDelegate&lt;/span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// @optional -(void)beaconConnectionDidSucceeded:(ESTBeacon *)beacon;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e"> [Export (&amp;#34;beaconConnectionDidSucceeded:&amp;#34;)]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e"> [EventArgs(&amp;#34;BeaconConnectionDidSucceeded&amp;#34;)]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">void&lt;/span> BeaconConnectionDidSucceeded (ESTBeacon beacon);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// ...&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>When the event is created it has the signature:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">event&lt;/span> EventHandler&amp;lt;BeaconConnectionDidSucceededEventArgs&amp;gt; BeaconConnectionDidSucceeded;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The class &lt;code>BeaconConnectionDidSucceededEventArgs&lt;/code> is created and wraps all the parameters in the delegate call as properties - so it will have public property of type &lt;code>ESTBeacon&lt;/code> named &lt;code>Beacon&lt;/code>. Note that the attribute doesn&amp;rsquo;t have &lt;code>EventArgs&lt;/code> on the end of the name - this is added automatically by the compiler. If you do add it, you get an error:&lt;/p>
&lt;pre tabindex="0">&lt;code>BTOUCHTASK: error BI1005: btouch: EventArgs in
EstimoteBinding.ESTBeaconDelegate.BeaconConnectionDidSucceeded attribute should not include
the text &amp;#39;EventArgs&amp;#39; at the end
&lt;/code>&lt;/pre>&lt;p>This process needs to be repeated for all delegate methods and all classes that use delegates - or as much as you think you will need for internal projects. On my long list of things to do is to look at generating these using VS2015 and see if I can automate this step using Roslyn.&lt;/p>
&lt;h4 id="step-6---getting-it-ready-to-use-with-another-project">Step 6 - Getting it ready to use with another project&lt;/h4>
&lt;p>The code now compiles, but as always compilable code isn&amp;rsquo;t shippable code. There&amp;rsquo;s a few more things left to do.&lt;/p>
&lt;p>First, we need to ensure it supports the 64-bit processors. In the &lt;code>libEstimoteSDK.linkwith.cs&lt;/code> you will see it is set to link with v7, v7s and the simulator:&lt;/p>
&lt;pre tabindex="0">&lt;code>LinkTarget.ArmV7 | LinkTarget.ArmV7s | LinkTarget.Simulator
&lt;/code>&lt;/pre>&lt;p>We need to add the 64-bit processors to this list, so change it to:&lt;/p>
&lt;pre tabindex="0">&lt;code>LinkTarget.ArmV7 | LinkTarget.ArmV7s | LinkTarget.Arm64 | LinkTarget.Simulator | LinkTarget.Simulator64
&lt;/code>&lt;/pre>&lt;br/>
&lt;p>Secondly we should review naming. Objective Sharpie tries, but it does get things wrong. For example, the &lt;code>beaconConnectionDidFail&lt;/code> method call is named wrong, instead being named by it&amp;rsquo;s parameter:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">// @optional -(void)beaconConnectionDidFail:(ESTBeacon *)beacon withError:(NSError *)error;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">[Export (&amp;#34;beaconConnectionDidFail:withError:&amp;#34;)]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">void&lt;/span> WithError (ESTBeacon beacon, NSError error);
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This should be changed to be:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">// @optional -(void)beaconConnectionDidFail:(ESTBeacon *)beacon withError:(NSError *)error;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">[Export (&amp;#34;beaconConnectionDidFail:withError:&amp;#34;)]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">void&lt;/span> BeaconConnectionDidFail (ESTBeacon beacon, NSError error);
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>I haven&amp;rsquo;t yet worked out a pattern as to when these odd namings happen - if you work it out please let me know!.&lt;/p>
&lt;h4 id="step-7---">Step 7 - ???&lt;/h4>
&lt;h4 id="step-8---profit">Step 8 - Profit!&lt;/h4>
&lt;p>Not really, but you now have a nice binding for the Estimote SDK. Hopefully these instructions make sense, tweet me/mail me with any issues you may have or any questions. Xamarin has a load of &lt;a href="http://developer.xamarin.com/guides/ios/advanced_topics/binding_objective-c/">really helpfull docs&lt;/a> covering pretty much everything you would need to know about binding.&lt;/p>
&lt;p>And if you can&amp;rsquo;t be bothered to do all this your self, you can just download my bindings from &lt;a href="https://github.com/jimbobbennett/EstimoteBinding">my GitHub page&lt;/a> which I am trying to keep pretty much up to date and includes a Xamarin.Forms based test app to show it all working. I hope to have a NuGet package or a Xamarin component available soon.&lt;/p></description></item><item><title>JimLib.Xamarin is now updated to the Unified API</title><link>https://jimbobbennett.dev/blogs/jimlib-xamarin-is-now-updated-to-the-unified-api/</link><pubDate>Thu, 05 Feb 2015 21:07:19 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/jimlib-xamarin-is-now-updated-to-the-unified-api/</guid><description>&lt;p>Finally, after fighting with Xamarin and having my Surface die and need to be reinstalled twice, I&amp;rsquo;ve managed to get &lt;a href="https://github.com/jimbobbennett/JimLib.Xamarin">JimLib.Xamarin&lt;/a> updated to use the new Xamarin Unified API so it should be suitable for submitting new apps to the iPhone app store. I&amp;rsquo;ll be updating my first app &lt;a href="https://appsto.re/i6Bw6St">Second Screen for Plex&lt;/a> soon and sending it to the app store for approval and will update with the results. After all, you never know what weird and wonderful things the app store approval process will turn up.&lt;/p>
&lt;p>This is in GitHub, and updated on NuGet.&lt;/p></description></item><item><title>I'm on iTunes again!</title><link>https://jimbobbennett.dev/blogs/im-on-itunes-again/</link><pubDate>Thu, 29 Jan 2015 20:20:53 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/im-on-itunes-again/</guid><description>&lt;p>This time for an app, not for a &lt;a href="https://jimbobbennett.dev/blogs/im-on-itunes/">podcast&lt;/a>. One of my iTunes apps is finally complete and is now approved and up on iTunes:&lt;/p>
&lt;p>&lt;a href="https://appsto.re/i6Bw6St">Second screen for Plex&lt;/a>
&lt;a href='https://appsto.re/i6Bw6St'>
&lt;img src="Download_on_the_App_Store_Badge_US-UK_135x40.svg" alt="">
&lt;/a>&lt;/p>
&lt;p>If you use &lt;a href="http://plex.tv">Plex&lt;/a> as your media server/player then you&amp;rsquo;ll love this app - it connects to your server and shows you what&amp;rsquo;s currently playing including the cast and an IMDB link. It saves the hassle of searching IMDB to find out who that actor is or where else you&amp;rsquo;ve seen that actress. It also allows you to keep tabs on what other people are watching from your server, and it works over the internet (assuming your server is shared via MyPlex) so you can check up to see if the kids are watching cartoons when they should be doing homework.&lt;/p>
&lt;p>It&amp;rsquo;s available for a snip at 79p/99c - less than the price of an extra shot in that expensive coffee you just bought at Starbucks, it&amp;rsquo;s a no brainer price to make your life so much easier.&lt;/p>
&lt;p>&lt;img src="SecondScreenSplash_320x480.png" alt="App splash">&lt;/p></description></item><item><title>I'm on iTunes!</title><link>https://jimbobbennett.dev/blogs/im-on-itunes/</link><pubDate>Sun, 25 Jan 2015 21:57:11 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/im-on-itunes/</guid><description>&lt;p>As mentioned &lt;a href="https://jimbobbennett.dev/blogs/technical-tests/">before&lt;/a>, I wrote a guest post for &lt;a href="http://www.corejavainterviewquestions.com">Core Java Interview Questions&lt;/a> all about technical testing as part of the interview process. Sam, the sites editor, has been doing a podcast for the site and was kind enough to invite me along to discuss my blog post with him for an episode. What was meant to be a 20 minute chat turned in to an hour discussing everything from technical tests to the advantages of being an expat.&lt;/p>
&lt;p>You can grab it by subscribing to the podcast on &lt;a href="https://itunes.apple.com/gb/podcast/core-java-interview-questions/id949010155?mt=2">iTunes&lt;/a> (I&amp;rsquo;m on episode 4) or direct from the website &lt;a href="http://www.corejavainterviewquestions.com/podcast4/">http://www.corejavainterviewquestions.com/podcast4/&lt;/a>.&lt;/p>
&lt;p>&lt;img src="jimbennettcorejavainterviewquestions-300x213.png" alt="&amp;ldquo;Can you code?&amp;rdquo; is the most important thing to me">&lt;/p></description></item><item><title>Xamarin Unified API</title><link>https://jimbobbennett.dev/blogs/xamarin-unified-api/</link><pubDate>Tue, 13 Jan 2015 22:37:52 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/xamarin-unified-api/</guid><description>&lt;p>Recently Apple announced some changes to their requirements for apps submitted to the iOS app store. From the 1st February all new apps must support 64-bit (for updates to existing apps, it&amp;rsquo;s 1st June).&lt;/p>
&lt;p>Xamarin, not wanting to do anything the easy way have decided that as well as supporting this, they will overhaul their API and unify their Mac and iOS APIs. Based on how poorly they managed the iOS rollout (like not being able to build iOS 8 apps using Visual Studio or on Yosemite until a week after iOS 8 was live), I&amp;rsquo;m very sceptical about how successful this will be. Combine this with a major update ot Xamarin.Forms at the same time and this is a recipe for disaster. Luckily they decided to have an extra weeks testing and it&amp;rsquo;s only just &lt;a href="http://blog.xamarin.com/xamarin.ios-unified-api-with-64-bit-support/">been released to their stable channel&lt;/a>, with 3 weeks to go until Apple&amp;rsquo;s deadline.&lt;/p>
&lt;p>Tonight I decided to upgrade &lt;a href="https://github.com/jimbobbennett/JimLib.Xamarin">JimLib.Xamarin&lt;/a>. The first thing to note is they have a tool to do the hard work for you. At least they do in Xamarin Studio for Mac - not in the Windows version or in Visual Studio.
So the first step in the upgrade is to load it all up in Xamarin Studio on my Mac and run the wizard. So far, so good. This changes the references to monotouch to point to Xamarin.iOS and updates namespaces. Unfortunately if you are using Xamarin.Forms or Xamarin.Settings these referencs stay around, even upgrading their nuget packages to the latest version which supports 64-bit. The easiest thing I found to do was completely remove and re-add these packages.
Xamarin.Forms has a nasty thing though - it adds an error condition to the .csproj file if the nuget package is not there, and it doesn&amp;rsquo;t remove this when removing the nuget package. The fix is to edit the .csproj file and manually remove the error condition. Which is nice.&lt;/p>
&lt;p>The next thing to do is fix any type issues. They&amp;rsquo;ve changed things like int and float (standard C# types) to use nint and nfloat (weird iOS types), which seems non-intuative. Int already changes from 32 to 64 bit depending on platform so I fail to see why they need nint.&lt;/p>
&lt;p>The next step is to get it to build. This wasn&amp;rsquo;t too hard, just cleaning up the mess in the csproj files, changing some types etc.&lt;/p>
&lt;p>Finally, I&amp;rsquo;m tring to build it on Visual Studio. This doesn&amp;rsquo;t work. I&amp;rsquo;m getting:&lt;/p>
&lt;p>&lt;code>The name InitializeComponent does not exist in the current context&lt;/code>&lt;/p>
&lt;p>This works on Xamarin Studio on the Mac, obviously, not on Visual Studio.&lt;/p>
&lt;p>Will update this once I know more about why&amp;hellip;&lt;/p>
&lt;p>Update:&lt;/p>
&lt;p>I&amp;rsquo;ve finally got to the bottom of why it was not compiling. To do this I created a new Xamarin.Forms app, added a Xaml file and compared the .csproj files by hand.
It seems somewhere on the way the Generator property on the Xaml file was set to &lt;code>MSBuild:Compile&lt;/code>. On the new project, it is set to &lt;code>MSBuild:UpdateDesignTimeXaml&lt;/code>. I manually updated the .csproj files and it works.&lt;/p>
&lt;p>Nasty!&lt;/p>
&lt;p>Update 2:&lt;/p>
&lt;p>It seems this was documented in the &lt;a href="https://forums.xamarin.com/discussion/29934/xamarin-forms-1-3-0-released/p1">release notes in the Xamarin.Forms forum&lt;/a>, but not in the Unified API migration guide. Thanks to Robert Stubbs on the forums for pointing this out. Hopefully Xamarin will improve the docs at some point.&lt;/p></description></item><item><title>Christmas geekery</title><link>https://jimbobbennett.dev/blogs/christmas-geekery/</link><pubDate>Wed, 24 Dec 2014 13:12:46 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/christmas-geekery/</guid><description>&lt;p>Just a quick post to wish you all a very merry Christmas and a happy new year. Or a happy Saturnalia, or Festivus, or however you celebrate at this time of year.&lt;/p>
&lt;p>I&amp;rsquo;ll be spending the time playing with a few things. I&amp;rsquo;m looking forward to seeing how well &lt;a href="https://www.jetbrains.com/resharper/">Resharper 9&lt;/a> works with Xamarin.Forms, and playing with my &lt;a href="http://www.estimote.com">Estimote&lt;/a> iBeacons. I&amp;rsquo;ll also hopefuly be recording a podcast for &lt;a href="http://www.corejavainterviewquestions.com">Core Java Interview Questions&lt;/a> with my friend Sam, and will be blogging about it all.&lt;/p>
&lt;p>See you in the new year!&lt;/p></description></item><item><title>Technical tests</title><link>https://jimbobbennett.dev/blogs/technical-tests/</link><pubDate>Thu, 20 Nov 2014 21:15:09 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/technical-tests/</guid><description>&lt;p>A good friend of mine, &lt;a href="http://samatkinson.com">Sam&lt;/a>, has started an awesome site for Java developers to help with the always enjoyable process of interviewing.&lt;/p>
&lt;p>It&amp;rsquo;s available at:&lt;/p>
&lt;p>&lt;a href="http://www.corejavainterviewquestions.com">http://www.corejavainterviewquestions.com&lt;/a>&lt;/p>
&lt;p>He was nice enough to ask me to do a guest post, so not being a Java programmer I decided to post about doing technical tests - something nice and language agnostic. The post is question is here:&lt;/p>
&lt;p>&lt;a href="http://www.corejavainterviewquestions.com/technical-tests/">http://www.corejavainterviewquestions.com/technical-tests/&lt;/a>&lt;/p>
&lt;p>Have a read and provide any feedback. Always happy to discuss these tests so tweet me at @jimbobbennett with any questions.&lt;/p></description></item><item><title>Blind technology</title><link>https://jimbobbennett.dev/blogs/blind-technology/</link><pubDate>Tue, 18 Nov 2014 21:45:01 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/blind-technology/</guid><description>&lt;p>Busy, busy, busy. In the last month I&amp;rsquo;ve relocated form Thailand to the UK with my family, got my UK company up and running (more coming on this in a later post), lined up one client, fought with the Apple app store to get my developer account set up right so I can sell apps (still not done), found a new place to live and been fighting with overbearing bureaucracy. I&amp;rsquo;ve also found loads of time to spend playing with my daughter before work becomes too overbearing, and the upshot of this is little time for technology. My &lt;a href="https://jimbobbennett.dev/blogs/time-to-teach/">Udemy course&lt;/a> is still nowhere near finished, my apps are not on the Apple app store yet and I don&amp;rsquo;t even have a working Windows 10 VM (mind you, from what I hear not many others do either).&lt;/p>
&lt;p>Hey ho, back to the grindstone from now on.&lt;/p>
&lt;p>One cool thing I did have time to do is head to Microsoft&amp;rsquo;s Future Decoded conference in London. It was a great day, some fantastic speakers (including that &lt;a href="http://bit.ly/14GyJJz">drummer guy from D&amp;rsquo;Ream&lt;/a>) and the chance to hear about some awesome technology.&lt;/p>
&lt;p>The one piece that really caught my eye surprisingly wasn&amp;rsquo;t the announcement that Microsoft have &lt;a href="http://blogs.msdn.com/b/dotnet/archive/2014/11/12/net-core-is-open-source.aspx">open sourced .Net&lt;/a> and released &lt;a href="http://blogs.msdn.com/b/visualstudio/archive/2014/11/12/visual-studio-2015-preview-visual-studio-community-2013-visual-studio-2013-update-4-and-more.aspx">new Visual Studio goodies&lt;/a>. It was in fact a software/hardware solution from &lt;a href="https://futurecities.catapult.org.uk/project-full-view/-/asset_publisher/oDS9tiXrD0wi/content/project-cities-unlocked/">Microsoft Services work with Future Cities&lt;/a> in conjunction with &lt;a href="http://www.guidedogs.org.uk">Guide Dogs for the Blind&lt;/a> to help blind people navigate. A very good friend of mine is almost totally blind so I&amp;rsquo;m very interested in technology that helps people in his situation. The history of the project is that they were asked to help people navigate around a new city, and seeing as one of their team is blind they decided it would be a good place to start - the needs of the sighted are a lot less than those of people who are visually impaired in a new city so solving for the harder case will also help ensure you cover as much as possible for the easy case.&lt;/p>
&lt;p>The basic idea behind the project is to provide visually impaired people with the ability to navigate around a city. For us sighted people it&amp;rsquo;s easy - we whip out our smartphone and load up google maps. If you&amp;rsquo;re blind, this is impossible. The Microsoft guys have come up with what is almost like turn by turn navigation using audio clues to guide you around. Dogs are great for stopping you walking out in front of cars but can&amp;rsquo;t distinguish between Starbucks and a dry cleaners.&lt;/p>
&lt;p>The first part of the technology uses &lt;a href="http://en.wikipedia.org/wiki/Binaural_recording">binaural&lt;/a> sound processing - the ability to make a sound seem like it is coming from somewhere in 3D space using normal headphones. Unlike normal stereo, this allows sounds to be behind, in front, above, or anywhere instead of simply left/right positioned. Combine this with a smartphone with a built in compass and you have the ability to put sound in a particular location regardless of which way the user is facing (assuming the smartphone is facing the same way relative to the user of course).&lt;/p>
&lt;p>The downsides for this as a navigation tool are that, as mentioned, the smartphone has to always be facing in the same direction as the user, as well as the user having to wear headphones. A blind person would never want this as their ears are vital to navigating around. If you can&amp;rsquo;t hear traffic for example then you couldn&amp;rsquo;t safely walk the streets.
The solution to both of these is a special headset. It&amp;rsquo;s based around bone conductivity headphones (these transmit sound by vibrating the bones in your skull allowing your ears to be free from blockages) with a box of electronics on the back that contains a compass, accelerometer and a bluetooth connection to the phone. This means the headset can always be in the same relative direction to the user to allow the sound to be positioned accurately.&lt;/p>
&lt;p>So now we have a tool that can track which way you are facing an provide audio clues at a given compass point. So the next step is to combine this with GPS, map data and a speach interface. For basic city walking it is able to name shops that you are interested in with the name being in the right direction to where you are facing. It can also navigate you to a given destination using a simple sound in the direction you need to turn - so if the place you want is 100 yards ahead on the current street, then right for 50 yards then right again for 20 it will sound in front of you whilst you walk, then turn right when you should turn, then right again when you should turn then announce when you are at your destination. All without being intrusive.&lt;/p>
&lt;p>It sounds like such a simple solution and having tried it out I can say it is really well done. I&amp;rsquo;m hoping they are going to open source the binaural technology so I can have a play at creating something similar.&lt;/p>
&lt;p>Good work Microsoft!&lt;/p></description></item><item><title>Useful links</title><link>https://jimbobbennett.dev/blogs/usefull-links/</link><pubDate>Wed, 15 Oct 2014 02:44:35 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/usefull-links/</guid><description>&lt;p>I thought it would be good to create a page full of usefull links - things that have helped me solve some problems and are complete so there&amp;rsquo;s no real need for me to blog their content.&lt;/p>
&lt;p>&lt;a href="http://jmillerdev.net/symbolicating-ios-crash-files-xamarin-ios/">Adding symbols to Xamarin crash reports for iOS&lt;/a> - this article shows how to add symbol information to a crash report retrieved from your device via XCode for a Xamarin app.&lt;/p>
&lt;p>&lt;a href="https://github.com/XLabs/Xamarin-Forms-Labs">Xamarin.Forms.Labs&lt;/a> - Add on controls and features for Xamarin.Forms apps.&lt;/p></description></item><item><title>Orientation with Xamarin.Forms</title><link>https://jimbobbennett.dev/blogs/orientation-with-xamarin-forms/</link><pubDate>Fri, 10 Oct 2014 03:52:28 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/orientation-with-xamarin-forms/</guid><description>&lt;p>Xamarin.Forms is a great cross platform development tool when it works, but being cross platform it suffers from a sever lack of features. Some of these are understandable as they are different on each platform so it&amp;rsquo;s hard to provide a consistent experience for the developer. Some are bad ommisions as they are vital to all platforms.&lt;/p>
&lt;p>The current ommission I&amp;rsquo;m working on is Orientation. I have yet to see a device that is square. Every device has two orientations, portrait and landscape and a lot of apps change their UI depending on which orientation is in use.&lt;/p>
&lt;p>&lt;img src="bg_13761402694716.jpg" alt="Portrait or landscape">&lt;/p>
&lt;p>Out of the box, Xamarin.Forms just provides one content for your page, so if you want to change it based on the device orientation you can&amp;rsquo;t. Some views will handle changes for you - GridView from the Xamarin.Forms.Labs toolkit changes the number of items across based on the orientation, contols will resize based on the available space - but nothing allows a completly different control layout.&lt;/p>
&lt;p>So I&amp;rsquo;ve decided to roll my own. I have my own &lt;code>BaseContentPage&lt;/code> class derived from &lt;code>ContentPage&lt;/code> to provide some consistent UI features like an activity spinner and services to the ViewModel, and I&amp;rsquo;ve extended this to include orientation helpers. This is just iOS only for now (if anyone wants to send me a free Xamarin.Andriod business license and Android phone I&amp;rsquo;ll gladly update it to do &amp;lsquo;droid as well :) )&lt;/p>
&lt;p>First I had to create a new renderer for the page to provide information on the orientation and notification of changes.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">[assembly: ExportRenderer(typeof(BaseContentPage), typeof(BaseContentPageRenderer))]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">namespace&lt;/span> JimBobBennett.JimLib.Xamarin.ios.Views
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">BaseContentPageRenderer&lt;/span> : PageRenderer
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">protected&lt;/span> &lt;span style="color:#66d9ef">override&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> OnElementChanged(VisualElementChangedEventArgs e)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">base&lt;/span>.OnElementChanged(e);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ((BaseContentPage) Element).Appearing += (s, e1) =&amp;gt; SetOrientation();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> SetOrientation();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">override&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> DidRotate(UIInterfaceOrientation fromInterfaceOrientation)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">base&lt;/span>.DidRotate(fromInterfaceOrientation);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> SetOrientation();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">private&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> SetOrientation()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ((BaseContentPage) Element).OrientationChanged(InterfaceOrientation.GetOrientation());
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This render calls the &lt;code>OrientationChanged&lt;/code> method on the &lt;code>BaseContentPage&lt;/code> on creation, on appearing and whenever the orientation is changed by overriding the &lt;code>DidRotate&lt;/code> method on the Page renderer. The &lt;code>InterfaceOrientation.GetOrientation()&lt;/code> extension method is my own and converts the iOS &lt;code>UIInterfaceOrientation&lt;/code> enum into my own &lt;code>Orientation&lt;/code> enum to allow it to not be platform specific.&lt;/p>
&lt;p>In my &lt;code>BaseContentPage&lt;/code> I&amp;rsquo;ve defined two properties, &lt;code>PortraitContent&lt;/code> and &lt;code>LandscapeContent&lt;/code>, both of type view. I&amp;rsquo;ve also changed the default property to be &lt;code>PortraitContent&lt;/code>, so when the content is set in XAML it sets the &lt;code>PortraitContent&lt;/code> property instead of the &lt;code>Content&lt;/code> property. This is done using the &lt;code>ContentProperty&lt;/code> attribute, same as in WPF.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">[ContentProperty(&amp;#34;PortraitContent&amp;#34;)]&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Internally in my page I set the &lt;code>Content&lt;/code> to be a number of views to support my functionality, so when this property is set externally I route the value to a child of one of my grids and reset the content back to the required views. I enhanced this to pass the content to the &lt;code>PortraitContent&lt;/code> property to any C# code that sets this will still work.
To make the magic happen on orientation change I implemented the &lt;code>OrientationChanged&lt;/code> method to set either the only content available if only one value is set, or to set the content depending on the orientation.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">if&lt;/span> (_portraitContent == &lt;span style="color:#66d9ef">null&lt;/span> &amp;amp;&amp;amp; _landscapeContent == &lt;span style="color:#66d9ef">null&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// do nothing&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">else&lt;/span> &lt;span style="color:#66d9ef">if&lt;/span> (_portraitContent != &lt;span style="color:#66d9ef">null&lt;/span> &amp;amp;&amp;amp; _landscapeContent == &lt;span style="color:#66d9ef">null&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> _contentGrid.Children.Clear();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> _contentGrid.Children.Add(_portraitContent);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">else&lt;/span> &lt;span style="color:#66d9ef">if&lt;/span> (_portraitContent == &lt;span style="color:#66d9ef">null&lt;/span> &amp;amp;&amp;amp; _landscapeContent != &lt;span style="color:#66d9ef">null&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> _contentGrid.Children.Clear();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> _contentGrid.Children.Add(_landscapeContent);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">else&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> _contentGrid.Children.Clear();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> _contentGrid.Children.Add(Orientation == Orientation.Landscape ? _landscapeContent : _portraitContent);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This works well except for one problem. This takes effect after the orientation is changed. What happens is:&lt;/p>
&lt;ul>
&lt;li>Orientation is changed&lt;/li>
&lt;li>Screen rotates&lt;/li>
&lt;li>Xamarin.Forms re-lays out the controls based on the new orientaion&lt;/li>
&lt;li>Content is changed&lt;/li>
&lt;/ul>
&lt;p>It looks a bit rubbish as the user sees the portrait content laid out in landscape first before the landscape content is shown. Easy fix though - remove the content before the change, then add the new one after. This can be detected in the rendereer by overriding &lt;code>WillRotate&lt;/code>.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">override&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> WillRotate(UIInterfaceOrientation toInterfaceOrientation, &lt;span style="color:#66d9ef">double&lt;/span> duration)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">base&lt;/span>.WillRotate(toInterfaceOrientation, duration);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ((BaseContentPage)Element).OrientationChanging();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">protected&lt;/span> &lt;span style="color:#66d9ef">internal&lt;/span> &lt;span style="color:#66d9ef">virtual&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> OrientationChanging()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> _contentGrid.Children.Clear();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Much nicer.&lt;/p>
&lt;p>The only bug I&amp;rsquo;m left with now that I have yet to fix is for images. I have an image in both my portrait and landscape views that uses the same image source. When changing a few times sometimes the portrait image is blank. I&amp;rsquo;ve tried raising property changes to fix it but no dice. Once I fix it (or more realistically work round it as it looks like a Xamarin bug) I&amp;rsquo;ll update this post with the details.&lt;/p>
&lt;p>All the code for this is available on &lt;a href="https://github.com/jimbobbennett/JimLib.Xamarin">in JimLib.Xamarin on GitHub&lt;/a>.&lt;/p></description></item><item><title>Xamarin Insights</title><link>https://jimbobbennett.dev/blogs/xamarin-insights/</link><pubDate>Fri, 10 Oct 2014 01:28:54 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/xamarin-insights/</guid><description>&lt;p>At the moment Xamarin are holding their annual Evolve conference in Atlanta. Unfortunately I&amp;rsquo;m not there, but I&amp;rsquo;ve been keeping up to date with their announcements and one caught my eye - &lt;a href="http://blog.xamarin.com/monitoring-your-apps-with-xamarin-insights/">Xamarin Insights&lt;/a>. I&amp;rsquo;ve been looking for a Xamarin compatible analytics and crash reporter for a while and it looke like this does the job.&lt;/p>
&lt;p>So far I&amp;rsquo;ve loked at:&lt;/p>
&lt;ul>
&lt;li>Flurry - analytics but no iOS 8 Xamarin bindings&lt;/li>
&lt;li>HockeyApp - crash reporting but no analytics&lt;/li>
&lt;li>Crashlytics - I have no idea what this is as they have a stupid website and a weird invitation process that I can&amp;rsquo;t be bothered to wade through.&lt;/li>
&lt;/ul>
&lt;p>There is no all in one Xamarin compatible solution that I have seen, but Insights seems to be what I&amp;rsquo;m looking for. It provides event tracing so you can see what bits of your app are being used, crash reporting with upload of dSym files for tracking crashes including seeing the stack and user tracking.
It was a bit flakey when I started using it - crash reports wouldn&amp;rsquo;t show and no user were visible but it improved over the day. I guess Xamarin are hard at work ensuring it&amp;rsquo;s all working properly as it was only just announced.&lt;/p>
&lt;p>It&amp;rsquo;s pretty easy to set up - just import the NuGet package then call &lt;code>Insights.Initialize(&amp;quot;your app id&amp;quot;);&lt;/code>. After that you can track events using &lt;code>Insights.Track(&amp;quot;event name&amp;quot;);&lt;/code> and can even pass event data to the track call.&lt;/p>
&lt;p>I included it in my latest app beta and it picked up a crash that happened. Unfortunately even though I had uploaded the dSYM file, it wasn&amp;rsquo;t showing the stack trace. A bit of investigation on my side found the issue - I hadn&amp;rsquo;t included debug symbols in my build. These have to be turned on so it can link the stack trace back to the lines of code. Easy enough to do in VS.&lt;/p>
&lt;p>&lt;img src="DebugSymbols.png" alt="Turn on Enable Debugging from the iOS Build tab">&lt;/p>
&lt;p>&lt;img src="FullDebugInfo.png" alt="Turn on full debug info form the Build Advanced dialog">&lt;/p>
&lt;p>It&amp;rsquo;s well worth a try - free to existing Xamarin subscribers during their beta. Hopefully when pricing is announced it&amp;rsquo;ll be reasonable.
I&amp;rsquo;m also hoping it&amp;rsquo;ll include distribution as well, it would be nice to upload a build from VS/XS including the dSym file and distribute it to testers and get data back instead of having to also use tools like TestFlight.&lt;/p></description></item><item><title>iOS pull to refresh without using a UITableView</title><link>https://jimbobbennett.dev/blogs/ios-pull-to-refresh-without-using-a-uitableview/</link><pubDate>Sun, 28 Sep 2014 08:38:16 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/ios-pull-to-refresh-without-using-a-uitableview/</guid><description>&lt;p>I&amp;rsquo;ve been working on the UI for my current app, trying to make some usability improvements. The main screen is a list of data containing an image and some text. Although this is a standard UI pattern, the problem I&amp;rsquo;m having with it is one of size. List rows are usually short and full width. For text this is fine, but not so good for images, then end up being small and not very easy to see. For the data I&amp;rsquo;m showing the image is just as important as the text, if not more so for quick identification of the data. I&amp;rsquo;s also wasting a lot of space as there number of rows will be very small most of the time, probably only one or 2 rows.
To improve this I&amp;rsquo;ve decided to move to a grid like layout, with varying columns depending on if the view is portrait or landscape. The end result is much nicer to look at and use, but coding it up let to a problem.&lt;/p>
&lt;p>I was using a derivative of the Xamarin.Forms &lt;code>ListView&lt;/code> class with support for pull to refresh courtesy of &lt;a href="http://motzcod.es/post/87917979362/pull-to-refresh-for-xamarin-forms-ios">James Montemagno&amp;rsquo;s blog&lt;/a>. This provides a Xamarin wrapper around the well known &lt;code>UIRefreshControl&lt;/code> and tying it to a &lt;code>UITableView&lt;/code>.
This is all great, until you change from a &lt;code>ListView&lt;/code> to something else, in my case a custom generated grid view.&lt;/p>
&lt;p>Luckily, &lt;code>UIScrollView&lt;/code> also supports pull to refresh, just it&amp;rsquo;s not as well documented. It has to be a &lt;code>UIScrollView&lt;/code> or derivative, not any other control as it needs the pull down bounce to trigger the refresh.&lt;/p>
&lt;p>To implement it in my grid view I first created a &lt;code>PullToRefreshScrollView&lt;/code> and associated renderer to host my grid.
The code for the view lives in my portable project and just defines some bindable properties for the command to execute when refreshing, a flag to turn on the refresh indicator and a refresh message. All lifted directly from James&amp;rsquo;s &lt;a href="https://github.com/jamesmontemagno/Xamarin.Forms-PullToRefreshListView/blob/master/PullToRefresh/PullToRefreshListView.cs">PullToRefreshListView&lt;/a>.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">PullToRefreshScrollView&lt;/span> : ScrollView
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">static&lt;/span> &lt;span style="color:#66d9ef">readonly&lt;/span> BindableProperty IsRefreshingProperty =
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> BindableProperty.Create&amp;lt;PullToRefreshScrollView, &lt;span style="color:#66d9ef">bool&lt;/span>&amp;gt;(p =&amp;gt; p.IsRefreshing, &lt;span style="color:#66d9ef">false&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">static&lt;/span> &lt;span style="color:#66d9ef">readonly&lt;/span> BindableProperty RefreshCommandProperty =
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> BindableProperty.Create&amp;lt;PullToRefreshScrollView, ICommand&amp;gt;(p =&amp;gt; p.RefreshCommand, &lt;span style="color:#66d9ef">null&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">static&lt;/span> &lt;span style="color:#66d9ef">readonly&lt;/span> BindableProperty MessageProperty =
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> BindableProperty.Create&amp;lt;PullToRefreshScrollView, &lt;span style="color:#66d9ef">string&lt;/span>&amp;gt;(p =&amp;gt; p.Message, &lt;span style="color:#66d9ef">string&lt;/span>.Empty);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">bool&lt;/span> IsRefreshing
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">get&lt;/span> { &lt;span style="color:#66d9ef">return&lt;/span> (&lt;span style="color:#66d9ef">bool&lt;/span>)GetValue(IsRefreshingProperty); }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">set&lt;/span> { SetValue(IsRefreshingProperty, &lt;span style="color:#66d9ef">value&lt;/span>); }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> ICommand RefreshCommand
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">get&lt;/span> { &lt;span style="color:#66d9ef">return&lt;/span> (ICommand)GetValue(RefreshCommandProperty); }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">set&lt;/span> { SetValue(RefreshCommandProperty, &lt;span style="color:#66d9ef">value&lt;/span>); }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">string&lt;/span> Message
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">get&lt;/span> { &lt;span style="color:#66d9ef">return&lt;/span> (&lt;span style="color:#66d9ef">string&lt;/span>)GetValue(MessageProperty); }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">set&lt;/span> { SetValue(MessageProperty, &lt;span style="color:#66d9ef">value&lt;/span>); }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The next bit is a wrapper for the &lt;code>UIRefreshControl&lt;/code> - again lifted from the &lt;a href="https://github.com/jamesmontemagno/Xamarin.Forms-PullToRefreshListView/blob/master/iOS/Renderers/FormsUIRefreshControl.cs">same place&lt;/a> and put into my iOS project.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">FormsUIRefreshControl&lt;/span> : UIRefreshControl
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> FormsUIRefreshControl()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ValueChanged += (sender, e) =&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">var&lt;/span> command = RefreshCommand;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span>(command == &lt;span style="color:#66d9ef">null&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> command.Execute(&lt;span style="color:#66d9ef">null&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> };
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">private&lt;/span> &lt;span style="color:#66d9ef">string&lt;/span> _message;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">string&lt;/span> Message
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">get&lt;/span> { &lt;span style="color:#66d9ef">return&lt;/span> _message;}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">set&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> _message = &lt;span style="color:#66d9ef">value&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> (&lt;span style="color:#66d9ef">string&lt;/span>.IsNullOrWhiteSpace (_message))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> AttributedTitle = &lt;span style="color:#66d9ef">new&lt;/span> MonoTouch.Foundation.NSAttributedString(_message);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">private&lt;/span> &lt;span style="color:#66d9ef">bool&lt;/span> _isRefreshing;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">bool&lt;/span> IsRefreshing
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">get&lt;/span> { &lt;span style="color:#66d9ef">return&lt;/span> _isRefreshing;}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">set&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> _isRefreshing = &lt;span style="color:#66d9ef">value&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> (_isRefreshing)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> BeginRefreshing();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">else&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> EndRefreshing();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> ICommand RefreshCommand { &lt;span style="color:#66d9ef">get&lt;/span>; &lt;span style="color:#66d9ef">set&lt;/span>; }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Finally the renderer. To create the refresh control in the scroll view, it&amp;rsquo;s a simple case of creating the &lt;code>UIRefreshControl&lt;/code> and adding it as a subview of the &lt;code>UIScrollView&lt;/code>. When you pull the scroll view down it will trigger a ValueChange event on the &lt;code>UIRefreshControl&lt;/code>, which our &lt;code>FormsUIRefreshControl&lt;/code> handles to execute the provided command.
Now for the gotcha - the refresh only happens when you pull the scroll view down far enough. If the contents of the scroll view is smaller than the available space then it won&amp;rsquo;t scroll in either direction, stopping the pull action from doing anything. Good news is we can make the scroll view always scroll by setting:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>AlwaysBounceVertical = &lt;span style="color:#66d9ef">true&lt;/span>;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Here&amp;rsquo;s the full code for the renderer:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">PullToRefreshScrollViewRenderer&lt;/span> : ScrollViewRenderer
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">private&lt;/span> FormsUIRefreshControl _refreshControl;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">protected&lt;/span> &lt;span style="color:#66d9ef">override&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> OnElementChanged(VisualElementChangedEventArgs e)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">base&lt;/span>.OnElementChanged(e);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> (_refreshControl != &lt;span style="color:#66d9ef">null&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">var&lt;/span> pullToRefreshScrollView = (PullToRefreshScrollView)Element;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> pullToRefreshScrollView.PropertyChanged += OnElementPropertyChanged;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> _refreshControl = &lt;span style="color:#66d9ef">new&lt;/span> FormsUIRefreshControl
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> RefreshCommand = pullToRefreshScrollView.RefreshCommand,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Message = pullToRefreshScrollView.Message
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> };
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> AlwaysBounceVertical = &lt;span style="color:#66d9ef">true&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> AddSubview(_refreshControl);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">private&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> OnElementPropertyChanged(&lt;span style="color:#66d9ef">object&lt;/span> sender, System.ComponentModel.PropertyChangedEventArgs e)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">var&lt;/span> pullToRefreshScrollView = Element &lt;span style="color:#66d9ef">as&lt;/span> PullToRefreshScrollView;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> (pullToRefreshScrollView == &lt;span style="color:#66d9ef">null&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> (e.PropertyName == PullToRefreshScrollView.IsRefreshingProperty.PropertyName)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> _refreshControl.IsRefreshing = pullToRefreshScrollView.IsRefreshing;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">else&lt;/span> &lt;span style="color:#66d9ef">if&lt;/span> (e.PropertyName == PullToRefreshScrollView.MessageProperty.PropertyName)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> _refreshControl.Message = pullToRefreshScrollView.Message;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">else&lt;/span> &lt;span style="color:#66d9ef">if&lt;/span> (e.PropertyName == PullToRefreshScrollView.RefreshCommandProperty.PropertyName)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> _refreshControl.RefreshCommand = pullToRefreshScrollView.RefreshCommand;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This control is now part of &lt;a href="Xamarin">JimLib.Xamarin, available on GitHub&lt;/a>.&lt;/p></description></item><item><title>ComPlexion and legal issues</title><link>https://jimbobbennett.dev/blogs/complexion-and-legal-issues/</link><pubDate>Fri, 26 Sep 2014 03:11:47 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/complexion-and-legal-issues/</guid><description>&lt;p>I&amp;rsquo;ve been working on an open source &lt;a href="http://plex.tv">Plex&lt;/a> REST library. The idea behind it is to provide a simple way to connect to a Plex media server and get info on the currently playing movie or TV show. The most important info being a link to IMDB - pretty much every time my wife and I watch something we dig out of phones to look up an actors name or what else we have seen them in.&lt;/p>
&lt;p>The reason I&amp;rsquo;m developing this library is so that I can use it in an upcoing iOS app that acts like a second screen, providing these details in an easy to use way. More info on this will be coming soon once it&amp;rsquo;s more complete, but if you&amp;rsquo;d like to be a beta tester for the app then email me at &lt;a href="mailto:jim@moomoo.io">jim@moomoo.io&lt;/a> .&lt;/p>
&lt;p>I named my library ComPlexion - simply because it sounded good, included Plex in the name and I&amp;rsquo;m rubbish at picking names so went for the first one I could think of. However, I decided to have a read of the Plex legal pages with regard to their trademarks just to make sure that I named my app appropriately and email a link to ComPlexion to the Plex legal team just to verify.&lt;/p>
&lt;p>As it turns out, they don&amp;rsquo;t want me to use the name. According to their &lt;a href="https://plex.tv/legal">legal page&lt;/a>:&lt;/p>
&lt;p>You may:&lt;/p>
&lt;ul>
&lt;li>Name your website, product, or application with something unique, that satisfies the other Guidelines.&lt;/li>
&lt;li>Feel free to include language on your site explaining that your application “Works with Plex”.&lt;/li>
&lt;li>Use “for Plex” following the name of your application, provided that the name of your application is unique.&lt;/li>
&lt;/ul>
&lt;p>You may not:&lt;/p>
&lt;ul>
&lt;li>Use Plex or derivatives thereof in the name of your application&lt;/li>
&lt;/ul>
&lt;p>So looks like ComPlexion is out. I&amp;rsquo;ve renamed it to:&lt;/p>
&lt;p>&lt;strong>RestAndRelaxForPlex&lt;/strong>&lt;/p>
&lt;p>Not the best name, but it abides by their rules. It&amp;rsquo;s not a huge problem, they have built a great app and ecosystem so it&amp;rsquo;s only fair not in infringe on their tradmarks or imply that they are behind or endorse a third party product.&lt;/p>
&lt;p>&lt;a href="https://github.com/jimbobbennett/RestAndRelaxForPlex">The new GitHub repo is here.&lt;/a>&lt;/p></description></item><item><title>Performance tuning a website</title><link>https://jimbobbennett.dev/blogs/performance-tuning-a-website/</link><pubDate>Sat, 13 Sep 2014 10:52:26 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/performance-tuning-a-website/</guid><description>&lt;p>Despite the rise in fast home broadband, tuning your website for performance is still just as important as it was in the days of dial up. Although home connections can be fast in most first world countries (I used to have a 1Gb connection in Hong Kong), there are stil a lot of people in developing countries who only have slower speeds, as well as a huge increase in mobile users who have either limited speed or usage caps (or in my current case, are in a country whose main cables have been cut by a typhoon so the internet is now at dial up speeds until they fix it in a weeks time).&lt;/p>
&lt;p>Today as part of working on &lt;a href="https://www.moomoo.io">MooMoo.io&lt;/a> I decided to have a look at the performance and see what I could do to improve it.
Profiling is important to see what can be improved, but there are some tricks that apply to all websites that should be done as a matter of course. The basic principle is to reduce the amount of data sent over the wire and the number of requests made.&lt;/p>
&lt;h3 id="minification">Minification&lt;/h3>
&lt;p>&lt;a href="http://en.wikipedia.org/wiki/Minification_%28programming%29">Minification&lt;/a> is the act of taking js or css files and reducing their size - removing comments, white space and other unnecessary characters, renaming variables to smaller names, that sort of thing. The downside to this is it makes the code unreadable, so the normal process is to write JavaScript or CSS normally, then create a minified version (usually named &lt;filename>.min.js) as part of a build step. A lot of third party libraries will already provide minified versions of their code, so in general you should always use these where available.&lt;/p>
&lt;p>For MooMoo.io I decided to add some code to my Node.js server to automatically minify my CSS and js files during startup, then change my HTML to refer to the minified versions. This means I can develop using the full versions and they are converted when needed. At the same time, I will concatenate all my js files into one. This means the browser only has to make one server request to load all js code instead of one request per file, reducing the bandwidth used.&lt;/p>
&lt;p>&lt;strong>CSS&lt;/strong>&lt;/p>
&lt;p>For CSS minification, I am using &lt;a href="https://www.npmjs.org/package/minifier">minifier&lt;/a>.&lt;/p>
&lt;pre tabindex="0">&lt;code>$ npm install minifier --save
&lt;/code>&lt;/pre>&lt;p>In my code I already use compass to compile SASS giving me one css file, so I just need to minify that one.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-js" data-lang="js">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">minifier&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;minifier&amp;#39;&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">minifier&lt;/span>.&lt;span style="color:#a6e22e">minify&lt;/span>(&lt;span style="color:#a6e22e">__dirname&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#e6db74">&amp;#39;/public/stylesheets/site.css&amp;#39;&lt;/span>, {})
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This will spit out &lt;code>/public/stylesheets/site.min.css&lt;/code>. One quick change to my HTML head code and it&amp;rsquo;s using the minified version.&lt;/p>
&lt;p>&lt;strong>js&lt;/strong>&lt;/p>
&lt;p>For js minification, I am using &lt;a href="https://www.npmjs.org/package/uglify-js">uglify-js&lt;/a>.&lt;/p>
&lt;pre tabindex="0">&lt;code>$ npm install uglify-js --save
&lt;/code>&lt;/pre>&lt;p>This can take multiple js files and spit out minified code, which can then be saved to a file.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-js" data-lang="js">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">fs&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;fs&amp;#39;&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">uglify&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;uglify-js&amp;#34;&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">jsFiles&lt;/span> &lt;span style="color:#f92672">=&lt;/span> [
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">__dirname&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#e6db74">&amp;#39;/../public/vendor/jquery/dist/jquery.min.js&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">__dirname&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#e6db74">&amp;#39;/../public/vendor/foundation/js/vendor/fastclick.js&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">__dirname&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#e6db74">&amp;#39;/../public/vendor/foundation/js/foundation.min.js&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">__dirname&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#e6db74">&amp;#39;/../public/vendor/angular/angular.min.js&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">__dirname&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#e6db74">&amp;#39;/../public/vendor/angular-resource/angular-resource.min.js&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">__dirname&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#e6db74">&amp;#39;/../public/vendor/angular-route/angular-route.min.js&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>];
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">uglified&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">uglify&lt;/span>.&lt;span style="color:#a6e22e">minify&lt;/span>(&lt;span style="color:#a6e22e">jsFiles&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">fs&lt;/span>.&lt;span style="color:#a6e22e">writeFile&lt;/span>(&lt;span style="color:#a6e22e">__dirname&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#e6db74">&amp;#39;/public/js/concat.min.js&amp;#39;&lt;/span>, &lt;span style="color:#a6e22e">uglified&lt;/span>.&lt;span style="color:#a6e22e">code&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span> (&lt;span style="color:#a6e22e">err&lt;/span>){
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span>(&lt;span style="color:#a6e22e">err&lt;/span>) {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">log&lt;/span>(&lt;span style="color:#a6e22e">err&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> } &lt;span style="color:#66d9ef">else&lt;/span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">log&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;Script generated and saved:&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;concat.min.js&amp;#39;&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>});
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>As mentioned above, uglify creates an object containing the minified code in the &lt;code>code&lt;/code> property, so this needs to be saved to a file using &lt;code>fs&lt;/code>, the Node file module. In this example, 6 files are concatenated into one minified file not only reducing the soze but also reducing the server hits.&lt;/p>
&lt;h3 id="reducing-image-sizes">Reducing image sizes&lt;/h3>
&lt;p>Images can take up a lot of bandwidth. JPEGs have compression built in so reducing the size of these is easy. PNGs are not so easy. They are useful for web sites because they allow transparency, but this comes with a cost of larger file sizes. There are tools to compress PNGs by reducing the colours though. The one I used is &lt;a href="https://tinypng.com/">TinyPNG&lt;/a> - just drop in your images and it spits out compressed versions. I manged to get a 70% reduction in file size across all my images this way.&lt;/p>
&lt;h3 id="compressing-resources">Compressing resources&lt;/h3>
&lt;p>The last step is to compress as much as possible when sending data. Modern browsers will request gzipped files where possible to reduce bandwidth. With Node and Express it&amp;rsquo;s easy to enable gzipping of all content using the &lt;a href="https://www.npmjs.org/package/compression">Compression middleware&lt;/a>.&lt;/p>
&lt;pre tabindex="0">&lt;code>$ npm install compression --save
&lt;/code>&lt;/pre>&lt;p>This middleware can then be inserted right at the start to compress as much as possible - every request that goes through this middleware will be compressed.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-js" data-lang="js">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">app&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">express&lt;/span>();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">app&lt;/span>.&lt;span style="color:#a6e22e">use&lt;/span>(&lt;span style="color:#a6e22e">compression&lt;/span>({
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">threshold&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#ae81ff">512&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}));
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>In this example I&amp;rsquo;ve set the compression to compress anything below 512 bytes. Below this there is not much point as the zip headers will be bigger than any space you save.&lt;/p>
&lt;h3 id="result">Result&lt;/h3>
&lt;p>The end result of doing this for me was a much faster page I&amp;rsquo;ve been using &lt;a href="http://gtmetrix.com/">GTMetrix&lt;/a> to profile my page and it&amp;rsquo;s reduced in size from over 600Kb to 200Kb, and is currently rated A by PageSpeed and B by Y Slow - up from F for both when I started.&lt;/p>
&lt;p>The only thing I fall down on is browser caching. Seeing as the site is still very mch in development I don&amp;rsquo;t want to turn this on until it settles down a bit.&lt;/p></description></item><item><title>FauxGhost - a clean, responsive Ghost theme</title><link>https://jimbobbennett.dev/blogs/fauxghost-a-clean-responsive-ghost-theme/</link><pubDate>Sat, 13 Sep 2014 07:46:23 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/fauxghost-a-clean-responsive-ghost-theme/</guid><description>&lt;p>This blog, like many others coming out recently, uses the &lt;a href="http://www.ghost.org">Ghost blogging platform&lt;/a>. This is a really nice, simple blogging platform with cheap hosting, built by some super smart people.&lt;/p>
&lt;p>The theme support for Ghost is excellent with loads of good themes available (some for money, some open source), and really great documentation on how to create your own theme. Admitedly their marketplace leaves a lot to be desired but it&amp;rsquo;s early days for the platform so I&amp;rsquo;m sure this will improve.
The default theme Casper is quite nice, but there are better ones. I started off using &lt;a href="https://github.com/axiantheme/ghostion">Ghostion&lt;/a>, but since the initial release, no more maintence has been done on it. It also had a few bugs which I needed to fix as well as neededing changes in a few places to add the tweaks I needed, such as links to my &lt;a href="http://twitter.com/jimbobbennett">twitter&lt;/a> feed. Eventually I decided to overhaul it properly and come up with a new theme based off Ghostion.&lt;/p>
&lt;p>And so Faux Ghost was born.&lt;/p>
&lt;p>&lt;img src="FauxGhost.png" alt="Faux Ghost">&lt;/p>
&lt;p>Grab it from &lt;a href="https://www.moomoo.io/fauxghost">MooMoo.io&lt;/a>. Comments, criticisims, PRs etc. all appreciated.&lt;/p></description></item><item><title>WeakEvents in PCLs</title><link>https://jimbobbennett.dev/blogs/weakevents-in-pcls/</link><pubDate>Sun, 07 Sep 2014 08:05:45 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/weakevents-in-pcls/</guid><description>&lt;p>One of the biggest causes of memory leaks I&amp;rsquo;ve seen in C# applications is events. Although C# can&amp;rsquo;t leak in the same way C++ can, it&amp;rsquo;s easy to unintentionally end up with references you weren&amp;rsquo;t expecting - and what a lot of people don&amp;rsquo;t realise or forget is that subscribing to an event holds a reference from the event source to the event target, essentially keeping the target alive.&lt;/p>
&lt;p>A simple example is when you have a long lived object:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">FooManager&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">event&lt;/span> EventHandler FooEvent;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>and subscribe from something like a model that is only meant to live for the lifetime of a popup window or other short lived object.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">ShortLivedModel&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> ShortLivedModel(FooManager fm)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> fm.FooEvent += FooHandler;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">private&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> FooHandler(&lt;span style="color:#66d9ef">object&lt;/span> sender, EventArgs args)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Just by doing this the &lt;code>FooManager&lt;/code> internally holds a reference to the &lt;code>FooModel&lt;/code> keeping it alive. If you create one model each time the window is popped up you can very quickly build up a big leak, especially if the view model holds onto the model, and the view holds onto the view model - that one model keeps a massic object graph alive.&lt;/p>
&lt;p>So how do we deal with it?&lt;/p>
&lt;p>The best option is to remember to unsubscribe. But this isn&amp;rsquo;t always easy. Especially with WPF code there is no simple way to see when a control is closed if it&amp;rsquo;s not a window. It&amp;rsquo;s also easy to forget, especially in complicated code where the event subscription could be in a base class you don&amp;rsquo;t know about or don&amp;rsquo;t have access to.&lt;/p>
&lt;p>There is an easier way - weak events. These don&amp;rsquo;t hold a reference to the target allowing the target to be GC&amp;rsquo;d without unsubscribing. Even better , you can use them in the event implementation making it transparent to the subscriber. This is quite a standard pattern and Microsoft provides a good implementation of both a &lt;a href="http://msdn.microsoft.com/en-us/library/system.windows.weakeventmanager%28v=vs.110%29.aspx">specific&lt;/a> and &lt;a href="http://msdn.microsoft.com/en-us/library/hh199438%28v=vs.110%29.aspx">generic&lt;/a> weak event manager. The problem with these is that they don&amp;rsquo;t work for PCL projects - they are too heavily linked to reflection.&lt;/p>
&lt;p>Luckily it&amp;rsquo;s not that hard to create your own that is PCL compliant.&lt;/p>
&lt;p>The pattern I&amp;rsquo;m going to use is to change the event implementation to wire the target of the event into the weak event manager, then tell the weak event manager to fire the event when needed.&lt;/p>
&lt;p>Lets start with the calling code first, then build up the weak event manager from there.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">MyClass&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">private&lt;/span> WeakEventManager _manager = &lt;span style="color:#66d9ef">new&lt;/span> WeakEventManager();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">event&lt;/span> EventHandler MyEvent
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">add&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> _manager.AddEventHandler(&lt;span style="color:#e6db74">&amp;#34;MyEvent&amp;#34;&lt;/span>, &lt;span style="color:#66d9ef">value&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">remove&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> _manager.RemoveEventHandler(&lt;span style="color:#e6db74">&amp;#34;MyEvent&amp;#34;&lt;/span>, &lt;span style="color:#66d9ef">value&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">protected&lt;/span> &lt;span style="color:#66d9ef">virtual&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> OnMyEvent()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> _manager.HandleEvent(&lt;span style="color:#66d9ef">this&lt;/span>, EventArgs.Empty, &lt;span style="color:#e6db74">&amp;#34;MyEvent&amp;#34;&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>In the above code we are declaring a &lt;code>WeakEventManager&lt;/code>, then wiring up the value passed to the add handler for the event to it. When we want to invoke our event we tell the &lt;code>WeakEventManager&lt;/code> to invoke the event by name with whatever sender and args we require.&lt;/p>
&lt;p>Lets look at the implementation now. The full code contains thread safety, a static to get one manager per source object and other helpful bits. The code here is just the basics for brevity.&lt;/p>
&lt;p>&lt;strong>First, adding the event handlers.&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">WeakEventManager&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">private&lt;/span> &lt;span style="color:#66d9ef">readonly&lt;/span> Dictionary&amp;lt;&lt;span style="color:#66d9ef">string&lt;/span>, List&amp;lt;Tuple&amp;lt;WeakReference, MethodInfo&amp;gt;&amp;gt;&amp;gt; _eventHandlers = &lt;span style="color:#66d9ef">new&lt;/span> Dictionary&amp;lt;&lt;span style="color:#66d9ef">string&lt;/span>, List&amp;lt;Tuple&amp;lt;WeakReference, MethodInfo&amp;gt;&amp;gt;&amp;gt;();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> AddEventHandler&amp;lt;TEventArgs&amp;gt;(&lt;span style="color:#66d9ef">string&lt;/span> eventName, EventHandler&amp;lt;TEventArgs&amp;gt; &lt;span style="color:#66d9ef">value&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">where&lt;/span> TEventArgs : EventArgs
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> BuildEventHandler(eventName, &lt;span style="color:#66d9ef">value&lt;/span>.Target, &lt;span style="color:#66d9ef">value&lt;/span>.GetMethodInfo());
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> AddEventHandler(&lt;span style="color:#66d9ef">string&lt;/span> eventName, EventHandler &lt;span style="color:#66d9ef">value&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> BuildEventHandler(eventName, &lt;span style="color:#66d9ef">value&lt;/span>.Target, &lt;span style="color:#66d9ef">value&lt;/span>.GetMethodInfo());
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">private&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> BuildEventHandler(&lt;span style="color:#66d9ef">string&lt;/span> eventName, &lt;span style="color:#66d9ef">object&lt;/span> handlerTarget, MethodInfo methodInfo)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> List&amp;lt;Tuple&amp;lt;WeakReference, MethodInfo&amp;gt;&amp;gt; target;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> (!_eventHandlers.TryGetValue(eventName, &lt;span style="color:#66d9ef">out&lt;/span> target))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> target = &lt;span style="color:#66d9ef">new&lt;/span> List&amp;lt;Tuple&amp;lt;WeakReference, MethodInfo&amp;gt;&amp;gt;();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> _eventHandlers.Add(eventName, target);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> target.Add(Tuple.Create(&lt;span style="color:#66d9ef">new&lt;/span> WeakReference(handlerTarget), methodInfo));
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>There are 2 &lt;code>AddEventHandler&lt;/code> methods to cover events that are of type &lt;code>EventHandler&lt;/code> and those of type &lt;code>EventHandler&amp;lt;args&amp;gt;&lt;/code>. Both route through to the same helper but are needed as they are not convertible.
The code here has a dictionary of a list of handlers and targets to the event name. Each item in the list contains the &lt;code>MethodInfo&lt;/code> of the handler (lambdas still have method info so they can be used as the event target) allowing the invocator to call the method, and a weak reference to the target so we know what to call the method on. The weak reference bit is important here. We don&amp;rsquo;t want to keep a string reference as that would keep the target alive - the thing we&amp;rsquo;re trying to avoid!
For each call we add the passed in handler and a weak reference to it&amp;rsquo;s target to the list held against the event name. Notice no type safety with the event names. There is nothing that validates that the name given is an event on the source object - the manager doesn&amp;rsquo;t even know what the source object is! This provides to my mind greater flexibility so the manager can also be used as an event broker.&lt;/p>
&lt;p>&lt;strong>Next, the event invocator.&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> HandleEvent(&lt;span style="color:#66d9ef">object&lt;/span> sender, &lt;span style="color:#66d9ef">object&lt;/span> args, &lt;span style="color:#66d9ef">string&lt;/span> eventName)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">var&lt;/span> toRaise = &lt;span style="color:#66d9ef">new&lt;/span> List&amp;lt;Tuple&amp;lt;&lt;span style="color:#66d9ef">object&lt;/span>, MethodInfo&amp;gt;&amp;gt;();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> List&amp;lt;Tuple&amp;lt;WeakReference, MethodInfo&amp;gt;&amp;gt; target;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> (_eventHandlers.TryGetValue(eventName, &lt;span style="color:#66d9ef">out&lt;/span> target))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">foreach&lt;/span> (&lt;span style="color:#66d9ef">var&lt;/span> tuple &lt;span style="color:#66d9ef">in&lt;/span> target.ToList())
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">var&lt;/span> o = tuple.Item1.Target;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> (o == &lt;span style="color:#66d9ef">null&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> target.Remove(tuple);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">else&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> toRaise.Add(Tuple.Create(o, tuple.Item2));
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">foreach&lt;/span> (&lt;span style="color:#66d9ef">var&lt;/span> tuple &lt;span style="color:#66d9ef">in&lt;/span> toRaise)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> tuple.Item2.Invoke(tuple.Item1, &lt;span style="color:#66d9ef">new&lt;/span>[] {sender, args});
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This code finds the event with the given name in the dictionary, and if it finds it works through the list of handlers. Each target in the list is evaluated to see if it&amp;rsquo;s null or not. With a &lt;code>WeakReference&lt;/code>, the &lt;code>Target&lt;/code> returns null if it has been GC&amp;rsquo;d. There is an &lt;code>IsAlive&lt;/code> method but this is pretty useless as there is a race condition, it could be GC&amp;rsquo;d between the call to &lt;code>IsAlive&lt;/code> and the call to &lt;code>Target&lt;/code>. The best way is to get a reference to the target, if the target is null the reference is null and if the target is not null the reference stops it being GC&amp;rsquo;d until we&amp;rsquo;ve finished using it.
If the target is null, we remove the item from the list and carry on. If it&amp;rsquo;s not null, we store it in a list to invoke at the end.
Once we have all the alive handlers, we loop through them invoking the method on the target.&lt;/p>
&lt;p>&lt;strong>Lastly, we need the remove code.&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> RemoveEventHandler&amp;lt;TEventArgs&amp;gt;(&lt;span style="color:#66d9ef">string&lt;/span> eventName, EventHandler&amp;lt;TEventArgs&amp;gt; &lt;span style="color:#66d9ef">value&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">where&lt;/span> TEventArgs : EventArgs
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> RemoveEventHandlerImpl(eventName, &lt;span style="color:#66d9ef">value&lt;/span>.Target, &lt;span style="color:#66d9ef">value&lt;/span>.GetMethodInfo());
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> RemoveEventHandler(&lt;span style="color:#66d9ef">string&lt;/span> eventName, EventHandler &lt;span style="color:#66d9ef">value&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> RemoveEventHandlerImpl(eventName, &lt;span style="color:#66d9ef">value&lt;/span>.Target, &lt;span style="color:#66d9ef">value&lt;/span>.GetMethodInfo());
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">private&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> RemoveEventHandlerImpl(&lt;span style="color:#66d9ef">string&lt;/span> eventName, &lt;span style="color:#66d9ef">object&lt;/span> handlerTarget, MemberInfo methodInfo)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> List&amp;lt;Tuple&amp;lt;WeakReference, MethodInfo&amp;gt;&amp;gt; target;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> (_eventHandlers.TryGetValue(eventName, &lt;span style="color:#66d9ef">out&lt;/span> target))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">foreach&lt;/span> (&lt;span style="color:#66d9ef">var&lt;/span> tuple &lt;span style="color:#66d9ef">in&lt;/span> target.Where(t =&amp;gt; t.Item1.Target == handlerTarget &amp;amp;&amp;amp;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> t.Item2.Name == methodInfo.Name).ToList())
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> target.Remove(tuple);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This just loops through the list against the event name and removes the entries for the given target and method name. This is needed to ensure intentionaly unsubscribing from the events works but as mentioned above is not needed to allow the target to be GC&amp;rsquo;d.&lt;/p>
&lt;p>The full code for this is on &lt;a href="https://github.com/jimbobbennett/JimLib/blob/master/JimLib/Events/WeakEventManager.cs">GitHub&lt;/a> and it&amp;rsquo;s part of the &lt;a href="https://www.nuget.org/packages/JimBobBennett.JimLib/">JimLib NuGet package&lt;/a>.&lt;/p></description></item><item><title>Weird goings on with Xamarin</title><link>https://jimbobbennett.dev/blogs/weird-goings-on-with-xamarin/</link><pubDate>Sat, 06 Sep 2014 07:40:58 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/weird-goings-on-with-xamarin/</guid><description>&lt;p>Yesterday and today I had some weird things happening with Xamarin, so I thought it was work documenting them in case anyone else has the same issue.&lt;/p>
&lt;h3 id="first---build-errors">First - Build errors.&lt;/h3>
&lt;p>I upgraded to the latest Xamarin and suddenly building for an iPhone using Visual Studio was failing with an odd error:&lt;/p>
&lt;p>&lt;code>Failed to resolve &amp;quot;System.Reflection.Emit.ModuleBuilder&amp;quot; reference from &amp;quot;mscorlib, Version=4.0.0.0, Culture=neutral, PublicKeyToken=b77a5c561934e089&amp;quot; C:\Program Files(x86)\MSBuild\Xamarin\iOS\Xamarin.iOS.Common.targets&lt;/code>&lt;/p>
&lt;p>It works on the simulator and from Xamarin Studio on the Mac, but not from Visual Studio. Not a good thing realy seeing as I paid a few hundred dollars extra for my license to enable me to develop in VS.&lt;/p>
&lt;p>Luckily someone else had also seen this and a workaround is available. The bug is reported in the &lt;a href="https://bugzilla.xamarin.com/show_bug.cgi?id=22636">Xamarin BugZilla&lt;/a>, so check this to see if it&amp;rsquo;s been fixed.
The problem was caused by NewtonSoft.Json. Their .Net 4.5 portable library isn&amp;rsquo;t that portable it seems, so shows this error. I&amp;rsquo;ve &lt;a href="https://github.com/JamesNK/Newtonsoft.Json/issues/366">raised it with NewtonSoft&lt;/a> so hopefull yit&amp;rsquo;ll be fixed. The weird thing here is it only fails when building for the device from VS, not from Xamarin Studio on OXS (I haven&amp;rsquo;t tried Xamarin Studio on Windows yet).
The &lt;a href="https://bugzilla.xamarin.com/show_bug.cgi?id=22636#c11">workaround&lt;/a> on Windows is to repoint the dll reference from the &lt;code>portable-net45+wp80+win8+wpa81&lt;/code> version to the &lt;code>portable-net40+sl4+wp7+win8&lt;/code>. Unfortunatley, this breaks the build on Xamarin Studio on OSX, so to build there you have to put it back.
Repointing the reference involves a change to the .csproj file:&lt;/p>
&lt;pre tabindex="0">&lt;code>&amp;lt;Reference Include=&amp;#34;Newtonsoft.Json&amp;#34;&amp;gt;
&amp;lt;HintPath&amp;gt;..\..\packages\Newtonsoft.Json.6.0.4\lib\portable-net45+wp80+win8+wpa81\Newtonsoft.Json.dll&amp;lt;/HintPath&amp;gt;
&amp;lt;/Reference&amp;gt;
&lt;/code>&lt;/pre>&lt;p>becomes:&lt;/p>
&lt;pre tabindex="0">&lt;code>&amp;lt;Reference Include=&amp;#34;Newtonsoft.Json&amp;#34;&amp;gt;
&amp;lt;HintPath&amp;gt;..\..\packages\Newtonsoft.Json.6.0.4\lib\portable-net40+sl4+wp7+win8\Newtonsoft.Json.dll&amp;lt;/HintPath&amp;gt;
&amp;lt;/Reference&amp;gt;
&lt;/code>&lt;/pre>&lt;h3 id="second---weird-crashes-with-storekit">Second - Weird crashes with StoreKit&lt;/h3>
&lt;p>This one had me scratching my head for a while. I was using StoreKit for in app purchasing, and when I was loading the list of available products it would crash. Most of the time. No proper error, no debugger breaking, just a crash with a mono SIGSEGV error. When I debugged it it wouldn&amp;rsquo;t always crash and sometimes it would just work. It was the kind of weird thing that I would normally contribute to a race condition but there wasn&amp;rsquo;t any threading issues that I could see.
In my frustration after a couple of hours I did what I should have done at the start - search StackOverflow. One quick search and I &lt;a href="http://stackoverflow.com/questions/3324596/storekit-skproductsrequest-crash">had my answer&lt;/a>. When making a request, the request has to stay alive long enough for the callbacks. If you declare it as a local variable like I was doing it can be GC&amp;rsquo;d before the callbacks. The non deterministic nature of the GC was why it didn&amp;rsquo;t always happen.&lt;/p>
&lt;p>My code was:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> LoadAvailableProducts(&lt;span style="color:#66d9ef">params&lt;/span> &lt;span style="color:#66d9ef">string&lt;/span>[] productIdentifiers)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">var&lt;/span> productKeys = &lt;span style="color:#66d9ef">new&lt;/span> NSSet(productIdentifiers);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">var&lt;/span> request = &lt;span style="color:#66d9ef">new&lt;/span> SKProductsRequest(productKeys);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> request.RequestFailed += (s, e) =&amp;gt; { &lt;span style="color:#75715e">/* Do something */&lt;/span>};
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> request.ReceivedResponse += (s, e) =&amp;gt; { &lt;span style="color:#75715e">/* Do something */&lt;/span>};
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> request.Start();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Notice the local variable &lt;code>request&lt;/code>? That was my culprit. One change to a field and it all works:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cs" data-lang="cs">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">private&lt;/span> SKProductsRequest _request;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> LoadAvailableProducts(&lt;span style="color:#66d9ef">params&lt;/span> &lt;span style="color:#66d9ef">string&lt;/span>[] productIdentifiers)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">var&lt;/span> productKeys = &lt;span style="color:#66d9ef">new&lt;/span> NSSet(productIdentifiers);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> _request = &lt;span style="color:#66d9ef">new&lt;/span> SKProductsRequest(productKeys);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> _request.RequestFailed += (s, e) =&amp;gt; { &lt;span style="color:#75715e">/* Do something */&lt;/span>};
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> _request.ReceivedResponse += (s, e) =&amp;gt; { &lt;span style="color:#75715e">/* Do something */&lt;/span>};
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> _request.Start();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>NDepend - Part 1</title><link>https://jimbobbennett.dev/blogs/ndepend/</link><pubDate>Fri, 29 Aug 2014 09:43:13 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/ndepend/</guid><description>&lt;p>Patrick from &lt;a href="http://www.NDepend.com">NDepend&lt;/a> reached out to me today to ask me to review NDepend. Having dabbled with it a while ago, I was more than happy to say yes and try out the latest version.&lt;/p>
&lt;p>If you&amp;rsquo;ve never heard of NDepend before, it&amp;rsquo;s a code quality tool. It analyses your code and provides a number of quality metrics such coupling and cyclomatic complexity - check out all the features &lt;a href="http://www.ndepend.com/features/">here&lt;/a>. These are a good way to get an overview of the general quality of your code - it doesn&amp;rsquo;t tell you if your code works but gives a view on how well coded your application is. For example, a high &lt;a href="http://en.wikipedia.org/wiki/Cyclomatic_complexity">cyclomatic complexity&lt;/a> means you have a lot of code paths - this doesn&amp;rsquo;t mean your code is broken but it does mean it will be harder to read and maintain. And as every developer knows, the largest portion of your job is maintaining code, so we want it to be as easy as possible.&lt;/p>
&lt;p>I like having these kind of metrics available, along with measurements like unit test count and coverage. What I look for in these is both the numbers as well as trends. If the complexity is going down, the unit test count is going up and the coverage is staying high or increasing then I know I and my team are working to keep the quality up or improving. Any negative trends mean that things are potentially getting worse so things need to change. These kind of tools are great locally so you can monitor your code before check in, but more important as part of continous integration and delivery - allowing you to monitor the trends across builds and even block check ins or fail builds if metrics move too far in the wrong direction.&lt;/p>
&lt;p>NDepend works as a stand alone tool, a Visual Studio plugin and with a build server. One big downside for me is it doesn&amp;rsquo;t run on the Mac - I&amp;rsquo;m developing iOS apps in .Net using Xamarin so need my build agent running on a Mac. So lets start the review from the beginning - installation.&lt;/p>
&lt;p>The &amp;lsquo;installer&amp;rsquo; is a zip file, so you can just dump it anywhere. This makes it easier in corporate environments with locked down admin. Once unzipped and the license file dropped in, I started with the Visual Studio add-in as my prefered workflow is to do everything from VS before check in. I closed all Visual Studio instances that I had open, ran the add in installed, told it to install into VS 2013. I then launched my first solution - a Xamarin.Forms app and the NDepend menu was there.
I then loaded a second solution to help me test my app - this one is a Node.js solution that I use for my apps back end. As it&amp;rsquo;s loading I get this:&lt;/p>
&lt;p>&lt;img src="Untitled-1.png" alt="">&lt;/p>
&lt;p>Not a good start. I had to close 8 of these then wait a minute before VS became responsive. I closed and tried again - the same. I then closed all instances of VS and tried again - same same. I then tried another Node solution and this worked. Seems it only happens with my main app backend soluton.&lt;/p>
&lt;p>Obviously I can&amp;rsquo;t carry on like this, so I&amp;rsquo;ve sent the details to NDepend support and uninstalled it. NDepend does provide a standalone tool for doing this analysis, but my preferred workflow is to do all my unit testing/coverage checking/static analysis inside Visual Studio before check in.&lt;/p>
&lt;p>&lt;strong>Update&lt;/strong>&lt;/p>
&lt;p>To me a good measure of a person or company is not if they make mistakes but how they deal with them. In the case of NDepend they have been excellent. Their support team have been working with me to help address this issue - including making a good effort to try to reproduce the issue with no success.
My code contains proprietry IP so I couldn&amp;rsquo;t just send it to them, so I&amp;rsquo;ve been trying to reproduce the issue in something I can send.
Turns out, I can&amp;rsquo;t reproduce it either. It only happens with my Node soution run from one folder - if I copy the whole folder somewhere else it works. In the end the fix was simple - delete everything and re-clone from git. Once I did this, everything worked for a while - then VS crashed and the error returned.
It does seem as there are issues with NDepend and Node projects including crashing when right clicking on folders. Luckily the Node tools team are on it and have &lt;a href="https://nodejstools.codeplex.com/workitem/1332">addressed it for a future release&lt;/a>.&lt;/p>
&lt;p>Once I&amp;rsquo;m up and running I&amp;rsquo;ll be putting NDepend through it&amp;rsquo;s paces with &lt;a href="https://github.com/jimbobbennett/JimLib">JimLib&lt;/a> and adding more posts.&lt;/p>
&lt;p>&lt;em>The features described and my opinions are based on my time spent with NDepend. If anything is incorrect please feel free to correct me and I will update this review&lt;/em>&lt;/p></description></item><item><title>Setting the font for an Entry control using Xamarin.Forms</title><link>https://jimbobbennett.dev/blogs/setting-the-font-for-an-entry-control-using-xamarin-forms-2/</link><pubDate>Wed, 27 Aug 2014 05:02:19 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/setting-the-font-for-an-entry-control-using-xamarin-forms-2/</guid><description>&lt;p>&lt;a href="http://xamarin.com/forms">Xamarin.Forms&lt;/a> depsite being very cool is stil a bit lacking when it comes to not only a good range of controls, but also to the abilities of those controls.
One example of this is the Entry control - a simple text box. One thing you can&amp;rsquo;t do with the out of the box implementation is to set the Font. Such a normal thing to do, but not supported.&lt;/p>
&lt;p>Luckily, it&amp;rsquo;s reasonably easy to roll your own controls.
Due to the platform independent nature of Xamarin.Forms, to create a control you have to actually create 2 pieces - a portable control, then platform specific renderers to draw the control on each device. I don&amp;rsquo;t have an android subscription, and can&amp;rsquo;t be bothered with WinPhone at the moment, so will only be showing how to do this for iOS.&lt;/p>
&lt;p>First, we need the control inside a portable project. These can be derived from an existing control - here we derive from Entry as we want to extend its functionality.&lt;/p>
&lt;pre tabindex="0">&lt;code>public class ExtendedEntry : Entry
{
}
&lt;/code>&lt;/pre>&lt;p>Then we add the bindable properties. These are Xamarins version of dependency properties - they have a static field declaring the property then an instance property to get/set the value.&lt;/p>
&lt;pre tabindex="0">&lt;code>public class ExtendedEntry : Entry
{
public static readonly BindableProperty FontProperty =
BindableProperty.Create(&amp;#34;Font&amp;#34;, typeof(Font),
typeof(ExtendedEntry), new Font());
public Font Font
{
get { return (Font)GetValue(FontProperty); }
set { SetValue(FontProperty, value); }
}
}
&lt;/code>&lt;/pre>&lt;p>This is all we need for our control. Next up is the renderer. This wraps platform specific controls to provide the necessary functionality.
In the case of the Entry control on iOS, the UITextField control is wrapped. To set our font we need to pass the value from the control to the UITextField in the renderer.&lt;/p>
&lt;p>First we create our renderer deriving from the existing entry renderer:&lt;/p>
&lt;pre tabindex="0">&lt;code>public class ExtendedEntryRenderer : EntryRenderer
{
}
&lt;/code>&lt;/pre>&lt;p>The we override a few methods - &lt;code>OnElementChanged&lt;/code> to handle the creation of the control and &lt;code>OnElementPropertyChanged&lt;/code> to handle any updates to the properties on the control. In these methods we need to set the font on the UITextView. The Control property of the renderer refers to the underlying UITExtField, the Element property is the ExtendedEntry control.&lt;/p>
&lt;pre tabindex="0">&lt;code>public class ExtendedEntryRenderer : EntryRenderer
{
protected override void OnElementChanged(ElementChangedEventArgs&amp;lt;Entry&amp;gt; e)
{
base.OnElementChanged(e);
var view = (Labs.Controls.ExtendedEntry)Element;
SetFont(view);
}
protected override void OnElementPropertyChanged(object sender, PropertyChangedEventArgs e)
{
base.OnElementPropertyChanged(sender, e);
var view = (Labs.Controls.ExtendedEntry)Element;
if (string.IsNullOrEmpty(e.PropertyName) ||
e.PropertyName == &amp;#34;Font&amp;#34;)
SetFont(view);
}
private void SetFont(Labs.Controls.ExtendedEntry view)
{
UIFont uiFont;
if (view.Font != Font.Default &amp;amp;&amp;amp;
(uiFont = view.Font.ToUIFont()) != null)
Control.Font = uiFont;
else if (view.Font == Font.Default)
Control.Font = UIFont.SystemFontOfSize(17f);
}
}
&lt;/code>&lt;/pre>&lt;p>As you can we, the Xamarin.Forms Font class provides a nice converter to UIFont to make our life easier, and if the font is not supported we resort to a default system font and size. For the property change we just update the font if the property that changes is the font, or if a property change is raised for an empty string - this saves updating when not required and the empty string check is because raising with an empty string as the property name is the way to say all properties have been updated.&lt;/p>
&lt;p>If we keep it like this, then the font is changed, but there is a bug - the height of the control doesn&amp;rsquo;t change to match the height of the font, we make the font larger and the top/bottom of the text is missing. The final step is to set the height. Luckily UITextField will work out the required height based on the font that is set, so we can create a dummy UITextField, set it&amp;rsquo;s font, get the required height and apply it to both our control and the UITextField hosted in it:&lt;/p>
&lt;pre tabindex="0">&lt;code>private void ResizeHeight()
{
if (Element.HeightRequest &amp;gt;= 0) return;
var height = Math.Max(Bounds.Height,
new UITextField
{
Font = Control.Font
}.IntrinsicContentSize.Height);
Control.Frame = new RectangleF(0.0f,
0.0f,
(float) Element.Width,
height);
Element.HeightRequest = height;
}
&lt;/code>&lt;/pre>&lt;p>This method uses the HeightRequest property of the Entry control to request a large/smaller height as necessary. This causes the layout to adjust the size to fit if possible. If the HeightRequest is already set (it is -1 if not set), then we do nothing as the user has already decided on what height is needed. All we need to do is just call this after setting the font and everything now works.&lt;/p>
&lt;p>The full source for EnhancedEntry including other properties is available as part of &lt;a href="https://github.com/jimbobbennett/JimLib.Xamarin">JimLIb.Xamarin&lt;/a>. I&amp;rsquo;ve also raised a PR to add this to &lt;a href="https://github.com/XForms/Xamarin-Forms-Labs">Xamarin.Forms.Labs&lt;/a>.&lt;/p></description></item><item><title>Continuous deployment with JimLib</title><link>https://jimbobbennett.dev/blogs/continuous-deployment-with-jimlib/</link><pubDate>Wed, 27 Aug 2014 03:41:57 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/continuous-deployment-with-jimlib/</guid><description>&lt;p>Today I&amp;rsquo;ve finally moved to the world of continuous deployment - albeit for one of my projects only so far, but it&amp;rsquo;s a start. For my &lt;a href="http://github.com/jimbobbennett/JimLib">JimLib&lt;/a> open source API I&amp;rsquo;ve automated the whole deployment process so after checkin it builds and deploys to NuGet automatically.&lt;/p>
&lt;h3 id="steps-in-the-process">Steps in the process&lt;/h3>
&lt;p>I do all my development in Visual Studio, which now can connect to git. I have this wired up to &lt;a href="http://github.com/jimbobbennett/JimLib">my GitHub repo&lt;/a> so I can commit changes to my local repo and sync back to GitHub.&lt;/p>
&lt;p>Once changes are synced, I use &lt;a href="http://www.appveyor.com">AppVeyor&lt;/a> to do my builds. They provide a free service for public repositories so can automate all open source builds without you spending a penny. I have set this up to:&lt;/p>
&lt;ul>
&lt;li>Pick up pushes to my repo&lt;/li>
&lt;li>Increment a version number and set this in AssemblyInfo.cs&lt;/li>
&lt;li>Build everything&lt;/li>
&lt;li>Run all unit tests&lt;/li>
&lt;li>Package up the NuGet package including symbols&lt;/li>
&lt;li>Push the NuGet packages to &lt;a href="https://www.nuget.org/packages/JimBobBennett.JimLib/">NuGet.org&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>AppVeyor even provides markdown for a build status:&lt;/p>
&lt;p>&lt;a href="https://ci.appveyor.com/project/jimbobbennett/jimlib">&lt;img src="https://ci.appveyor.com/api/projects/status/pxisjdt5qxf05utr" alt="Build status">&lt;/a>&lt;/p>
&lt;h3 id="how-can-i-be-sure-im-deploying-the-right-thing">How can I be sure I&amp;rsquo;m deploying the right thing?&lt;/h3>
&lt;p>This is where unit tests come in. I try to get as much coverage as possible (91% at the moment), and use this to provide a level of certainty that any new changes work (assuming my tests are good) and that I haven&amp;rsquo;t broken anything with any new changes. The build process runs the tests and won&amp;rsquo;t push the package unless all tests pass.&lt;/p>
&lt;h3 id="downsides-to-appveyor">Downsides to AppVeyor&lt;/h3>
&lt;p>AppVeyor is very good, I&amp;rsquo;m really impressed with what they offer for free. It&amp;rsquo;s not fast to get a build, sometimes you can be waiting for up to an hour but for free thsi is fine. The only downside so far is NuGet package restore. They always provide a clean environment to build on and even with package restore turned on you have to build twice with they don&amp;rsquo;t do. It means you have to check your packages into git. Not the end of the world, but a bit annoying.&lt;/p></description></item><item><title>Securing a Heroku site with SSL</title><link>https://jimbobbennett.dev/blogs/securing-a-heroku-site-with-ssl/</link><pubDate>Sat, 16 Aug 2014 10:12:53 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/securing-a-heroku-site-with-ssl/</guid><description>&lt;p>For my mobile app development work, I&amp;rsquo;ve been building a Node.js website with a REST api that my apps can use. It&amp;rsquo;s hosted at &lt;a href="https://www.moomoo.io">MooMoo.io&lt;/a> and is running using a free &lt;a href="https://www.heroku.com/">Heroku&lt;/a> account - I don&amp;rsquo;t have anything useful on my site or many users of my API at the moment, so their free single dyno is perfect for my needs. I&amp;rsquo;m also taking advantage of the free sandbox MongoDB account from &lt;a href="http://mongolab.com/">MongoLab&lt;/a>. It&amp;rsquo;s pretty cool just how much I can get for free, and I only need to pay if my apps take off and I start making money.&lt;/p>
&lt;p>One thing I did have to pay for though is SSL. For my API I don&amp;rsquo;t want unencrypted connections, so the easiest thing to do is to access it only over HTTPS. It took me a while to get it all set up, so I thought it would be usefull to document the steps in case anyone else is doing the same thing.&lt;/p>
&lt;p>First, you need an SSL certificate. My domains are currently with &lt;a href="http://DNSimple.com">DNSimple&lt;/a>, a great company that tries to be simple and honest and not full of the crap that &lt;a href="http://www.godaddy.com">other sites&lt;/a> have. Assuming you have a DNSimple account holding your domains (and if not, transfer them already!), it&amp;rsquo;s simple to get a certificate from RapidSSL with one click and $20. All it takes is an approver with an email address that matches your URL (google apps provides 30 days free trial if you don&amp;rsquo;t have email set up) and you get the certificate.
Once you have the certificate, you can view it and the private key on DNSimple - and copy them into 2 files, server.crt for the certificate and server.key for the private key.
For RapidSSL you do need an additional certificate downloaded from their site, but this is easy to get with curl:&lt;/p>
&lt;pre tabindex="0">&lt;code>curl https://knowledge.rapidssl.com/library/VERISIGN/INTERNATIONAL_AFFILIATES/RapidSSL/AR1548/RapidSSLCABundle.txt &amp;gt; bundle.pem
&lt;/code>&lt;/pre>&lt;p>Next, upload the keys to Heroku. You need to enable the &lt;a href="http://addons.heroku.com/ssl">SSL Endpoint add-on&lt;/a> - &lt;strong>This is not free&lt;/strong> - it&amp;rsquo;s $20 a month so it&amp;rsquo;s not cheap.
To upload, use the Heroku toolbelt:&lt;/p>
&lt;pre tabindex="0">&lt;code>heroku certs:add server.crt bundle.pem server.key --app &amp;lt;your app name&amp;gt;
&lt;/code>&lt;/pre>&lt;p>This will then change the url to your app, so you&amp;rsquo;ll need to update the CNAME record for your custom domain if you are using one to point to the new url. The output of the &lt;code>certs:add&lt;/code> command will show the new url:&lt;/p>
&lt;pre tabindex="0">&lt;code>Resolving trust chain... done
Adding SSL Endpoint to &amp;lt;your app name&amp;gt;... done
&amp;lt;your app name&amp;gt; now served by &amp;lt;something&amp;gt;.herokussl.com
Certificate details:
...
&lt;/code>&lt;/pre>&lt;p>Heroku implements HTTPS in an interesting way - the connection to Heroku is encrypted and converted to a raw HTTP request that is forwarded to your app. This means that your app doesn&amp;rsquo;t need to handle HTTPS, just HTTP which makes it easier to develop. The downside is Heroku has access to the unencrypted data, but with any cloud provider there has to be trust.&lt;/p>
&lt;p>The last step if you want to do it is to redirect from HTTP to HTTPS. Normally you could use &lt;code>req.secure&lt;/code> in Node to identify secure requests, but this doesn&amp;rsquo;t work with Heroku as all requests to your app are unencrypted HTTP. Luckily, Heroku adds some custom headers to the request that allows you to identify if the original url was HTTP or HTTPS. &lt;code>x-forwarded-proto&lt;/code> is used to indicate the protocol that was used for the request that was forwarded to your app. If this is set to &lt;code>https&lt;/code>, you know the request was from HTTPS. If not, you can redirect:&lt;/p>
&lt;pre tabindex="0">&lt;code>if (env != &amp;#39;development&amp;#39;) // only redirect in prod
{
app.use(function(req, res, next)
{
if (req.headers[&amp;#39;x-forwarded-proto&amp;#39;] != &amp;#39;https&amp;#39;)
res.redirect([&amp;#39;https://&amp;#39;, req.get(&amp;#39;Host&amp;#39;), req.url].join(&amp;#39;&amp;#39;));
else
next();
});
}
&lt;/code>&lt;/pre>&lt;p>To see this in action, head to &lt;a href="http://www.moomoo.io">http://www.moomoo.io&lt;/a>, and you&amp;rsquo;ll be redirected to &lt;a href="https://www.moomoo.io">https://www.moomoo.io&lt;/a>.&lt;/p></description></item><item><title>JimLib.Xamarin now available</title><link>https://jimbobbennett.dev/blogs/jimlib-xamarin-now-available/</link><pubDate>Fri, 15 Aug 2014 07:30:06 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/jimlib-xamarin-now-available/</guid><description>&lt;p>My second NuGet package is now available: &lt;a href="https://www.nuget.org/packages/JimBobBennett.JimLib.Xamarin/">JimLib.Xamarin&lt;/a>. This contains a selection of helpers to make developing iOS apps with Xamarin easier (WinPhone/Android will come later when I have an Android license/Android device/Windows Phone device to test on).&lt;/p>
&lt;p>It&amp;rsquo;s all open source - code is on &lt;a href="https://github.com/jimbobbennett/JimLib.Xamarin">GitHub&lt;/a>, symbols are also available (as talked about &lt;a href="https://jimbobbennett.dev/blogs/symbols-for-nuget-packages/">here&lt;/a>).&lt;/p>
&lt;p>Grab it and give it a spin. Contributions/criticism/pull requests/money/beer always welcome.&lt;/p></description></item><item><title>Grouping in ListViews with Xamarin.Forms</title><link>https://jimbobbennett.dev/blogs/grouping-in-listviews-with-xamarin-forms/</link><pubDate>Fri, 15 Aug 2014 03:38:39 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/grouping-in-listviews-with-xamarin-forms/</guid><description>&lt;p>Xamarin.Forms provides a lot of cool features to use for mobile app development, and the documentation is pretty good - but sometimes the cool features you want to use are a bit lacking in docs. There are example projects but it can be hard to interpret what you need to do to get something working.&lt;/p>
&lt;p>The latest area that was confusing me was grouping in &lt;a href="http://iosapi.xamarin.com/?link=T%3aXamarin.Forms.ListView">ListView&lt;/a>. There are properties for specifiying the grouping, but no details on the correct way to use it. After a bit of trial an error, I managed to work out the following:&lt;/p>
&lt;ul>
&lt;li>Your &lt;code>ItemsSource&lt;/code> should be a collection of something derived from a collection - each of the inner collection objects is a group (e.g. for people grouped by first initial you would have a maximum of 26 items in your outer collection - each item being a collection of people with the same first initial).&lt;/li>
&lt;li>The &lt;code>GroupDisplayBinding&lt;/code> property should be set to a property on the inner collection objects - so rather that have a collection of collections, you need a collection of something derived from collection that adds a property to provide the group name.&lt;/li>
&lt;li>If you want fast scrolling you need to provide the &lt;code>GroupShortNameBinding&lt;/code> property to bind to the short name (e.g. first letter of a name).&lt;/li>
&lt;li>If you want more magic in the group header, set the &lt;code>GroupHeaderTemplate&lt;/code> instead of the &lt;code>GroupDisplayBinding&lt;/code> to have a custom header (setting &lt;code>GroupDisplayBinding&lt;/code> clears &lt;code>GroupHeaderTemplate&lt;/code>, so you can only set one or the other).&lt;/li>
&lt;/ul>
&lt;p>Here&amp;rsquo;s an example of the kind of classes you can use for the &lt;code>ItemsSource&lt;/code> property:&lt;/p>
&lt;pre tabindex="0">&lt;code>public class InnerCollection : List&amp;lt;string&amp;gt;
{
public string Title { get; set; }
}
public class ItemsSourceCollection : List&amp;lt;InnerCollection&amp;gt;
{
}
&lt;/code>&lt;/pre>&lt;p>Then use this like so:&lt;/p>
&lt;pre tabindex="0">&lt;code>public class MyPage : ContentPage
{
public MyPage()
{
var listView = new ListView();
var items = new ItemsSourceCollection();
listView.ItemsSource = items;
// bind the grouping to the title of the inner collection
listView.GroupDisplayBinding = new Binding(&amp;#34;Title&amp;#34;);
}
}
&lt;/code>&lt;/pre>&lt;p>Rather than create this structure each time, &lt;a href="https://www.nuget.org/packages/JimBobBennett.JimLib/">JimLib&lt;/a> contains a handy &lt;code>ListItemCollection&amp;lt;T&amp;gt;&lt;/code> class to provide all this functionality and more.&lt;/p></description></item><item><title>Symbols for NuGet packages</title><link>https://jimbobbennett.dev/blogs/symbols-for-nuget-packages/</link><pubDate>Fri, 15 Aug 2014 03:11:18 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/symbols-for-nuget-packages/</guid><description>&lt;p>Since releaseing &lt;a href="https://github.com/jimbobbennett/JimLib">JimLib&lt;/a> onto &lt;a href="https://www.nuget.org/packages/JimBobBennett.JimLib/">NuGet&lt;/a>, I&amp;rsquo;ve been dogfooding it as much as possible for my own development. One area I noticed was lacking was in symbol support - if I wanted to view the inner workings of my classes I had to decompile the source using ReSharper. Not an ideal situation.&lt;/p>
&lt;p>Luckily there is a better way. &lt;a href="http://www.symbolsource.org/">SymbolSource&lt;/a> is a free service that hosts symbol and source packages for a huge array of NuGet packages and it&amp;rsquo;s integrated into Visual Studio - if a symbol package is available there then with one click you can navigate the source and even step through the code in the debugger. And if that&amp;rsquo;s not great enough as it is, you can easily create and upload symbol packages right from NuGet with minimal changes. The docs are &lt;a href="http://docs.nuget.org/docs/creating-packages/creating-and-publishing-a-symbol-package">here&lt;/a> but basically you add the pdb files and source to your .nuspec, then let NuGet do the magic for you - it will create 2 .nupack files when you pack with the &lt;code>-symbols&lt;/code> flag, one without symbols with the normal name, and one with with an extension of &lt;code>.symbols.nupkg&lt;/code>. When publishing there is nothing extra to do - if the &lt;code>.symbols.nupkg&lt;/code> package is found it will be uploaded to the SymbolSource server at the same time as the main package is uploaded to NuGet.&lt;/p>
&lt;p>Check it out - grab the latest &lt;a href="https://www.nuget.org/packages/JimBobBennett.JimLib/">JimLib NuGet package&lt;/a>, use it in your app and step into the code.&lt;/p></description></item><item><title>Images for an iOS app</title><link>https://jimbobbennett.dev/blogs/images-for-an-ios-app/</link><pubDate>Thu, 14 Aug 2014 02:18:56 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/images-for-an-ios-app/</guid><description>&lt;p>When developing for iOS there are a number of different image sizes needed. Just for the springboard icon you need different sizes for iPhones and iPads, both retina and normal versions. When you add spotlight icons (again both retina and normal), iTunes icons the list gets huge.&lt;/p>
&lt;p>To help with this and to practice my Node.js skills, I created a node app that does it for you. It&amp;rsquo;s based on the default express app, you give it an image file and it downlods you a zip file containing all the possible image sizes you could want all named correctly.
The code uses Express 3. I know express 4 is out, but 4 doesn&amp;rsquo;t support file uploads using body-parser. When I work out how to do it, I&amp;rsquo;ll update the code.&lt;/p>
&lt;p>This is built using the &lt;a href="https://nodejstools.codeplex.com">Node.js tools for Visual Studio&lt;/a> but the code will run with any node install. You will need &lt;a href="http://www.imagemagick.org">ImageMagick&lt;/a> installed to make it work.&lt;/p>
&lt;p>&lt;a href="https://github.com/jimbobbennett/ImageResizer">Clone it from my GitHub&lt;/a>&lt;/p></description></item><item><title>Todays tea</title><link>https://jimbobbennett.dev/blogs/todays-tea/</link><pubDate>Thu, 14 Aug 2014 02:11:16 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/todays-tea/</guid><description>&lt;p>Todays bubble tea is banana milk tea with bubbles. Quite nice, but a bit too sweet and the banana taste is a bit artificial.&lt;/p>
&lt;p>&lt;img src="bubbletea-2.jpg" alt="Banana milk tea">&lt;/p>
&lt;p>I also snapped a quick photo of my lunch yesterday being cooked fresh for me. One of the great things about thai street food is a lot of it is cooked in front of you so you know whats in it and that it&amp;rsquo;s really, really fresh.&lt;/p>
&lt;p>&lt;img src="dinner.jpg" alt="Spicy chicken">&lt;/p></description></item><item><title>Bubbles, bubbles, bubbles. My bubbles!</title><link>https://jimbobbennett.dev/blogs/bubbles-bubbles-bubbles-my-bubbles/</link><pubDate>Mon, 11 Aug 2014 02:25:02 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/bubbles-bubbles-bubbles-my-bubbles/</guid><description>&lt;p>More bubble tea today. Coffee milk tea with bubbles. Tastes of sweet coffee with an aftertaste of tea - weird but not unpleasant. Nice chewy bubbles.&lt;/p>
&lt;p>&lt;img src="bubbletea-1.jpg" alt="Coffee milk tea with bubbles">&lt;/p></description></item><item><title>My first NuGet package</title><link>https://jimbobbennett.dev/blogs/my-first-nuget-package/</link><pubDate>Sun, 10 Aug 2014 03:34:31 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/my-first-nuget-package/</guid><description>&lt;p>For pretty much every project I&amp;rsquo;ve worked on I&amp;rsquo;ve used the same set of extensions and helper classes to make my life easier. For example:&lt;/p>
&lt;ul>
&lt;li>Fluent API on strings &lt;code>myString.IsNullOrEmpty()&lt;/code> instead of &lt;code>string.IsNullOrEmpty(myString)&lt;/code>.&lt;/li>
&lt;li>An &lt;code>ObservableCollectionEx&amp;lt;T&amp;gt;&lt;/code> class that allows adding multiple items but only raising on &lt;code>CollectionChanged&lt;/code> event.&lt;/li>
&lt;/ul>
&lt;p>For my latest project, I&amp;rsquo;ve found myself creating these all over again. Seeing as I&amp;rsquo;m using this for an open source API, I thought it might be time to wrap these up into another open source library and make it available on NuGet. Therefore I present JimLib to the world.&lt;/p>
&lt;p>The source is on &lt;a href="https://github.com/jimbobbennett/JimLib">GitHub&lt;/a> with the API described on the &lt;a href="https://github.com/jimbobbennett/JimLib/wiki">Wiki&lt;/a>.&lt;/p>
&lt;p>The package is available from &lt;a href="http://www.nuget.org/packages/JimBobBennett.JimLib/">NuGet&lt;/a>.&lt;/p>
&lt;p>Install using &lt;code>Install-Package JimBobBennett.JimLib&lt;/code>.&lt;/p>
&lt;p>Submissions and feedback are welcome. I&amp;rsquo;ll be expanding this library as I go along.&lt;/p></description></item><item><title>Bubble Tea</title><link>https://jimbobbennett.dev/blogs/bubble-tea/</link><pubDate>Sun, 10 Aug 2014 02:20:45 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/bubble-tea/</guid><description>&lt;p>After a post on FaceBook about enjoying some Bubble Tea, a friend of mine suggested that I should blog about it.&lt;br>
Seeing as I am currently in Thailand, home of the best food in the world, I guess it makes sense to extend this to all food. Most of my meals are incredible food cooked fresh and purchased from markets for usually 40p-80p a dish - so why not share them with the world.&lt;/p>
&lt;p>I&amp;rsquo;ll start today with bubble tea - read about it on &lt;a href="http://en.wikipedia.org/wiki/Bubble_tea">Wikipedia&lt;/a> if you&amp;rsquo;ve never heard of it. Essentially it&amp;rsquo;s a Taiwanese drink made of milky tea with tapioca pearls in the bottom, but there are many variants made with green tea, fruit teas, juices and jellies instead of bubbles.&lt;/p>
&lt;p>This morning I stopped at the Bubble Boy (a chain of Bubble Tea stands) at the &lt;a href="https://goo.gl/maps/rZQtC">Ekkami BTS station&lt;/a>.&lt;/p>
&lt;p>&lt;img src="bubbletea--2-.jpg" alt="Bubble boy stand at Ekami">&lt;/p>
&lt;p>I grabbed a Chocolate milk tea with chocolate pudding at the bargain price of 45 baht (83p/$1.40). It&amp;rsquo;s really, really nice - you can&amp;rsquo;t taste the tea that much, just a milky chocolate drink with undertones of bitter dark chocolate. The chocolate pudding is dark chocolate flavour pearls that are nice and chewy without a too intense taste. Definitely one I&amp;rsquo;ll have again.&lt;/p>
&lt;p>&lt;img src="bubbletea--1--1.jpg" alt="Chocolate milk tea with chocolate pudding">&lt;/p></description></item><item><title>Creating a NuGet PCL that works with Xamarin.ios</title><link>https://jimbobbennett.dev/blogs/creating-a-nuget-pcl-that-works-with-xamarin-ios/</link><pubDate>Thu, 07 Aug 2014 06:33:27 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/creating-a-nuget-pcl-that-works-with-xamarin-ios/</guid><description>&lt;p>I&amp;rsquo;ve been playing with Xamarin.Forms recently to develop an iOS app. The aim is to use my &lt;a href="https://github.com/jimbobbennett/ComPlexion">portable open source Plex API&lt;/a> in the app (more details of the app will come later once it&amp;rsquo;s ready to release).&lt;/p>
&lt;p>The basic concept of &lt;a href="http://xamarin.com/forms">Xamarin.Forms&lt;/a> is to have a core portable class library containing all the application code, and very thin platform specific libraries that wrap the core code in an application that targets the relevant platform.&lt;/p>
&lt;p>In principle - all very easy. The problem comes when you want to use other libraries with it. These libraries must be portable class libraries - PCLs. Again in principle, very easy. But the devil is in the details&amp;hellip;&lt;/p>
&lt;p>The main stumbling block I hit was HttpClient. The Microsoft PCL I use to access the Plex REST API. In principle this is a PCL so should work on all platforms. But it doesn&amp;rsquo;t.
The issue is actually with Xamarin.ios. This doesn&amp;rsquo;t support the Microsoft HTTP client, instead it uses the Mono version. This means my Plex API has to target both the MS and Mono versions - which is a problem as the namespaces are the same, and my iOS app project can&amp;rsquo;t have a dependency to the MS version, and the Windows Phone project can&amp;rsquo;t have a dependency to the Mono version.&lt;/p>
&lt;p>My solution was to do the following:&lt;/p>
&lt;ul>
&lt;li>Change my code library code to not access the HTTPClient directly, but have an interface to a wrapper class.&lt;/li>
&lt;li>Create a Xamarin.ios class library project that has an implementation of the interface using the Mono HTTPClient library.&lt;/li>
&lt;li>Create a Windows PCL project (Windows 8, Windows Phone and Windows Phone Silverlight) that links to the source of the iOS implementation (the namespaces are the same so the source can be shared) that references the MS PCL HTTPClient NuGet package.&lt;/li>
&lt;/ul>
&lt;p>This will spit out 3 dlls - one PCL for the core with no HTTP access, an iOS class library using the Mono HTTPClient and a Windows PCL that uses the MS HTTPClient.&lt;/p>
&lt;p>Next challenge was to get this into a NuGet package. The more recent versions of NuGet have full PCL support which makes the whole thing easier.
To install the dlls into the correct targets I just had to ensure the target of the files was set to the correct location:&lt;/p>
&lt;pre tabindex="0">&lt;code>&amp;lt;files&amp;gt;
&amp;lt;!-- portable --&amp;gt;
&amp;lt;file src=&amp;#34;..\Complexion.Portable\bin\$Configuration$\Complexion.Portable.dll&amp;#34; target=&amp;#34;lib\portable-net45+win+wp80+MonoAndroid10+MonoTouch10\Complexion.Portable.dll&amp;#34; /&amp;gt;
&amp;lt;!-- ios --&amp;gt;
&amp;lt;file src=&amp;#34;..\Complexion.Portable\bin\$Configuration$\Complexion.Portable.dll&amp;#34; target=&amp;#34;lib\MonoTouch10\Complexion.Portable.dll&amp;#34; /&amp;gt;
&amp;lt;file src=&amp;#34;..\Complexion.ios\bin\iPhone\$Configuration$\Complexion.ios.dll&amp;#34; target=&amp;#34;lib\MonoTouch10\Complexion.ios.dll&amp;#34; /&amp;gt;
&amp;lt;!-- Win --&amp;gt;
&amp;lt;file src=&amp;#34;..\Complexion.Portable\bin\$Configuration$\Complexion.Portable.dll&amp;#34; target=&amp;#34;lib\portable-net45+win+wp80\Complexion.Portable.dll&amp;#34; /&amp;gt;
&amp;lt;file src=&amp;#34;..\Complexion.Win\bin\$Configuration$\Complexion.Win.dll&amp;#34; target=&amp;#34;lib\portable-net45+win+wp80\Complexion.Win.dll&amp;#34; /&amp;gt;
&amp;lt;/files&amp;gt;
&lt;/code>&lt;/pre>&lt;p>The core portable library is output to a fully portable target, as well as to individual targets for iOS and Windows. The individual platform specifi dlls are then output to specific targets. Using this setup, if I install this package to a portable project, just Complexion.Portable is installed. If it&amp;rsquo;s for iOS (MonoTouch) then Complexion.Portable and Complexion.ios is installed. Similarly for Windows 8/Windows Phone Complexion.Portable and Complexion.Win gets installed.&lt;/p>
&lt;p>The final addition was dependencies. For the portable dll there are no other dependencies. For ios there are also no additional dependencies as the Mono HTTPClient is available in the default Xamarin.iOS references. Windows is different though - it needs the Microsoft HTTPClient NuGet package installed.
Thankfully &lt;a href="http://docs.nuget.org/docs/reference/nuspec-reference#Specifying_Dependencies_in_version_2.0_and_above">NuGet now supports dependencies by different targets&lt;/a>. Groups can be defined with a target attribute and these are only installed into projects that match the target. This means I can add groups for the different windows targets that have the Microsoft HTTPClient dependency, and nothing will be installed for other platforms.&lt;/p>
&lt;pre tabindex="0">&lt;code>&amp;lt;dependencies&amp;gt;
&amp;lt;group targetFramework=&amp;#34;net45&amp;#34;&amp;gt;
&amp;lt;dependency id=&amp;#34;Microsoft.Bcl&amp;#34; version=&amp;#34;1.1.9&amp;#34; /&amp;gt;
&amp;lt;dependency id=&amp;#34;Microsoft.Bcl.Build&amp;#34; version=&amp;#34;1.0.14&amp;#34; /&amp;gt;
&amp;lt;dependency id=&amp;#34;Microsoft.Net.Http&amp;#34; version=&amp;#34;2.2.22&amp;#34; /&amp;gt;
&amp;lt;/group&amp;gt;
&amp;lt;group targetFramework=&amp;#34;win&amp;#34;&amp;gt;
&amp;lt;dependency id=&amp;#34;Microsoft.Bcl&amp;#34; version=&amp;#34;1.1.9&amp;#34; /&amp;gt;
&amp;lt;dependency id=&amp;#34;Microsoft.Bcl.Build&amp;#34; version=&amp;#34;1.0.14&amp;#34; /&amp;gt;
&amp;lt;dependency id=&amp;#34;Microsoft.Net.Http&amp;#34; version=&amp;#34;2.2.22&amp;#34; /&amp;gt;
&amp;lt;/group&amp;gt;
&amp;lt;group targetFramework=&amp;#34;wp80&amp;#34;&amp;gt;
&amp;lt;dependency id=&amp;#34;Microsoft.Bcl&amp;#34; version=&amp;#34;1.1.9&amp;#34; /&amp;gt;
&amp;lt;dependency id=&amp;#34;Microsoft.Bcl.Build&amp;#34; version=&amp;#34;1.0.14&amp;#34; /&amp;gt;
&amp;lt;dependency id=&amp;#34;Microsoft.Net.Http&amp;#34; version=&amp;#34;2.2.22&amp;#34; /&amp;gt;
&amp;lt;/group&amp;gt;
&amp;lt;/dependencies&amp;gt;
&lt;/code>&lt;/pre>&lt;p>Check out &lt;a href="https://github.com/jimbobbennett/ComPlexion">my GitHub project&lt;/a> for the full API code nuspec file.&lt;/p></description></item><item><title>Complexion - an open source API for Plex</title><link>https://jimbobbennett.dev/blogs/complexion-an-open-source-api-for-plex/</link><pubDate>Mon, 04 Aug 2014 02:46:47 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/complexion-an-open-source-api-for-plex/</guid><description>&lt;p>I&amp;rsquo;ve just released the first alpha version of &lt;a href="https://github.com/jimbobbennett/ComPlexion">Complexion&lt;/a>, available on my &lt;a href="https://github.com/jimbobbennett/ComPlexion">GitHub page&lt;/a>. This is my first true open source API, which I hope to put up on NuGet in the near future.&lt;/p>
&lt;p>This is a portable .Net API that connects to &lt;a href="http://plex.tv">Plex&lt;/a> - either to a local Plex Media Server specified by it&amp;rsquo;s IP or hostname, or via MyPlex to discover your media servers. This does require a &lt;a href="https://plex.tv/subscription/about">PlexPass&lt;/a> subscription.&lt;/p>
&lt;p>To use the API via MyPlex, create an instance of the MyPlexConnection and connect using your MyPlex username and password to get all supported devices and servers that use your MyPlex account.&lt;/p>
&lt;pre tabindex="0">&lt;code>var myPlexConnection = new MyPlexConnection();
await plex.ConnectAsync(&amp;lt;userName&amp;gt;, &amp;lt;password&amp;gt;);
&lt;/code>&lt;/pre>&lt;p>From each device, you can connect to a Server using the Server class. You can also connect using a local URI if you don&amp;rsquo;t want to connect to MyPlex.&lt;/p>
&lt;pre tabindex="0">&lt;code>var myPlexServer = myPlexConnection.Servers.First();
var server = new Server(myPlexServer, &amp;lt;userName&amp;gt;, &amp;lt;password&amp;gt;);
await server.ConnectAsync();
&lt;/code>&lt;/pre>&lt;p>or&lt;/p>
&lt;pre tabindex="0">&lt;code>var server = new Server(&amp;#34;192.168.1.1&amp;#34;); // IP address of local server
await server.ConnectAsync();
&lt;/code>&lt;/pre>&lt;p>From here you can get a list of videos now playing on each client:&lt;/p>
&lt;pre tabindex="0">&lt;code>var videos = await server.GetNowPlayingAsync();
foreach (var video in videos)
Console.WriteLine(video.title + &amp;#34; on &amp;#34; video.Player.title);
&lt;/code>&lt;/pre>&lt;p>This is still a very early alpha - I haven&amp;rsquo;t even checked in the unit tests yet, so the API will very likely change and may not even work (I haven&amp;rsquo;t been able to test it using a remote connection as my current network setup doesn&amp;rsquo;t allow my to open the port). Please try it out and send me feedback or pull requests.&lt;/p>
&lt;p>I will be dogfooding this API - I&amp;rsquo;m working on an app that uses it for &lt;a href="http://MooMoo.io">Moo Moo&lt;/a>&lt;/p></description></item><item><title>Why can't all laptops use the same charger?</title><link>https://jimbobbennett.dev/blogs/why-cant-all-laptops-use-the-same-charger/</link><pubDate>Fri, 01 Aug 2014 06:29:53 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/why-cant-all-laptops-use-the-same-charger/</guid><description>&lt;p>As the title really, why can&amp;rsquo;t all laptops use the same charger - including laptops from the same company.&lt;/p>
&lt;p>I&amp;rsquo;ve trvelled 45 minutes to the co-working space I&amp;rsquo;m working at only to find I&amp;rsquo;ve forgotten my MacBook Pro charger, and it&amp;rsquo;s only got 10% left. I have my Surface and the charger for that, but of course it&amp;rsquo;s not the same. I can&amp;rsquo;t even borrow one as the only free chargers here are for MacBook Airs - different plug. This means I&amp;rsquo;ll be heading back home soon.&lt;/p>
&lt;p>Why can&amp;rsquo;t they all just use the same charger - like with phones where the EU has pushed for all phones to use mini-usb to charge. If we could have a USB spec that provides enough voltage for the laptop to charge then have them all using USB chargers then life would be so much easier.&lt;/p></description></item><item><title>Portable class libraries</title><link>https://jimbobbennett.dev/blogs/portable-class-libraries/</link><pubDate>Wed, 30 Jul 2014 07:16:02 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/portable-class-libraries/</guid><description>&lt;p>Portable class libraries (or PCLs) are the flavour of the month at the moment. They are a .net library designed to be cross platform - so they work just as well on Windows 8 as they do on Xamarin. Where Microsoft are supporting Xamarin as much as possible, they are releasing a number of their core libraries as PCL.&lt;/p>
&lt;p>Unfortunately, where they are only recently a big thing, NuGet package support is limited. I&amp;rsquo;m writing a client library for the &lt;a href="http://plex.tv">Plex&lt;/a> media server which I want to use from a Xamarin app (and will put up &lt;a href="https://github.com/jimbobbennett/ComPlexion">here on GitHub&lt;/a> once it&amp;rsquo;s ready) and this makes hits the Plex REST API for it&amp;rsquo;s communication. Luckily, REST is easy on .Net thanks to RestSharp, an awesome NuGet package that simplifies creating REST clients.&lt;/p>
&lt;p>Problem is, it&amp;rsquo;s not PCL. There is a PortableREST package but this doesn&amp;rsquo;t have authentication which I need. In the end, I decided to roll my own using Microsofts PCL &lt;a href="http://msdn.microsoft.com/en-us/library/system.net.http.httpclient%28v=vs.110%29.aspx">HttpClient&lt;/a>.&lt;/p>
&lt;p>Another downside is the support for different platforms. Creating a PCL requires selecting which platforms will be supported, and not all of them have all the classes you may want to use. For example, I&amp;rsquo;m using ObservableCollection, which is not supported in Silverlight 5, so my PCL doesn&amp;rsquo;t support that platform. Annoyingly, when you change the supported platform, you have to re-install any NuGet packages that target multiple platforms to get the version that targets the platforms you&amp;rsquo;ve selected. Seems a bit of a faff really.&lt;/p>
&lt;p>Going forward, I plan to make all my libraries PCL. Hopefully more and more people will also do this. And hopefully, the process will get easier.&lt;/p></description></item><item><title>Favicons</title><link>https://jimbobbennett.dev/blogs/favicons-2/</link><pubDate>Tue, 29 Jul 2014 04:21:04 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/favicons-2/</guid><description>&lt;p>After &lt;a href="https://jimbobbennett.dev/blogs/socialnetworkingandhowtheworldseesme/">changing my avatars&lt;/a>, I decided to update my Ghost blog to show my new avatar as the icon in the browser/bookmarks and springboard icon on iPhones/iPads.&lt;/p>
&lt;p>Coming at this with limited HTML/Web experience I had no idea where to start, so thought I&amp;rsquo;d write this as a guid to help anyone else wanting to do the same thing.&lt;/p>
&lt;p>What you need is called a Favicon. By default the web browser picks up a file called favicon.ico from the web site root, but it can be changed by using the link tag.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-html" data-lang="html">&lt;span style="display:flex;">&lt;span>&amp;lt;&lt;span style="color:#f92672">link&lt;/span> &lt;span style="color:#a6e22e">rel&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;icon&amp;#34;&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">...&lt;/span> /&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Wikipedia has a good article on it &lt;a href="http://en.wikipedia.org/wiki/Favicon">here&lt;/a>. Any normal image type can be used assuming you want it to work in the proper browsers (Chrome/Firefox/Safari/Opera), but for IE prior to version 11 you have to use an .ico file. Converting to ico&amp;rsquo;s is easy - there are plenty of sites that will do it for free. I used &lt;a href="http://www.icoconverter.com/">IconConverter&lt;/a> for mine.&lt;/p>
&lt;p>This works great for browsers, but Apple has the ability to use icons when adding a shortcut to your site to the springboard. It supports multiple sizes to match the resolutions of different devices (so watch out when a new device comes out with a different resolution, make sure to update the icons). The details of this are &lt;a href="https://developer.apple.com/library/mac/documentation/AppleApplications/Reference/SafariWebContent/ConfiguringWebApplications/ConfiguringWebApplications.html">here&lt;/a>, but it essentially boils down to one link per icon size:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-html" data-lang="html">&lt;span style="display:flex;">&lt;span>&amp;lt;&lt;span style="color:#f92672">link&lt;/span> &lt;span style="color:#a6e22e">rel&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;apple-touch-icon&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">href&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;touch-icon-iphone.png&amp;#34;&lt;/span>/&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&amp;lt;&lt;span style="color:#f92672">link&lt;/span> &lt;span style="color:#a6e22e">rel&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;apple-touch-icon&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">sizes&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;76x76&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">href&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;touch-icon-ipad.png&amp;#34;&lt;/span>/&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&amp;lt;&lt;span style="color:#f92672">link&lt;/span> &lt;span style="color:#a6e22e">rel&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;apple-touch-icon&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">sizes&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;120x120&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">href&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;touch-icon-iphone-retina.png&amp;#34;&lt;/span>/&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&amp;lt;&lt;span style="color:#f92672">link&lt;/span> &lt;span style="color:#a6e22e">rel&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;apple-touch-icon&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">sizes&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;152x152&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">href&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;touch-icon-ipad-retina.png&amp;#34;&lt;/span>/&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The names in the hrefs are to indicate which device uses which icons, but you can use your own names of course. The icons get the normal Apple reflective shine etc added to them - but this can be stopped by adding &lt;strong>-precomposed&lt;/strong> to the the rel attribute:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-html" data-lang="html">&lt;span style="display:flex;">&lt;span>&amp;lt;&lt;span style="color:#f92672">link&lt;/span> &lt;span style="color:#a6e22e">rel&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;apple-touch-icon-precomposed&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">href&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;touch-icon-iphone.png&amp;#34;&lt;/span> /&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The icon sizes must match the required size for the device. These sizes are:&lt;/p>
&lt;ul>
&lt;li>iPhone - 60x60 (note iOS6 was 57x57, iOS7 is 60x60)&lt;/li>
&lt;li>iPad - 76x76&lt;/li>
&lt;li>Retina iPhone (iPhone 4 and later) - 120x120&lt;/li>
&lt;li>Retina iPad (third generation and later) - 152x152&lt;/li>
&lt;/ul>
&lt;p>Note that the original iPhone size was changed in iOS7 - so whenever a new iOS version comes out it&amp;rsquo;s worth checking if there are any size changes.&lt;/p>
&lt;p>To get these working on my Ghost blog, I edited the theme. I am using a modified version of &lt;a href="https://github.com/axiantheme/ghostion">Ghostion&lt;/a> which I will be tidying up and making available publicly when I get a moment. One note about Ghost - it provides it&amp;rsquo;s own favicon in the root, so just by adding one to the root of your theme won&amp;rsquo;t make it work - you will still get thge Ghost one. You have to place it somewhere other than the root and add links to the icons in your header.&lt;/p>
&lt;p>&lt;strong>Note&lt;/strong>
I made a few changes to this after a comment from &lt;a href="http://realfavicongenerator.net/">RealFaviconGenerator&lt;/a>. It looks like they have an awesome site to generate all the favicons you could need automatically. I haven&amp;rsquo;t tried it out myself yet but will do next time I need one.&lt;/p></description></item><item><title>Social networking and how the world sees me.</title><link>https://jimbobbennett.dev/blogs/socialnetworkingandhowtheworldseesme/</link><pubDate>Tue, 29 Jul 2014 03:48:22 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/socialnetworkingandhowtheworldseesme/</guid><description>&lt;p>When starting to develop your online brand, there is many things to consider, including how the world sees you. The first thing anyone looking at your public profiles will see is your avatar - the image you use to define who you are. As there are so many different social networks or areas with profiles, it&amp;rsquo;s easy to have fragmentation in your public avatar. A quick scan of my profiles has lead to quite a few:&lt;/p>
&lt;ul>
&lt;li>Ghost&lt;/li>
&lt;li>Twitter&lt;/li>
&lt;li>Facebook&lt;/li>
&lt;li>Github&lt;/li>
&lt;li>Gravatar&lt;/li>
&lt;li>LinkedIn&lt;/li>
&lt;li>Google+ (does anyone still use this? I just post to it to help google index my posts)&lt;/li>
&lt;/ul>
&lt;p>Across these I had 4 different avatars - all of which are probably not good for a public brand. Two have me with my daughter - I love her to bits but I&amp;rsquo;m representing me publicly, and don&amp;rsquo;t want my family to be involved in my brand and want to protect their privacy. The other 2 have beer in my hand, including a nice one of me a bit drunk at the Hong Kong Rugby Sevens. There is nothing wrong with beer, and nothing wrong with getting drunk (responsibly of course) but again with a public profile it&amp;rsquo;s good to avoid anything that could predjudice people against me - it&amp;rsquo;s easy to look at one photo and make assumptions about the people in it.&lt;/p>
&lt;p>My new avatar was cropped from a photo taken of me recently - I did a scan of all my photos to find something suitable. Not overly boring and smart - this does represent me as a person, not me in a suit being formally interviewed - but shows a bit of personality.&lt;/p>
&lt;p>&lt;img src="JimRound.jpg" alt="">&lt;/p></description></item><item><title>Taking a break</title><link>https://jimbobbennett.dev/blogs/taking-a-break/</link><pubDate>Wed, 09 Jul 2014 10:26:28 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/taking-a-break/</guid><description>&lt;p>I&amp;rsquo;m taking some time out - just a couple of weeks. Spending time with my family in the UK before moving to Thailand to start my adventure in the world of startups and journeyman programming.&lt;/p>
&lt;p>Will be back and blogging again soon.&lt;/p></description></item><item><title>Setting up a website on Heroku</title><link>https://jimbobbennett.dev/blogs/setting-up-a-website-on-heroku/</link><pubDate>Thu, 26 Jun 2014 00:32:41 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/setting-up-a-website-on-heroku/</guid><description>&lt;p>Now that I&amp;rsquo;m (almost) out of the rat race and working on my own apps, I though it was time to create a website to host my work. I haven&amp;rsquo;t got a company set up yet (that&amp;rsquo;s coming soon) but I&amp;rsquo;ve been watching a rather excellent &lt;a href="http://pluralsight.com/training/Courses/TableOfContents/building-angularjs-nodejs-apps-mean">Pluralsight training course on the MEAN stack&lt;/a>. In this course they use &lt;a href="http://www.heroku.com/home">Heroku&lt;/a> to host a Node.js application, so I though I&amp;rsquo;d try it myself.&lt;/p>
&lt;p>The advantages of Heroku that I can see are:&lt;/p>
&lt;ul>
&lt;li>Price - for 1 dyno, enough for a small load there&amp;rsquo;s nothing to pay, no need to even give a credit card. All free. Great for development or a small site. Scaling up is easy as well, just hand over the credit card and increase the number of dynos.&lt;/li>
&lt;li>Ease of setup - once you have an account, you just install the developer toolbelt, link your git repo to a remote Heroku repo and push the code. You can push to an app you create on the Heroku site, or it&amp;rsquo;ll even create the app for you.&lt;/li>
&lt;li>Simple configuration - getting things like a domain name set up is trivial.&lt;/li>
&lt;li>Loads of add ons - admitedly you have to hand over a credit card for verification first, but there are loads of easily available add ons like MongoDB, analytics, email, the list goes on. All seem to have free tiers as well, again ideal for development.&lt;/li>
&lt;/ul>
&lt;p>I started with a basic node express app, nothing too fancy, just a &amp;lsquo;coming soon&amp;rsquo; page using bootstrap. Once this was running locally, I uploaded it to my private GitHub repo. This was my starting point.
The total time to get it running in Heroku was about an hour, and this is coming from never having done it before - and half of that was trying to figure out why it wasn&amp;rsquo;t picking up the port from the environment variables (turned out I pushed the wrong branch). I won&amp;rsquo;t go into the details of how to do it, the &lt;a href="http://devcenter.heroku.com/articles/getting-started-with-nodejs">Heroku documentation&lt;/a> is excellent and the Pluralsight course mentioned earlier goes through the details as well. DRY should apply to blogs as well you know!&lt;/p>
&lt;p>Overall I was very impressed at how simple and easy it was. I think I&amp;rsquo;ll continue using Heroku for my website, especially when I add more features such as MongoDB. Seeing as it runs Node.js as well, I should be able to create the servers for the apps I&amp;rsquo;m planning to write on it with ease.&lt;/p>
&lt;p>Check out my website so far - not much but more is coming soon.&lt;/p>
&lt;p>&lt;a href="http://www.moomoo.io">MooMoo.io&lt;/a>&lt;/p>
&lt;p>&lt;img src="Ducky.svg" alt="">&lt;/p></description></item><item><title>Waiting again</title><link>https://jimbobbennett.dev/blogs/waiting-again/</link><pubDate>Wed, 25 Jun 2014 21:55:40 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/waiting-again/</guid><description>&lt;p>As I&amp;rsquo;ve mentioned before, I&amp;rsquo;m taking 6-9 months out of the rat race so I can do my own thing, including learning some new skills to take into the world of work. The skills in question are HTML/Javascript and Xamarin.&lt;/p>
&lt;p>Javascript is becoming ubiquitous, it&amp;rsquo;s the &lt;a href="http://www.hanselman.com/blog/JavaScriptIsWebAssemblyLanguageAndThatsOK.aspx">assembly language of the web&lt;/a> and for any startup being able to create a web site or web application is important. I&amp;rsquo;m going to learn it alongside Node, HTML and all the tooling in that space. It&amp;rsquo;s hard actually as there is so many frameworks, so many tools to learn so I&amp;rsquo;m going to focus on the MEAN stack. There is an excellent &lt;a href="http://www.pluralsight.com/training/Courses/TableOfContents/building-angularjs-nodejs-apps-mean">Pluralsight course&lt;/a> on this - worth a watch if you have a subscription (what do you mean you don&amp;rsquo;t - get one already). I&amp;rsquo;ll be using this to create my web site - more information coping soon.&lt;/p>
&lt;p>&lt;a href="http://xamarin.com">Xamarin&lt;/a> is breaking ground in cross platform application development. Not content with allowing C# apps to be run on iOS and Android they went on to introduce &lt;a href="http://xamarin.com/forms">Xamarin.Forms&lt;/a> to allow cross platform UI development using XAML. I&amp;rsquo;ve been developing in C# for the past 7 years so it&amp;rsquo;s the natural next step for developing in the mobile space. Having done desktop applications for years in WPF it make sense to expand my skills to include mobile.&lt;/p>
&lt;p>Why is this post entitled waiting? I&amp;rsquo;m waiting for my Xamarin license. They&amp;rsquo;ve really helpfully put together a subscription that matches both my needs and my meagre unemployed person budget and I&amp;rsquo;m just waiting for the invoice. It&amp;rsquo;s been a few days now and although I appreciate they are busy and these things take time, I&amp;rsquo;m itching to get started! My own impatience is getting the better of me. I know I can develop using the 30 day trial in Xamarin studio but I&amp;rsquo;m licensing a version that includes Xamarin for Visual Studio and I really can&amp;rsquo;t wait to produce an app in VS for my iPhone.&lt;/p></description></item><item><title>Synergy</title><link>https://jimbobbennett.dev/blogs/synergy/</link><pubDate>Mon, 16 Jun 2014 11:52:09 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/synergy/</guid><description>&lt;p>As you&amp;rsquo;ve probably seen from my other posts, I&amp;rsquo;m developing iOS apps using Visual Studio on Windows as my development environment, and a MacBook Pro for running the actual builds. This is a pain when I want to test. As good as Ripple is, it&amp;rsquo;s not as good as the actual iOS simulator. It&amp;rsquo;s a pain jumping from one computer to the other.&lt;/p>
&lt;p>Thats where &lt;a href="http://synergy-project.org/">Synergy&lt;/a> comes in. It&amp;rsquo;s a small app you install on all your computers and it allows you to use your mouse/keyboard on them all. So for my setup I have my surface as my left most screen, a 24&amp;quot; cinema display as my center screen connected to the Surface, and my MacBook Pro as my right hand screen. I move my mouse across to the right and it appears on the Mac, so I can use all the Mac apps without changin keyboard or mouse. Very useful. It&amp;rsquo;s free as well, but they do ask for donations, so you can try it out and once you realise just how awesome it is you can donate as much as you think it&amp;rsquo;s worth (they suggest $10).&lt;/p></description></item><item><title>Popping my open source cherry</title><link>https://jimbobbennett.dev/blogs/popping-my-open-source-cherry/</link><pubDate>Tue, 10 Jun 2014 22:06:57 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/popping-my-open-source-cherry/</guid><description>&lt;p>Today the pull request for my first ever contribution to someone else&amp;rsquo;s open source project was accepted and merged.&lt;/p>
&lt;p>It was a small bug fix to &lt;a href="http://www.idangero.us/framework7/">Framework7&lt;/a> - a really cool HTML5 framework for building iOS 7 style apps. I&amp;rsquo;m using it for my first cordova project and what it outputs looks just like a native iOS 7 app. Highly recommended.&lt;/p>
&lt;p>A big thank you to &lt;a href="https://github.com/nolimits4web">Vladimir Kharlampidi&lt;/a> for creating this project.&lt;/p>
&lt;p>Even though my fix was small, I did feel a bit nervous once I commited it. Would it be accepted or laughed at. It was quite a rush when I got the email saying it had been merged.&lt;/p>
&lt;p>One done, many more to come.&lt;/p></description></item><item><title>Lets eat!</title><link>https://jimbobbennett.dev/blogs/lets-eat/</link><pubDate>Mon, 02 Jun 2014 23:11:41 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/lets-eat/</guid><description>&lt;p>So once again I&amp;rsquo;m &lt;a href="https://jimbobbennett.dev/blogs/waiting-12-05-2014/">waiting&lt;/a>, this time whilst I download the XCode 6 preview. I&amp;rsquo;m working on a simple node application for photo management - uploading, storing, showing thumbnail previews and showing the pictures. Nothing complicated but more of my self learning of node and javascript. Seeing as Apple have just announced &lt;a href="https://developer.apple.com/swift/">Swift&lt;/a> I thought I might try to develop a simple iOS app in Swift that talks to my node app.
Once XCode is dowloaded over my pathetic broadband (5 hours 28 minutes remaining) I&amp;rsquo;ll give it a go and blog about it.&lt;/p>
&lt;p>In the meantime, I decided to eat some dessert. I make a mean version of banoffie pie, using raspberries which add a tartness that cuts through the sweetness of the pie.&lt;/p>
&lt;p>&lt;img src="Cake-1.jpg" alt="">&lt;/p>
&lt;p>The recipe is simple. What, a recipe on a technology blog? Well why not - developers have to eat after a hard day pumping mouse and keyboard.&lt;/p>
&lt;p>Base - melt a couple of ounces of butter in a pan, and add a small pack of finely crushed digestive biscuits (bung them in a ziplock bag and roll over them with a rolling pin). Press into a greased pie dish to make a bottom and sides and slap in the fridge.&lt;/p>
&lt;p>Toffee - put an unopened can of sweetened condensed milk into a large pan of boiling water and boil for 3 hours. Make sure the can is always completely covered with water. After 3 hours, open the can and spread the contents into the pie dish. Be warned, the contents of the can is stupidly hot, will spurt out when you pierce the can with a can opener and sticks like shit to a blanket. Best to open it wearing oven gloves. Bung the pie dish back in the fridge.&lt;/p>
&lt;p>Once the toffee is cooled, cover in raspberries. Then whip some cream with some hot chocolate powder (not cocoa, it&amp;rsquo;s too bitter, needs to be a decent hot chocolate powder) and spread on top.&lt;/p>
&lt;p>Then eat. Nom, nom, nom.&lt;/p>
&lt;p>&lt;img src="Cake-2.jpg" alt="">&lt;/p></description></item><item><title>Using Visual Studio to develop Cordova apps part 2 - Creating an app</title><link>https://jimbobbennett.dev/blogs/using-visual-studio-to-develop-cordova-apps-part-2-angular/</link><pubDate>Tue, 27 May 2014 00:10:02 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/using-visual-studio-to-develop-cordova-apps-part-2-angular/</guid><description>&lt;p>Building on &lt;a href="http://jimbobbennett.ghost.io/using-visual-studio-to-develop-cordova-apps/">the previous post in this series&lt;/a>, I thought it would be fun to try to learn &lt;a href="https://angularjs.org/">Angular.js&lt;/a> and include this in my Cordova app. I could also do with so nice looking widgets, so I decided to have a play with &lt;a href="http://topcoat.io/">TopCoat&lt;/a>.&lt;/p>
&lt;p>First thing I need is an app to build. One of my current &amp;lsquo;First World Problems&amp;rsquo; is having to convert from US units (mg/dL) to international blood sugar units (mmol/L). I&amp;rsquo;m a diabetic and I&amp;rsquo;ve been living most of my life in the UK and in Hong Kong - two countries that use international units for blood sugar measurement. I&amp;rsquo;m now living in Bermuda, and they only sell US spec blood sugar meters, and provide testing strips that only work with these small set of meters. The meters are factory locked to US units for some reason (unlike international meters that can be changed). So for now, I&amp;rsquo;m stuck with testing in US units.&lt;/p>
&lt;p>The conversion is 18 to 1 - so a US measurement of 90 is the same as an international measurement of 5. Simple enough, but I&amp;rsquo;ve got better things to do than learn my 18 times table, like create an app to do the conversion for me.&lt;/p>
&lt;p>So, lets create an app.&lt;/p>
&lt;h2 id="building-the-app">Building the app&lt;/h2>
&lt;p>I&amp;rsquo;m starting with the simple HelloWorld example from the previous post, and changing it to suit my needs.
The UI is really simple - a top bar and two input boxes.&lt;/p>
&lt;p>&lt;img src="35InchScreenshot1SMall.png" alt="Basic screen layout">&lt;/p>
&lt;p>The top bar is the TopCoat navigation bar&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-HTML" data-lang="HTML">&lt;span style="display:flex;">&lt;span>&amp;lt;&lt;span style="color:#f92672">div&lt;/span> &lt;span style="color:#a6e22e">class&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;topcoat-navigation-bar&amp;#34;&lt;/span>&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;lt;&lt;span style="color:#f92672">div&lt;/span> &lt;span style="color:#a6e22e">class&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;topcoat-navigation-bar__item center full&amp;#34;&lt;/span>&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;lt;&lt;span style="color:#f92672">h1&lt;/span> &lt;span style="color:#a6e22e">class&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;topcoat-navigation-bar__title&amp;#34;&lt;/span>&amp;gt;Blood Sugar Converter&amp;lt;/&lt;span style="color:#f92672">h1&lt;/span>&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;lt;/&lt;span style="color:#f92672">div&lt;/span>&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&amp;lt;/&lt;span style="color:#f92672">div&lt;/span>&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This gives a nice header bar. I&amp;rsquo;m using the TopCoat mobile dark skin, I really like the way it looks.&lt;/p>
&lt;p>For the input boxes I wanted to select all when you press them - that way you can overtype instead of having to delete the existing contents. A quick search of Stack Overflow gives a few suggestions to select everything, but these lead to a problem. When the text is selected the iPhone pops up a menu with standard options for selected text, Cut, Copy etc. This is far from ideal as it looks really bad.
In the end, I just set the value to undefined on the click event handler. This clears the box so there is nothing to select allowing you to type the number without having to delete everything.
The fun part with the input boxes was the conversion. Rather than having to click a button to convert, I wanted it to happen on the fly. This is where Angular comes in. Angular allows you to bind the values from input boxes to variables - you update the input, the variable automatically updates, you update a variable, the field showing it automatically updates. It also provides events to detect value changes.&lt;/p>
&lt;p>So first off, a controller.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-Javascript" data-lang="Javascript">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">// Create the angular module
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">bloodSugarConversionApp&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">angular&lt;/span>.&lt;span style="color:#a6e22e">module&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;BloodSugarConversionApp&amp;#39;&lt;/span>, []);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">// Create the controller
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">bloodSugarConversionApp&lt;/span>.&lt;span style="color:#a6e22e">controller&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;BloodSugarConversionCtrl&amp;#39;&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span> (&lt;span style="color:#a6e22e">$scope&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// defines the initial values for our variables
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">$scope&lt;/span>.&lt;span style="color:#a6e22e">usMeasurement&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">$scope&lt;/span>.&lt;span style="color:#a6e22e">internationalMeasurement&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// this function is wired up to a change handler for the US input field
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#75715e">// when this changes, it updates the international measurement
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">$scope&lt;/span>.&lt;span style="color:#a6e22e">changeUSMeasurement&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">function&lt;/span>()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// setting the international measurement updates the value in the input
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">$scope&lt;/span>.&lt;span style="color:#a6e22e">internationalMeasurement&lt;/span> &lt;span style="color:#f92672">=&lt;/span> Math.&lt;span style="color:#a6e22e">round&lt;/span>((&lt;span style="color:#a6e22e">$scope&lt;/span>.&lt;span style="color:#a6e22e">usMeasurement&lt;/span> &lt;span style="color:#f92672">/&lt;/span> &lt;span style="color:#ae81ff">18&lt;/span>) &lt;span style="color:#f92672">*&lt;/span> &lt;span style="color:#ae81ff">10&lt;/span>) &lt;span style="color:#f92672">/&lt;/span> &lt;span style="color:#ae81ff">10&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> };
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// this function is wired up to a change handler for the international input field
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#75715e">// when this changes, it updates the US measurement
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">$scope&lt;/span>.&lt;span style="color:#a6e22e">changeInternationalMeasurement&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">function&lt;/span>()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// setting the US measurement updates the value in the input
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">$scope&lt;/span>.&lt;span style="color:#a6e22e">usMeasurement&lt;/span> &lt;span style="color:#f92672">=&lt;/span> Math.&lt;span style="color:#a6e22e">round&lt;/span>((&lt;span style="color:#a6e22e">$scope&lt;/span>.&lt;span style="color:#a6e22e">internationalMeasurement&lt;/span> &lt;span style="color:#f92672">*&lt;/span> &lt;span style="color:#ae81ff">18&lt;/span>) &lt;span style="color:#f92672">*&lt;/span> &lt;span style="color:#ae81ff">10&lt;/span>) &lt;span style="color:#f92672">/&lt;/span> &lt;span style="color:#ae81ff">10&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> };
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>});
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>So, what&amp;rsquo;s going on here. First we define a callback that creates the &lt;em>BloodSugarConversionCtrl&lt;/em> controller. This function sets up the &lt;em>$scope&lt;/em> to have a couple of variables for the two units of measurement initialised to 0, and declares a couple of functions on it that will convert when a value changes.
This controller is then wired up in our HTML.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-HTML" data-lang="HTML">&lt;span style="display:flex;">&lt;span>&amp;lt;&lt;span style="color:#f92672">div&lt;/span> &lt;span style="color:#a6e22e">ng-controller&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;BloodSugarConversionCtrl&amp;#34;&lt;/span>&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;lt;&lt;span style="color:#f92672">p&lt;/span> &lt;span style="color:#a6e22e">class&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;label-text centered&amp;#34;&lt;/span>&amp;gt;mg/dL&amp;lt;/&lt;span style="color:#f92672">p&lt;/span>&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;lt;&lt;span style="color:#f92672">input&lt;/span> &lt;span style="color:#a6e22e">ng-model&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;usMeasurement&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">ng-change&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;changeUSMeasurement()&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">onclick&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;this.value = undefined&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">type&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;number&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">step&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;0.1&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">class&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;topcoat-text-input centered&amp;#34;&lt;/span> /&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;lt;&lt;span style="color:#f92672">p&lt;/span> &lt;span style="color:#a6e22e">class&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;label-text centered&amp;#34;&lt;/span>&amp;gt;mmol/L&amp;lt;/&lt;span style="color:#f92672">p&lt;/span>&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;lt;&lt;span style="color:#f92672">input&lt;/span> &lt;span style="color:#a6e22e">ng-model&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;internationalMeasurement&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">ng-change&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;changeInternationalMeasurement()&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">onclick&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;this.value = undefined&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">type&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;number&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">step&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;0.1&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">class&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;topcoat-text-input centered&amp;#34;&lt;/span> /&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&amp;lt;/&lt;span style="color:#f92672">div&lt;/span>&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>At the outer &lt;code>&amp;lt;div&amp;gt;&lt;/code> we set the controller using the &lt;code>ng-controller&lt;/code> attribute, and this is accessible to the inner elements. We then set the model using the &lt;code>ng-model&lt;/code> attribute against the inputs - this binds the given variable to the value for the input. Finally we wire up the events - the &lt;code>onclick&lt;/code> to clear the value when selected (as described above), and the &lt;code>ng-change&lt;/code> to handle the value change and update the corresponding value.&lt;/p>
&lt;p>And that is basically it. Angular takes care of the hard parts.&lt;/p>
&lt;p>When I ran it, it did look a bit bad. The app could be scrolled - it&amp;rsquo;s essentially a hosted web page so the scrolling is a default behavior. It also scrolled up when you selected the input boxes so that the keyboard could fit on the screen, and this made the status bar visible through the HTML elements. Scrolling was easy to turn off - just add a line to the &lt;em>config.xml&lt;/em>&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-XML" data-lang="XML">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;lt;preference&lt;/span> &lt;span style="color:#a6e22e">name=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;DisallowOverscroll&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">value=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;true&amp;#34;&lt;/span> &lt;span style="color:#f92672">/&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Removing the status bar was harder. There are many solutions on the web for earlier versions of Cordova or earlier versions of iOS, but for Cordova 3.3.1 and iOS 7 the only way I could get it to work was using the StatusBar plug-in. Install it by adding an entry to the vs features in the &lt;em>config.xml&lt;/em>&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-XML" data-lang="XML">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;lt;vs:feature&amp;gt;&lt;/span>org.apache.cordova.statusbar&lt;span style="color:#f92672">&amp;lt;/vs:feature&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Then hide it in the &lt;em>onDeviceReady&lt;/em> event&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-Javascript" data-lang="Javascript">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">StatusBar&lt;/span>.&lt;span style="color:#a6e22e">hide&lt;/span>();
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Done.&lt;/p>
&lt;h2 id="deploying-to-the-app-store">Deploying to the App store&lt;/h2>
&lt;p>Once done, I thought it only fair to share the app with the world for free on the app store.&lt;/p>
&lt;p>Doing this was fairly simple. The Cordova build engine that runs on my Mac spits out an XCode project for the app for every build. It&amp;rsquo;s a simple job to load this into XCode, set the relevant provisioning profiles and upload it to the store.
The only gotcha is the version number. The default one in the &lt;em>config.xml&lt;/em> is 1.0.0.0. iTunes app submissions only allow a 3 part version, so you&amp;rsquo;ll have to update this to 1.0.0 or similar before it will pass validation.&lt;/p>
&lt;p>My app is currently awaiting review - I&amp;rsquo;ll update this post with a link once it&amp;rsquo;s passed and available.&lt;/p>
&lt;p>The source for this app is available on &lt;a href="https://github.com/jimbobbennett/BloodSugarConverter">GitHub&lt;/a>. I&amp;rsquo;m new to HTML and JavaScript so please be kind. All comments and criticisms greatfully received.&lt;/p></description></item><item><title>What to do when you're stuck inside.</title><link>https://jimbobbennett.dev/blogs/updating-my-blog/</link><pubDate>Mon, 26 May 2014 13:04:22 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/updating-my-blog/</guid><description>&lt;p>It&amp;rsquo;s a glorious day here, a perfect day to take my wife and daughter to the beach.
Unfortunately we currently live in Bermuda, an island paradise with stunning beaches and clean water. Why is this unfortunate? Because the country is so badly run. Today is Bermuda day, and they are celebrating by closing one of the main roads for a half marathon. This road is the one that my house is on. So for the rest of the day, I can&amp;rsquo;t get the car out and drive to the beach. I can&amp;rsquo;t walk either as I&amp;rsquo;ll have to walk on roads with no pavement that are open that are narrow and the drivers here are idiots, so it&amp;rsquo;s not safe with a child.
They didn&amp;rsquo;t tell us the road would be closed, no sign on the exit from our estate - my wife popped out with our daughter and got shouted at by people on the side of the road and the police and made to leave her car in the local supermarket and walk back. Not her fault - there was nothing to indicate that the road would be closed. But thats the way here - hence why we are leaving soon.&lt;/p>
&lt;p>So I thought today would be a good day to tidy up a few things in the running.&lt;/p>
&lt;h2 id="tidying-up">Tidying Up&lt;/h2>
&lt;p>Firstly I finally tidied up my desk so I could work using a proper keyboard and monitor. Most of my recent dabbling was using my Surface on a coffee table in front of the sofa whilst my wife was glued to &lt;em>&amp;lsquo;Americas Next Greys New Girl Anatomy&amp;rsquo;&lt;/em> or whatever it is she watches. My setup isn&amp;rsquo;t the latest and greatest, but it does what I need.
My Windows development box is a &lt;a href="http://www.microsoft.com/surface/en-us/products/surface-pro-2">Surface Pro 2&lt;/a>, the 256GB model with 8GB RAM. It&amp;rsquo;s a great Windows 8 tablet (shame Windows 8 isn&amp;rsquo;t a great tablet OS - not having a &amp;lsquo;Modern UI&amp;rsquo; browers unless IE is your default being the worst part), and a pretty powerful dev box. I&amp;rsquo;ve got the type keyboard which is fine to type with but the trackpad is rubbish, not a patch on the Apple track pads.
For input on my desk I prefer a mechanical keyboard and decent mouse. Logitech do some pretty decent kit so I&amp;rsquo;ve got myself a &lt;a href="http://gaming.logitech.com/en-us/product/g710plus-mechanical-gaming-keyboard">G710+&lt;/a> keyboard and &lt;a href="http://www.logitech.com/en-us/product/performance-mouse-mx">Performance MX&lt;/a> mouse - a darkfield one as my desk has a glass top. The surface has a nice screen which works beautifully as a small second, with an old 24&amp;quot; Apple Cinema display as my main monitor. Add a 13&amp;quot; MacBook Pro for OSX/iOS development and I&amp;rsquo;m all set.
My desk as mentioned before is a glass topped one. Nothing great, just a cheap Ikea number. I don&amp;rsquo;t have a great chair (though I&amp;rsquo;d love an Aeron) but instead I use a large excercise ball. Work those abs whilst working the fingers.
Add a Kinect and a load of other junk and away I go.&lt;/p>
&lt;p>&lt;img src="Desktop.png" alt="My desk">&lt;/p>
&lt;h2 id="blogging">Blogging&lt;/h2>
&lt;p>Secondly - this blog. I wanted a better theme so I&amp;rsquo;ve installed &lt;a href="http://ghostion.ghostdemo.axiantheme.com/">Ghostion&lt;/a>, a really nice looking theme based on &lt;a href="http://foundation.zurb.com/">Foundation 5&lt;/a>. I had to make a few tweaks to make it look better on my iPhone which was a good excuse to get my hands dirty with Foundation. I&amp;rsquo;m still very new to HTML, Javascript and all the eleventy billion frameworks out there so it took a while, but I&amp;rsquo;m pleased with the result.&lt;/p>
&lt;p>I really like the way with Foundation that you can hide elements based on the screen size with a simple css class.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-HTML" data-lang="HTML">&lt;span style="display:flex;">&lt;span>&amp;lt;&lt;span style="color:#f92672">div&lt;/span> &lt;span style="color:#a6e22e">class&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;row hide-for-small-only&amp;#34;&lt;/span>&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">&amp;lt;!-- Large screen content --&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&amp;lt;/&lt;span style="color:#f92672">div&lt;/span>&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-HTML" data-lang="HTML">&lt;span style="display:flex;">&lt;span>&amp;lt;&lt;span style="color:#f92672">div&lt;/span> &lt;span style="color:#a6e22e">class&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;row show-for-small-only&amp;#34;&lt;/span>&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">&amp;lt;!-- Small screen content --&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&amp;lt;/&lt;span style="color:#f92672">div&lt;/span>&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Ghostion has some really cool features that work out of the box with minimal configuration. &lt;a href="http://disqus.com/">Disqus&lt;/a> for commenting or Google Analytics are all available by just adding the relevant id&amp;rsquo;s to one file.&lt;/p>
&lt;h2 id="coding">Coding&lt;/h2>
&lt;p>Finally, time to do some coding. The rest of today will be spent on a couple of apps. Years ago I did a game in the iOS app store, which I&amp;rsquo;m planning on resurrecting and re-releasing and putting the code on GitHub. I also want to finish playing with Cordova apps using Visual Studio, so I&amp;rsquo;ll try to get something from there on the app store. Blog posts on these coming soon!&lt;/p></description></item><item><title>Trust</title><link>https://jimbobbennett.dev/blogs/trust/</link><pubDate>Tue, 13 May 2014 23:52:13 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/trust/</guid><description>&lt;p>I wrote this post on &lt;a href="http://medium.com">Medium&lt;/a> a while ago, so as part of my attempts to bring together all my work into as smaller number of places as possible, here it is.&lt;/p>
&lt;h2 id="shouldnt-our-default-position-be-to-trust-first">Shouldn’t our default position be to trust first?&lt;/h2>
&lt;p>I was having a conversation with a friend of mine recently about his current work situation. His team leader has a default state of not trusting in the knowledge and abilities of the team. Systems are locked down so only the team leader can access them, decisions are made by said leader and bypass the knowledge, skills and abilities of the team. This was raised up the chain by one of his co workers only to be told to spend time earning that trust (despite already being there for a while). This has made for an unhappy team with one already leaving and a few more making plans in that direction.”&lt;/p>
&lt;p>This is a very different model to how I like to run teams. I want to have a team working with me where I can trust in the skills of every member — instead of locking them out I open everything up to them. If they lack the right skills, instead of blocking them from doing a task I’d rather work with them to help them learn how to do it. Put them in a place where they can learn through self discovery, learn through failure with a guiding hand to help them succeed next time. I find this makes for a very cohesive team, everyone feels valued, they matter to the success of the team and they feel their skills growing. To quote Peopleware by Tom DeMarco and Timothy Lister “Once you have decided to go with a certain group, your best tactic is to trust them … People who feel untrusted have little inclination to bond together into a cooperative team”&lt;/p>
&lt;p>I feel very comfortable with my model. I always try my hardest to ensure that I interview thoroughly so that I know what my new hires can and can’t do. I also spend time with the team on a one to one basis to constantly get and give feedback on how they are doing as a team member and I am doing as their team lead. This constant cycle of information allows me to know when to sit back and leave them to it, or sit with them and help guide. And if I find someone on the team who cannot be trusted despite all efforts? Sorry — they’re out. Harsh, but fairer to the team as a whole. One bad apple should not ruin the success of the rest of the team.&lt;/p>
&lt;p>To me, trust in the workplace is earned in the interview and cemented by doing good work, not something that still has to be earned by someone who has already been through extensive interviews, worked for the company for a number of months and is delivering on target. This is the same as how we live our lives. We sit on a chair because we trust it won’t break on us (unless our initial assessment of the chair shows it’s already broken), we eat food and trust it won’t kill us (unless it already smells bad), we fall in love trusting that our partners will be faithful, only removing that trust if they show otherwise.&lt;/p>
&lt;p>Trust is good. My advice to my friend — go somewhere where you are trusted.&lt;/p></description></item><item><title>Using Visual Studio to develop Cordova apps</title><link>https://jimbobbennett.dev/blogs/using-visual-studio-to-develop-cordova-apps/</link><pubDate>Tue, 13 May 2014 23:35:37 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/using-visual-studio-to-develop-cordova-apps/</guid><description>&lt;p>So after &lt;a href="http://jimbobbennett.ghost.io/waiting-12-05-2014/">yesterdays&lt;/a> attempt to create a &amp;lsquo;Hello World&amp;rsquo; app using the new Cordova tools for Visual Studio, I thought tonight I&amp;rsquo;d try again.&lt;/p>
&lt;p>If you haven&amp;rsquo;t heard the news, Microsoft &lt;a href="http://blogs.msdn.com/b/somasegar/archive/2014/05/12/mobile-first-cloud-first-development-visual-studio-apache-cordova-tooling-and-cloud-optimized-net-futures.aspx">announced&lt;/a> a CTP of support for Cordova inside Visual Studio. Thats right, Microsoft is opening up to a world of other devices. The aim is to allow you to build HTML5 apps inside Visual Studio and deploy to Windows Phone, Android and iOS, all from one place (with a networked Mac for iOS building).
I guess this might put Adobe&amp;rsquo;s PhoneGap out of business, but hey, thats how it works when you build a business exposing open source software.&lt;/p>
&lt;p>I&amp;rsquo;m writing this as I go along trying to do a &amp;lsquo;Hello World&amp;rsquo; app, and so far not much success.&lt;/p>
&lt;p>I&amp;rsquo;m working through the &lt;a href="http://go.microsoft.com/fwlink/?LinkID=397716">documentation&lt;/a> and here are my experiences:&lt;/p>
&lt;p>First I did the basics - I launched Visual Studio and created a new solution using the new Multi Device Hybrid App template. I set up my MacBook Pro to host the remote build and simulation agent, set the build output to be the iOS simulator and hit build. First problem - it couldn&amp;rsquo;t find Java. It seems the installer didn&amp;rsquo;t successfully install the Java 7 JDK. One more delay whilst I download and install this.&lt;/p>
&lt;p>Once the JDK was installed - I tried building and running again. Next thing I know, up pops Chrome (with the obligatory set your default browser prompt - I use IE as my default simply so I can use a bowser on my surface in Metro mode, oh for Firefox for Metro) running the iOS simulator with my &amp;lsquo;Hello World&amp;rsquo; app running. WooHoo!&lt;/p>
&lt;p>&lt;img src="CordovaSimulator.jpg" alt="">&lt;/p>
&lt;p>Now to try the first interesting bit - can I run the app on an iOS simulator on my Mac? Lets set the output on Visual Studio and see what happens!
So far so good - things are happening on the Mac&amp;rsquo;s terminal.
And as if by magic:&lt;/p>
&lt;p>&lt;img src="CordovaSimulatorOnMac.jpg" alt="">&lt;/p>
&lt;p>I&amp;rsquo;m in shock. No third party paid for components like Xamarin, just an installer from Microsoft that installs open source code and I have an iOS simulator on my Mac running code from Visual Studio. This is groundbreaking stuff (to a techy of course - it didn&amp;rsquo;t cause my wife to even look up from whatever celebrity gossip site she&amp;rsquo;s browsing).&lt;/p>
&lt;p>Lets take it all the way - lets see if it can run on my iPhone itself.&lt;/p>
&lt;p>Seems you can&amp;rsquo;t have it all - Code signing error. I guess I need to provision my iPhone. BRB!&lt;/p>
&lt;p>Time to let a picture paint a thousand words:&lt;/p>
&lt;p>&lt;img src="CordovaOniPhone.jpg" alt="">&lt;/p>
&lt;p>Excuse the poor quality shot - it&amp;rsquo;s late and I couldn&amp;rsquo;t be bothered to turn the lights up. Thats the same app - the basic Visual Studio Multi Device Hybrid app template built on my Surface using my MacBookPro as a remote build agent, installed using iTunes on the Surface running on my iPhone.&lt;/p>
&lt;p>iPhone development has just got a lot easier.&lt;br>
Tomorrow I&amp;rsquo;ll try adding some code and developing a simple app.&lt;/p></description></item><item><title>Waiting</title><link>https://jimbobbennett.dev/blogs/waiting-12-05-2014/</link><pubDate>Mon, 12 May 2014 15:36:15 +0000</pubDate><author>jim@jimbobbennett.io (Jim Bennett)</author><guid>https://jimbobbennett.dev/blogs/waiting-12-05-2014/</guid><description>&lt;p>Every journey begins with a first step. Unfortunately that first step is not always made as soon as the journey is ready to begin.&lt;/p>
&lt;p>Over the past few days I&amp;rsquo;ve been starting the preparation for a new life. My family and I are escaping the rat race for a while. I&amp;rsquo;m working out the notice period on my nine-to-five, my wife is packing up the house and we&amp;rsquo;re taking a break from the normal life to allow me to focus on growing my tech career - a chance to contribute to open source or blog without the IP clause in my job contract limiting what I can post, a chance to try out a few app ideas and work towards a startup or two (and probably fail along the way), and most of all a chance to not work the norms of a five day week and allow me to work when I am at my best, and fit time in with my family when it is best for them.&lt;/p>
&lt;h2 id="getting-started">Getting Started&lt;/h2>
&lt;p>As well as mental preparation, at some point you have to break ground. Today I purchased my own domain name, signed up to &lt;a href="http://ghost.org">Ghost&lt;/a> to start this blog and decidec to write my first technical post.
Today Microsoft &lt;a href="http://msdn.microsoft.com/en-us/vstudio/dn722381">announced&lt;/a> support for &lt;a href="http://cordova.apache.org/">Cordova&lt;/a> in Visual Studio. Seeing as I have a few startup ideas that will involve connecting the desktop to mobile, it piqued my interest.&lt;/p>
&lt;p>So this evening (after the latest Game of Thrones of course) I decided to do a basic Hello World developed on my Surface and running on an iOS simulator.&lt;/p>
&lt;p>This would be my first step on the journey.&lt;/p>
&lt;p>But, like all first steps there is the preparation. You can&amp;rsquo;t take a walk without putting on your shoes. And tonight my laces are taking a long time to tie up. All down to Internet speed.
At the moment I am waiting for the tooling to install. It has to do a large download over my slow internet connection, then install everything. All this before I can begin. At this rate I&amp;rsquo;ll be tucked up in bed with my enthusiasm drowned in bourbon before I&amp;rsquo;m even asked for the obligatory re-boot.&lt;/p>
&lt;p>Currently it&amp;rsquo;s the Android SDK that is taking the time - which is doubly annoying as I only want to develop for iOS.&lt;/p>
&lt;p>Ah well, at least I have time to set up my domain to point to my Ghost hosting and write this post.&lt;/p></description></item></channel></rss>